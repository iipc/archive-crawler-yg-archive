{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":163406187,"authorName":"Kristinn Sigurdsson","from":"&quot;Kristinn Sigurdsson&quot; &lt;kris@...&gt;","profile":"kristsi25","replyTo":"LIST","senderId":"Ah5AqJCYNEvbvOhQjsE32cjOAvvrJFryrvoJhgCLtRc0byPYUCSBe4KPZknzPqKN_I1vyaXJbRY6NFCkWahzEbt5sVDizM7tQNeq1YUEYg","spamInfo":{"isSpam":false,"reason":"0"},"subject":"RE: [archive-crawler] continuous crawling proposal","postDate":"1107352088","msgId":1484,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDA2NzhEQjE5NjhFQUM3NDA5Q0MzRDBBQjdBMTFCODRBMDZFQzRCQHNrYXJmdXIuYm9rLmxvY2FsPg==","inReplyToHeader":"PFBpbmUuTE5YLjQuNTYuMDUwMjAyMDc1MjI5MC4yMTQyMUBwaWtlc3BlYWsubWV0YWNhcnRhLmNvbT4="},"prevInTopic":1483,"nextInTopic":1485,"prevInTime":1483,"nextInTime":1485,"topicId":1452,"numMessagesInTopic":24,"msgSnippet":"... And thank you for bringin this up, it was worth clarifying in general. ... A million domains and hundreds of millions of URIs?  Even with VERY good ","rawEmail":"Return-Path: &lt;kris@...&gt;\r\nX-Sender: kris@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 64525 invoked from network); 2 Feb 2005 13:48:37 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m25.grp.scd.yahoo.com with QMQP; 2 Feb 2005 13:48:37 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (207.241.224.172)\n  by mta1.grp.scd.yahoo.com with SMTP; 2 Feb 2005 13:48:37 -0000\r\nReceived: (qmail 3406 invoked by uid 100); 2 Feb 2005 13:32:23 -0000\r\nReceived: from forritun-4.bok.hi.is (HELO forritun4) (kris@...@130.208.152.83)\n  by mail-dev.archive.org with SMTP; 2 Feb 2005 13:32:23 -0000\r\nTo: &lt;archive-crawler@yahoogroups.com&gt;\r\nDate: Wed, 2 Feb 2005 13:48:08 -0000\r\nMessage-ID: &lt;0678DB1968EAC7409CC3D0AB7A11B84A06EC4B@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: multipart/alternative;\n\tboundary=&quot;----=_NextPart_000_0000_01C5092D.D5608CE0&quot;\r\nX-Priority: 3 (Normal)\r\nX-MSMail-Priority: Normal\r\nX-Mailer: Microsoft Outlook, Build 10.0.4510\r\nImportance: Normal\r\nIn-Reply-To: &lt;Pine.LNX.4.56.0502020752290.21421@...&gt;\r\nX-MimeOLE: Produced By Microsoft MimeOLE V6.00.2800.1441\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=0.8 required=6.5 tests=AWL,HTML_30_40,\n\tHTML_FONTCOLOR_BLUE,HTML_MESSAGE autolearn=no version=2.63\r\nX-eGroups-Remote-IP: 207.241.224.172\r\nFrom: &quot;Kristinn Sigurdsson&quot; &lt;kris@...&gt;\r\nSubject: RE: [archive-crawler] continuous crawling proposal\r\nX-Yahoo-Group-Post: member; u=163406187\r\nX-Yahoo-Profile: kristsi25\r\n\r\n\r\n------=_NextPart_000_0000_01C5092D.D5608CE0\r\nContent-Type: text/plain;\n\tcharset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n&gt;Kris,\n&gt;\n&gt;Thanks for the dialog.  The details are getting clearer to me. \n =\r\n\nAnd thank you for bringin this up, it was worth clarifying in general.\n \n&gt;=\r\n\n&gt;Particularly this:\n&gt;\n&gt;&gt; Again, nothing you couldn&#39;t modify the BDBFrontie=\r\nr to do, it just\n&gt;&gt; doesn&#39;t make sense to try and make it do everything. Fo=\r\nr a typical\n&gt;&gt; snapshot crawl, covering tens of thousands of domains and te=\r\nns if not\n&gt;&gt; hundred of millions of URIs, it just doesn&#39;t make any sense to=\r\n encumber\n&gt;&gt; it with managing time of next fetch etc. when FIFO does the jo=\r\nb\n&gt;&gt; perfectly well.\n&gt;\n&gt;How big a crawl do you think you could do iterative=\r\nly with ARFrontier?\n&gt;Could it iterate over 10^6 domains with 10^8 documents=\r\n every couple days\n&gt;with the same hardware that BDBFrontier would require? =\r\n\n \nA million domains and hundreds of millions of URIs?  Even with VERY good=\r\n\nhardware, the BdbFrontier would need more then a couple of days to cover\ns=\r\nomething that big.\n \nThe idea behind the ARFrontier was to accept an additi=\r\nonal overhead per host\n(by having seperate queues, not the &#39;melding&#39; that t=\r\nhe BdbFrontier uses),\nthis would be more memory usage and of course the cos=\r\nt (in processor time\nand IO wait) associated with an ordered list of URIs.\n=\r\n \nSo with large numbers of hosts (or domains) the ARFrontier uses more memo=\r\nry\nthen the BdbFrontier. It does not allow for hosts to be held inactive an=\r\nd\nother optimizations that the BdbFrontier uses. This is because they don&#39;t=\r\n\napply. All the host queues need to be active if they have URIs ready for\ni=\r\nssuing.\n \nIt is designed for hundreds of hosts and millions of documents, I=\r\n don&#39;t know\nof anyone interested in processing a larger collection with suc=\r\nh frequency.\nI belive that the number of URIs is not a limiting factor (alt=\r\nhough if your\nrevisit policy is scheduling URIs faster then the hardware ca=\r\nn process them,\nyou&#39;ll wind up continually overdue), but the number of host=\r\ns is likely to be\nlimiting, due to memory. But no testing has been done on =\r\nthe upper bound.\nThe tests I have scheduled are of the dozens of hosts, hun=\r\ndreds of thousands\nof URIs magnitude.\n \nEven our complete .is snapshots, on=\r\nly cover about 10,000 domains (maybe\n50,000 hosts including off-domain imag=\r\nes etc.) and about 30-40 million URIs.\nA test of the BdbFrontier against th=\r\ne entire .is TLD revealed that it is\ncapable of doing it, but with the mach=\r\ninery available (a decent single CPU\nmachine and 1.5GB memory) it would tak=\r\ne upwards of a month to complete.\n \n&gt;\n&gt;Eventually, I&#39;d like to get Heritrix=\r\n to the point that it can iterate over\n&gt;even larger private networks. \n \nJu=\r\nst how large are they going to be? I mean, the last .is snapshot\n(described=\r\n above) resulted in over 700 GB of compressed data. Doing that\nevery two da=\r\nys (never mind not storing the duplicates, just the bandwidth)\nseems excess=\r\nive. And your numbers above are an order of magnitude beyond\nthis.\n \n- Kris=\r\n\n\r\n------=_NextPart_000_0000_01C5092D.D5608CE0\r\nContent-Type: text/html;\n\tcharset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.0 Transitional//EN&quot;&gt;\n&lt;HTML&gt;&lt;HEAD&gt;=\r\n&lt;TITLE&gt;Message&lt;/TITLE&gt;\n&lt;META http-equiv=3DContent-Type content=3D&quot;text/html=\r\n; charset=3Diso-8859-1&quot;&gt;\n&lt;META content=3D&quot;MSHTML 6.00.2800.1476&quot; name=3DGEN=\r\nERATOR&gt;&lt;/HEAD&gt;\n&lt;BODY&gt;\n&lt;DIV&gt;&lt;FONT face=3DArial color=3D#0000ff size=3D2&gt;&gt;=\r\nKris,&lt;BR&gt;&gt;&lt;BR&gt;&gt;Thanks for \nthe dialog.&nbsp; The details are getting =\r\nclearer to me.&lt;SPAN \nclass=3D392293513-02022005&gt;&nbsp;&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/DIV&gt;\n=\r\n&lt;DIV&gt;&lt;FONT face=3DArial color=3D#0000ff size=3D2&gt;&lt;SPAN \nclass=3D392293513-0=\r\n2022005&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&nbsp;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;FONT face=3DArial size=3D2&gt;&lt;SPAN c=\r\nlass=3D392293513-02022005&gt;And thank you for \nbringin this up, it was worth =\r\nclarifying in general.&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;FONT&gt;&lt;FONT face=3DArial&gt;&lt;F=\r\nONT color=3D#0000ff&gt;&lt;FONT size=3D2&gt;&lt;SPAN \nclass=3D392293513-02022005&gt;&nbsp;=\r\n&lt;/SPAN&gt;&lt;BR&gt;&gt;&lt;BR&gt;&gt;Particularly \nthis:&lt;BR&gt;&gt;&lt;BR&gt;&gt;&gt; Again, nothi=\r\nng you couldn&#39;t modify the BDBFrontier to \ndo, it just&lt;BR&gt;&gt;&gt; doesn&#39;t =\r\nmake sense to try and make it do everything. For \na typical&lt;BR&gt;&gt;&gt; sna=\r\npshot crawl, covering tens of thousands of domains and \ntens if not&lt;BR&gt;&gt;=\r\n&gt; hundred of millions of URIs, it just doesn&#39;t make any \nsense to encumb=\r\ner&lt;BR&gt;&gt;&gt; it with managing time of next fetch etc. when FIFO \ndoes the=\r\n job&lt;BR&gt;&gt;&gt; perfectly well.&lt;BR&gt;&gt;&lt;BR&gt;&gt;How big a crawl do you \nthi=\r\nnk you could do iteratively with ARFrontier?&lt;BR&gt;&gt;Could it iterate over \n=\r\n10^6 domains with 10^8 documents every couple days&lt;BR&gt;&gt;with the same har=\r\ndware \nthat BDBFrontier would require?&lt;SPAN \nclass=3D392293513-02022005&gt;&nb=\r\nsp;&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;FONT&gt;&lt;FONT face=3DArial&gt;=\r\n&lt;FONT&gt;&lt;FONT size=3D2&gt;&lt;SPAN \nclass=3D392293513-02022005&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/FONT=\r\n&gt;&lt;/FONT&gt;&lt;/FONT&gt;&nbsp;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;FONT&gt;&lt;FONT face=3DArial&gt;&lt;FONT&gt;&lt;FONT size=\r\n=3D2&gt;&lt;SPAN class=3D392293513-02022005&gt;A \nmillion domains and hundreds of mi=\r\nllions of URIs?&nbsp; Even with VERY good \nhardware, the BdbFrontier would =\r\nneed more then a couple of days to cover \nsomething that big.&lt;/SPAN&gt;&lt;/FONT&gt;=\r\n&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;FONT&gt;&lt;FONT face=3DArial&gt;&lt;FONT&gt;&lt;FONT size=\r\n=3D2&gt;&lt;SPAN \nclass=3D392293513-02022005&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&=\r\nnbsp;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;FONT&gt;&lt;FONT face=3DArial&gt;&lt;FONT&gt;&lt;FONT size=3D2&gt;&lt;SPAN \nclass=\r\n=3D392293513-02022005&gt;The idea behind the ARFrontier was to accept an \naddi=\r\ntional overhead per host (by having seperate queues, not the &#39;melding&#39; that=\r\n \nthe BdbFrontier uses), this would be more memory usage&nbsp;and of course=\r\n the \ncost (in processor time and IO wait)&nbsp;associated with an ordered =\r\nlist of \nURIs.&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;FONT&gt;&lt;FONT fa=\r\nce=3DArial&gt;&lt;FONT&gt;&lt;FONT size=3D2&gt;&lt;SPAN \nclass=3D392293513-02022005&gt;&lt;/SPAN&gt;&lt;/=\r\nFONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&nbsp;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;FONT&gt;&lt;FONT face=3DArial&gt;&lt;FONT&gt;=\r\n&lt;FONT size=3D2&gt;&lt;SPAN class=3D392293513-02022005&gt;So \nwith large numbers of h=\r\nosts (or domains) the ARFrontier uses more memory then \nthe BdbFrontier. It=\r\n does not allow for hosts to be held inactive and other \noptimizations that=\r\n the BdbFrontier uses. This is because they don&#39;t apply. All \nthe host queu=\r\nes need to be active if they have URIs ready for \nissuing.&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/F=\r\nONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;FONT&gt;&lt;FONT face=3DArial&gt;&lt;FONT&gt;&lt;FONT size=3D2=\r\n&gt;&lt;SPAN \nclass=3D392293513-02022005&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&nbsp=\r\n;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;FONT&gt;&lt;FONT face=3DArial&gt;&lt;FONT color=3D#0000ff&gt;&lt;FONT size=3D2&gt;=\r\n&lt;FONT \ncolor=3D#000000&gt;&lt;SPAN class=3D392293513-02022005&gt;It is designed for =\r\nhundreds of \nhosts and millions of documents, I don&#39;t know of anyone intere=\r\nsted in processing \na larger collection with such frequency.&nbsp; I belive=\r\n that the number of URIs \nis not a limiting factor (although if your revisi=\r\nt policy is scheduling URIs \nfaster then the hardware can process them, you=\r\n&#39;ll wind up continually overdue), \nbut the number of hosts is likely to be =\r\nlimiting, due to memory. But no testing \nhas been done on the upper bound. =\r\nThe tests I have scheduled are of the dozens \nof hosts, hundreds of thousan=\r\nds of URIs \nmagnitude.&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/DIV&gt;\n&lt;DIV=\r\n&gt;&lt;FONT&gt;&lt;FONT face=3DArial&gt;&lt;FONT color=3D#0000ff&gt;&lt;FONT size=3D2&gt;&lt;FONT \ncolor=\r\n=3D#000000&gt;&lt;SPAN \nclass=3D392293513-02022005&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/=\r\nFONT&gt;&lt;/FONT&gt;&nbsp;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;FONT&gt;&lt;FONT face=3DArial&gt;&lt;FONT color=3D#0000f=\r\nf&gt;&lt;FONT size=3D2&gt;&lt;FONT \ncolor=3D#000000&gt;&lt;SPAN class=3D392293513-02022005&gt;Ev=\r\nen our complete .is snapshots, \nonly cover about 10,000 domains (maybe 50,0=\r\n00 hosts including off-domain images \netc.) and about 30-40 million URIs. A=\r\n test of the BdbFrontier against the entire \n.is TLD revealed that it is ca=\r\npable of doing it, but with the machinery \navailable (a decent single CPU m=\r\nachine and 1.5GB memory) it would take upwards \nof a month to complete.&lt;/SP=\r\nAN&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;FONT&gt;&lt;FONT face=3DArial&gt;=\r\n&lt;FONT color=3D#0000ff&gt;&lt;FONT size=3D2&gt;&lt;FONT \ncolor=3D#000000&gt;&lt;SPAN \nclass=3D=\r\n392293513-02022005&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;FONT&gt;&lt;FONT&gt;&lt;F=\r\nONT \ncolor=3D#0000ff&gt;&lt;FONT face=3DArial&gt;&lt;FONT size=3D2&gt;&lt;FONT color=3D#00000=\r\n0&gt;&lt;SPAN \nclass=3D392293513-02022005&gt;&nbsp;&lt;/SPAN&gt;&lt;BR&gt;&lt;/FONT&gt;&gt;&lt;BR&gt;&gt;Eve=\r\nntually, I&#39;d \nlike to get Heritrix to the point that it can iterate over&lt;BR=\r\n&gt;&gt;even larger \nprivate networks.&lt;SPAN \nclass=3D392293513-02022005&gt;&nbsp;=\r\n&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;FONT&gt;&lt;FONT&gt;&lt;FONT&gt;&lt;FO=\r\nNT face=3DArial&gt;&lt;FONT size=3D2&gt;&lt;SPAN \nclass=3D392293513-02022005&gt;&lt;/SPAN&gt;&lt;/F=\r\nONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;FONT \nface=3DArial size=3D2&gt;&lt;/FONT&gt;&nbsp;&lt;=\r\n/DIV&gt;\n&lt;DIV&gt;&lt;SPAN class=3D392293513-02022005&gt;&lt;FONT face=3DArial size=3D2&gt;Jus=\r\nt how large are \nthey going to be? I mean, the last .is snapshot (described=\r\n above) resulted in \nover 700 GB of compressed data. Doing that every two d=\r\nays (never mind not \nstoring the duplicates, just the bandwidth) seems exce=\r\nssive. And your numbers \nabove are an order of magnitude beyond this.&lt;/FONT=\r\n&gt;&lt;/SPAN&gt;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;SPAN class=3D392293513-02022005&gt;&lt;FONT face=3DArial \nsi=\r\nze=3D2&gt;&lt;/FONT&gt;&lt;/SPAN&gt;&nbsp;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;SPAN class=3D392293513-02022005&gt;&lt;FO=\r\nNT face=3DArial size=3D2&gt;- \nKris&lt;/FONT&gt;&lt;/SPAN&gt;&lt;/DIV&gt;&lt;/BODY&gt;&lt;/HTML&gt;\n\r\n------=_NextPart_000_0000_01C5092D.D5608CE0--\r\n\n"}}