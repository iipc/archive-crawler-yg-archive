{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":547657027,"authorName":"Légré Robert","from":"=?utf-8?B?TMOpZ3LDqSBSb2JlcnQ=?= &lt;attabi225@...&gt;","profile":"attabi225","replyTo":"LIST","senderId":"q-SExfx9IkVmv8dPuXMZKLbdc1J-yno7POO8UA6t4KdWgYwMzIpdkCG7XDntnHcCUYC8qLg27GPdC8nvvhH95pHjRDVSkfsw41Crg9B1OTQF3_3QA_KupWqNnUs","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Setting parameters to get  deeper section of a domain - Heritrix 1.14.4","postDate":"1356703882","msgId":7879,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDEzNTY3MDM4ODIuNDg4Mi5ZYWhvb01haWxOZW9Ad2ViMTcxODAzLm1haWwuaXIyLnlhaG9vLmNvbT4=","inReplyToHeader":"PDUwREQxMDJCLjIwMDA3MDFAYXJjaGl2ZS5vcmc+","referencesHeader":"PGtiZWZzcis1bHBzQGVHcm91cHMuY29tPiA8NTBERDEwMkIuMjAwMDcwMUBhcmNoaXZlLm9yZz4="},"prevInTopic":7877,"nextInTopic":0,"prevInTime":7878,"nextInTime":7880,"topicId":7876,"numMessagesInTopic":3,"msgSnippet":"Hi, I am using heritrix-2.0.2  to crawl some website and scan them by monkey-spider ( until here everything is ok  by your help )  but right I am using this","rawEmail":"Return-Path: &lt;attabi225@...&gt;\r\nX-Sender: attabi225@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 29839 invoked from network); 28 Dec 2012 14:11:24 -0000\r\nX-Received: from unknown (98.137.35.160)\n  by m5.grp.sp2.yahoo.com with QMQP; 28 Dec 2012 14:11:24 -0000\r\nX-Received: from unknown (HELO nm15.bullet.mail.ird.yahoo.com) (77.238.189.68)\n  by mta4.grp.sp2.yahoo.com with SMTP; 28 Dec 2012 14:11:23 -0000\r\nX-Received: from [77.238.189.53] by nm15.bullet.mail.ird.yahoo.com with NNFMP; 28 Dec 2012 14:11:22 -0000\r\nX-Received: from [212.82.108.134] by tm6.bullet.mail.ird.yahoo.com with NNFMP; 28 Dec 2012 14:11:22 -0000\r\nX-Received: from [127.0.0.1] by omp1039.mail.ird.yahoo.com with NNFMP; 28 Dec 2012 14:11:22 -0000\r\nX-Yahoo-Newman-Property: ymail-3\r\nX-Yahoo-Newman-Id: 529594.45332.bm@...\r\nX-Received: (qmail 8021 invoked by uid 60001); 28 Dec 2012 14:11:22 -0000\r\nX-YMail-OSG: 7nbymn4VM1kBF6gCcK6mthlvF89rDB9Y1T_JWbwIsbVzTlF\n d8kMTwMZc.R1to4J4Wjl2ZoaDg3RJFV06DF2k2QW.b4PDuy_b5n.weMkwdRu\n OswgyzG8OFEehLZ9Hp8hn0pSwqwRku2nRndNZGmX5Iyo_SjrKOFKR1.ywRIR\n mPlk9c.gOTQPdSZcJOc1vtMvNlVnErjwJxWLS_5zN8z.M502r.Jg27dmVqmA\n Xnlz14q6jmt69Ha6ifR7to1FHdAm6C23etLHRQ5cbAiqZPqDqr52ggKD_ixL\n ctNrWCGjW70NzRyU0FznmNCkl7gPK_qcTxguXPDVZx4L7zYXCg74zeQJIfch\n qkay.tKJsWIY6L4QcZtRt9zr8aEmuLhJgiU7y5a7zh7riRtNyP3dbG.FYc7g\n Rf7pXO4OPKsG8m2IqBrZFECQiCvKdFDtNZlRaRywf7TnQlFBClfIjyINpytl\n InsBzdXdpm6kTMd49S6rud5ZfxqbV7I_KSMGD5S8gYkr.LW0fZdeEI7DR3Wa\n qifaMQapl59bRspB9sVvBPO4TEpP0fCwUvfI6vwlxEJ3d6lHL5TUSc.B.CkG\n bLxfmM5Its.2k70bkYTT0FcJjGlCnymujihxSHxA6VdzW0vKvDSrkfGEUiUz\n ans.JJ9.pnu_6.Z84bsY8TTX3zR4BATFYLE7ClWD3Xi1mQ32aobTQPIEyeyp\n YkBIaFML3TLoozwrOZpFyWKWOERYNGy0DGtmyfvlur.YRMIvmKjXkWTwYLGL\n 8cAJqQy6T9Vh36PL92m096QaFWyN.H4cIwshwU7L1ku9jHo2naidIgeJPOf2\n IDjYPNmAkKZh0cqMV2BOlXIVBwr5aZZImx7M4UPdAj1j4AfwlxM7zppddkMj\n xiO4rNCADPA7PHjnHgiNRD6JVs3Y4IfVGnvoyB.NU06pChs54mIUgUKMk7Fr\n PFtgPI3V5EH6JjY8VkObzJlwhJWtTp9dqLVR1ZL5z0aSrL3_VuyCGkZNDDPw\n kj6uP_yCgrmpVxY_uQ6lOSdMQVcJwI8dsq.kezhSmkUVi5IeYGmxhkK8yFm9\n 2Yt3ABW0HeJidFmJ7YVyqBoeInQ_SfZG_.33kyWK9_FPeViVHegkGP2TNd3A\n f3jfBNakFuNLtvRpotQVVtxlAJ6epnBZ5CZj7ICQyvFg8r0czm7YT7FOG3m3\n xWjygrP9GNNauXud5jidHOK6eLKSY74Op_afe3c0SgQtRlZB1L8gRR4ZnD89\n FFeOOXCcYYuInEI6x2MEdiXLp0XRDw5TVXaHJEK0kIxEqERaM7DT.FBQ_4jN\n 9eHjbOgBDVxz2E6NC4buvV4gu1w8PlU4VbGY.ILfce01Mq.Xu48iNWi2BoZu\n ySPKj5B6PYNM06gssrC1iYJr23n47j3canAiqbo3wVzUCI.SWR1zMQllQAUA\n vWdbBdm6CaLxTVe8RrkiWWymb7UZsPivUrc9kCf7V8SQVbwNOLRVdxbHj32C\n NsP4nSJXXCXwRtwWj6C.V2c7rTmobDlT5M1KohDq6cget5vsWTMAw1_UdY97\n jdHksnC2JCTqYRv3V..Qp5.VkTq4yDYPWXY7kHbTafn1tLNqUi50IKOtbp29\n 3FK2zP0JReWkpKxQgLs4de6h0quKJWAFWb5rqJrkJiE0B1dTgjx.FtvHYfpF\n sHXDEEM8KYVSsxJg27wKmbdb.Q2ExJtpAdCdUXvcA.oGAYMT8YuJheo8MMCr\n Kr3yfiWZWEMKLCwGXRRUNMwT1fMRaxhJW9hSeEAZIb53D1.o7reZcunQP5G4\n f4xfbXtA_xZZOzZVi9ybxUl5bnLJo4Egz2wk9UVjrABEvLEbnxBwrDM_7SNV\n .QVE0wdbwCMGkCYf.sxuNm0a1Z3VWS66RVnibj4u5N6Bg.yT8Ztmm1bMW7jy\n H_SrhisTd3TyYkz9c9enchXIiqTR.2W.WQLLUK4dtMnyrdmp9cPu2thJIs3T\n w4LfEav_xQ_dOFhaRPhNmr6lavEReLU6SZF8UuMjgUnlIMBYxL_Zdc49Mthk\n aJb1u650mAaShGXgsk.rD98xiHAqk75DR_AcH\r\nX-Received: from [197.251.148.171] by web171803.mail.ir2.yahoo.com via HTTP; Fri, 28 Dec 2012 14:11:22 GMT\r\nX-Rocket-MIMEInfo: 001.001,SGksIEkgYW0gdXNpbmcgaGVyaXRyaXgtMi4wLjLCoCB0byBjcmF3bCBzb21lIHdlYnNpdGUgYW5kIHNjYW4gdGhlbSBieSBtb25rZXktc3BpZGVyICggdW50aWwgaGVyZSBldmVyeXRoaW5nIGlzIG9rwqAgYnkgeW91ciBoZWxwICnCoCBidXQgcmlnaHQgSSBhbSB1c2luZyB0aGlzIHNjcmlwdCBmb3IgbnV0Y2gtMS4wIHRvIGV4dHJhY3QgdGhlbSAoIEkgc2F3IHRoaXMgZm9sZGVyIEFyY3Jhd2xkaXIvIGNyYXdsZGIgc2VnbWVudHMgbGlua2RiIGluZGV4ZXMpIGFuZCB0b21jYXQtNiB0byBzaG93IHRoZW0gYnUBMAEBAQE-\r\nX-Mailer: YahooMailWebService/0.8.129.483\r\nReferences: &lt;kbefsr+5lps@...&gt; &lt;50DD102B.2000701@...&gt;\r\nMessage-ID: &lt;1356703882.4882.YahooMailNeo@...&gt;\r\nDate: Fri, 28 Dec 2012 14:11:22 +0000 (GMT)\r\nTo: &quot;archive-crawler@yahoogroups.com&quot; &lt;archive-crawler@yahoogroups.com&gt;\r\nIn-Reply-To: &lt;50DD102B.2000701@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: multipart/mixed; boundary=&quot;1353131092-1562524924-1356703882=:4882&quot;\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: =?utf-8?B?TMOpZ3LDqSBSb2JlcnQ=?= &lt;attabi225@...&gt;\r\nReply-To: =?utf-8?B?TMOpZ3LDqSBSb2JlcnQ=?= &lt;attabi225@...&gt;\r\nSubject: Re: [archive-crawler] Setting parameters to get  deeper section of a domain - Heritrix 1.14.4\r\nX-Yahoo-Group-Post: member; u=547657027; y=lSC89fZf-lK8JHHY2qIhUzRkl5R8ZeE32bnayDikkE_TTBJ9\r\nX-Yahoo-Profile: attabi225\r\n\r\n\r\n--1353131092-1562524924-1356703882=:4882\r\nContent-Type: multipart/alternative; boundary=&quot;1353131092-1334564947-1356703882=:4882&quot;\r\n\r\n\r\n--1353131092-1334564947-1356703882=:4882\r\nContent-Type: text/plain; charset=utf-8\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nHi, I am using heritrix-2.0.2=C2=A0 to crawl some website and scan them by =\r\nmonkey-spider ( until here everything is ok=C2=A0 by your help )=C2=A0 but =\r\nright I am using this script for nutch-1.0 to extract them ( I saw this fol=\r\nder Arcrawldir/ crawldb segments linkdb indexes) and tomcat-6 to show them =\r\nbut nothing is display in my nutch-tomcat.\nplease can you still help me \n\n\n=\r\n________________________________\n De=C2=A0: Noah Levitt &lt;nlevitt@...=\r\ng&gt;\n=C3=80=C2=A0: archive-crawler@yahoogroups.com \nCc=C2=A0: mamdev &lt;amineme=\r\nrsni@...&gt; \nEnvoy=C3=A9 le : Vendredi 28 d=C3=A9cembre 2012 3h21\nObjet=\r\n=C2=A0: Re: [archive-crawler] Setting parameters to get  deeper section of =\r\na domain - Heritrix 1.14.4\n \n\n=C2=A0 \nHello,\n\nIn h1 you can configure an ov=\r\nerride just for that domain. Easiest way to do that is through the web ui. =\r\nClick &quot;Overrides&quot;, type in the domain, and set your max-hops value.\n\nIn h3 =\r\nyou can use a sheet. https://webarchive.jira.com/wiki/display/Heritrix/Shee=\r\nts\n\nNoah\n\nOn 2012-12-26 01:26 , mamdev wrote:\n&gt;\n&gt;\n&gt; Hi all,\n&gt;\n&gt; I&#39;m trying =\r\nto crawl a domain with a news subsection containing more than 200 hundred p=\r\nages, linked to each other with &quot;Older&quot; and &quot;Newer&quot; buttons.\n&gt;\n&gt; With the d=\r\nefault configuration (max-link-hops=3D25) and the url of news subsection as=\r\n seeds , i only get the first 26 pages and it&#39;s logical.\n&gt;\n&gt; What i&#39;m looki=\r\nng for , is a configuration to get all subsection news pages without changi=\r\nng the default number of hops.\n&gt;\n&gt; Is it possible?\n&gt; Should i crawl separat=\r\nly the subsection news?\n&gt;\n&gt;\n&gt; Thanks in advance.\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; \n\n \r\n--1353131092-1334564947-1356703882=:4882\r\nContent-Type: text/html; charset=utf-8\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n&lt;html&gt;&lt;body&gt;&lt;div style=3D&quot;color:#000; background-color:#fff; font-family:ti=\r\nmes new roman, new york, times, serif;font-size:12pt&quot;&gt;&lt;div&gt;Hi, I am using h=\r\neritrix-2.0.2&nbsp; to crawl some website and scan them by monkey-spider ( =\r\nuntil here everything is ok&nbsp; by your help )&nbsp; but right I am using=\r\n this script for nutch-1.0 to extract them ( I saw this folder Arcrawldir/ =\r\ncrawldb segments linkdb indexes) and tomcat-6 to show them but nothing is d=\r\nisplay in my nutch-tomcat.&lt;/div&gt;&lt;div&gt;please can you still help me &lt;br&gt;&lt;/div=\r\n&gt;  &lt;div style=3D&quot;font-family: times new roman, new york, times, serif; font=\r\n-size: 12pt;&quot;&gt; &lt;div style=3D&quot;font-family: times new roman, new york, times,=\r\n serif; font-size: 12pt;&quot;&gt; &lt;div dir=3D&quot;ltr&quot;&gt; &lt;font face=3D&quot;Arial&quot; size=3D&quot;2=\r\n&quot;&gt; &lt;hr size=3D&quot;1&quot;&gt;  &lt;b&gt;&lt;span style=3D&quot;font-weight:bold;&quot;&gt;De&nbsp;:&lt;/span&gt;&lt;/=\r\nb&gt; Noah Levitt &lt;nlevitt@...&gt;&lt;br&gt; &lt;b&gt;&lt;span style=3D&quot;font-weigh=\r\nt: bold;&quot;&gt;=C3=80&nbsp;:&lt;/span&gt;&lt;/b&gt; archive-crawler@yahoogroups.com &lt;br&gt;&lt;b&gt;&lt;=\r\nspan\n style=3D&quot;font-weight: bold;&quot;&gt;Cc&nbsp;:&lt;/span&gt;&lt;/b&gt; mamdev &lt;aminemer=\r\nsni@...&gt; &lt;br&gt; &lt;b&gt;&lt;span style=3D&quot;font-weight: bold;&quot;&gt;Envoy=C3=A9 le =\r\n:&lt;/span&gt;&lt;/b&gt; Vendredi 28 d=C3=A9cembre 2012 3h21&lt;br&gt; &lt;b&gt;&lt;span style=3D&quot;font=\r\n-weight: bold;&quot;&gt;Objet&nbsp;:&lt;/span&gt;&lt;/b&gt; Re: [archive-crawler] Setting param=\r\neters to get  deeper section of a domain - Heritrix 1.14.4&lt;br&gt; &lt;/font&gt; &lt;/di=\r\nv&gt; &lt;br&gt;&lt;div id=3D&quot;yiv1632153601&quot;&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;div&gt;\n&lt;span style=3D&quot;display=\r\n:none;&quot;&gt;&nbsp;&lt;/span&gt;\n\n\n\n    &lt;div id=3D&quot;yiv1632153601ygrp-text&quot;&gt;\n      \n   =\r\n   \n      &lt;div&gt;Hello,&lt;br&gt;\n&lt;br&gt;\nIn h1 you can configure an override just for=\r\n that domain. Easiest way to do that is through the web ui. Click &quot;Override=\r\ns&quot;, type in the domain, and set your max-hops value.&lt;br&gt;\n&lt;br&gt;\nIn h3 you can=\r\n use a sheet. &lt;a rel=3D&quot;nofollow&quot; target=3D&quot;_blank&quot; href=3D&quot;https://webarch=\r\nive.jira.com/wiki/display/Heritrix/Sheets&quot;&gt;https://webarchive.jira.com/wiki=\r\n/display/Heritrix/Sheets&lt;/a&gt;&lt;br&gt;\n&lt;br&gt;\nNoah&lt;br&gt;\n&lt;br&gt;\nOn 2012-12-26 01:26 , m=\r\namdev wrote:&lt;br&gt;\n&gt;&lt;br&gt;\n&gt;&lt;br&gt;\n&gt; Hi all,&lt;br&gt;\n&gt;&lt;br&gt;\n&gt; I&#39;m tryin=\r\ng to crawl a domain with a news subsection containing more than 200 hundred=\r\n pages, linked to each other with &quot;Older&quot; and &quot;Newer&quot; buttons.&lt;br&gt;\n&gt;&lt;br&gt;=\r\n\n&gt; With the default configuration (max-link-hops=3D25) and the url of ne=\r\nws subsection as seeds , i only get the first 26 pages and it&#39;s logical.&lt;br=\r\n&gt;\n&gt;&lt;br&gt;\n&gt; What i&#39;m looking for , is a configuration to get all subsec=\r\ntion news pages without changing the default number of hops.&lt;br&gt;\n&gt;&lt;br&gt;\n&=\r\ngt; Is it possible?&lt;br&gt;\n&gt; Should i crawl separatly the subsection news?&lt;=\r\nbr&gt;\n&gt;&lt;br&gt;\n&gt;&lt;br&gt;\n&gt; Thanks in advance.&lt;br&gt;\n&gt;&lt;br&gt;\n&gt;&lt;br&gt;\n&gt;&lt;br=\r\n&gt;\n&gt;&lt;br&gt;\n&gt;&lt;br&gt;\n&gt;&lt;br&gt;\n&gt;&lt;br&gt;\n&gt; &lt;br&gt;\n&lt;/div&gt;\n\n    &lt;/div&gt;\n     \n\n\n=\r\n\n&lt;/div&gt;\n\n\n\n\n\n&lt;/div&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt; &lt;/div&gt;  &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\r\n--1353131092-1334564947-1356703882=:4882--\r\n\n\r\n--1353131092-1562524924-1356703882=:4882\r\nContent-Type: application/x-shellscript; name=&quot;nutch-ARC.sh&quot;\r\nContent-Disposition: attachment; filename=&quot;nutch-ARC.sh&quot;\r\n\r\n[ Attachment content not displayed ]\r\n--1353131092-1562524924-1356703882=:4882--\r\n\n"}}