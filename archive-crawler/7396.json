{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":55685036,"authorName":"cmiles74","from":"&quot;cmiles74&quot; &lt;twitch@...&gt;","profile":"cmiles74","replyTo":"LIST","senderId":"to4o2c2sAHWoYGFrUNqQgjUFRKLJPTsvKKhPb_7qjnChl7UGhM_lPBLF301axviygP-oe8R3uRQ7C8MLKlqsOTklDu_xByADe1c","spamInfo":{"isSpam":false,"reason":"6"},"subject":"HDFSWriter an Heritrix 3.1","postDate":"1320842046","msgId":7396,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGo5ZHJ2dSs1dmltQGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":7400,"prevInTime":7395,"nextInTime":7397,"topicId":7396,"numMessagesInTopic":2,"msgSnippet":"We re interested in writing our crawl data to HadoopFS to make it easier to process this data with Hadoop. I found the following project on GitHubâ€¦ ","rawEmail":"Return-Path: &lt;twitch@...&gt;\r\nX-Sender: twitch@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 71655 invoked from network); 9 Nov 2011 12:34:06 -0000\r\nX-Received: from unknown (98.137.35.162)\n  by m14.grp.sp2.yahoo.com with QMQP; 9 Nov 2011 12:34:06 -0000\r\nX-Received: from unknown (HELO ng14-ip1.bullet.mail.ne1.yahoo.com) (98.138.215.225)\n  by mta6.grp.sp2.yahoo.com with SMTP; 9 Nov 2011 12:34:06 -0000\r\nX-Received: from [98.138.217.180] by ng14.bullet.mail.ne1.yahoo.com with NNFMP; 09 Nov 2011 12:34:06 -0000\r\nX-Received: from [69.147.65.149] by tg5.bullet.mail.ne1.yahoo.com with NNFMP; 09 Nov 2011 12:34:06 -0000\r\nX-Received: from [98.137.35.12] by t9.bullet.mail.sp1.yahoo.com with NNFMP; 09 Nov 2011 12:34:06 -0000\r\nDate: Wed, 09 Nov 2011 12:34:06 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;j9drvu+5vim@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;cmiles74&quot; &lt;twitch@...&gt;\r\nSubject: HDFSWriter an Heritrix 3.1\r\nX-Yahoo-Group-Post: member; u=55685036; y=zEDfgZgPYEWckDdmpcd3AHe7HDw51qL434XyzlPWZADs3Mw\r\nX-Yahoo-Profile: cmiles74\r\n\r\nWe&#39;re interested in writing our crawl data to HadoopFS to make it easier to=\r\n process this data with Hadoop. I found the following project on GitHub=85\n=\r\n\n https://github.com/znbailey/heritrix-hdfs-writer\n\nIt doesn&#39;t compile clea=\r\nnly against the current Heritrix 3.1 release and I am interested in bringin=\r\ng this code up-to-date. Before I dig in, has anyone done this work already?=\r\n\n\nThank you\n--\nMiles\n\n\n"}}