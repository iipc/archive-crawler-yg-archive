{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"-01gWpx4x1mncbYNzLSRFK0N2uBTtFtl--nUyUIPWmGiC6CxG-k3Yk5pNsZ6HtSC1qG-hAbWP3N4flnpZndcWsZnZlq5qE4","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Funny crawler bug?  Perhaps a feature.","postDate":"1219903211","msgId":5432,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ4QjYzRUVCLjcwODAxMDBAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDQ4QjYxNzYxLjUwNDA2MDRAYmF5YXJlYS5uZXQ+","referencesHeader":"PDQ4QjYxNzYxLjUwNDA2MDRAYmF5YXJlYS5uZXQ+"},"prevInTopic":5431,"nextInTopic":0,"prevInTime":5431,"nextInTime":5433,"topicId":5431,"numMessagesInTopic":2,"msgSnippet":"That s mighty odd! The -5s indicate some catchable runtime error that only spoils the URI itself. There will be more info in the runtime-errors.log -- can you ","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 49003 invoked from network); 28 Aug 2008 06:00:13 -0000\r\nX-Received: from unknown (66.218.67.95)\n  by m45.grp.scd.yahoo.com with QMQP; 28 Aug 2008 06:00:13 -0000\r\nX-Received: from unknown (HELO relay01.pair.com) (209.68.5.15)\n  by mta16.grp.scd.yahoo.com with SMTP; 28 Aug 2008 06:00:13 -0000\r\nX-Received: (qmail 14689 invoked from network); 28 Aug 2008 06:00:12 -0000\r\nX-Received: from unknown (HELO ?10.0.10.7?) (unknown)\n  by unknown with SMTP; 28 Aug 2008 06:00:12 -0000\r\nX-pair-Authenticated: 70.137.153.40\r\nMessage-ID: &lt;48B63EEB.7080100@...&gt;\r\nDate: Wed, 27 Aug 2008 23:00:11 -0700\r\nUser-Agent: Thunderbird 2.0.0.16 (Windows/20080708)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;48B61761.5040604@...&gt;\r\nIn-Reply-To: &lt;48B61761.5040604@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Funny crawler bug?  Perhaps a feature.\r\nX-Yahoo-Group-Post: member; u=137285340; y=TzRosglCXWJRsAd1h07Dqn5YwJPa0rvNH3PQHhrzKGv3\r\nX-Yahoo-Profile: gojomo\r\n\r\nThat&#39;s mighty odd!\n\nThe -5s indicate some catchable runtime error that only spoils the URI \nitself. There will be more info in the runtime-errors.log -- can you \nforward a few typical cases?\n\nI would also be interested in what a -SIGQUIT java threads dump shows \nfor the JVM, and if there are any other alerts/exceptions around the \ntime of the &#39;resume&#39;.\n\n(It should have already been writing recover.gz, unless you&#39;d turned \nthat off -- that&#39;s a very old feature, that predates checkpointing, for \nreproducing a rough facsimile of frontier state after a crash. So that \ndoesn&#39;t strike me as too odd, unless it&#39;s the only one of your crawlers \nwriting such a recover log. Is it?)\n\nFinally, I wonder what would happen with a redundant &#39;resume&#39; request -- \ndoes its reported state catch up?\n\nWe may not be able to figure out exactly what happened but capturing \nthis info could help the next time it shows up.\n\n- Gordon @ IA\n\nlekash wrote:\n&gt; Hi there,\n&gt; \n&gt; I have an interesting situation on a random crawler right now.\n&gt; \n&gt; Running 1.15, so its all my problem, of course.\n&gt; But I thought I would tell you all, for perhaps the entertainment value.\n&gt; \n&gt; Essentially, this crawler started to experience -5 return codes from DNS \n&gt; lookups.\n&gt; And so, stopped crawling.\n&gt; \n&gt; Being the resourceful yet modest fellow I am, I paused it, started a \n&gt; checkpoint. \n&gt; Annoying, but it often works.\n&gt; \n&gt; Then, when it reported done, I cleverly clicked resume, just to see what \n&gt; might happen.\n&gt; Kind of wedged there for a while, I went home and to sleep.  Check on it \n&gt; in the morning.\n&gt; \n&gt; So now, this fine crawler is crawling away, and has been all day.\n&gt; It reports itself as paused, and doesn&#39;t log anything to the \n&gt; progress-statistics.log.\n&gt; However, crawl.log continues to grow just fine, as do downloaded arcs.\n&gt; \n&gt; And the last humor filled thing is that recover.gz seems to march right \n&gt; in step.\n&gt; \n&gt; Not sure if I managed to activate some in progress feature, of creating \n&gt; a continuous\n&gt; recover log, or what the eventual state will be.   But I&#39;ll leave it up, \n&gt; and see what happens.\n&gt; Not to mention,  I want the crawl data, and its best to not annoy people \n&gt; by too often,\n&gt; recrawling their site.\n&gt; \n&gt; John\n&gt; \n&gt; \n&gt; ------------------------------------\n&gt; \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n"}}