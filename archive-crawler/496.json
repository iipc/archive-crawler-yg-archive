{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"q9edV9zjtW1honEfSSlFj6SXzX_Twjy_Q2DY2l_N0NMvxiiWO6WAWnmpkfDkIpEbi2aZt_kcatdPbiLwarMJzszG4j3_D8E","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Seed Status","postDate":"1085879997","msgId":496,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQwQjkzNkJELjcwNzAxMDhAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGM5YjN0dCs4dHFtQGVHcm91cHMuY29tPg==","referencesHeader":"PGM5YjN0dCs4dHFtQGVHcm91cHMuY29tPg=="},"prevInTopic":494,"nextInTopic":0,"prevInTime":495,"nextInTime":497,"topicId":494,"numMessagesInTopic":2,"msgSnippet":"... I think what you mean is: you want a notification when an entire site (as was started with a single seed) is done . While the crawler knows when it has","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 93581 invoked from network); 30 May 2004 01:19:35 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m21.grp.scd.yahoo.com with QMQP; 30 May 2004 01:19:35 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (209.237.232.202)\n  by mta5.grp.scd.yahoo.com with SMTP; 30 May 2004 01:19:35 -0000\r\nReceived: (qmail 1694 invoked by uid 100); 30 May 2004 01:12:27 -0000\r\nReceived: from adsl-67-121-76-118.dsl.snfc21.pacbell.net (HELO archive.org) (gojomo@...@67.121.76.118)\n  by mail-dev.archive.org with SMTP; 30 May 2004 01:12:27 -0000\r\nMessage-ID: &lt;40B936BD.7070108@...&gt;\r\nDate: Sat, 29 May 2004 18:19:57 -0700\r\nUser-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.5b) Gecko/20030901 Thunderbird/0.2\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;c9b3tt+8tqm@...&gt;\r\nIn-Reply-To: &lt;c9b3tt+8tqm@...&gt;\r\nContent-Type: text/plain; charset=us-ascii; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: *\r\nX-Spam-Status: No, hits=1.9 required=6.0 tests=AWL,RCVD_IN_DYNABLOCK,\n\tRCVD_IN_SORBS autolearn=no version=2.63\r\nX-eGroups-Remote-IP: 209.237.232.202\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Seed Status\r\nX-Yahoo-Group-Post: member; u=137285340\r\nX-Yahoo-Profile: gojomo\r\n\r\njirleech wrote:\n\n&gt; Is there any way to know when a specific seed url has finished being\n&gt; crawled?  The reason I ask is that I need to know when a seed is done\n&gt; so that I can index that url with lucene.  I have successfully writen\n&gt; a DiskWriterProcessor that does a good job mirroring a site and\n&gt; writing it disk.  Now I need to Index each site separately.  I would\n&gt; like to use the current threads that Heritrix has instead of indexing\n&gt; after a full crawl has been comleted.  If I knew when a seed is\n&gt; finished then, i can spawn my indexer.  Im not sure if I was able to\n&gt; articulate this correctly, but I hope you get the jist of it.  \n&gt; Thanks,\n\nI think what you mean is: you want a notification when an entire\nsite (as was started with a single seed) is &quot;done&quot;.\n\nWhile the crawler knows when it has exhausted all the URIs it\nknows about on site XYZ, if it is still crawling other sites,\nit might discover new content for site XYZ. So there&#39;s not\nnecessarily a clean &quot;finished&quot; state until the whole crawl is\nstopped.\n\nIf you need on-the-fly indexing, is there any reason you&#39;re not\nfeeding each document to Lucene as it is processed, perhaps just\nbefore or after it&#39;s written to disk?\n\n(Regarding the temporary exhaustion of per-site work queues:\nthis is a well-defined transition inside the KeyedQueue class --\nit goes to EMPTY state and then may even be discarded -- but\nthere&#39;s currently no straightforward way to hook into that\ntransition.)\n\n- Gordon @ IA\n\n\n"}}