{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":270755834,"authorName":"Natalia Torres","from":"Natalia Torres &lt;ntorres@...&gt;","replyTo":"LIST","senderId":"QRE3SIhrxMNgUJ_GR4-fInBgE0fgx9VfeltHdSoBSsCI3GD3z3kFSi4OTVDJxYAd9i7TeCGj1UnACY5lZ0PIJ2fd8-rjPmhT","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Deduplication with Heritrix 1.12","postDate":"1193669425","msgId":4632,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ3MjVGMzMxLjgwMDAxMDNAY2VzY2EuZXM+","inReplyToHeader":"PDQ2QUZCNEIwLjEwOTA5MDVAYXJjaGl2ZS5vcmc+","referencesHeader":"PDQ2QTRBNzk4LjkwMjAwMDNAY2VzY2EuZXM+IDwwQUJGOEJFOC1BNDg2LTRFMUMtODVERi1ERTNDRTU3RDkzQjNAYXJjaGl2ZS5vcmc+IDw0NkE3NDZDMi4zMDIwNzAzQGNlc2NhLmVzPiA8NDZBRkI0QjAuMTA5MDkwNUBhcmNoaXZlLm9yZz4="},"prevInTopic":4484,"nextInTopic":0,"prevInTime":4631,"nextInTime":4633,"topicId":4453,"numMessagesInTopic":6,"msgSnippet":"Hi Sorry for replying late... The heritrix_out log has no information so I restart heritrix I crwal a new job and these errors appears any more.... But I m","rawEmail":"Return-Path: &lt;ntorres@...&gt;\r\nX-Sender: ntorres@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 11251 invoked from network); 29 Oct 2007 14:50:54 -0000\r\nX-Received: from unknown (66.218.67.94)\n  by m48.grp.scd.yahoo.com with QMQP; 29 Oct 2007 14:50:54 -0000\r\nX-Received: from unknown (HELO carlit.cesca.es) (84.88.0.2)\n  by mta15.grp.scd.yahoo.com with SMTP; 29 Oct 2007 14:50:53 -0000\r\nX-Received: from carlit.cesca.es (localhost [127.0.0.1])\n\tby carlit.cesca.es (Postfix) with ESMTP id BD37B331DA8\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Mon, 29 Oct 2007 15:50:51 +0100 (CET)\r\nX-Received: from [192.94.163.137] (mirapallars.cesca.es [192.94.163.137])\n\t(using TLSv1 with cipher RC4-MD5 (128/128 bits))\n\t(No client certificate requested)\n\tby carlit.cesca.es (Postfix) with ESMTP id 8FD4F33189C\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Mon, 29 Oct 2007 15:50:51 +0100 (CET)\r\nMessage-ID: &lt;4725F331.8000103@...&gt;\r\nDate: Mon, 29 Oct 2007 15:50:25 +0100\r\nUser-Agent: Debian Thunderbird 1.0.2 (X11/20060830)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;46A4A798.9020003@...&gt; &lt;0ABF8BE8-A486-4E1C-85DF-DE3CE57D93B3@...&gt; &lt;46A746C2.3020703@...&gt; &lt;46AFB4B0.1090905@...&gt;\r\nIn-Reply-To: &lt;46AFB4B0.1090905@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Natalia Torres &lt;ntorres@...&gt;\r\nSubject: Re: [archive-crawler] Deduplication with Heritrix 1.12\r\nX-Yahoo-Group-Post: member; u=270755834\r\n\r\nHi\nSorry for replying late...\nThe heritrix_out log has no information so I restart heritrix I crwal a \nnew job and these errors appears any more.... But I&#39;m still testing de \nduplication. The second crawl has the same size as first (800MB) and \nthere are changes on the URL..\n\nI try both PersistLogProcessor an PersistStoreProcessor for \ndeduplication features.\n\nHow can I preload the &#39;state&#39; using the command line tool using\nPersistLog Processor? I&#39;m looking for information about it on cmdline \nproject but there are no many information.\n\nUsing PersistStoreProcess how to reuse the state directory? I&#39;ve tried \nsetting the state path to the previus crawl state directory.\n\n\n\nGordon Mohr wrote:\n&gt; \n&gt; \n&gt; I&#39;m not sure what would have caused your errors; I would look in\n&gt; heritrix_out. log to see if there are any other errors suggestive of a\n&gt; broader problem. (In particular, the error stacks you quote don&#39;t\n&gt; mention any deduplication- specific functionality. )\n&gt; \n&gt; Generally, though:\n&gt; \n&gt; When using the 1.12 deduplication features, on the first crawl, you\n&gt; should use only one of either the PersistLogProcessor or the\n&gt; PersistStoreProcess or.\n&gt; \n&gt; Then, on the followup crawl, you make sure its &#39;state&#39; directory is\n&gt; preloaded with information from the earlier crawl.\n&gt; \n&gt; If you used the PersistLogProcessor , then the info from the log created\n&gt; must be loaded into a new &#39;state&#39; directory, using the bundled\n&gt; PersistProcessor class as a command-line tool.\n&gt; \n&gt; If you used the PersistStoreProcess or, you should be able to reuse the\n&gt; &#39;state&#39; directory from the earlier crawl directly. However, it will\n&gt; contain extraneous information, so you may also use the PersistProcessor\n&gt; class as a command-line tool to export the info from the old state\n&gt; directory into a new, minimal state directory.\n&gt; \n&gt; On this followup crawl, you may also use the PersistLogProcessor or\n&gt; PersistStoreProcess or again to collect the info for a future repeated run.\n&gt; \n&gt; Right now the process is awkward -- with too many options and manual\n&gt; steps -- because there isn&#39;t enough experience to recommend best\n&gt; practices. As experience is gathered, we will work to make the best\n&gt; processes more automatic, and achievable completely within the Web UI\n&gt; with a minimum amount of configuration.\n&gt; \n&gt; - Gordon\n&gt; \n&gt; Natalia Torres wrote:\n&gt;  &gt; Yes!! I try it creating jobs, some using PersistStoreProcess and some\n&gt;  &gt; using PersistLogStore. I use the same state directory in initial crawl\n&gt;  &gt; and the second crawl.\n&gt;  &gt;\n&gt;  &gt; After hours crawling I get 28 altert message as\n&gt;  &gt;\n&gt;  &gt; com.sleepycat. util.RuntimeExce ptionWrapper: (JE 3.2.23) Can&#39;t open a\n&gt;  &gt; cursor Database state can&#39;t be DbState.CLOSED must be DbState.OPEN\n&gt;  &gt; Cause: com.sleepycat. je.DatabaseExcep tion: (JE 3.2.23) Can&#39;t open a\n&gt;  &gt; cursor Database state can&#39;t be DbState.CLOSED must be DbState.OPEN\n&gt;  &gt; at com.sleepycat. je.Database. checkRequiredDbS tate(Database. java:1069)\n&gt;  &gt; at com.sleepycat. je.Database. openCursor( Database. java:359)\n&gt;  &gt; at\n&gt;  &gt; com.sleepycat. collections. CurrentTransacti on.openCursor( \n&gt; CurrentTransacti on.java:364)\n&gt;  &gt; at\n&gt;  &gt; com.sleepycat. collections. MyRangeCursor. openCursor( MyRangeCursor. \n&gt; java:53)\n&gt;  &gt; at com.sleepycat. collections. MyRangeCursor. (MyRangeCursor. java:30)\n&gt;  &gt; at com.sleepycat. collections. DataCursor. init(DataCursor. java:171)\n&gt;  &gt; at com.sleepycat. collections. DataCursor. (DataCursor. java:59)\n&gt;  &gt; at com.sleepycat. collections. BlockIterator. hasNext(BlockIte \n&gt; rator.java: 299)\n&gt;  &gt; at\n&gt;  &gt; org.apache.commons. httpclient. cookie.CookieSpe cBase.match( \n&gt; CookieSpecBase. java:607)\n&gt;  &gt; at\n&gt;  &gt; org.apache.commons. httpclient. HttpMethodBase. addCookieRequest \n&gt; Header(HttpMetho dBase.java: 1193)\n&gt;  &gt; at\n&gt;  &gt; org.apache.commons. httpclient. HttpMethodBase. addRequestHeader \n&gt; s(HttpMethodBase .java:1327)\n&gt;  &gt; at\n&gt;  &gt; org.apache.commons. httpclient. HttpMethodBase. writeRequestHead \n&gt; ers(HttpMethodBa se.java:2056)\n&gt;  &gt; at\n&gt;  &gt; org.apache.commons. httpclient. HttpMethodBase. writeRequest( \n&gt; HttpMethodBase. java:1939)\n&gt;  &gt; at\n&gt;  &gt; org.apache.commons. httpclient. HttpMethodBase. execute(HttpMeth \n&gt; odBase.java: 1000)\n&gt;  &gt; at\n&gt;  &gt; org.archive. httpclient. HttpRecorderGetM ethod.execute( \n&gt; HttpRecorderGetM ethod.java: 116)\n&gt;  &gt; at\n&gt;  &gt; org.apache.commons. httpclient. HttpMethodDirect or.executeWithRe \n&gt; try(HttpMethodDi rector.java: 397)\n&gt;  &gt; at\n&gt;  &gt; org.apache.commons. httpclient. HttpMethodDirect or.executeMethod \n&gt; (HttpMethodDirec tor.java: 170)\n&gt;  &gt; at\n&gt;  &gt; org.apache.commons. httpclient. HttpClient. executeMethod( \n&gt; HttpClient. java:396)\n&gt;  &gt; at\n&gt;  &gt; org.apache.commons. httpclient. HttpClient. executeMethod( \n&gt; HttpClient. java:346)\n&gt;  &gt; at org.archive. crawler.fetcher. FetchHTTP. innerProcess( FetchHTTP. \n&gt; java:500)\n&gt;  &gt; at org.archive. crawler.framewor k.Processor. process(Processo \n&gt; r.java:112)\n&gt;  &gt; at\n&gt;  &gt; org.archive. crawler.framewor k.ToeThread. processCrawlUri( \n&gt; ToeThread. java:302)\n&gt;  &gt; at org.archive. crawler.framewor k.ToeThread. run(ToeThread. java:151)\n&gt;  &gt;\n&gt;  &gt; Stacktrace: com.sleepycat. util.RuntimeExce ptionWrapper: (JE 3.2.23)\n&gt;  &gt; Can&#39;t open a cursor Database state can&#39;t be DbState.CLOSED must be\n&gt;  &gt; DbState.OPEN\n&gt;  &gt; at\n&gt;  &gt; com.sleepycat. collections. StoredContainer. convertException \n&gt; (StoredContainer .java:447)\n&gt;  &gt; at com.sleepycat. collections. BlockIterator. hasNext(BlockIte \n&gt; rator.java: 380)\n&gt;  &gt; at\n&gt;  &gt; org.apache.commons. httpclient. cookie.CookieSpe cBase.match( \n&gt; CookieSpecBase. java:607)\n&gt;  &gt; at\n&gt;  &gt; org.apache.commons. httpclient. HttpMethodBase. addCookieRequest \n&gt; Header(HttpMetho dBase.java: 1193)\n&gt;  &gt; at\n&gt;  &gt; org.apache.commons. httpclient. HttpMethodBase. addRequestHeader \n&gt; s(HttpMethodBase .java:1327)\n&gt;  &gt; at\n&gt;  &gt; org.apache.commons. httpclient. HttpMethodBase. writeRequestHead \n&gt; ers(HttpMethodBa se.java:2056)\n&gt;  &gt; at\n&gt;  &gt; org.apache.commons. httpclient. HttpMethodBase. writeRequest( \n&gt; HttpMethodBase. java:1939)\n&gt;  &gt; at\n&gt;  &gt; org.apache.commons. httpclient. HttpMethodBase. execute(HttpMeth \n&gt; odBase.java: 1000)\n&gt;  &gt; at\n&gt;  &gt; org.archive. httpclient. HttpRecorderGetM ethod.execute( \n&gt; HttpRecorderGetM ethod.java: 116)\n&gt;  &gt; at\n&gt;  &gt; org.apache.commons. httpclient. HttpMethodDirect or.executeWithRe \n&gt; try(HttpMethodDi rector.java: 397)\n&gt;  &gt; at\n&gt;  &gt; org.apache.commons. httpclient. HttpMethodDirect or.executeMethod \n&gt; (HttpMethodDirec tor.java: 170)\n&gt;  &gt; at\n&gt;  &gt; org.apache.commons. httpclient. HttpClient. executeMethod( \n&gt; HttpClient. java:396)\n&gt;  &gt; at\n&gt;  &gt; org.apache.commons. httpclient. HttpClient. executeMethod( \n&gt; HttpClient. java:346)\n&gt;  &gt; at org.archive. crawler.fetcher. FetchHTTP. innerProcess( FetchHTTP. \n&gt; java:500)\n&gt;  &gt; at org.archive. crawler.framewor k.Processor. process(Processo \n&gt; r.java:112)\n&gt;  &gt; at\n&gt;  &gt; org.archive. crawler.framewor k.ToeThread. processCrawlUri( \n&gt; ToeThread. java:302)\n&gt;  &gt; at org.archive. crawler.framewor k.ToeThread. run(ToeThread. java:151)\n&gt;  &gt; Caused by: com.sleepycat. je.DatabaseExcep tion: (JE 3.2.23) Can&#39;t \n&gt; open a\n&gt;  &gt; cursor Database state can&#39;t be DbState.CLOSED must be DbState.OPEN\n&gt;  &gt; at com.sleepycat. je.Database. checkRequiredDbS tate(Database. java:1069)\n&gt;  &gt; at com.sleepycat. je.Database. openCursor( Database. java:359)\n&gt;  &gt; at\n&gt;  &gt; com.sleepycat. collections. CurrentTransacti on.openCursor( \n&gt; CurrentTransacti on.java:364)\n&gt;  &gt; at\n&gt;  &gt; com.sleepycat. collections. MyRangeCursor. openCursor( MyRangeCursor. \n&gt; java:53)\n&gt;  &gt; at com.sleepycat. collections. MyRangeCursor. (MyRangeCursor. java:30)\n&gt;  &gt; at com.sleepycat. collections. DataCursor. init(DataCursor. java:171)\n&gt;  &gt; at com.sleepycat. collections. DataCursor. (DataCursor. java:59)\n&gt;  &gt; at com.sleepycat. collections. BlockIterator. hasNext(BlockIte \n&gt; rator.java: 299)\n&gt;  &gt;\n&gt;  &gt;\n&gt;  &gt; N.\n&gt;  &gt;\n&gt;  &gt;\n&gt;  &gt;\n&gt;  &gt; Yahoo! Groups Links\n&gt;  &gt;\n&gt;  &gt;\n&gt;  &gt;\n&gt; \n&gt; \n\n-- \n......................................................................\n          __\n         / /          Natalia Torres\n   C E / S / C A      Dept. de Sistemes\n       /_/            Centre de Supercomputaci� de Catalunya\n\n   Gran Capit�, 2-4 (Edifici Nexus)  �  08034 Barcelona\n   T. 93 205 6464 � F.  93 205 6979  �  ntorres@...\n......................................................................\n\n"}}