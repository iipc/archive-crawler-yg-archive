{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"-4Lty280MQ4Jm1uvMOoTfdP4N5bBpPyd4PijRNr84NbN7qIUfyhv4feABTH2a399XiqTLTd-rAlkSTvhVk2fIvTMqoo8y4c","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Question about ARC files and Heritrix logs","postDate":"1146706866","msgId":2836,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ0NTk1QkIyLjIwMDA5QGFyY2hpdmUub3JnPg==","inReplyToHeader":"PHM0NTlmYTRmLjA3OEBzaGFkYm9sdC5uYXRsaWIuZ292dC5uej4=","referencesHeader":"PHM0NTlmYTRmLjA3OEBzaGFkYm9sdC5uYXRsaWIuZ292dC5uej4="},"prevInTopic":2835,"nextInTopic":0,"prevInTime":2835,"nextInTime":2837,"topicId":2835,"numMessagesInTopic":2,"msgSnippet":"... You could come close, but not reproduce all info in these logs from ARCs. For example, taking a representative successful crawl.log line: ","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 70882 invoked from network); 4 May 2006 01:40:37 -0000\r\nReceived: from unknown (66.218.67.34)\n  by m35.grp.scd.yahoo.com with QMQP; 4 May 2006 01:40:37 -0000\r\nReceived: from unknown (HELO mail.archive.org) (207.241.227.188)\n  by mta8.grp.scd.yahoo.com with SMTP; 4 May 2006 01:40:37 -0000\r\nReceived: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id 46EF614106562\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Wed,  3 May 2006 18:40:37 -0700 (PDT)\r\nReceived: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id 10715-01-10 for &lt;archive-crawler@yahoogroups.com&gt;;\n\tWed, 3 May 2006 18:40:36 -0700 (PDT)\r\nReceived: from [192.168.0.15] (adsl-71-130-102-78.dsl.pltn13.pacbell.net [71.130.102.78])\n\tby mail.archive.org (Postfix) with ESMTP id 4E05B1410653E\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Wed,  3 May 2006 18:40:36 -0700 (PDT)\r\nMessage-ID: &lt;44595BB2.20009@...&gt;\r\nDate: Wed, 03 May 2006 18:41:06 -0700\r\nUser-Agent: Mail/News 1.5 (X11/20060309)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;s459fa4f.078@...&gt;\r\nIn-Reply-To: &lt;s459fa4f.078@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Virus-Scanned: Debian amavisd-new at archive.org\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Question about ARC files and Heritrix logs\r\nX-Yahoo-Group-Post: member; u=137285340; y=anGNnpak-Jl-b81PaLOJ74d90keEdUNeu4VWwrcRE7f9\r\nX-Yahoo-Profile: gojomo\r\n\r\nGordon Paynter wrote:\n&gt; Hi all:\n&gt; \n&gt; Can anyone confirm that (in theory) the Heritrix crawl.log file can be entirely reproduced from the ARC files generated by a successful crawl?\n&gt; \n&gt; And to take this a little further, I think the same is probably true of \n&gt;   crawl.log\n&gt;   progress-statistics.log\n&gt;   uri-errors.log\n&gt; but not of\n&gt;    local-errors.log\n&gt;    runtime-errors.log\n&gt; \n&gt; Of the reports, I think the following are  reproducible from the ARC files generated by a successful crawl:\n&gt;   crawl-report.txt (excpt the crawl name)\n&gt;   hosts-report.txt\n&gt;   seeds-report.txt\n&gt;   responsecode-report.txt\n&gt; but not\n&gt;   frontier-report.txt (?)\n&gt;   processors-report.txt\n&gt;   mimetype-report.txt\n&gt; \n&gt; \n&gt; Can anyone confirm/deny?\n\nYou could come close, but not reproduce all info in these logs from ARCs.\n\nFor example, taking a representative successful crawl.log line:\n\n2006-04-28T00:29:38.171Z   200       8521\n  http://mcgruff.org/mab/template2_files/tmp_logo1.gif ERE\n  http://mcgruff.org/mab/ image/gif #124 20060428002802698+95470\n  IGSBHINIDURTQLUGI6XLHC7TLFC7NDMO - -\n\nThe 1st-column log-time is not identical to the time in the ARC: it is \nmore when processing completed, whereas the ARC time is when the \nfetch-attempt began.\n\nThe 2nd-column return-code, 3rd-column length, and 4th-column URI are \nall evident from examining the ARC.\n\nThe 5th-column hops-path and 6th-column via-URI could probably be \nreconstructed by careful examination of everything leading up to a \ncapture (essentially simulated the crawl), but such a reconstruction \nmight find multiple equally-plausible paths without enough info to be \ncertain which was the one actually used for initial discovery.\n\nThe 6th-column MIME type is evident in the ARC.\n\nThe 7th-column thread-number is not stored anywhere other than the \ncrawl.log, and could not be reconstructed.\n\nThe 8th-column fetch-start-time+fetch-duration matches the ARC time in \nits first 14 digits -- but the milliseconds digits and duration info are \nnot stored anywhere else and could not be reconstructed.\n\nThe 9th-column SHA1 hash could be recalculated from the ARC.\n\nThe 10th-column source-tag (if present) would face the same problems as \nthe hops-path and via-URI -- a plausible value could be constructed, but \ndue to multiple paths it might not be identical to that in the original \ncrawl.log.\n\nThe 11th-column annotations are not stored in the ARC and could not be \nreconstructed.\n\nFailed crawl.log lines provide greater difficulties. Two examples:\n\n2006-05-02T23:45:45.280Z -9998          -\n  http://www.aauw.org/images/harass/getacro.gif - - no-type #012 - - - -\n\nThere is no entry in the ARCs for an URI that, like this one, was never \ntried due to a robots-exclusion rule (-9998). You could synthesize these \nlines by re-extracting the ARC contents and re-applying the robots rules.\n\n2006-05-03T07:21:44.145Z    -2          - http://mma.gov.br/robots.txt P\n  http://mma.gov.br/port/sqa/clima/capa/index.html no-type #012 - - -\n  le:SocketTimeoutException@HTTP,30t\n\nAfter 30 tries, with no successful connection, the crawler gave up on \nthis URI, and recorded that in the crawl.log with a connection-failed \n(-2) code. Nothing was written to any ARC in this case; all a \nreconstruction could do is surmise that the URL, if discovered in other \ncontent, was probably tried.\n\nSimilarly, with progress-statistics.log, you could probably estimate \nsimilar but probably not identical values for many of the internal \nprogress-rates and resource-usage-levels.\n\nA crawl simulation which ran the same URI-extraction code against the \nARC content would probably be capable of creating an equivalent \nuri-errors.log.\n\nYou are correct that the local-errors and runtime-errors logs would not \nbe reconstructable from the ARC content. (Simulating a crawl against the \nARCs might trigger some of the same RuntimeExceptions, though.)\n\nRegarding reports, the make-reports.pl script in the Heritrix bin \ndirectory tried to recreate rough equivalents to the various reports \nfrom the crawl.log (rather than ARCs). Some of the report tallies vary \nbecause the exact same input numbers are not available.\n\nThe same would be the case from ARCs, for many of reasons mentioned in \nthe crawl.log case.\n\nWithout simulating/modelling what the crawl did as it travelled from URI \nto URI, aspects of the seeds-report would be hard to deduce -- and the \nsame level of detail for how any seeds failed would not be available \nfrom ARCs alone (no failure codes).\n\nThe mimetype-report should be easy to reconstruct from ARC content; the \nprocessors-report could largely be reconstructed by feeding the same \ncontent to the same processors in a simulated crawl; the frontier-report \ncould also be created via such a simulated crawl. However, I suppose \nsuch a running re-extraction and simulated-queues-maintenance is \nprobably more effort than you were contemplating.\n\nHope this helps.\n\n- Gordon @ IA\n\n\n&gt; Gordon\n&gt; \n&gt; \n&gt; \n&gt;  \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n&gt;  \n&gt; \n&gt; \n&gt; \n\n\n"}}