{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":165458231,"authorName":"Bjarne Andersen","from":"Bjarne Andersen &lt;bja@...&gt;","profile":"bjarne_dk2000","replyTo":"LIST","senderId":"owQdRt9NJ4zLzwcZF85Ends2_UL9wcFdZ5bSdgi5gNAVtMw5db7bkrmiJtMH1ILMyepNo3UuO1fo50g_AdiZa9R-vNVVhIGX92rpgvr_4LE","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Restricting Hertirx  ???","postDate":"1163493929","msgId":3536,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ1NTk4MjI5LjcwMTA4MDlAc3RhdHNiaWJsaW90ZWtldC5kaz4=","inReplyToHeader":"PGVqOTB2OStnOGxvQGVHcm91cHMuY29tPg==","referencesHeader":"PGVqOTB2OStnOGxvQGVHcm91cHMuY29tPg=="},"prevInTopic":3533,"nextInTopic":0,"prevInTime":3535,"nextInTime":3537,"topicId":3533,"numMessagesInTopic":2,"msgSnippet":"If you can define what you don t want by regexp s you can just add an exclude-filter to your scope-section of order.xml ","rawEmail":"Return-Path: &lt;bja@...&gt;\r\nX-Sender: bja@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 99389 invoked from network); 14 Nov 2006 08:53:26 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m36.grp.scd.yahoo.com with QMQP; 14 Nov 2006 08:53:26 -0000\r\nReceived: from unknown (HELO luna.statsbiblioteket.dk) (130.225.24.87)\n  by mta6.grp.scd.yahoo.com with SMTP; 14 Nov 2006 08:53:26 -0000\r\nReceived: from [172.18.251.249] (pc975.sb.statsbiblioteket.dk [172.18.251.249])\n by luna.statsbiblioteket.dk\n (iPlanet Messaging Server 5.2 HotFix 1.16 (built May 14 2003))\n with ESMTP id &lt;0J8P00E7XPNURS@...&gt; for\n archive-crawler@yahoogroups.com; Tue, 14 Nov 2006 09:45:30 +0100 (MET)\r\nDate: Tue, 14 Nov 2006 09:45:29 +0100\r\nIn-reply-to: &lt;ej90v9+g8lo@...&gt;\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-id: &lt;45598229.7010809@...&gt;\r\nOrganization: Statsbiblioteket\r\nMIME-version: 1.0\r\nContent-type: multipart/mixed; boundary=&quot;Boundary_(ID_4/lX90UTtJZstPO9LBls4g)&quot;\r\nX-Accept-Language: en-us, en\r\nUser-Agent: Mozilla Thunderbird 1.0 (X11/20041206)\r\nReferences: &lt;ej90v9+g8lo@...&gt;\r\nFrom: Bjarne Andersen &lt;bja@...&gt;\r\nSubject: Re: [archive-crawler] Restricting Hertirx  ???\r\nX-Yahoo-Group-Post: member; u=165458231; y=VhpeXs7n8cVzauAGMhCr-_KjW_O761gTS3HQQw42RpfyNePpgvbw-w\r\nX-Yahoo-Profile: bjarne_dk2000\r\n\r\n\r\n--Boundary_(ID_4/lX90UTtJZstPO9LBls4g)\r\nContent-type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-transfer-encoding: 7BIT\r\n\r\nIf you can define what you don&#39;t want by regexp&#39;s you can just add an exclude-filter to your scope-section of order.xml\n\t    &lt;newObject name=&quot;exclude-filter&quot; class=&quot;org.archive.crawler.filter.OrFilter&quot;&gt;\n                 &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n                 &lt;boolean name=&quot;if-matches-return&quot;&gt;true&lt;/boolean&gt;\n                 &lt;map name=&quot;filters&quot;&gt;\n                     &lt;newObject name=&quot;not_wanted_URLs&quot; class=&quot;org.archive.crawler.filter.URIListRegExpFilter&quot;&gt;\n                         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n                         &lt;boolean name=&quot;if-match-return&quot;&gt;true&lt;/boolean&gt;\n                         &lt;string name=&quot;list-logic&quot;&gt;OR&lt;/string&gt;\n                         &lt;stringList name=&quot;regexp-list&quot;&gt;\n                             &lt;string&gt;www&#92;.xyz&#92;.com&#92;/teamprofile&#92;.html&lt;/string&gt;\n                             &lt;string&gt;.*another_unwanted_regexp_URI.*&lt;/string&gt;\n                         &lt;/stringList&gt;\n                     &lt;/newObject&gt;\n                 &lt;/map&gt;\n             &lt;/newObject&gt;\n\nIn the default profile you already have the exclude-filter section - in that case only add:\n\t\t    &lt;newObject name=&quot;not_wanted_URLs&quot; class=&quot;org.archive.crawler.filter.URIListRegExpFilter&quot;&gt;\n                         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n                         &lt;boolean name=&quot;if-match-return&quot;&gt;true&lt;/boolean&gt;\n                         &lt;string name=&quot;list-logic&quot;&gt;OR&lt;/string&gt;\n                         &lt;stringList name=&quot;regexp-list&quot;&gt;\n                             &lt;string&gt;www&#92;.xyz&#92;.com&#92;/teamprofile&#92;.html&lt;/string&gt;\n                             &lt;string&gt;.*another_unwanted_regexp_URI.*&lt;/string&gt;\n                         &lt;/stringList&gt;\n                     &lt;/newObject&gt;\n\nHope that helps\n\nbest\n-- \nBjarne Andersen\nDaily Manager - netarchive.dk\n\nState & University Library\nUniversitetsparken\nDK-8000 Aarhus C\nT: +45 89462165 - C: +45 25662353\nCVR/SE 10100682 - EAN 5798000791084\nhttp://netarchive.dk\n\njls_nayak1983 wrote:\n&gt; \n&gt; \n&gt; \n&gt; Hi,\n&gt; \n&gt; I have url &quot;http://www.xyz.com &lt;http://www.xyz.com&gt;&quot; in my seeds.txt \n&gt; file. When I run\n&gt; the heritrix it crawl various pages ie..\n&gt; \n&gt; http://www.xyz.com/robot.txt &lt;http://www.xyz.com/robot.txt&gt;\n&gt; http://www.xyz.com/index.html &lt;http://www.xyz.com/index.html&gt;\n&gt; http://www.xyz.com/documentaion.html &lt;http://www.xyz.com/documentaion.html&gt;\n&gt; http://www.xyz.com/faq.html &lt;http://www.xyz.com/faq.html&gt;\n&gt; http://www.xyz.com/teamprofile.html &lt;http://www.xyz.com/teamprofile.html&gt;\n&gt; \n&gt; Crawling is going fine. But I dont want the page\n&gt; http://www.xyz.com/teamprofile.html \n&gt; &lt;http://www.xyz.com/teamprofile.html&gt; to be crawled. To get this what I\n&gt; need to do ? What my seeds.txt file contains and what modifications in\n&gt; order.xml file must be made ? Please help me.\n&gt; \n&gt; Thanks\n&gt; J.L.Nayak\n&gt; \n&gt; \n\n\n\n\r\n--Boundary_(ID_4/lX90UTtJZstPO9LBls4g)\r\nContent-type: text/x-vcard; charset=utf-8; name=bja.vcf\r\nContent-disposition: attachment; filename=bja.vcf\r\n\r\n[ Attachment content not displayed ]\r\n--Boundary_(ID_4/lX90UTtJZstPO9LBls4g)--\r\n\n"}}