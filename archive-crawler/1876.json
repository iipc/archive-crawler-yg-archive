{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":215515511,"authorName":"Mike Schwartz","from":"Mike Schwartz &lt;mschwartz@...&gt;","profile":"mfschwartz","replyTo":"LIST","senderId":"8DzVxT586fxbsYbfB06xk7ij6hxdqPgewK98ChriCZJZUnOHdYxBZ0LuP2q5LhsWHXohKhy8p23ItVuxcKBW0Dc3zoIGO1w4Cqk","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] A mixed bag of issues, thoughts and  suggestions (long)]","postDate":"1116976147","msgId":1876,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDYuMi4wLjE0LjIuMjAwNTA1MjQxNzA0NTQuMDJiZDI1MjhAdmhvc3Q2LmF0b21pY3NlcnZlcnMuY29tPg==","inReplyToHeader":"PDQyOTNBMUFELjcwNzAwMDhAYXB0YXMuY29tPg==","referencesHeader":"PDQyOTNBMUFELjcwNzAwMDhAYXB0YXMuY29tPg=="},"prevInTopic":0,"nextInTopic":1886,"prevInTime":1875,"nextInTime":1877,"topicId":1876,"numMessagesInTopic":2,"msgSnippet":"hi, I have a request about the note below suggesting getting rid of the recovery journal: Can the IA folks please keep the recovery journal code in the","rawEmail":"Return-Path: &lt;mschwartz@...&gt;\r\nX-Sender: mschwartz@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 52044 invoked from network); 24 May 2005 23:09:06 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m25.grp.scd.yahoo.com with QMQP; 24 May 2005 23:09:06 -0000\r\nReceived: from unknown (HELO vhost6.atomicservers.com) (216.58.160.194)\n  by mta1.grp.scd.yahoo.com with SMTP; 24 May 2005 23:09:06 -0000\r\nReceived: from dev4lt.aptas.com ([64.78.237.253])\n\t(authenticated (0 bits))\n\tby vhost6.atomicservers.com (8.11.6/8.11.6) with ESMTP id j4ON95232207\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Tue, 24 May 2005 17:09:05 -0600\r\nMessage-Id: &lt;6.2.0.14.2.20050524170454.02bd2528@...&gt;\r\nX-Mailer: QUALCOMM Windows Eudora Version 6.2.0.14\r\nDate: Tue, 24 May 2005 17:09:07 -0600\r\nTo: archive-crawler@yahoogroups.com\r\nIn-Reply-To: &lt;4293A1AD.7070008@...&gt;\r\nReferences: &lt;4293A1AD.7070008@...&gt;\r\nMime-Version: 1.0\r\nContent-Type: multipart/alternative;\n\tboundary=&quot;=====================_273700890==.ALT&quot;\r\nX-eGroups-Msg-Info: 1:12:0\r\nFrom: Mike Schwartz &lt;mschwartz@...&gt;\r\nSubject: Re: [archive-crawler] A mixed bag of issues, thoughts and\n  suggestions (long)]\r\nX-Yahoo-Group-Post: member; u=215515511\r\nX-Yahoo-Profile: mfschwartz\r\n\r\n\r\n--=====================_273700890==.ALT\r\nContent-Type: text/plain; charset=&quot;us-ascii&quot;; format=flowed\r\n\r\nhi,\n\nI have a request about the note below suggesting getting rid of the \nrecovery journal:\n\nCan the IA folks please keep the recovery journal code in the released code \nbase (perhaps as a feature disabled by default)?  The reason is that our \ncrawls need to be able to track each URL crawled back to the seed via which \nit was emitted, and the RecoveryLogMapper class I contributed a few months \nago (org/archive/crawler/util/RecoveryLogMapper.java) reads through the \nrecovery journal to support this function.  I&#39;m guessing there are other \nfolks out there who would also find it useful to be able to do this, too.\n\nThanks\n  - Mike Schwartz\n\n&gt;-------- Original Message --------\n&gt;Subject:        [archive-crawler] A mixed bag of issues, thoughts and\n&gt;suggestions (long)\n&gt;Date:   Mon, 23 May 2005 10:53:05 -0000\n&gt;From:   Kristinn Sigurdsson &lt;kris@...&gt;\n&gt;Reply-To:       archive-crawler@yahoogroups.com\n&gt;To:     &lt;archive-crawler@yahoogroups.com&gt;\n&gt;\n&gt;\n&gt;\n&gt;The following is a mixed bag of issues, thoughts and suggestions that\n&gt;occurred to me during the last few weeks as I worked on the AR module\n&gt;and was managing a broad crawl. Some are more thought out then others\n&gt;and their importance varies wildly.\n&gt;\n&gt;Some of this is posted here to get some discussion, other bits are\n&gt;mostly pointed at the boys at the Archive. Basically, this is a mixed bag.\n&gt;\n&gt;*Remaining time*\n&gt;\n&gt;This feature is of negligible use and is more likely to confuse than\n&gt;inform users. The time estimate is only going to give a reasonable\n&gt;figure if there is only one host left (or several hosts with a similar\n&gt;number of documents) and we&#39;re already done with the &#39;discovery&#39; phase.\n&gt;This may be of use towards the end of some focused crawls, but generally\n&gt;this is of little value. Since this value is almost always wrong I\n&gt;believe that it is far more likely to confuse users. I also find it\n&gt;annoying to have another time counter as I occasionally get it mixed up\n&gt;when I&#39;m looking up the duration of the crawl, but that&#39;s a lesser issue.\n&gt;\n&gt;Unless the estimate can be improved significantly (and this requires\n&gt;taking into account the number of queues and their relative sizes and\n&gt;the politeness restrictions for anything approaching a reasonable\n&gt;estimate) I vote to remove this feature.\n&gt;\n&gt;\n&gt;*The &#39;Crawl resuming&#39; at the top of the progress-statistics.log*\n&gt;\n&gt;A change to how the crawls are started has led to a CRAWL RESUMING being\n&gt;printed at the top of the progress-statistics.log. Perhaps the events\n&gt;need to be augmented to include a CRAWL STARTING that the\n&gt;progress-statistics.log would ignore. In any case, this needs to be fixed.\n&gt;\n&gt;\n&gt;*Include actual memory used in the progress-statistics.log instead of or\n&gt;in addition to current heap size.*\n&gt;\n&gt;Actual memory used is of much greater interest, especially when looking\n&gt;through the log to see memory usage trends.\n&gt;\n&gt;\n&gt;*Default Bdb cache percent to something modest, like 35-40% (OOM errors)*\n&gt;\n&gt;The AR module encountered some issues with the default setting. I&#39;m not\n&gt;going to vote for any one value, but I suggest that crawls should always\n&gt;retain a good chunk of memory after the Bdb cache grows to its maximum\n&gt;allowed size.\n&gt;\n&gt;\n&gt;*Get rid of the recovery journal in favor of decent crash resistance via\n&gt;Bdb *\n&gt;\n&gt;This is a bigger issue (and I know it&#39;s something you guys want to do).\n&gt;The recovery journal has never (for me) worked as a crash recovery tool.\n&gt;The AR frontier is able to reconstruct itself based on its databases\n&gt;without any trouble. If done right, resuming a crawl could be done in a\n&gt;matter of seconds, instead of hours (or days). I&#39;d vote to make this the\n&gt;#1 priority for 1.6!\n&gt;\n&gt;\n&gt;*Allow frontiers to provide &#39;servlets&#39; that enables more detailed\n&gt;monitoring and control.*\n&gt;\n&gt;I don&#39;t really care how it&#39;s done, but we need to allow modules,\n&gt;especially (or even exclusively) Frontiers, need to have customized\n&gt;control pages!\n&gt;\n&gt;\n&gt;*Display data, 4GB should be 4.442GB etc.*\n&gt;\n&gt;Need to improve how data amounts are condensed, currently the jump from\n&gt;4095MB to 4GB lacks granularity. I&#39;d be happy to fix this if we could\n&gt;agree on exactly how things are supposed to be. My suggestion: show four\n&gt;characters. So we&#39;d go from 4095 MB to 4GB and then 4.001GB etc. when we\n&gt;hit 40GB we go to 40.01 etc. same for the move from B to KB and KB to MB\n&gt;\n&gt;Additionally, we could have a mouse-over pop up the exact number of bytes.\n&gt;\n&gt;\n&gt;*Default log lines to show be 40 instead of 50*\n&gt;\n&gt;A bit of a nit-pick. I&#39;ve got a screen running at 1024 lines of vertical\n&gt;resolution and 40 lines fill up my screen. Since not many users are\n&gt;likely to have higher resolution (in fact I&#39;d expect the average to be\n&gt;lower) I suggest we amend the default value to 40 (or possibly 35).\n&gt;\n&gt;\n&gt;*Link from help to /help/regexpr.jsp*\n&gt;\n&gt;I find this page invaluable when adding new regular expressions,\n&gt;especially to crawls in progress. Lets you double check those reg.expr.\n&gt;using the same interpreter. The page has been available for awhile, but\n&gt;either the link was dropped or it never existed. Either way, a link\n&gt;should be added to the help page.\n&gt;\n&gt;\n&gt;*Cost assignment on -5000/-5001*\n&gt;\n&gt;More of a question, do URIs that return with -500X &#39;cost&#39; anything? I&#39;d\n&gt;suggest that they shouldn&#39;t. After all, they aren&#39;t actually crawled.\n&gt;\n&gt;\n&gt;*HostnameQueueAssignmentPolicy attaches the port number to the hostname*\n&gt;\n&gt;Is this really sensible considering that these are used as the basic\n&gt;politeness units. Different ports, same server. I&#39;d think we&#39;d want to\n&gt;handle it all the same way.\n&gt;\n&gt;\n&gt;*Daily reports? Detailed look at the crawl, printed to a file daily? *\n&gt;\n&gt;I was thinking that it might be nice to add a &#39;Daily report&#39; feature to\n&gt;the StatisticsTracker. It would generate a (new) report file at a\n&gt;specified time each day. Information regarding the number of URIs,\n&gt;amount of data, bandwidth usage etc. would be printed, giving a nice\n&gt;summary on the progress so far.\n&gt;\n&gt;\n&gt;*URI reg.expr filter (OR based) that has a list of strings instead of\n&gt;just one.*\n&gt;\n&gt;I find myself using a series of URI reg.expr. filters to tackle numerous\n&gt;issues. I was thinking that it might be useful to add a similar filter\n&gt;that contained a list of strings. This would make it a lot easier to add\n&gt;additional filters while a crawl is in progress. I can handle this if\n&gt;you agree it&#39;s a good idea.\n&gt;\n&gt;\n&gt;*In help (and perhaps a link from the logs) provide a quick link to the\n&gt;result codes (local, not on web).*\n&gt;\n&gt;I find myself looking these up a lot. Having a handy, local reference\n&gt;would be useful. Should include both the HTTP codes and the ones\n&gt;specified by Heritrix.\n&gt;\n&gt;\n&gt;*Changes to Meta-data, description do not have any effect.*\n&gt;\n&gt;This has been around for awhile I think. The only time this is written\n&gt;is when a profile/job is created. Changes seem to have no effect.\n&gt;\n&gt;\n&gt;*Add items crawled to Bdb reports for each queue.*\n&gt;\n&gt;The BdbFrontier report should list the number or URIs crawled for each\n&gt;queue. Currently you can sort of calculate this based on the expenditure\n&gt;and average cost (which is of little use of you are using\n&gt;ZeroCostAssignmentPolicy).\n&gt;\n&gt;\n&gt;*BdbFrontier: Add a log that details when queues are created and move\n&gt;from active to inactive and finally to exhausted.*\n&gt;\n&gt;This would make it easier to monitor crawls. Basically when a queue\n&gt;moves between any of the above states a line should be written in the\n&gt;log. This way you could quickly grep through the log and see how that\n&gt;queue is being processed.\n&gt;\n&gt;The log line might look something like this:\n&gt;\n&gt;[time-date] [queue-name] [old state] [new state] [queue-size] [URIs\n&gt;crawled] [total expended] [last cost] [average cost]\n&gt;\n&gt;\n&gt;- Kris\n&gt;\n&gt;\n&gt;------------------------------------------------------------------------\n&gt;*Yahoo! Groups Links*\n&gt;\n&gt;     * To visit your group on the web, go to:\n&gt;       http://groups.yahoo.com/group/archive-crawler/\n&gt;\n&gt;     * To unsubscribe from this group, send an email to:\n&gt;       archive-crawler-unsubscribe@yahoogroups.com\n&gt;&lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;\n&gt;     * Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;.\n\r\n--=====================_273700890==.ALT\r\nContent-Type: text/html; charset=&quot;us-ascii&quot;\r\n\r\n&lt;html&gt;\n&lt;body&gt;\nhi,&lt;br&gt;&lt;br&gt;\nI have a request about the note below suggesting getting rid of the\nrecovery journal:&lt;br&gt;&lt;br&gt;\nCan the IA folks please keep the recovery journal code in the released\ncode base (perhaps as a feature disabled by default)?&nbsp; The reason is\nthat our crawls need to be able to track each URL crawled back to the\nseed via which it was emitted, and the RecoveryLogMapper class I\ncontributed a few months ago\n(org/archive/crawler/util/RecoveryLogMapper.java) reads through the\nrecovery journal to support this function.&nbsp; I&#39;m guessing there are\nother folks out there who would also find it useful to be able to do\nthis, too.&lt;br&gt;&lt;br&gt;\nThanks&lt;br&gt;\n&nbsp;- Mike Schwartz&lt;br&gt;&lt;br&gt;\n&lt;blockquote type=cite class=cite cite=&quot;&quot;&gt;&lt;font size=3&gt;-------- Original\nMessage --------&lt;br&gt;\nSubject:\n&lt;x-tab&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;/x-tab&gt;\n[archive-crawler] A mixed bag of issues, thoughts and&lt;br&gt;\nsuggestions (long)&lt;br&gt;\nDate: &lt;x-tab&gt;&nbsp;&nbsp;&lt;/x-tab&gt;Mon, 23 May 2005 10:53:05 -0000&lt;br&gt;\nFrom: &lt;x-tab&gt;&nbsp;&nbsp;&lt;/x-tab&gt;Kristinn Sigurdsson\n&lt;kris@...&gt;&lt;br&gt;\nReply-To:\n&lt;x-tab&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;/x-tab&gt;\narchive-crawler@yahoogroups.com&lt;br&gt;\nTo:\n&lt;x-tab&gt;&nbsp;&nbsp;&nbsp;&nbsp;&lt;/x-tab&gt;\n&lt;archive-crawler@yahoogroups.com&gt;&lt;br&gt;&lt;br&gt;\n&lt;br&gt;&lt;br&gt;\nThe following is a mixed bag of issues, thoughts and suggestions\nthat&lt;br&gt;\noccurred to me during the last few weeks as I worked on the AR\nmodule&lt;br&gt;\nand was managing a broad crawl. Some are more thought out then\nothers&lt;br&gt;\nand their importance varies wildly.&lt;br&gt;&lt;br&gt;\nSome of this is posted here to get some discussion, other bits are&lt;br&gt;\nmostly pointed at the boys at the Archive. Basically, this is a mixed\nbag.&lt;br&gt;&lt;br&gt;\n*Remaining time*&lt;br&gt;&lt;br&gt;\nThis feature is of negligible use and is more likely to confuse than&lt;br&gt;\ninform users. The time estimate is only going to give a reasonable&lt;br&gt;\nfigure if there is only one host left (or several hosts with a\nsimilar&lt;br&gt;\nnumber of documents) and we&#39;re already done with the &#39;discovery&#39;\nphase.&lt;br&gt;\nThis may be of use towards the end of some focused crawls, but\ngenerally&lt;br&gt;\nthis is of little value. Since this value is almost always wrong I&lt;br&gt;\nbelieve that it is far more likely to confuse users. I also find it&lt;br&gt;\nannoying to have another time counter as I occasionally get it mixed\nup&lt;br&gt;\nwhen I&#39;m looking up the duration of the crawl, but that&#39;s a lesser\nissue.&lt;br&gt;&lt;br&gt;\nUnless the estimate can be improved significantly (and this requires&lt;br&gt;\ntaking into account the number of queues and their relative sizes\nand&lt;br&gt;\nthe politeness restrictions for anything approaching a reasonable&lt;br&gt;\nestimate) I vote to remove this feature.&lt;br&gt;&lt;br&gt;\n&lt;br&gt;\n*The &#39;Crawl resuming&#39; at the top of the progress-statistics.log*&lt;br&gt;&lt;br&gt;\nA change to how the crawls are started has led to a CRAWL RESUMING\nbeing&lt;br&gt;\nprinted at the top of the progress-statistics.log. Perhaps the\nevents&lt;br&gt;\nneed to be augmented to include a CRAWL STARTING that the&lt;br&gt;\nprogress-statistics.log would ignore. In any case, this needs to be\nfixed.&lt;br&gt;&lt;br&gt;\n&lt;br&gt;\n*Include actual memory used in the progress-statistics.log instead of\nor&lt;br&gt;\nin addition to current heap size.*&lt;br&gt;&lt;br&gt;\nActual memory used is of much greater interest, especially when\nlooking&lt;br&gt;\nthrough the log to see memory usage trends.&lt;br&gt;&lt;br&gt;\n&lt;br&gt;\n*Default Bdb cache percent to something modest, like 35-40% (OOM\nerrors)*&lt;br&gt;&lt;br&gt;\nThe AR module encountered some issues with the default setting. I&#39;m\nnot&lt;br&gt;\ngoing to vote for any one value, but I suggest that crawls should\nalways&lt;br&gt;\nretain a good chunk of memory after the Bdb cache grows to its\nmaximum&lt;br&gt;\nallowed size.&lt;br&gt;&lt;br&gt;\n&lt;br&gt;\n*Get rid of the recovery journal in favor of decent crash resistance\nvia&lt;br&gt;\nBdb *&lt;br&gt;&lt;br&gt;\nThis is a bigger issue (and I know it&#39;s something you guys want to\ndo).&lt;br&gt;\nThe recovery journal has never (for me) worked as a crash recovery\ntool.&lt;br&gt;\nThe AR frontier is able to reconstruct itself based on its databases&lt;br&gt;\nwithout any trouble. If done right, resuming a crawl could be done in\na&lt;br&gt;\nmatter of seconds, instead of hours (or days). I&#39;d vote to make this\nthe&lt;br&gt;\n#1 priority for 1.6!&lt;br&gt;&lt;br&gt;\n&lt;br&gt;\n*Allow frontiers to provide &#39;servlets&#39; that enables more detailed&lt;br&gt;\nmonitoring and control.*&lt;br&gt;&lt;br&gt;\nI don&#39;t really care how it&#39;s done, but we need to allow modules,&lt;br&gt;\nespecially (or even exclusively) Frontiers, need to have customized&lt;br&gt;\ncontrol pages!&lt;br&gt;&lt;br&gt;\n&lt;br&gt;\n*Display data, 4GB should be 4.442GB etc.*&lt;br&gt;&lt;br&gt;\nNeed to improve how data amounts are condensed, currently the jump\nfrom&lt;br&gt;\n4095MB to 4GB lacks granularity. I&#39;d be happy to fix this if we\ncould&lt;br&gt;\nagree on exactly how things are supposed to be. My suggestion: show\nfour&lt;br&gt;\ncharacters. So we&#39;d go from 4095 MB to 4GB and then 4.001GB etc. when\nwe&lt;br&gt;\nhit 40GB we go to 40.01 etc. same for the move from B to KB and KB to\nMB&lt;br&gt;&lt;br&gt;\nAdditionally, we could have a mouse-over pop up the exact number of\nbytes.&lt;br&gt;&lt;br&gt;\n&lt;br&gt;\n*Default log lines to show be 40 instead of 50*&lt;br&gt;&lt;br&gt;\nA bit of a nit-pick. I&#39;ve got a screen running at 1024 lines of\nvertical&lt;br&gt;\nresolution and 40 lines fill up my screen. Since not many users are&lt;br&gt;\nlikely to have higher resolution (in fact I&#39;d expect the average to\nbe&lt;br&gt;\nlower) I suggest we amend the default value to 40 (or possibly\n35).&lt;br&gt;&lt;br&gt;\n&lt;br&gt;\n*Link from help to /help/regexpr.jsp*&lt;br&gt;&lt;br&gt;\nI find this page invaluable when adding new regular expressions,&lt;br&gt;\nespecially to crawls in progress. Lets you double check those\nreg.expr.&lt;br&gt;\nusing the same interpreter. The page has been available for awhile,\nbut&lt;br&gt;\neither the link was dropped or it never existed. Either way, a link&lt;br&gt;\nshould be added to the help page.&lt;br&gt;&lt;br&gt;\n&lt;br&gt;\n*Cost assignment on -5000/-5001*&lt;br&gt;&lt;br&gt;\nMore of a question, do URIs that return with -500X &#39;cost&#39; anything?\nI&#39;d&lt;br&gt;\nsuggest that they shouldn&#39;t. After all, they aren&#39;t actually\ncrawled.&lt;br&gt;&lt;br&gt;\n&lt;br&gt;\n*HostnameQueueAssignmentPolicy attaches the port number to the\nhostname*&lt;br&gt;&lt;br&gt;\nIs this really sensible considering that these are used as the basic&lt;br&gt;\npoliteness units. Different ports, same server. I&#39;d think we&#39;d want\nto&lt;br&gt;\nhandle it all the same way.&lt;br&gt;&lt;br&gt;\n&lt;br&gt;\n*Daily reports? Detailed look at the crawl, printed to a file daily?\n*&lt;br&gt;&lt;br&gt;\nI was thinking that it might be nice to add a &#39;Daily report&#39; feature\nto&lt;br&gt;\nthe StatisticsTracker. It would generate a (new) report file at a&lt;br&gt;\nspecified time each day. Information regarding the number of URIs,&lt;br&gt;\namount of data, bandwidth usage etc. would be printed, giving a nice&lt;br&gt;\nsummary on the progress so far.&lt;br&gt;&lt;br&gt;\n&lt;br&gt;\n*URI reg.expr filter (OR based) that has a list of strings instead\nof&lt;br&gt;\njust one.*&lt;br&gt;&lt;br&gt;\nI find myself using a series of URI reg.expr. filters to tackle\nnumerous&lt;br&gt;\nissues. I was thinking that it might be useful to add a similar\nfilter&lt;br&gt;\nthat contained a list of strings. This would make it a lot easier to\nadd&lt;br&gt;\nadditional filters while a crawl is in progress. I can handle this\nif&lt;br&gt;\nyou agree it&#39;s a good idea.&lt;br&gt;&lt;br&gt;\n&lt;br&gt;\n*In help (and perhaps a link from the logs) provide a quick link to\nthe&lt;br&gt;\nresult codes (local, not on web).*&lt;br&gt;&lt;br&gt;\nI find myself looking these up a lot. Having a handy, local\nreference&lt;br&gt;\nwould be useful. Should include both the HTTP codes and the ones&lt;br&gt;\nspecified by Heritrix.&lt;br&gt;&lt;br&gt;\n&lt;br&gt;\n*Changes to Meta-data, description do not have any effect.*&lt;br&gt;&lt;br&gt;\nThis has been around for awhile I think. The only time this is\nwritten&lt;br&gt;\nis when a profile/job is created. Changes seem to have no\neffect.&lt;br&gt;&lt;br&gt;\n&lt;br&gt;\n*Add items crawled to Bdb reports for each queue.*&lt;br&gt;&lt;br&gt;\nThe BdbFrontier report should list the number or URIs crawled for\neach&lt;br&gt;\nqueue. Currently you can sort of calculate this based on the\nexpenditure&lt;br&gt;\nand average cost (which is of little use of you are using&lt;br&gt;\nZeroCostAssignmentPolicy).&lt;br&gt;&lt;br&gt;\n&lt;br&gt;\n*BdbFrontier: Add a log that details when queues are created and\nmove&lt;br&gt;\nfrom active to inactive and finally to exhausted.*&lt;br&gt;&lt;br&gt;\nThis would make it easier to monitor crawls. Basically when a queue&lt;br&gt;\nmoves between any of the above states a line should be written in\nthe&lt;br&gt;\nlog. This way you could quickly grep through the log and see how\nthat&lt;br&gt;\nqueue is being processed.&lt;br&gt;&lt;br&gt;\nThe log line might look something like this:&lt;br&gt;&lt;br&gt;\n[time-date] [queue-name] [old state] [new state] [queue-size] [URIs&lt;br&gt;\ncrawled] [total expended] [last cost] [average cost]&lt;br&gt;&lt;br&gt;\n&lt;br&gt;\n- Kris&lt;br&gt;&lt;br&gt;\n&lt;br&gt;\n------------------------------------------------------------------------&lt;br&gt;\n*Yahoo! Groups Links*&lt;br&gt;&lt;br&gt;\n&nbsp;&nbsp;&nbsp; * To visit your group on the web, go to:&lt;br&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n&lt;a href=&quot;http://groups.yahoo.com/group/archive-crawler/&quot; eudora=&quot;autourl&quot;&gt;\nhttp://groups.yahoo.com/group/archive-crawler/&lt;/a&gt;&lt;br&gt;&lt;br&gt;\n&nbsp;&nbsp;&nbsp; * To unsubscribe from this group, send an email\nto:&lt;br&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\narchive-crawler-unsubscribe@yahoogroups.com&lt;br&gt;\n&lt;&lt;a href=&quot;mailto:archive-crawler-unsubscribe@yahoogroups.com%3Fsubject=Unsubscribe&quot; eudora=&quot;autourl&quot;&gt;\nmailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&lt;/a&gt;\n&gt;&lt;br&gt;&lt;br&gt;\n&nbsp;&nbsp;&nbsp; * Your use of Yahoo! Groups is subject to the Yahoo!\nTerms of&lt;br&gt;\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Service\n&lt;&lt;a href=&quot;http://docs.yahoo.com/info/terms/&quot; eudora=&quot;autourl&quot;&gt;\nhttp://docs.yahoo.com/info/terms/&lt;/a&gt;&gt;.&lt;br&gt;\n&lt;/font&gt;&lt;/blockquote&gt;&lt;/body&gt;\n&lt;/html&gt;\n\r\n--=====================_273700890==.ALT--\r\n\n"}}