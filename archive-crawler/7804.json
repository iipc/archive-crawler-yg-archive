{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"2un4Z_LGWq4lm2W3Xzke_nz3MVqDzYXLr883jjEHJbLX4cgnUY3U4CnhqD2BuVCysTxETAi9O68tyehU1CJQ99BrXFCW7Gk","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] Recovering a crawler","postDate":"1348865189","msgId":7804,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDUwNjYwQ0E1LjgwNzA5MDhAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDc0Qzk3RTdERjVBNzc4NEQ5OTcyMTdGRjc1RDEyMTY2MEZDMUQ5NTdAdzJrMy1ic3BleDE+","referencesHeader":"PDc0Qzk3RTdERjVBNzc4NEQ5OTcyMTdGRjc1RDEyMTY2MEZDMUQ3NDhAdzJrMy1ic3BleDE+IDw1MDYzMkRDNS43MDUwNzAwQGFyY2hpdmUub3JnPiA8NzRDOTdFN0RGNUE3Nzg0RDk5NzIxN0ZGNzVEMTIxNjYwRkMxRDk1N0B3MmszLWJzcGV4MT4="},"prevInTopic":7803,"nextInTopic":0,"prevInTime":7803,"nextInTime":7805,"topicId":7795,"numMessagesInTopic":5,"msgSnippet":"The stack dumps show the launchthread in BDB-JE code enumerating state file, holding a lock that is also blocking a web UI request. Normally, BDB-JE s","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 55074 invoked from network); 28 Sep 2012 20:46:40 -0000\r\nX-Received: from unknown (98.137.35.161)\n  by m10.grp.sp2.yahoo.com with QMQP; 28 Sep 2012 20:46:40 -0000\r\nX-Received: from unknown (HELO relay02.pair.com) (209.68.5.16)\n  by mta5.grp.sp2.yahoo.com with SMTP; 28 Sep 2012 20:46:39 -0000\r\nX-Received: (qmail 93154 invoked by uid 0); 28 Sep 2012 20:46:37 -0000\r\nX-Received: from 174.240.39.65 (HELO silverbook.local) (174.240.39.65)\n  by relay02.pair.com with SMTP; 28 Sep 2012 20:46:37 -0000\r\nX-pair-Authenticated: 174.240.39.65\r\nMessage-ID: &lt;50660CA5.8070908@...&gt;\r\nDate: Fri, 28 Sep 2012 13:46:29 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.7; rv:15.0) Gecko/20120907 Thunderbird/15.0.1\r\nMIME-Version: 1.0\r\nTo: &quot;Coram, Roger&quot; &lt;Roger.Coram@...&gt;\r\nCc: archive-crawler@yahoogroups.com\r\nReferences: &lt;74C97E7DF5A7784D997217FF75D121660FC1D748@w2k3-bspex1&gt; &lt;50632DC5.7050700@...&gt; &lt;74C97E7DF5A7784D997217FF75D121660FC1D957@w2k3-bspex1&gt;\r\nIn-Reply-To: &lt;74C97E7DF5A7784D997217FF75D121660FC1D957@w2k3-bspex1&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Recovering a crawler\r\nX-Yahoo-Group-Post: member; u=137285340; y=6Rv31WXvWSFVkmoW4pEB1M4oQTcfRMmJSrbje68i3PJk\r\nX-Yahoo-Profile: gojomo\r\n\r\nThe stack dumps show the &#39;launchthread&#39; in BDB-JE code enumerating state \nfile, holding a lock that is also blocking a web UI request.\n\nNormally, BDB-JE&#39;s initial opening of the prior state is pretty quick -- \nI&#39;ve not noticed it taking a long time. But, perhaps in a very large or \noften-reused state directory, or in the presence of some other issues \n(IO contention? network-shared drive? filesystem unlike my prior \nexperience?), there are new issues making it take pathologically long.\n\n(I might also collect a few jstacks over a short period to see whether \nthe BDB-JE code is always in that listFiles, or ranging over several \ntasks; and check system logs to see if perhaps some OS or HW issues \nmight be making normally fast operations slow.)\n\nAs Kenji notes, you may not need the old &#39;state&#39; material to be \navailable for the relaunch at all. It is needed if you&#39;re using \nHeritrix&#39;s &#39;checkpoints&#39;, and may be if you&#39;re using the \nduplication-reduction/Persist-history functions (and haven&#39;t sent that \noff to a separate BDB environment). But, for an old-style recovery-log \nreplay, only the scan of that log is needed to reproduce the \nfrontier-state. So, the &#39;state&#39; directory could be discarded or moved \naside, just as if in H1 starting a new crawl with an empty &#39;state&#39; \ndirectory.\n\nIf that works to circumvent the BDB-JE delay, I would still expect the \nreplay of a large recovery log to take many hours... but it would be \nproceeding in a thread servicing the &#39;action&#39; directory, and I wouldn&#39;t \nexpect it to block the web UI.\n\n- Gordon\n\nOn 9/27/12 2:45 AM, Coram, Roger wrote:\n&gt; Hi Gordon,\n&gt; The recovery-log approach is the one we&#39;ve used in the past\n&gt; (build-&gt;launch paused-&gt;copy log-&gt;unpause when complete). However, in\n&gt; this case we&#39;re not even getting as far as copying the file to the\n&gt; &#39;action&#39; directory. The heritrix_out.log show the following, then\n&gt; nothing more:\n&gt;\n&gt; \t2012-09-27 08:25:40.880 INFO thread-11\n&gt; org.archive.crawler.framework.CrawlJob.launch() Job launched\n&gt; \t2012-09-27 08:25:42.387 INFO thread-12\n&gt; org.archive.spring.PathSharingContext.initLaunchId() launch id\n&gt; 20120927082542\n&gt; \t2012-09-27 08:25:42.591 INFO thread-12\n&gt; org.springframework.context.support.DefaultLifecycleProcessor$LifecycleG\n&gt; roup.start() Starting beans in phase 0\n&gt;\n&gt; The JVM is definitely busy and an &#39;lsof&#39; implies that it&#39;s accessing the\n&gt; contents of the &#39;state&#39; directory; the frontier.recover.gz isn&#39;t being\n&gt; written to.\n&gt;\n&gt; I&#39;ve attached a section from jstack - am I right in inferring that the\n&gt; BLOCKED thread is the web-UI?\n&gt;\n&gt; Many thanks,\n&gt; Roger\n&gt;\n&gt;\n&gt; -----Original Message-----\n&gt; From: Gordon Mohr [mailto:gojomo@...]\n&gt; Sent: 26 September 2012 17:31\n&gt; To: archive-crawler@yahoogroups.com\n&gt; Cc: Coram, Roger\n&gt; Subject: Re: [archive-crawler] Recovering a crawler\n&gt;\n&gt; A recovery using the H3 checkpointing mechanism, if such a checkpoint is\n&gt; available, should be very quick (almost instant).\n&gt;\n&gt; Using the recovery log approach will take much longer -- on the order of\n&gt; days to replay weeks&#39; worth of prior crawling is not surprising.\n&gt;\n&gt; Note that in H3, to use the recovery-log approach, you&#39;d normally drop\n&gt; the &quot;.recover.gz&quot; log into the &#39;action&#39; directory and do a &#39;paused&#39;\n&gt; launch of the crawl, only unpausing the crawl once there&#39;s evidence of\n&gt; some number of URIs appearing in the frontier queues. (That can take a\n&gt; while, because first there&#39;s one pass of the entire .recover log to\n&gt; discover already-visited URIs, then a 2nd pass to add URis.)\n&gt;\n&gt; I don&#39;t think that any part of this should block the UI, so there may be\n&gt; something else wrong. One way to confirm progress would be to check that\n&gt; the machine is CPU/IO busy and that repeated Java thread dumps (via the\n&gt; &#39;jstack&#39; utility or sending a SIGQUIT and viewing the heritrix_out log)\n&gt; show stacks suggesting intended activity. (This might also reveal if\n&gt; there&#39;s a good reason for the unresponsive web UI.) I also believe the\n&gt; new launch&#39;s &#39;.recovery.gz&#39; file would be growing during an in-progress\n&gt; recovery.\n&gt;\n&gt;\n&gt; If for some reason the recovery is hung, the heritrix_out.log or thread\n&gt; dumps might indicate why with an error or suspicious thread stack.\n&gt;\n&gt; - Gordon\n&gt;\n&gt; On 9/26/12 2:19 AM, Coram, Roger wrote:\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; Hi,\n&gt;&gt;\n&gt;&gt; One of our crawlers had to be restarted several weeks into a crawl\n&gt;&gt; (H3.1.1). After a successful build and clicking &#39;Launch&#39; the crawler\n&gt;&gt; and its web-UI have been completely unresponsive (the last job.log\n&gt;&gt; entry was &quot;INFO Job launched&quot; nearly 48 hours ago). The &#39;state&#39;\n&gt;&gt; directory for this particular crawler (using the\n&gt;&gt; PersistStoreProcessor) is more than 3TB in size.\n&gt;&gt;\n&gt;&gt; My question: how long can a recovery typically take? We&#39;ve had to\n&gt;&gt; recover crawlers before but it&#39;s never taken quite this long before.\n&gt;&gt; Is there some way to figure out what it&#39;s doing?\n&gt;&gt;\n&gt;&gt; Thanks.\n&gt;&gt;\n&gt;&gt; Roger G. Coram\n&gt;&gt;\n&gt;&gt; Web Archiving Engineer\n&gt;&gt;\n&gt;&gt; The British Library\n&gt;&gt;\n&gt;&gt; T: +44 (0)1937 546607\n&gt;&gt;\n&gt;&gt; F: +44 (0)1937 546872\n&gt;&gt;\n&gt;&gt; E: roger.coram@... &lt;mailto:roger.coram@...&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; \n\n"}}