{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"Michael Stack","from":"Michael Stack &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"vBloYQAKdTi816d4VSUY2w6-pqcQukjyVBphSNn5Ujfp5niUZTTV_hb2n117KM2K97QDSLXweSOT2kbt2MHaIwLSjKf4vNXB","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Carrying the already-seen list between crawls","postDate":"1148061622","msgId":2871,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ0NkUwN0I2LjgwNTA4MDNAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGI4MTI1OWEwMDYwNTE5MTAwOHUyMjljZDdmZGtmZjI4MmZmZmZmN2ZlYzE1QG1haWwuZ21haWwuY29tPg==","referencesHeader":"PGI4MTI1OWEwMDYwNDE4MTgwN2w3NThiNmJiM3NiZWJhMWNkNWQ2MjhlMDFiQG1haWwuZ21haWwuY29tPgkgPDQ0NDVEOENBLjMwMjA1MDdAYXJjaGl2ZS5vcmc+IDxiODEyNTlhMDA2MDUxOTEwMDh1MjI5Y2Q3ZmRrZmYyODJmZmZmZjdmZWMxNUBtYWlsLmdtYWlsLmNvbT4="},"prevInTopic":2870,"nextInTopic":2880,"prevInTime":2870,"nextInTime":2872,"topicId":2791,"numMessagesInTopic":7,"msgSnippet":"... Do you think such an option would be of general use?  Running checkpointing costs little if you use the Fast checkpointing mode.  At least that is our","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 21505 invoked from network); 19 May 2006 18:00:15 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m29.grp.scd.yahoo.com with QMQP; 19 May 2006 18:00:14 -0000\r\nReceived: from unknown (HELO dns.duboce.net) (63.203.238.114)\n  by mta4.grp.scd.yahoo.com with SMTP; 19 May 2006 18:00:14 -0000\r\nReceived: from [192.168.1.105] ([192.168.1.105])\n\tby dns-eth1.duboce.net (8.10.2/8.10.2) with ESMTP id k4JGkMw14532;\n\tFri, 19 May 2006 09:46:22 -0700\r\nMessage-ID: &lt;446E07B6.8050803@...&gt;\r\nDate: Fri, 19 May 2006 11:00:22 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; PPC Mac OS X Mach-O; en-US; rv:1.8.0.1) Gecko/20060127 SeaMonkey/1.0\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;b81259a00604181807l758b6bb3sbeba1cd5d628e01b@...&gt;\t &lt;4445D8CA.3020507@...&gt; &lt;b81259a00605191008u229cd7fdkff282fffff7fec15@...&gt;\r\nIn-Reply-To: &lt;b81259a00605191008u229cd7fdkff282fffff7fec15@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: Michael Stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] Carrying the already-seen list between crawls\r\nX-Yahoo-Group-Post: member; u=168599281; y=va8rKezO-hB4S6qw17P0vapQ-XwJH4Ni0migyzgXpka3JasUhRW_RCl2\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\nGreg Kempe wrote:\n&gt; ...\n&gt; On a related note, how possible is it for a BdbFrontier to recover\n&gt; using only the bdb environment? That is, how important is the\n&gt; org.archive.crawler.frontier.BdbFrontier.serialized file created\n&gt; during a checkpoint (or any of the other .serialized files, for that\n&gt; matter)? If the crawler could resume using only the bdb environment,\n&gt; explicit checkpoints could be optional. In such a case things like\n&gt; statistics may be lost, but at least the already-seen list and\n&gt; frontier would be recoverable. The alternative -- using recover.gz --\n&gt; loses the same data but is more cumbersome to resume from.\n&gt;\nDo you think such an option would be of general use?  Running \ncheckpointing costs little if you use the &#39;Fast checkpointing&#39; mode.  At \nleast that is our impression.  Is yours different?  Run it often.  With \ncheckpointing you can be &#39;certain&#39; you&#39;re resuming from a wholesome state.\n\nThe alternative, having the crawler just start with whatever the current \nstate of the bdb dbs, is likely doable but we would need to spend time \nmaking sure crawler is in a determinate state whatever the last \ncondition of the bdb dbs and we&#39;d need to make reconciliation \ninternally: e.g.  adjusting a clean statistics object to go against \nalready-populated bdb dbs.  The latter task can be costly.  IIRC, just \ngettting a count of whats in the bdb took a long time.  When I last \nlooked at this stuff, it took longer than a checkpoint recovery (With a \ncheckpoint recovery we serialize out the statistics class.  It is \nkeeping the running counts of bdb content).\n\nOne idea we&#39;ve kicked around is having the recover.gz log start over at \neach checkpoint.  After a checkpoint recovery, optionally you could \nreplay the recovery.gz to bring the crawler even closer to the crash point.\n\nAnother idea is having the already-seen external to the crawler \npersisting across crawls.\n\nSt.Ack\n\n"}}