{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":465980601,"authorName":"Zach Bailey","from":"Zach Bailey &lt;zach.bailey@...&gt;","replyTo":"LIST","senderId":"OWYqz1vjnMbDz1ZoN8R6-uI8khvmXrzbhN6Eq0qMQU86FnW-qGAIZhJnMfA-LB1MeDUTTxx0kAYebCc8r_ntcvAIynFU_3TnwTf9RQc","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Simple, single-site crawl &quot;hangs&quot; on last few URIs?","postDate":"1285182322","msgId":6739,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEFBTkxrVGk9eWh1TVpHRk8xNWs0T2FIN1RSUHllVF9ncj1CaUR6ejlRV0ZOd0BtYWlsLmdtYWlsLmNvbT4="},"prevInTopic":0,"nextInTopic":6740,"prevInTime":6738,"nextInTime":6740,"topicId":6739,"numMessagesInTopic":4,"msgSnippet":"I ve been proving out our use of heritrix over the past week or so and I ve noticed the following issue when doing a simple, single-domain crawl. Here is how I","rawEmail":"Return-Path: &lt;zach.bailey@...&gt;\r\nX-Sender: zach.bailey@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 61488 invoked from network); 22 Sep 2010 19:05:22 -0000\r\nX-Received: from unknown (98.137.34.46)\n  by m1.grp.sp2.yahoo.com with QMQP; 22 Sep 2010 19:05:22 -0000\r\nX-Received: from unknown (HELO mail-pv0-f180.google.com) (74.125.83.180)\n  by mta3.grp.sp2.yahoo.com with SMTP; 22 Sep 2010 19:05:22 -0000\r\nX-Received: by pvc30 with SMTP id 30so319522pvc.11\n        for &lt;archive-crawler@yahoogroups.com&gt;; Wed, 22 Sep 2010 12:05:22 -0700 (PDT)\r\nMIME-Version: 1.0\r\nX-Received: by 10.114.102.20 with SMTP id z20mr714583wab.133.1285182322204; Wed,\n 22 Sep 2010 12:05:22 -0700 (PDT)\r\nX-Received: by 10.115.92.6 with HTTP; Wed, 22 Sep 2010 12:05:22 -0700 (PDT)\r\nDate: Wed, 22 Sep 2010 15:05:22 -0400\r\nMessage-ID: &lt;AANLkTi=yhuMZGFO15k4OaH7TRPyeT_gr=BiDzz9QWFNw@...&gt;\r\nTo: archive-crawler &lt;archive-crawler@yahoogroups.com&gt;\r\nContent-Type: multipart/alternative; boundary=001636457194c967880490ddd32d\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Zach Bailey &lt;zach.bailey@...&gt;\r\nSubject: Simple, single-site crawl &quot;hangs&quot; on last few URIs?\r\nX-Yahoo-Group-Post: member; u=465980601\r\n\r\n\r\n--001636457194c967880490ddd32d\r\nContent-Type: text/plain; charset=ISO-8859-1\r\n\r\nI&#39;ve been proving out our use of heritrix over the past week or so and I&#39;ve\nnoticed the following issue when doing a simple, single-domain crawl.\n\nHere is how I have the crawl configured - it is a mostly vanilla crawl\nconfiguration save for the following modifications:\n\n* metadata.operatorContactUrl specified (obviously)\n* seeds.textSource.value set to a single domain\n* Scope chain modifications: TooManyHopsDecideRule.maxHops = 3 and added\nMatchesFilePatternDecideRule with decision=REJECT and usePreset=ALL right\nbefore the PrerequisiteAcceptDecideRule\n* fetch processor modifications: removed extractorJS, extractorCSS, and\nextractorSWF\n\nThe crawl runs fine and when it gets down to the last couple of URLs it\n&quot;hangs&quot; and does not complete. Looking at the job status page I see:\n\n*Totals*\n   215 downloaded + 4 queued = 219 total\n   2.5 MiB crawled (2.5 MiB novel, 0 B dup-by-hash, 0 B not-modified)\n\n*Frontier*\n   17 URI queues: 2 active (0 in-process; 0 ready; 2 snoozed); 0 inactive; 0\nineligible; 0 retired; 15 exhausted [RUN: 0 in, 0 out]\n\nExamining the frontier report I see the following:\n\n -----===== SNOOZED QUEUES =====-----\nSNOOZED#0:\nQueue ssl, (p1)\n  2 items\n   wakes in: 7m25s888ms\n    last enqueued: dns:ssl\n      last peeked: dns:ssl\n   total expended: 4 (total budget: -1)\n   active balance: 2996\n   last(avg) cost: 1(1)\n   totalScheduled fetchSuccesses fetchFailures fetchDisregards\nfetchResponses robotsDenials successBytes totalBytes fetchNonResponses\n   2 0 0 0 0 0 0 0 5\n   SimplePrecedenceProvider\n   1\n\nSNOOZED#1:\nQueue www, (p1)\n  2 items\n   wakes in: 7m25s889ms\n    last enqueued: dns:www\n      last peeked: dns:www\n   total expended: 4 (total budget: -1)\n   active balance: 2996\n   last(avg) cost: 1(1)\n   totalScheduled fetchSuccesses fetchFailures fetchDisregards\nfetchResponses robotsDenials successBytes totalBytes fetchNonResponses\n   2 0 0 0 0 0 0 0 5\n   SimplePrecedenceProvider\n   1\n\nSo, it looks like there are some weird items being put into these queues\nthat don&#39;t belong there and it&#39;s hanging the crawl job? Is there a\nconfiguration option I can tweak to retire these queues or clear them out\nafter a specified idle period? Or, is this the result of a misconfiguration\nsomewhere?\n\nThanks,\n-Zach\n\r\n--001636457194c967880490ddd32d\r\nContent-Type: text/html; charset=ISO-8859-1\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nI&#39;ve been proving out our use of heritrix over the past week or so and =\r\nI&#39;ve noticed the following issue when doing a simple, single-domain cra=\r\nwl.&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Here is how I have the crawl configured - it is a mo=\r\nstly vanilla crawl configuration save for the following modifications:&lt;/div=\r\n&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;*=A0metadata.operatorContactUrl specified (obviously)=\r\n&lt;/div&gt;&lt;div&gt;* seeds.textSource.value set to a single domain&lt;/div&gt;&lt;div&gt;* Scop=\r\ne chain modifications: TooManyHopsDecideRule.maxHops =3D 3 and added Matche=\r\nsFilePatternDecideRule with decision=3DREJECT and usePreset=3DALL right bef=\r\nore the PrerequisiteAcceptDecideRule&lt;/div&gt;\n&lt;div&gt;* fetch processor modificat=\r\nions: removed extractorJS, extractorCSS, and extractorSWF&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/d=\r\niv&gt;&lt;div&gt;The crawl runs fine and when it gets down to the last couple of URL=\r\ns it &quot;hangs&quot; and does not complete. Looking at the job status pag=\r\ne I see:&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;meta charset=3D&quot;utf-8&quot;&gt;&lt;meta charset=3D=\r\n&quot;utf-8&quot;&gt;&lt;b&gt;&lt;font class=3D&quot;Apple-style-span&quot; face=3D&quot;arial, helvetica, sans-=\r\nserif&quot;&gt;Totals&lt;/font&gt;&lt;/b&gt;&lt;font class=3D&quot;Apple-style-span&quot; face=3D&quot;arial, hel=\r\nvetica, sans-serif&quot;&gt;&lt;br&gt;\n=A0=A0 215 downloaded + 4 queued =3D 219 total=A0&lt;=\r\nbr&gt;=A0=A0 2.5 MiB crawled (2.5 MiB novel, 0 B dup-by-hash, 0 B not-modified=\r\n)=A0&lt;/font&gt;&lt;/div&gt;&lt;div&gt;&lt;font class=3D&quot;Apple-style-span&quot; face=3D&quot;arial, helve=\r\ntica, sans-serif&quot;&gt;&lt;span class=3D&quot;Apple-style-span&quot; style=3D&quot;font-size: smal=\r\nl;&quot;&gt;&lt;br&gt;\n&lt;/span&gt;&lt;/font&gt;&lt;/div&gt;&lt;div&gt;&lt;meta charset=3D&quot;utf-8&quot;&gt;&lt;b&gt;&lt;font class=3D=\r\n&quot;Apple-style-span&quot; face=3D&quot;arial, helvetica, sans-serif&quot;&gt;Frontier&lt;/font&gt;&lt;/b=\r\n&gt;&lt;font class=3D&quot;Apple-style-span&quot; face=3D&quot;arial, helvetica, sans-serif&quot;&gt;&lt;br=\r\n&gt;=A0=A0 17 URI queues: 2 active (0 in-process; 0 ready; 2 snoozed); 0 inact=\r\nive; 0 ineligible; 0 retired; 15 exhausted [RUN: 0 in, 0 out]=A0&lt;/font&gt;&lt;/di=\r\nv&gt;\n&lt;div&gt;&lt;font class=3D&quot;Apple-style-span&quot; face=3D&quot;arial, helvetica, sans-ser=\r\nif&quot;&gt;&lt;br&gt;&lt;/font&gt;&lt;/div&gt;&lt;div&gt;&lt;font class=3D&quot;Apple-style-span&quot; face=3D&quot;arial, h=\r\nelvetica, sans-serif&quot;&gt;Examining the frontier report I see the following:&lt;/f=\r\nont&gt;&lt;/div&gt;\n&lt;div&gt;&lt;font class=3D&quot;Apple-style-span&quot; face=3D&quot;arial, helvetica, =\r\nsans-serif&quot;&gt;&lt;meta charset=3D&quot;utf-8&quot;&gt;&lt;span class=3D&quot;Apple-style-span&quot; style=\r\n=3D&quot;font-family: Times; font-size: medium; &quot;&gt;&lt;pre style=3D&quot;word-wrap: break=\r\n-word; white-space: pre-wrap; &quot;&gt;\n -----=3D=3D=3D=3D=3D SNOOZED QUEUES =3D=\r\n=3D=3D=3D=3D-----\nSNOOZED#0:\nQueue ssl, (p1)\n  2 items\n   wakes in: 7m25s88=\r\n8ms\n    last enqueued: dns:ssl\n      last peeked: dns:ssl\n   total expended=\r\n: 4 (total budget: -1)\n   active balance: 2996\n   last(avg) cost: 1(1)\n   t=\r\notalScheduled fetchSuccesses fetchFailures fetchDisregards fetchResponses r=\r\nobotsDenials successBytes totalBytes fetchNonResponses\n   2 0 0 0 0 0 0 0 5=\r\n\n   SimplePrecedenceProvider\n   1\n\nSNOOZED#1:\nQueue www, (p1)\n  2 items\n   =\r\nwakes in: 7m25s889ms\n    last enqueued: dns:www\n      last peeked: dns:www\n=\r\n   total expended: 4 (total budget: -1)\n   active balance: 2996\n   last(avg=\r\n) cost: 1(1)\n   totalScheduled fetchSuccesses fetchFailures fetchDisregards=\r\n fetchResponses robotsDenials successBytes totalBytes fetchNonResponses\n   =\r\n2 0 0 0 0 0 0 0 5\n   SimplePrecedenceProvider\n   1&lt;/pre&gt;&lt;/span&gt;&lt;/font&gt;&lt;/div=\r\n&gt;&lt;div&gt;So, it looks like there are some weird items being put into these que=\r\nues that don&#39;t belong there and it&#39;s hanging the crawl job? Is ther=\r\ne a configuration option I can tweak to retire these queues or clear them o=\r\nut after a specified idle period? Or, is this the result of a misconfigurat=\r\nion somewhere?&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks,&lt;/div&gt;&lt;div&gt;-Zach&lt;/div&gt;&lt;meta=\r\n charset=3D&quot;utf-8&quot;&gt;\n\r\n--001636457194c967880490ddd32d--\r\n\n"}}