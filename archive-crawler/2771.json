{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":235746949,"authorName":"Gordon Paynter","from":"&quot;Gordon Paynter&quot; &lt;Gordon.Paynter@...&gt;","replyTo":"LIST","senderId":"jQjMEVL6KgPOJFzEoWTIs2y8l7V6Xyw0Xu69sIn-G5_MXg1gLX4_FRsIe3FB7cyH_BUzvCHJpdq0Ue40U0iyYt6-BP6AToFAzrKMg_tz7YtnJed4wYJB","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Robots.txt parsing problem?","postDate":"1144218785","msgId":2771,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PHM0MzQwZDc3LjA0OUBzaGFkYm9sdC5uYXRsaWIuZ292dC5uej4="},"prevInTopic":2743,"nextInTopic":0,"prevInTime":2770,"nextInTime":2772,"topicId":2736,"numMessagesInTopic":7,"msgSnippet":"... Exactly this happened to me a year or two back (different site and different crawler, of course). I can understand it too. Chances are that the admin","rawEmail":"Return-Path: &lt;Gordon.Paynter@...&gt;\r\nX-Sender: Gordon.Paynter@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 76631 invoked from network); 5 Apr 2006 06:33:54 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m3.grp.scd.yahoo.com with QMQP; 5 Apr 2006 06:33:54 -0000\r\nReceived: from unknown (HELO jupiter.natlib.govt.nz) (210.55.131.76)\n  by mta4.grp.scd.yahoo.com with SMTP; 5 Apr 2006 06:33:53 -0000\r\nMessage-Id: &lt;s4340d77.049@...&gt;\r\nX-Mailer: Novell GroupWise Internet Agent 6.5.4 \r\nDate: Wed, 05 Apr 2006 18:33:05 +1200\r\nTo: &lt;archive-crawler@yahoogroups.com&gt;\r\nMime-Version: 1.0\r\nContent-Type: text/plain; charset=US-ASCII\r\nContent-Transfer-Encoding: quoted-printable\r\nContent-Disposition: inline\r\nX-SEEmail-Version: 2.0\r\nX-SEEmail: Liverton v2.15 MailMarshal Configuration\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: &quot;Gordon Paynter&quot; &lt;Gordon.Paynter@...&gt;\r\nSubject: Re: [archive-crawler] Robots.txt parsing problem?\r\nX-Yahoo-Group-Post: member; u=235746949\r\n\r\n&gt;&gt;&gt; kwright@... 03/10/06 1:23 AM &gt;&gt;&gt;\n&gt; It&#39;s funny they would chan=\r\nge their robots.txt and then turn around a few \n&gt; hours later and ding us f=\r\nor not looking at the new one.  \n\nExactly this happened to me a year or two=\r\n back (different site and different crawler, of course).\n\nI can understand =\r\nit too. Chances are that the admin noticed the crawler hitting his site in =\r\nways he didn&#39;t like, updated the robots.txt file, and expected the crawler =\r\nto change its behaviour immediately (i.e. the next time it requests a page =\r\nfrom the site). Which is a reasonable expectation, if you haven&#39;t ever thou=\r\nght about how a crawler might work.\n\nGordon\n\n\n"}}