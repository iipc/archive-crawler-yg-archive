{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"rxX7JrZ3-UP9S1z2YZcadLM7rY2_ekmbQ5kmVoPtuuZ1qiZa894H-NEZdy-_mwDpze67bKn_Qcx2RcGWPloY-yh1M6qJgS0","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: questions before we restart the crawl","postDate":"1327466962","msgId":7569,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRGMUY4OUQyLjUwMzA4MDRAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDRGMUYzNkJELjkwNTA0QGNzLmNtdS5lZHU+","referencesHeader":"PDRGMTU5NEQwLjIwOTA4MDhAY3MuY211LmVkdT4gPDRGMTVCQjNBLjUwMzA2QGFyY2hpdmUub3JnPiA8NEYxOUIzOTEuMTA3MDQwMUBjcy5jbXUuZWR1PiA8NEYxQTA0QkMuNjAxMDQwMkBjcy5jbXUuZWR1PiA8NEYxQTRCOUMuNTA5MDAwN0BhcmNoaXZlLm9yZz4gPDRGMUYzNkJELjkwNTA0QGNzLmNtdS5lZHU+"},"prevInTopic":7568,"nextInTopic":7573,"prevInTime":7568,"nextInTime":7570,"topicId":7527,"numMessagesInTopic":27,"msgSnippet":"The recovery needs only the same configuration as a fresh launch would require (crawler-beans.cxml and any other files your configuration requires), plus the","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 22698 invoked from network); 25 Jan 2012 04:49:25 -0000\r\nX-Received: from unknown (98.137.35.160)\n  by m8.grp.sp2.yahoo.com with QMQP; 25 Jan 2012 04:49:25 -0000\r\nX-Received: from unknown (HELO relay00.pair.com) (209.68.5.9)\n  by mta4.grp.sp2.yahoo.com with SMTP; 25 Jan 2012 04:49:25 -0000\r\nX-Received: (qmail 22929 invoked by uid 0); 25 Jan 2012 04:49:23 -0000\r\nX-Received: from 76.218.213.38 (HELO silverbook.local) (76.218.213.38)\n  by relay00.pair.com with SMTP; 25 Jan 2012 04:49:23 -0000\r\nX-pair-Authenticated: 76.218.213.38\r\nMessage-ID: &lt;4F1F89D2.5030804@...&gt;\r\nDate: Tue, 24 Jan 2012 20:49:22 -0800\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.7; rv:9.0) Gecko/20111222 Thunderbird/9.0.1\r\nMIME-Version: 1.0\r\nCc: David Pane &lt;dpane@...&gt;, archive-crawler@yahoogroups.com\r\nReferences: &lt;4F1594D0.2090808@...&gt; &lt;4F15BB3A.50306@...&gt; &lt;4F19B391.1070401@...&gt; &lt;4F1A04BC.6010402@...&gt; &lt;4F1A4B9C.5090007@...&gt; &lt;4F1F36BD.90504@...&gt;\r\nIn-Reply-To: &lt;4F1F36BD.90504@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: questions before we restart the crawl\r\nX-Yahoo-Group-Post: member; u=137285340; y=qqJ8ZYR8OsZoidUoRitCmQAyad5XmO8qHdh7SXiK4OPj\r\nX-Yahoo-Profile: gojomo\r\n\r\nThe recovery needs only the same configuration as a fresh launch would \nrequire (crawler-beans.cxml and any other files your configuration \nrequires), plus the frontier-recover logs.\n\nOf course you would want to make sure your starting-config files are \nupdated to mirror whatever mid-crawl changes you had prompted by other \nmeans (like new directives via the action directory) during the prior \nrun(s).\n\nYou may want to pre-split/filter the frontier-recover files to remove \nredundant lines, as described in the doc wiki page, to somewhat speed \nthe process. (I have just made a few corrections to that page to remove \nsome vagueness and better describe the situation when many files may be \ninvolved.)\n\nThe important thing to maintain in any such reformulation is that all de \nfacto &#39;include&#39; items (&#39;Fs&#39; lines, usually) get processed before all de \nfacto &#39;schedule/enqueue&#39; items (&#39;F+&#39; lines).\n\nWhen presenting in a single frontier-recover.gz file, this happens \nautomatically: one full pass through the file for &#39;include&#39; lines, then \nanother full pass for &#39;schedule&#39; lines. If presenting many files in one \naction directory, you should make sure their filenames lexicographically \nsort in the order that&#39;s necessary: all includes then all schedules. \n(Multiple files with the suffix .recover should NOT be presented this \nway: each file will have its include/schedule lines handled before the \nnext, which results in the wrong effect on the queues. All &#39;includes&#39; \nmust be before all &#39;schedules&#39;, so any multi-file process should use the \n&#39;splitting&#39; procedure.)\n\nI suspect you&#39;ll be doing this on a larger scale than anyone has before. \nI have no idea how long it will take and there&#39;s no way in the current \ncode to checkpoint its progress in the middle of a giant single load. \n(Checkpoints made during a file-load will NOT be an accurate snapshot of \nthe crawl state at that moment.)\n\nFor that reason, you might want to arrange a series of all your separate \n&#39;.include&#39; files, and all the separate &#39;.schedule&#39; files. Drop them in \nsmall batches in the right order into the &#39;action&#39; directory, watching \nwhen the files are moved to the &#39;done&#39; directory to gauge progress. *At \nthose intervening moments where the &#39;action&#39; directory has been \nemptied*, and nothing is filling the frontier included/queues, it should \nbe possible to make a valid manual checkpoint. This may also give you a \nbetter sense of the projected time-to-finish mid-process.\n\nGood luck!\n\n- Gordon\n\nOn 1/24/12 2:54 PM, David Pane wrote:\n&gt; Gordon,\n&gt;\n&gt; We are going to attempt to do a split recovery on one instance. I want\n&gt; to separate this process into another directory. Does the recovery\n&gt; process only need the frontier.recover files, the crawler-beans.cxml,\n&gt; opt-out.surt and seeds.txt? Can all checkpoints and state files be\n&gt; deleted and the warc files and logs moved to another location?\n&gt;\n&gt; --David\n&gt;\n&gt;\n&gt; On 1/21/2012 12:22 AM, Gordon Mohr wrote:\n&gt;&gt;&gt; 1) Can we continue from here but with &quot;clean&quot; Heritrix instances?\n&gt;&gt;&gt;\n&gt;&gt;&gt; Is there a way that we can continue from the this point forward, but\n&gt;&gt;&gt; start with Heritrix instances that will not be corrupt due to sever\n&gt;&gt;&gt; error? (e.g. using the\n&gt;&gt;&gt; https://webarchive.jira.com/wiki/display/Heritrix/Crawl+Recovery ) If\n&gt;&gt;&gt; so, would you recommend doing this? You mentioned that this could be\n&gt;&gt;&gt; time consuming. Each of our instances has downloaded around 170M URIs,\n&gt;&gt;&gt; they have over 700M queued URIs, what is your time estimate for\n&gt;&gt;&gt; something this large?\n&gt;&gt;&gt;\n&gt;&gt;&gt; We are willing to sacrifice a few days to get our crawler to a clean\n&gt;&gt;&gt; state again so we can crawl for another 30 days at the pace we have been\n&gt;&gt;&gt; crawling.\n&gt;&gt;\n&gt;&gt; You can do a big &#39;frontier-recover&#39; log replay to avoid recrawling the\n&gt;&gt; same URIs, and approximate the earlier queue state. Splitting/filters\n&gt;&gt; the logs manually beforehand as alluded to in the wiki page can speed\n&gt;&gt; this process somewhat... but given the size of all your log-segments\n&gt;&gt; that log grooming beforehand is itself likely to be a lengthy process.\n&gt;&gt;\n&gt;&gt; I don&#39;t think we&#39;ve ever done it with logs of 170M crawled / 870M\n&gt;&gt; discovered before, nor on any hardware comparable to yours. So it&#39;s\n&gt;&gt; impossible to project its duration in your environment. It&#39;s taken 2-3\n&gt;&gt; days for us on smaller crawls, slower hardware.\n&gt;&gt;\n&gt;&gt; An added complication is that this older frontier-recover-log replay\n&gt;&gt; technique happens in its own thread separate from the checkpointing\n&gt;&gt; process, so it is not, itself, accurately checkpointed during the long\n&gt;&gt; reload process.\n&gt;&gt;\n&gt;&gt; At nearly 1B discovered URIs per node, even if you are using the\n&gt;&gt; alternate BloomUriUniqFilter, if you are using it at its default size\n&gt;&gt; (~500MB) it will now be heavily saturated and thus returning many\n&gt;&gt; false-positives causing truly unique URIs to be rejected as duplicates.\n&gt;&gt; (If you&#39;re using a significantly larger filter, you may not yet be at a\n&gt;&gt; high false-positive rate: you&#39;d have to do the bloom filter math. If\n&gt;&gt; you&#39;re still using BdbUriUniqFilter, you&#39;re way way past the point where\n&gt;&gt; its disk seeks have usually made it too slow for our purposes.)\n\n"}}