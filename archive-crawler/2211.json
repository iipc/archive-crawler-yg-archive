{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"stack","from":"stack &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"-yxAfWAhYTh0ye_4m5yB8AkkOdqF8vqAgMSU3qe_Ft51R530c7fB8Gyx2hc1HuAeRK_t9NRe3Lh0vg-Gga78-g","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Heritrix 1.4 can&#39;t launch job - Fatal InitializationException","postDate":"1126798181","msgId":2211,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQzMjk5MzY1LjgwNTA2MDFAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDA1ZmEwMWM1YjlmYyRjZThjMzc0MCRiZDVlNmU5NEBNQzE1MjA4Pg==","referencesHeader":"PDA1ZmEwMWM1YjlmYyRjZThjMzc0MCRiZDVlNmU5NEBNQzE1MjA4Pg=="},"prevInTopic":2210,"nextInTopic":0,"prevInTime":2210,"nextInTime":2212,"topicId":2087,"numMessagesInTopic":6,"msgSnippet":"... I m glad. ... Ok. I ve removed the note from the release notes from circa heritrix 1.2.0 that talks of how we liked the IBM JVM.  I ve left in place the ","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 90745 invoked from network); 15 Sep 2005 15:38:20 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m31.grp.scd.yahoo.com with QMQP; 15 Sep 2005 15:38:20 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (207.241.224.171)\n  by mta4.grp.scd.yahoo.com with SMTP; 15 Sep 2005 15:38:20 -0000\r\nReceived: (qmail 27274 invoked by uid 100); 15 Sep 2005 15:37:59 -0000\r\nReceived: from adsl-71-130-102-78.dsl.pltn13.pacbell.net (HELO ?192.168.1.8?) (stack@...@71.130.102.78)\n  by mail-dev.archive.org with SMTP; 15 Sep 2005 15:37:59 -0000\r\nMessage-ID: &lt;43299365.8050601@...&gt;\r\nDate: Thu, 15 Sep 2005 08:29:41 -0700\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.7.8) Gecko/20050513 Debian/1.7.8-1\r\nX-Accept-Language: en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;05fa01c5b9fc$ce8c3740$bd5e6e94@MC15208&gt;\r\nIn-Reply-To: &lt;05fa01c5b9fc$ce8c3740$bd5e6e94@MC15208&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=-91.1 required=7.0 tests=AWL,HOT_NASTY,HTML_30_40,\n\tHTML_MESSAGE,PORN_4,USER_IN_WHITELIST autolearn=no version=2.63\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] Heritrix 1.4 can&#39;t launch job - Fatal InitializationException\r\nX-Yahoo-Group-Post: member; u=168599281; y=YiJO1PiGhRxVaTi4pfF-Iz1ERfOt6SP36F1Wc7c7TCvMeA4qPT97VZ8N\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\nCharles Foetz wrote:\n\n&gt; Sorry for the late reply - just back from 4 weeks travelling :)\n&gt;  \n&gt; Indeed the problem was that I used the IBM VM that comes with SuSe \n&gt; Enterprise version 9: J2RE 1.4.2 IBM build cxia321420-20040626\n&gt; With Sun&#39;s JVM it works flawlessly.\n\nI&#39;m glad.\n\n&gt;  \n&gt; Maybe this should be added to the user manual (currently recommends \n&gt; IBM&#39;s JVM for performance)?\n\nOk. I&#39;ve removed the note from the release notes from circa heritrix \n1.2.0 that talks of how we liked the IBM JVM.  I&#39;ve left in place the \ntrue statement that the IBM JVM is generally more performant (And \nelsewhere the note where it says we use the SUN JVM at the Archive).\n\nWe&#39;re reluctant recommending one JVM over another. Here at the archive, \nwe&#39;ve been using the SUN JVMs.  They seem to work best in our fedora \ncore 3/4 context (We&#39;re currently testing using a SUSE image -- will \nupdate the list w/ results of our testing later).  In another setting, \nIBM JVM might be a better choice.\n\n&gt;  \n&gt; Thanks a lot for your help\n&gt;  \n&gt; Charlie Foetz\n&gt; Bibliothï¿½que nationale de Luxembourg\n&gt;  \n&gt; ps I will attend the IWAW in Vienna\n\nI look forward to meeting you in person Charlie.\nYours,\nSt.Ack\n\n&gt;     ----- Original Message -----\n&gt;     *From:* stack\n&gt;     *To:* archive-crawler@yahoogroups.com\n&gt;     *Sent:* Thursday, August 18, 2005 12:45 AM\n&gt;     *Subject:* Re: [archive-crawler] Heritrix 1.4 can&#39;t launch job -\n&gt;     Fatal InitializationException\n&gt;\n&gt;     Charles Foetz wrote:\n&gt;\n&gt;     &gt; Note: This mail contains the stack trace and I&#39;ve attached the\n&gt;     &gt; order.xml file too\n&gt;     &gt; \n&gt;     &gt; I&#39;m running J2RE 1.4.2 IBM on SuSE Enterprise Server V.9\n&gt;     &gt; The job ends right away and all my log files are 0 bytes\n&gt;\n&gt;     Whats the version on your IBM JVM (Is it the latest?)  Would you mind\n&gt;     trying a sun jvm?  I&#39;ve not seen this exception before.  Its a\n&gt;     strange\n&gt;     complaint from the Reference class internals about our passing of\n&gt;     a null\n&gt;     reference queue but the queue shouldn&#39;t be null; its a data member\n&gt;     that\n&gt;     should be setup on initialized of the surrounding CachedBdbMap class.\n&gt;\n&gt;     Yours,\n&gt;     St.Ack\n&gt;\n&gt;     &gt; \n&gt;     &gt; \n&gt;     &gt; ----- Original Message -----\n&gt;     &gt;\n&gt;     &gt;     *From:* stack &lt;mailto:stack@...&gt;\n&gt;     &gt;     *To:* archive-crawler@yahoogroups.com\n&gt;     &gt;     &lt;mailto:archive-crawler@yahoogroups.com&gt;\n&gt;     &gt;     *Sent:* Monday, August 08, 2005 8:15 PM\n&gt;     &gt;     *Subject:* Re: [archive-crawler] Heritrix 1.4 can&#39;t launch job -\n&gt;     &gt;     Fatal InitializationException\n&gt;     &gt;\n&gt;     &gt;     \n&gt;     &gt;     Charles Foetz wrote:\n&gt;     &gt;\n&gt;     &gt;     &gt; Hello fellow crawlers,\n&gt;     &gt;     &gt;\n&gt;     &gt;     &gt; At Luxembourg&#39;s national library we&#39;re taking our first\n&gt;     steps in\n&gt;     &gt;     &gt; crawling. I&#39;m looking at this myself at the moment, I&#39;ve\n&gt;     managed\n&gt;     &gt;     &gt; to successfully crawl, store, search, retrieve and display\n&gt;     some\n&gt;     &gt;     sites\n&gt;     &gt;     &gt; as a prototype, using H1.2 for the crawling part. When I\n&gt;     installed\n&gt;     &gt;     &gt; H1.4 a month ago, it didn&#39;t work and I assumed an interference\n&gt;     &gt;     issue\n&gt;     &gt;     &gt; with 1.2 (an environment variable or something), but after\n&gt;     a new\n&gt;     &gt;     clean\n&gt;     &gt;     &gt; server installation (re-installing SuSe Enterprise 9 and then\n&gt;     &gt;     H1.4) I\n&gt;     &gt;     &gt; get the same error as soon as I try the first default job\n&gt;     (using\n&gt;     &gt;     one\n&gt;     &gt;     &gt; seed, having set the &quot;user-agent&quot; and &quot;from&quot; fields\n&gt;     correctly):\n&gt;     &gt;     &gt;\n&gt;     &gt;     &gt; Symptoms:\n&gt;     &gt;     &gt;\n&gt;     &gt;     &gt; - The job completes almost as soon as it starts,\n&gt;     &gt;\n&gt;     &gt;     This sounds like this issue:\n&gt;     &gt;     http://crawler.archive.org/faq.html#windowsstart.  Do you have\n&gt;     &gt;     your own\n&gt;     &gt;     wrapper script starting up Heritrix or are you using stock\n&gt;     &gt;     $HERITRIX_HOME/bin/heritrix?\n&gt;     &gt;\n&gt;     &gt; I don&#39;t use any wrapper script, I start it with\n&gt;     &gt; \n&gt;     &gt; export HERITRIX_HOME=/usr/local/heritrix-1.4.0/\n&gt;     &gt; $HERITRIX_HOME/bin/heritrix -p 8084\n&gt;     &gt; \n&gt;     &gt; (I&#39;ve also tried without the -port option and ran it on 8080 - same\n&gt;     &gt; results)\n&gt;     &gt;\n&gt;     &gt;\n&gt;     &gt;     &gt; - &quot;No statistics associated with job&quot; in the reports\n&gt;     &gt;     &gt; - No page is crawled or archived (specified arcs folder\n&gt;     isn&#39;t even\n&gt;     &gt;     &gt; created)\n&gt;     &gt;     &gt; - on the Jobs tab under &quot;Completed jobs&quot; I read &quot;Could not\n&gt;     &gt;     launch job\n&gt;     &gt;     &gt; - Fatal initializationException - A fatal\n&gt;     InitializationException\n&gt;     &gt;     &gt; occured when loading job:Unable to setup crawl modules:\n&gt;     &gt;     &gt; java.lang.NullPointerException: Reference Queue cannot be\n&gt;     null&quot;.\n&gt;     &gt;\n&gt;     &gt;     May we see the full stack trace for the exception?  Might\n&gt;     give us\n&gt;     &gt;     a clue\n&gt;     &gt;     (Is this being done on an NFS mount?  If so, try running on a\n&gt;     &gt;     local disk).\n&gt;     &gt;\n&gt;     &gt; Here&#39;s the stack track:\n&gt;     &gt; ----------------------------------\n&gt;     &gt; ----------------------------------\n&gt;     &gt; \n&gt;     &gt; Unable to setup crawl modules:\n&gt;     &gt; java.lang.NullPointerException: Reference queue cannot\n&gt;     &gt; be null\n&gt;     &gt;\n&gt;     &gt; Associated Throwable: java.lang.NullPointerException:\n&gt;     &gt; Reference queue cannot be null\n&gt;     &gt;\n&gt;     &gt;   Message:\n&gt;     &gt;     Reference queue cannot be null\n&gt;     &gt;\n&gt;     &gt;   Stacktrace:\n&gt;     &gt; java.lang.NullPointerException: Reference queue cannot\n&gt;     &gt; be null\n&gt;     &gt; at java.lang.ref.Reference.(Reference.java:226)\n&gt;     &gt; at\n&gt;     &gt; java.lang.ref.PhantomReference.(PhantomReference.java:72)\n&gt;     &gt; at\n&gt;     &gt; org.archive.util.CachedBdbMap$PhantomEntry.(CachedBdbMap.java:463)\n&gt;     &gt; at\n&gt;     &gt; org.archive.util.CachedBdbMap$SoftEntry.(CachedBdbMap.java:497)\n&gt;     &gt; at\n&gt;     &gt; org.archive.util.CachedBdbMap.put(CachedBdbMap.java:378)\n&gt;     &gt; at\n&gt;     &gt;\n&gt;     org.archive.crawler.frontier.BdbFrontier.getQueueFor(BdbFrontier.java:475)\n&gt;     &gt; at\n&gt;     &gt;\n&gt;     org.archive.crawler.frontier.BdbFrontier.sendToQueue(BdbFrontier.java:349)\n&gt;     &gt; at\n&gt;     &gt;\n&gt;     org.archive.crawler.frontier.BdbFrontier.receive(BdbFrontier.java:338)\n&gt;     &gt; at\n&gt;     &gt;\n&gt;     org.archive.crawler.util.BdbUriUniqFilter.add(BdbUriUniqFilter.java:265)\n&gt;     &gt; at\n&gt;     &gt;\n&gt;     org.archive.crawler.util.BdbUriUniqFilter.add(BdbUriUniqFilter.java:224)\n&gt;     &gt; at\n&gt;     &gt;\n&gt;     org.archive.crawler.frontier.BdbFrontier.schedule(BdbFrontier.java:321)\n&gt;     &gt; at\n&gt;     &gt;\n&gt;     org.archive.crawler.frontier.AbstractFrontier.loadSeeds(AbstractFrontier.java:412)\n&gt;     &gt; at\n&gt;     &gt;\n&gt;     org.archive.crawler.frontier.BdbFrontier.initialize(BdbFrontier.java:244)\n&gt;     &gt; at\n&gt;     &gt;\n&gt;     org.archive.crawler.framework.CrawlController.setupCrawlModules(CrawlController.java:572)\n&gt;     &gt; at\n&gt;     &gt;\n&gt;     org.archive.crawler.framework.CrawlController.initialize(CrawlController.java:336)\n&gt;     &gt; at\n&gt;     &gt;\n&gt;     org.archive.crawler.admin.CrawlJobHandler.startNextJobInternal(CrawlJobHandler.java:1050)\n&gt;     &gt; at\n&gt;     &gt;\n&gt;     org.archive.crawler.admin.CrawlJobHandler$2.run(CrawlJobHandler.java:1016)\n&gt;     &gt; at java.lang.Thread.run(Thread.java:567)\n&gt;     &gt;\n&gt;     &gt;\n&gt;     &gt;     &gt;\n&gt;     &gt;     &gt; What am I missing? Does any part of the job initialzation\n&gt;     differ\n&gt;     &gt;     &gt; signigicantly from H1.2?\n&gt;     &gt;     &gt;\n&gt;     &gt;\n&gt;     &gt;     I&#39;d doubt you&#39;re missing anything.  1.4 should run just like\n&gt;     1.2.\n&gt;     &gt;     Yours,\n&gt;     &gt;     St.Ack\n&gt;     &gt;\n&gt;     &gt;     &gt; Any ideas or hints greatly appreciated.\n&gt;     &gt;     &gt;\n&gt;     &gt;     &gt; Charlie\n&gt;     &gt;     &gt;\n&gt;     &gt;\n&gt;     &gt;\n&gt;     &gt;\n&gt;     ------------------------------------------------------------------------\n&gt;     &gt; YAHOO! GROUPS LINKS\n&gt;     &gt;\n&gt;     &gt;     *  Visit your group &quot;archive-crawler\n&gt;     &gt;       &lt;http://groups.yahoo.com/group/archive-crawler&gt;&quot; on the web.\n&gt;     &gt;       \n&gt;     &gt;     *  To unsubscribe from this group, send an email to:\n&gt;     &gt;        archive-crawler-unsubscribe@yahoogroups.com\n&gt;     &gt;      \n&gt;     &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;     &gt;       \n&gt;     &gt;     *  Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;     &gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;.\n&gt;     &gt;\n&gt;     &gt;\n&gt;     &gt;\n&gt;     ------------------------------------------------------------------------\n&gt;     &gt;\n&gt;     &gt;------------------------------------------------------------------------\n&gt;     &gt;\n&gt;     &gt;&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;crawl-order\n&gt;     xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\n&gt;     xsi:noNamespaceSchemaLocation=&quot;heritrix_settings.xsd&quot;&gt;\n&gt;     &gt;  &lt;meta&gt;\n&gt;     &gt;    &lt;name&gt;TestRun&lt;/name&gt;\n&gt;     &gt;    &lt;description&gt;Default Profile&lt;/description&gt;\n&gt;     &gt;    &lt;operator&gt;Admin&lt;/operator&gt;\n&gt;     &gt;    &lt;organization&gt;&lt;/organization&gt;\n&gt;     &gt;    &lt;audience&gt;&lt;/audience&gt;\n&gt;     &gt;    &lt;date&gt;20050809120352&lt;/date&gt;\n&gt;     &gt;  &lt;/meta&gt;\n&gt;     &gt;  &lt;controller&gt;\n&gt;     &gt;    &lt;string name=&quot;settings-directory&quot;&gt;settings&lt;/string&gt;\n&gt;     &gt;    &lt;string name=&quot;disk-path&quot;&gt;&lt;/string&gt;\n&gt;     &gt;    &lt;string name=&quot;logs-path&quot;&gt;logs&lt;/string&gt;\n&gt;     &gt;    &lt;string name=&quot;checkpoints-path&quot;&gt;checkpoints&lt;/string&gt;\n&gt;     &gt;    &lt;string name=&quot;state-path&quot;&gt;state&lt;/string&gt;\n&gt;     &gt;    &lt;string name=&quot;scratch-path&quot;&gt;scratch&lt;/string&gt;\n&gt;     &gt;    &lt;long name=&quot;max-bytes-download&quot;&gt;0&lt;/long&gt;\n&gt;     &gt;    &lt;long name=&quot;max-document-download&quot;&gt;0&lt;/long&gt;\n&gt;     &gt;    &lt;long name=&quot;max-time-sec&quot;&gt;0&lt;/long&gt;\n&gt;     &gt;    &lt;integer name=&quot;max-toe-threads&quot;&gt;50&lt;/integer&gt;\n&gt;     &gt;    &lt;integer name=&quot;recorder-out-buffer-bytes&quot;&gt;4096&lt;/integer&gt;\n&gt;     &gt;    &lt;integer name=&quot;recorder-in-buffer-bytes&quot;&gt;65536&lt;/integer&gt;\n&gt;     &gt;    &lt;integer name=&quot;bdb-cache-percent&quot;&gt;0&lt;/integer&gt;\n&gt;     &gt;    &lt;newObject name=&quot;scope&quot;\n&gt;     class=&quot;org.archive.crawler.scope.DomainScope&quot;&gt;\n&gt;     &gt;      &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;      &lt;string name=&quot;seedsfile&quot;&gt;seeds.txt&lt;/string&gt;\n&gt;     &gt;      &lt;integer name=&quot;max-link-hops&quot;&gt;25&lt;/integer&gt;\n&gt;     &gt;      &lt;integer name=&quot;max-trans-hops&quot;&gt;5&lt;/integer&gt;\n&gt;     &gt;      &lt;newObject name=&quot;exclude-filter&quot;\n&gt;     class=&quot;org.archive.crawler.filter.OrFilter&quot;&gt;\n&gt;     &gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;        &lt;boolean name=&quot;if-matches-return&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;     &gt;          &lt;newObject name=&quot;pathdepth&quot;\n&gt;     class=&quot;org.archive.crawler.filter.PathDepthFilter&quot;&gt;\n&gt;     &gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;            &lt;integer name=&quot;max-path-depth&quot;&gt;20&lt;/integer&gt;\n&gt;     &gt;            &lt;boolean name=&quot;path-less-or-equal-return&quot;&gt;false&lt;/boolean&gt;\n&gt;     &gt;          &lt;/newObject&gt;\n&gt;     &gt;          &lt;newObject name=&quot;pathologicalpath&quot;\n&gt;     class=&quot;org.archive.crawler.filter.PathologicalPathFilter&quot;&gt;\n&gt;     &gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;            &lt;integer name=&quot;repetitions&quot;&gt;3&lt;/integer&gt;\n&gt;     &gt;          &lt;/newObject&gt;\n&gt;     &gt;        &lt;/map&gt;\n&gt;     &gt;      &lt;/newObject&gt;\n&gt;     &gt;      &lt;newObject name=&quot;additionalScopeFocus&quot;\n&gt;     class=&quot;org.archive.crawler.filter.FilePatternFilter&quot;&gt;\n&gt;     &gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;        &lt;boolean name=&quot;if-match-return&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;        &lt;string name=&quot;use-default-patterns&quot;&gt;All&lt;/string&gt;\n&gt;     &gt;        &lt;string name=&quot;regexp&quot;&gt;&lt;/string&gt;\n&gt;     &gt;      &lt;/newObject&gt;\n&gt;     &gt;      &lt;newObject name=&quot;transitiveFilter&quot;\n&gt;     class=&quot;org.archive.crawler.filter.TransclusionFilter&quot;&gt;\n&gt;     &gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;        &lt;integer name=&quot;max-speculative-hops&quot;&gt;1&lt;/integer&gt;\n&gt;     &gt;        &lt;integer name=&quot;max-referral-hops&quot;&gt;-1&lt;/integer&gt;\n&gt;     &gt;        &lt;integer name=&quot;max-embed-hops&quot;&gt;-1&lt;/integer&gt;\n&gt;     &gt;      &lt;/newObject&gt;\n&gt;     &gt;    &lt;/newObject&gt;\n&gt;     &gt;    &lt;map name=&quot;http-headers&quot;&gt;\n&gt;     &gt;      &lt;string name=&quot;user-agent&quot;&gt;Mozilla/5.0 (compatible;\n&gt;     heritrix/1.4.0 +http://www.xxxx.xx&lt;/string&gt;\n&gt;     &gt;      &lt;string name=&quot;from&quot;&gt;xxxx.xxxx@...&lt;/string&gt;\n&gt;     &gt;    &lt;/map&gt;\n&gt;     &gt;    &lt;newObject name=&quot;robots-honoring-policy&quot;\n&gt;     class=&quot;org.archive.crawler.datamodel.RobotsHonoringPolicy&quot;&gt;\n&gt;     &gt;      &lt;string name=&quot;type&quot;&gt;classic&lt;/string&gt;\n&gt;     &gt;      &lt;boolean name=&quot;masquerade&quot;&gt;false&lt;/boolean&gt;\n&gt;     &gt;      &lt;text name=&quot;custom-robots&quot;&gt;&lt;/text&gt;\n&gt;     &gt;      &lt;stringList name=&quot;user-agents&quot;&gt;\n&gt;     &gt;      &lt;/stringList&gt;\n&gt;     &gt;    &lt;/newObject&gt;\n&gt;     &gt;    &lt;newObject name=&quot;frontier&quot;\n&gt;     class=&quot;org.archive.crawler.frontier.BdbFrontier&quot;&gt;\n&gt;     &gt;      &lt;float name=&quot;delay-factor&quot;&gt;5.0&lt;/float&gt;\n&gt;     &gt;      &lt;integer name=&quot;max-delay-ms&quot;&gt;5000&lt;/integer&gt;\n&gt;     &gt;      &lt;integer name=&quot;min-delay-ms&quot;&gt;500&lt;/integer&gt;\n&gt;     &gt;      &lt;integer name=&quot;max-retries&quot;&gt;30&lt;/integer&gt;\n&gt;     &gt;      &lt;long name=&quot;retry-delay-seconds&quot;&gt;900&lt;/long&gt;\n&gt;     &gt;      &lt;integer name=&quot;preference-embed-hops&quot;&gt;1&lt;/integer&gt;\n&gt;     &gt;      &lt;integer name=&quot;total-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt;     &gt;      &lt;integer name=&quot;max-per-host-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt;     &gt;      &lt;boolean name=&quot;ip-politeness&quot;&gt;false&lt;/boolean&gt;\n&gt;     &gt;      &lt;string name=&quot;force-queue-assignment&quot;&gt;&lt;/string&gt;\n&gt;     &gt;      &lt;boolean name=&quot;pause-at-finish&quot;&gt;false&lt;/boolean&gt;\n&gt;     &gt;      &lt;boolean name=&quot;hold-queues&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;      &lt;integer name=&quot;balance-replenish-amount&quot;&gt;3000&lt;/integer&gt;\n&gt;     &gt;      &lt;long name=&quot;queue-total-budget&quot;&gt;-1&lt;/long&gt;\n&gt;     &gt;      &lt;string\n&gt;     name=&quot;cost-policy&quot;&gt;org.archive.crawler.frontier.ZeroCostAssignmentPolicy&lt;/string&gt;\n&gt;     &gt;    &lt;/newObject&gt;\n&gt;     &gt;    &lt;map name=&quot;uri-canonicalization-rules&quot;&gt;\n&gt;     &gt;      &lt;newObject name=&quot;Lowercase&quot;\n&gt;     class=&quot;org.archive.crawler.url.canonicalize.LowercaseRule&quot;&gt;\n&gt;     &gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;      &lt;/newObject&gt;\n&gt;     &gt;      &lt;newObject name=&quot;Userinfo&quot;\n&gt;     class=&quot;org.archive.crawler.url.canonicalize.StripUserinfoRule&quot;&gt;\n&gt;     &gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;      &lt;/newObject&gt;\n&gt;     &gt;      &lt;newObject name=&quot;WWW&quot;\n&gt;     class=&quot;org.archive.crawler.url.canonicalize.StripWWWRule&quot;&gt;\n&gt;     &gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;      &lt;/newObject&gt;\n&gt;     &gt;      &lt;newObject name=&quot;SessionIDs&quot;\n&gt;     class=&quot;org.archive.crawler.url.canonicalize.StripSessionIDs&quot;&gt;\n&gt;     &gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;      &lt;/newObject&gt;\n&gt;     &gt;      &lt;newObject name=&quot;QueryStrPrefix&quot;\n&gt;     class=&quot;org.archive.crawler.url.canonicalize.FixupQueryStr&quot;&gt;\n&gt;     &gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;      &lt;/newObject&gt;\n&gt;     &gt;    &lt;/map&gt;\n&gt;     &gt;    &lt;map name=&quot;pre-fetch-processors&quot;&gt;\n&gt;     &gt;      &lt;newObject name=&quot;Preselector&quot;\n&gt;     class=&quot;org.archive.crawler.prefetch.Preselector&quot;&gt;\n&gt;     &gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;     &gt;        &lt;/map&gt;\n&gt;     &gt;        &lt;boolean name=&quot;recheck-scope&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;        &lt;boolean name=&quot;block-all&quot;&gt;false&lt;/boolean&gt;\n&gt;     &gt;        &lt;string name=&quot;block-by-regexp&quot;&gt;&lt;/string&gt;\n&gt;     &gt;      &lt;/newObject&gt;\n&gt;     &gt;      &lt;newObject name=&quot;Preprocessor&quot;\n&gt;     class=&quot;org.archive.crawler.prefetch.PreconditionEnforcer&quot;&gt;\n&gt;     &gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;     &gt;        &lt;/map&gt;\n&gt;     &gt;        &lt;integer name=&quot;ip-validity-duration-seconds&quot;&gt;21600&lt;/integer&gt;\n&gt;     &gt;        &lt;integer\n&gt;     name=&quot;robot-validity-duration-seconds&quot;&gt;86400&lt;/integer&gt;\n&gt;     &gt;      &lt;/newObject&gt;\n&gt;     &gt;    &lt;/map&gt;\n&gt;     &gt;    &lt;map name=&quot;fetch-processors&quot;&gt;\n&gt;     &gt;      &lt;newObject name=&quot;DNS&quot;\n&gt;     class=&quot;org.archive.crawler.fetcher.FetchDNS&quot;&gt;\n&gt;     &gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;     &gt;        &lt;/map&gt;\n&gt;     &gt;        &lt;boolean name=&quot;accept-non-dns-resolves&quot;&gt;false&lt;/boolean&gt;\n&gt;     &gt;      &lt;/newObject&gt;\n&gt;     &gt;      &lt;newObject name=&quot;HTTP&quot;\n&gt;     class=&quot;org.archive.crawler.fetcher.FetchHTTP&quot;&gt;\n&gt;     &gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;     &gt;        &lt;/map&gt;\n&gt;     &gt;        &lt;map name=&quot;midfetch-filters&quot;&gt;\n&gt;     &gt;        &lt;/map&gt;\n&gt;     &gt;        &lt;integer name=&quot;timeout-seconds&quot;&gt;1200&lt;/integer&gt;\n&gt;     &gt;        &lt;integer name=&quot;sotimeout-ms&quot;&gt;20000&lt;/integer&gt;\n&gt;     &gt;        &lt;long name=&quot;max-length-bytes&quot;&gt;0&lt;/long&gt;\n&gt;     &gt;        &lt;string name=&quot;load-cookies-from-file&quot;&gt;&lt;/string&gt;\n&gt;     &gt;        &lt;string name=&quot;save-cookies-to-file&quot;&gt;&lt;/string&gt;\n&gt;     &gt;        &lt;string name=&quot;trust-level&quot;&gt;open&lt;/string&gt;\n&gt;     &gt;        &lt;stringList name=&quot;accept-headers&quot;&gt;\n&gt;     &gt;        &lt;/stringList&gt;\n&gt;     &gt;        &lt;string name=&quot;http-proxy-host&quot;&gt;&lt;/string&gt;\n&gt;     &gt;        &lt;string name=&quot;http-proxy-port&quot;&gt;&lt;/string&gt;\n&gt;     &gt;        &lt;string name=&quot;default-encoding&quot;&gt;ISO-8859-1&lt;/string&gt;\n&gt;     &gt;        &lt;boolean name=&quot;sha1-content&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;        &lt;boolean name=&quot;send-connection-close&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;        &lt;boolean name=&quot;send-referer&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;        &lt;boolean name=&quot;send-range&quot;&gt;false&lt;/boolean&gt;\n&gt;     &gt;      &lt;/newObject&gt;\n&gt;     &gt;    &lt;/map&gt;\n&gt;     &gt;    &lt;map name=&quot;extract-processors&quot;&gt;\n&gt;     &gt;      &lt;newObject name=&quot;ExtractorHTTP&quot;\n&gt;     class=&quot;org.archive.crawler.extractor.ExtractorHTTP&quot;&gt;\n&gt;     &gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;     &gt;        &lt;/map&gt;\n&gt;     &gt;      &lt;/newObject&gt;\n&gt;     &gt;      &lt;newObject name=&quot;ExtractorHTML&quot;\n&gt;     class=&quot;org.archive.crawler.extractor.ExtractorHTML&quot;&gt;\n&gt;     &gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;     &gt;        &lt;/map&gt;\n&gt;     &gt;      &lt;/newObject&gt;\n&gt;     &gt;      &lt;newObject name=&quot;ExtractorCSS&quot;\n&gt;     class=&quot;org.archive.crawler.extractor.ExtractorCSS&quot;&gt;\n&gt;     &gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;     &gt;        &lt;/map&gt;\n&gt;     &gt;      &lt;/newObject&gt;\n&gt;     &gt;      &lt;newObject name=&quot;ExtractorJS&quot;\n&gt;     class=&quot;org.archive.crawler.extractor.ExtractorJS&quot;&gt;\n&gt;     &gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;     &gt;        &lt;/map&gt;\n&gt;     &gt;      &lt;/newObject&gt;\n&gt;     &gt;      &lt;newObject name=&quot;ExtractorSWF&quot;\n&gt;     class=&quot;org.archive.crawler.extractor.ExtractorSWF&quot;&gt;\n&gt;     &gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;     &gt;        &lt;/map&gt;\n&gt;     &gt;      &lt;/newObject&gt;\n&gt;     &gt;    &lt;/map&gt;\n&gt;     &gt;    &lt;map name=&quot;write-processors&quot;&gt;\n&gt;     &gt;      &lt;newObject name=&quot;Archiver&quot;\n&gt;     class=&quot;org.archive.crawler.writer.ARCWriterProcessor&quot;&gt;\n&gt;     &gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;     &gt;        &lt;/map&gt;\n&gt;     &gt;        &lt;boolean name=&quot;compress&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;        &lt;string name=&quot;prefix&quot;&gt;IAH&lt;/string&gt;\n&gt;     &gt;        &lt;string name=&quot;suffix&quot;&gt;${HOSTNAME}&lt;/string&gt;\n&gt;     &gt;        &lt;integer name=&quot;max-size-bytes&quot;&gt;100000000&lt;/integer&gt;\n&gt;     &gt;        &lt;stringList name=&quot;path&quot;&gt;\n&gt;     &gt;          &lt;string&gt;arcs&lt;/string&gt;\n&gt;     &gt;        &lt;/stringList&gt;\n&gt;     &gt;        &lt;integer name=&quot;pool-max-active&quot;&gt;5&lt;/integer&gt;\n&gt;     &gt;        &lt;integer name=&quot;pool-max-wait&quot;&gt;300000&lt;/integer&gt;\n&gt;     &gt;        &lt;long name=&quot;total-bytes-to-write&quot;&gt;0&lt;/long&gt;\n&gt;     &gt;      &lt;/newObject&gt;\n&gt;     &gt;    &lt;/map&gt;\n&gt;     &gt;    &lt;map name=&quot;post-processors&quot;&gt;\n&gt;     &gt;      &lt;newObject name=&quot;Updater&quot;\n&gt;     class=&quot;org.archive.crawler.postprocessor.CrawlStateUpdater&quot;&gt;\n&gt;     &gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;     &gt;        &lt;/map&gt;\n&gt;     &gt;      &lt;/newObject&gt;\n&gt;     &gt;      &lt;newObject name=&quot;Postselector&quot;\n&gt;     class=&quot;org.archive.crawler.postprocessor.Postselector&quot;&gt;\n&gt;     &gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;     &gt;        &lt;/map&gt;\n&gt;     &gt;        &lt;boolean name=&quot;seed-redirects-new-seed&quot;&gt;true&lt;/boolean&gt;\n&gt;     &gt;        &lt;boolean name=&quot;override-logger&quot;&gt;false&lt;/boolean&gt;\n&gt;     &gt;        &lt;map name=&quot;scope-rejected-uri-log-filters&quot;&gt;\n&gt;     &gt;        &lt;/map&gt;\n&gt;     &gt;      &lt;/newObject&gt;\n&gt;     &gt;    &lt;/map&gt;\n&gt;     &gt;    &lt;map name=&quot;loggers&quot;&gt;\n&gt;     &gt;      &lt;newObject name=&quot;crawl-statistics&quot;\n&gt;     class=&quot;org.archive.crawler.admin.StatisticsTracker&quot;&gt;\n&gt;     &gt;        &lt;integer name=&quot;interval-seconds&quot;&gt;20&lt;/integer&gt;\n&gt;     &gt;      &lt;/newObject&gt;\n&gt;     &gt;    &lt;/map&gt;\n&gt;     &gt;    &lt;string name=&quot;recover-path&quot;&gt;&lt;/string&gt;\n&gt;     &gt;    &lt;boolean name=&quot;recover-retain-failures&quot;&gt;false&lt;/boolean&gt;\n&gt;     &gt;    &lt;newObject name=&quot;credential-store&quot;\n&gt;     class=&quot;org.archive.crawler.datamodel.CredentialStore&quot;&gt;\n&gt;     &gt;      &lt;map name=&quot;credentials&quot;&gt;\n&gt;     &gt;      &lt;/map&gt;\n&gt;     &gt;    &lt;/newObject&gt;\n&gt;     &gt;  &lt;/controller&gt;\n&gt;     &gt;&lt;/crawl-order&gt;\n&gt;\n&gt;  \n&gt;\n&gt;\n&gt; SPONSORED LINKS\n&gt; Computer internet security \n&gt; &lt;http://groups.yahoo.com/gads?t=ms&k=Computer+internet+security&w1=Computer+internet+security&w2=Computer+internet+business&w3=Computer+internet+access&w4=Computer+internet+privacy+securities&w5=Computer+internet+help&w6=Computer+internet+connection&c=6&s=198&.sig=V04yaONvhRiZX9V-9vaMcA&gt; \n&gt; \tComputer internet business \n&gt; &lt;http://groups.yahoo.com/gads?t=ms&k=Computer+internet+business&w1=Computer+internet+security&w2=Computer+internet+business&w3=Computer+internet+access&w4=Computer+internet+privacy+securities&w5=Computer+internet+help&w6=Computer+internet+connection&c=6&s=198&.sig=QEM5QXY5E4yokvfp8I9OxA&gt; \n&gt; \tComputer internet access \n&gt; &lt;http://groups.yahoo.com/gads?t=ms&k=Computer+internet+access&w1=Computer+internet+security&w2=Computer+internet+business&w3=Computer+internet+access&w4=Computer+internet+privacy+securities&w5=Computer+internet+help&w6=Computer+internet+connection&c=6&s=198&.sig=GvFjo1UJpzPMTQeQeWH-9Q&gt; \n&gt;\n&gt; Computer internet privacy securities \n&gt; &lt;http://groups.yahoo.com/gads?t=ms&k=Computer+internet+privacy+securities&w1=Computer+internet+security&w2=Computer+internet+business&w3=Computer+internet+access&w4=Computer+internet+privacy+securities&w5=Computer+internet+help&w6=Computer+internet+connection&c=6&s=198&.sig=2cAxh4C_HeZYnGK5pWGQjg&gt; \n&gt; \tComputer internet help \n&gt; &lt;http://groups.yahoo.com/gads?t=ms&k=Computer+internet+help&w1=Computer+internet+security&w2=Computer+internet+business&w3=Computer+internet+access&w4=Computer+internet+privacy+securities&w5=Computer+internet+help&w6=Computer+internet+connection&c=6&s=198&.sig=XyuTAshDdmCMqHSTUW6r1Q&gt; \n&gt; \tComputer internet connection \n&gt; &lt;http://groups.yahoo.com/gads?t=ms&k=Computer+internet+connection&w1=Computer+internet+security&w2=Computer+internet+business&w3=Computer+internet+access&w4=Computer+internet+privacy+securities&w5=Computer+internet+help&w6=Computer+internet+connection&c=6&s=198&.sig=PWZ1Hrcj8Yl7bPjnNBOESg&gt; \n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------------------------------------------\n&gt; YAHOO! GROUPS LINKS\n&gt;\n&gt;     *  Visit your group &quot;archive-crawler\n&gt;       &lt;http://groups.yahoo.com/group/archive-crawler&gt;&quot; on the web.\n&gt;        \n&gt;     *  To unsubscribe from this group, send an email to:\n&gt;        archive-crawler-unsubscribe@yahoogroups.com\n&gt;       &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;        \n&gt;     *  Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;.\n&gt;\n&gt;\n&gt; ------------------------------------------------------------------------\n&gt;\n\n\n"}}