{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"bfA4_35C-oDB66Gju-_W0QEk41O9GJWumL4nR-lzT1h4kwqFbqKDVQt3UYY2FsW36Gl31UwXVMF-3oInCbSbIpEiGMtagLs","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] Re: Question about QueueOverbudgetDecideRule","postDate":"1257887941","msgId":6144,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRBRjlEOEM1LjYwNjA1MDdAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGhjbWpzZytpZXU3QGVHcm91cHMuY29tPg==","referencesHeader":"PGhjbWpzZytpZXU3QGVHcm91cHMuY29tPg=="},"prevInTopic":6138,"nextInTopic":0,"prevInTime":6143,"nextInTime":6145,"topicId":6126,"numMessagesInTopic":3,"msgSnippet":"There are at least 2 ways to limit the number of URIs Heritrix fetches from a host: - QuotaEnforcer, which discards extra URIs when they come up for fetching","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 89551 invoked from network); 10 Nov 2009 21:19:11 -0000\r\nX-Received: from unknown (66.196.94.107)\n  by m11.grp.re1.yahoo.com with QMQP; 10 Nov 2009 21:19:11 -0000\r\nX-Received: from unknown (HELO relay02.pair.com) (209.68.5.16)\n  by mta3.grp.re1.yahoo.com with SMTP; 10 Nov 2009 21:19:11 -0000\r\nX-Received: (qmail 13706 invoked from network); 10 Nov 2009 21:19:02 -0000\r\nX-Received: from 67.188.14.54 (HELO ?192.168.1.107?) (67.188.14.54)\n  by relay02.pair.com with SMTP; 10 Nov 2009 21:19:02 -0000\r\nX-pair-Authenticated: 67.188.14.54\r\nMessage-ID: &lt;4AF9D8C5.6060507@...&gt;\r\nDate: Tue, 10 Nov 2009 13:19:01 -0800\r\nUser-Agent: Thunderbird 2.0.0.23 (Windows/20090812)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;hcmjsg+ieu7@...&gt;\r\nIn-Reply-To: &lt;hcmjsg+ieu7@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Re: Question about QueueOverbudgetDecideRule\r\nX-Yahoo-Group-Post: member; u=137285340; y=96u2HDRyseMpQ95KaGxjJceIVUulcw9MA2RM3Ri9NsgJ\r\nX-Yahoo-Profile: gojomo\r\n\r\nThere are at least 2 ways to limit the number of URIs Heritrix fetches \nfrom a host:\n\n  - QuotaEnforcer, which discards extra URIs when they come up for \nfetching once certain tallies reach configured quotas\n  - frontier budgeting, which can either (a) retire a queue once it&#39;s \n&#39;expenditure&#39; goes over a budget threshold (even as the discovered URIs \ncontinue to queue up, in case you want to increase the budget later); or \n(b) using the contributed QueueOverbudgetDecideRule, discard as \nout-of-scope URIs once a queue has exhausted its budget.\n\nEach has different tradeoffs. The budgeting-based techniques, in \nparticular, may not offer the exact count-enforcement you seem to want, \nbecause the &#39;queue expenditures&#39; are not exactly 1-per-successful-URI. \n(They&#39;re close, with some usual queue-assignment and cost-assignment \npolicies, but not exact.)\n\nLooking at your order.xml, you&#39;ve configured the \nQueueOverbudgetDecideRule in a way where it&#39;s can&#39;t have the desired \neffect. Its &#39;decision&#39; is set to ACCEPT, so if the evaluated URI is \nassigned to an overbudget queue, it will return the ACCEPT decision. \nAnd, installed on LinksScoper, any decision other than REJECT simply \nmeans &quot;OK to run this processor&quot;. Finally, as a rule on a processor, it \nruns against the URI being processed, *not* the outlinks discovered. So \neven as a REJECT rule, it would only prevent LinksScoper activity on \nURIs that come from already-overbudget queues. That might approximate \nwhat you want -- no more discovered outlinks from such URIs -- but you \nwould miss URIs destined for other, under-budget queues.\n\nI believe the intended use of the QueueOverbudgetDecideRule is inside a \nDecidingScope, like the &#39;deciding-defaults&#39; profile. (You can convert \nsuch a scope to a &#39;broad&#39; crawl by making its initial rule an \nAcceptDecideRule rather than RejectDecideRule, and discarding the \nfollowing SurtPrefixedDecideRule for ACCEPTing some URIs.) Then, it will \napply to all URIs discovered and considered for inclusion, rejecting \nthose destined for already-overbudget queues.\n\nHope this helps,\n\n- Gordon @ IA\n\n\nolintocattaneo wrote:\n&gt; Replying to myself just in case anyone competent missed this.\n&gt; \n&gt; Olinto\n&gt; \n&gt; --- In archive-crawler@yahoogroups.com, &quot;olintocattaneo&quot;\n&gt; &lt;olintocattaneo@...&gt; wrote:\n&gt;&gt; Hello\n&gt;&gt; \n&gt;&gt; I&#39;m trying to get QueueOverbudgetDecideRule to work but I don&#39;t\n&gt;&gt; seem to be able to do this. Is this module still functional or\n&gt;&gt; maybe I have added it to a wrong place?\n&gt;&gt; \n&gt;&gt; Here is my order file: \n&gt;&gt; http://ihave.bushiq.com/stuff/order_20091022065616.xml\n&gt;&gt; \n&gt;&gt; What I want to accomplish is that I just want to crawl 5 pages from\n&gt;&gt; each host. I tried QuotaEnforcer initially but this module is\n&gt;&gt; really inefficient since when it finds new links to a host that has\n&gt;&gt; reached it&#39;s quota it will still try to check them out\n&gt;&gt; from&quot;already-seen&quot; database, will add them to queue if there are\n&gt;&gt; none and when the queue goes active and it doesn&#39;t find them it\n&gt;&gt; will write them to log file. This means that the crawling is using\n&gt;&gt; unnecessary amount of resources.\n&gt;&gt; \n&gt;&gt; If I want to crawl 5 pages from each domain it should do just that\n&gt;&gt; - 1. When extracting links from URL check if domain is already in\n&gt;&gt; the already-seen database, if it is check if it has reached quota,\n&gt;&gt; when it is not then add the links to queue but if it has then just\n&gt;&gt; drop the or write them to log file(would be nice to be able to\n&gt;&gt; specify this too).\n&gt;&gt; \n&gt;&gt; I&#39;m thinking that this is not possible right now and although I\n&gt;&gt; have spent weeks researching this very fine crawler it seems that\n&gt;&gt; it is not possible, maybe I&#39;m just doing something wrong though. I\n&gt;&gt; can achieve this behavior with Mnogosearch but compared to Heritrix\n&gt;&gt; it is not scalable and flexible enough for me.\n&gt;&gt; \n&gt;&gt; I&#39;m sure there are other people too who are interested about\n&gt;&gt; configuring Heritrix this way since limiting URL&#39;s per host/domain\n&gt;&gt; is something everyone would probably want to do and I&#39;m sure that\n&gt;&gt; they are already doing this but they might be doing this as\n&gt;&gt; inefficiently as me.\n&gt;&gt; \n&gt;&gt; Regards\n&gt;&gt; \n&gt;&gt; Olinto\n&gt;&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; ------------------------------------\n&gt; \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n"}}