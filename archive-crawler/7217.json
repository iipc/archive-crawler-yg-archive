{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":289645082,"authorName":"helloitsmaxine","from":"&quot;helloitsmaxine&quot; &lt;itsmaxine@...&gt;","profile":"helloitsmaxine","replyTo":"LIST","senderId":"AFlgl2PtDItZ_qhHBpZnbzBSI0BoxnSTchUUaTbMjC8nLh865GQyhzAxyGYxeTFaTtFMVPMm12xzQnHRzfUlsRWRwBs6kYNjKpWIAew","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: Crawl rate decreasing with time?","postDate":"1311291672","msgId":7217,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGowYWRlbys5ZmpoQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDRFMjhCNTA2LjYwMzAyMDZAYXJjaGl2ZS5vcmc+"},"prevInTopic":7216,"nextInTopic":7219,"prevInTime":7216,"nextInTime":7218,"topicId":7213,"numMessagesInTopic":9,"msgSnippet":"I m referring to what it says on the Activity Monitor, though admittedly I m not sure what the relevance of it is. Here are screencaps of the console/Activity","rawEmail":"Return-Path: &lt;itsmaxine@...&gt;\r\nX-Sender: itsmaxine@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 1742 invoked from network); 21 Jul 2011 23:41:19 -0000\r\nX-Received: from unknown (66.196.94.105)\n  by m10.grp.re1.yahoo.com with QMQP; 21 Jul 2011 23:41:19 -0000\r\nX-Received: from unknown (HELO n41b.bullet.mail.sp1.yahoo.com) (66.163.168.155)\n  by mta1.grp.re1.yahoo.com with SMTP; 21 Jul 2011 23:41:19 -0000\r\nX-Received: from [69.147.65.151] by n41.bullet.mail.sp1.yahoo.com with NNFMP; 21 Jul 2011 23:41:12 -0000\r\nX-Received: from [98.137.34.35] by t5.bullet.mail.sp1.yahoo.com with NNFMP; 21 Jul 2011 23:41:12 -0000\r\nDate: Thu, 21 Jul 2011 23:41:12 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;j0adeo+9fjh@...&gt;\r\nIn-Reply-To: &lt;4E28B506.6030206@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nFrom: &quot;helloitsmaxine&quot; &lt;itsmaxine@...&gt;\r\nSubject: Re: Crawl rate decreasing with time?\r\nX-Yahoo-Group-Post: member; u=289645082; y=u6enOoz-07O6hu7-QCdRe3AEbTvYA-VnYFtxz1zOowUtJbGuWg5srkQU1xZAglrFQ4r7bCHvqRZ6_-Q\r\nX-Yahoo-Profile: helloitsmaxine\r\n\r\nI&#39;m referring to what it says on the Activity Monitor, though admittedly I&#39;=\r\nm not sure what the relevance of it is. Here are screencaps of the console/=\r\nActivity Monitor (2 panes): \nhttp://img39.imageshack.us/img39/2212/ss25h36m=\r\n.jpg\nhttp://img29.imageshack.us/img29/9120/ss25h36mcpu.jpg\n\nThe swap report=\r\ned is 4.4gb at this point-about 25h into the crawl...is that a large enough=\r\n amount to warrant scaling back on heap?\n\nThe HTTP timeout-seconds value I =\r\nhave now is 1200 (that&#39;s 20 mins...seems long?) and the sotimeout-ms is 20,=\r\n000 (20s, I guess that makes sense). Would it help to reduce both or just t=\r\nhe sotimeout? How much of a reduction would you suggest? Could I make it as=\r\n low as 1 second? Or is maybe 5-10 better?\n\nCurrently it looks like URI&#39;s c=\r\nrawled is still under a million, though I would eventually like to grow it =\r\nto the tens of millions--would looking into the BloomUriUniqFilter be worth=\r\n it at this point?\n\nThanks for your suggestions; I really appreciate it!\n\n-=\r\n-- In archive-crawler@yahoogroups.com, Gordon Mohr &lt;gojomo@...&gt; wrote:\n&gt;\n&gt; =\r\nWhat do you mean by &quot;VM size&quot;? (What tool is reporting that number?)\n&gt; \n&gt; I=\r\nt would be very atypical for the heap size or JavaVM process address \n&gt; spa=\r\nce to be 150 gigabytes.\n&gt; \n&gt; What is the hardware like? (RAM, CPU, disk cou=\r\nnt/speed)\n&gt; \n&gt; If all the threads are working on something, and the &#39;conges=\r\ntion ratio&#39; \n&gt; is high, then the problem is not that there&#39;s too little tha=\r\nt&#39;s eligible \n&gt; to crawl politely.\n&gt; \n&gt; Some top possibilities:\n&gt; \n&gt; =95 Ja=\r\nva process size has grown larger than RAM and excessive swapping is \n&gt; occu=\r\nrring. Due to Java&#39;s pattern of memory access, you essentially never \n&gt; wan=\r\nt to be using swap. If &#39;top&#39; or &#39;vmstat&#39; show any swap being used, \n&gt; add R=\r\nAM or scale back the heap so that it isn&#39;t.\n&gt; \n&gt; =95 most threads are makin=\r\ng fetches against unresponsive sites, which can \n&gt; take a long time to time=\r\nout. Large crawls that hit giant link-lists to \n&gt; defunct/fake sites can ex=\r\nperience this. More threads, shortening the \n&gt; FetchHTTP soTimeout, and man=\r\nually pruning the bad URIs can help.\n&gt; \n&gt; =95 the crawl has grown so large =\r\nthat accesses to the data-structures \n&gt; which overflow to disk (notably the=\r\n default &#39;already-seen&#39; \n&gt; BdbUriUniqFilter) are now dominating its time us=\r\nage. On broader and \n&gt; larger crawls -- expected to grow to more than a few=\r\n tens of millions of \n&gt; URIs -- you may want to consider the BloomUriUniqFi=\r\nlter, though it has \n&gt; other RAM costs and imprecision caveats.\n&gt; \n&gt; Hope t=\r\nhis helps,\n&gt; \n&gt; - Gordon\n&gt; \n&gt; On 7/21/11 3:59 PM, helloitsmaxine wrote:\n&gt; &gt;=\r\n Some other details I&#39;ve noticed are that according to the activity\n&gt; &gt; mon=\r\nitor, the VM size is about 150gb, and CPU usage during the crawl\n&gt; &gt; is typ=\r\nically very low, with over 95% idle.\n&gt; &gt;\n&gt; &gt; Is that weird? If there is so =\r\nmuch CPU and VM available, would it\n&gt; &gt; just make sense to keep increasing =\r\nmemory allocation and # threads to\n&gt; &gt; keep crawl rates up? Anyone have exp=\r\nerience with this sort of thing?\n&gt; &gt;\n&gt; &gt; --- In archive-crawler@yahoogroups=\r\n.com,\n&gt; &gt; &quot;helloitsmaxine&quot;&lt;itsmaxine@&gt;  wrote:\n&gt; &gt;&gt;\n&gt; &gt;&gt; On my crawls I&#39;ve =\r\nnoticed that they generally have been starting\n&gt; &gt;&gt; out at pretty good rate=\r\ns, ie. 1500kb/s, but then after a few hours,\n&gt; &gt;&gt; this goes down to 0-50kb/=\r\ns and pretty much stays there.\n&gt; &gt;&gt;\n&gt; &gt;&gt; After reading about some other peo=\r\nple&#39;s same problems I tried a few\n&gt; &gt;&gt; tweaks: - increasing JVM memory to 1=\r\n024 - increasing # threads from\n&gt; &gt;&gt; 50 to 100 - increasing in/out recordin=\r\ng buffers However the problem\n&gt; &gt;&gt; still persists.\n&gt; &gt;&gt;\n&gt; &gt;&gt; Some informati=\r\non about my crawl is: - using Heritrix 1.4 - the max\n&gt; &gt;&gt; heap is being use=\r\nd (ie. current and max are the same) - the threads\n&gt; &gt;&gt; are all pretty much=\r\n active (99-100 out of 100 active at a time) -\n&gt; &gt;&gt; very high congestion ra=\r\ntio, (ie. 7000) - so far it has crawled\n&gt; &gt;&gt; 674003 URI&#39;s in about 20h.\n&gt; &gt;=\r\n&gt;\n&gt; &gt;&gt; Does anyone have insight into how I can prevent this problem? I&#39;ve\n&gt;=\r\n &gt;&gt; read this:\n&gt; &gt;&gt; https://webarchive.jira.com/wiki/display/Heritrix/makin=\r\ng+a+busy+crawl+go+faster\n&gt; &gt;&gt;\n&gt; &gt;&gt;\n&gt; and a few other posts but am not sure =\r\nwhat applies to my situation and \n&gt; what would be the best next steps to ta=\r\nke. Or if there&#39;s any other \n&gt; information that might be helpful let me kno=\r\nw!\n&gt; &gt;&gt;\n&gt; &gt;&gt; Thanks!\n&gt; &gt;&gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; -----------------------------=\r\n-------\n&gt; &gt;\n&gt; &gt; Yahoo! Groups Links\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}