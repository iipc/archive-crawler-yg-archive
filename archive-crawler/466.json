{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":147142055,"authorName":"bruce","from":"&quot;bruce&quot; &lt;bedouglas@...&gt;","profile":"usc_dog","replyTo":"LIST","senderId":"sXZvBsC7eQLIgzelk_PRKeAlSHPvNtuu5F1Q40OI7Aw7FhxmcNbHEU6qoKEvLxn8vPgNRi118r-0YL16pTgHtIv6PRwuarK5","spamInfo":{"isSpam":false,"reason":"0"},"subject":"RE: [archive-crawler] Heritrix - use...","postDate":"1085706468","msgId":466,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDAwMTIwMWM0NDQ1MCQzMmIwM2UyMCQwMzAxYThjMEBNZXNhLmNvbT4=","inReplyToHeader":"PDQwQjY3QjQ3LjUwNzAyMDZAYXJjaGl2ZS5vcmc+"},"prevInTopic":465,"nextInTopic":467,"prevInTime":465,"nextInTime":467,"topicId":455,"numMessagesInTopic":37,"msgSnippet":"hey... thanks for the response. my questions are pretty basic, so bear with me! 1) is it possible to provide a list of domains/urls that the app can crawl ","rawEmail":"Return-Path: &lt;bedouglas@...&gt;\r\nX-Sender: bedouglas@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 52648 invoked from network); 28 May 2004 01:50:09 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m25.grp.scd.yahoo.com with QMQP; 28 May 2004 01:50:09 -0000\r\nReceived: from unknown (HELO sccrmhc13.comcast.net) (204.127.202.64)\n  by mta1.grp.scd.yahoo.com with SMTP; 28 May 2004 01:50:09 -0000\r\nReceived: from sys2 (c-24-5-249-240.client.comcast.net[24.5.249.240])\n          by comcast.net (sccrmhc13) with SMTP\n          id &lt;2004052801015201600rgu23e&gt;; Fri, 28 May 2004 01:01:52 +0000\r\nTo: &lt;archive-crawler@yahoogroups.com&gt;\r\nDate: Thu, 27 May 2004 18:07:48 -0700\r\nMessage-ID: &lt;001201c44450$32b03e20$0301a8c0@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: text/plain;\n\tcharset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: 7bit\r\nX-Priority: 3 (Normal)\r\nX-MSMail-Priority: Normal\r\nX-Mailer: Microsoft Outlook CWS, Build 9.0.2416 (9.0.2910.0)\r\nImportance: Normal\r\nIn-Reply-To: &lt;40B67B47.5070206@...&gt;\r\nX-MimeOLE: Produced By Microsoft MimeOLE V6.00.2800.1165\r\nX-eGroups-Remote-IP: 204.127.202.64\r\nFrom: &quot;bruce&quot; &lt;bedouglas@...&gt;\r\nReply-To: &lt;bedouglas@...&gt;\r\nSubject: RE: [archive-crawler] Heritrix - use...\r\nX-Yahoo-Group-Post: member; u=147142055\r\nX-Yahoo-Profile: usc_dog\r\n\r\nhey...\n\nthanks for the response. my questions are pretty basic, so bear with me!\n\n1) is it possible to provide a list of domains/urls that the app can crawl\nthrough, thus creating a basic domain/pool of content. ie, is it possible\nfor us to &quot;feed&quot; the urls of the various college registrar sites to the app,\nand have it then return/save the information to an internal file, or series\nof files.\n\n2) is it possible to configure the app to only return pages from a given url\nthat have certain information/tags/elements, or is that better handled by\nthe parser/reader function?\n\n3) once we have the returned information, how difficult/easy is it to\nwrite/create a reader? if we are looking to parse multiple schools, would it\nmake sense to write a separate reader for each school that would have been\nreturned from the crawling app?\n\n4) are there reasonably well documented readers for us to review? it would\nhelp greatly to be able to run a crawling app, and then pass the reader over\nthe returned information... this would allow a way to see how the overall\napps actually function..\n\nthanks for your time/patience...\n\nbruce\n\n\n-----Original Message-----\nFrom: Michael Stack [mailto:stack@...]\nSent: Thursday, May 27, 2004 4:36 PM\nTo: archive-crawler@yahoogroups.com\nSubject: Re: [archive-crawler] Heritrix - use...\n\n\nbruce wrote:\n\n&gt;hi...\n&gt;\n&gt;we&#39;re looking at heritrix and it&#39;s possible uses as a crawling/spidering\n&gt;application. we&#39;re considering an application that would have to parse\n&gt;various university/college sites for registrar information.\n&gt;\n&gt;as such, we basically would know prior to searching what the various\n&gt;tags/text for a given element would be that we want to extract the\n&gt;information for. we&#39;re curious as to whether heritrix might be able to be\n&gt;easily modified for this kind of purpose. we haven&#39;t yet had an opportunity\n&gt;to get into the docs/code to really look at what it does.\n&gt;\n&gt;\nUse heritrix to crawl the sites to get the raw pages.  The raw pages are\nsaved to files known as ARC files. One file has hundreds of pages.  The\ncutoff point is hit when the file is (configurable) 100M in size.  These\nARC files would then serve as input to a parser of your writing that\nwould extract the pages/info you&#39;re trying to harvest.  To parse the ARC\nfiles, you need a reader.  There are a few options outlined here:\nhttp://crawler.archive.org/articles/developer_manual.html#arcreader.\n\nAsk more questions.\n\nYours,\nSt.Ack\n\n\n&gt;to be frank, we&#39;re looking for a solution that would allow us to not have\nto\n&gt;write unique perl scripts/parsers for each site!\n&gt;\n&gt;if there is someone who&#39;s familiar with this app that we could talk to, we\n&gt;would greatly appreciate a short conversation to get a better understanding\n&gt;of what the app does, and how it works.\n&gt;\n&gt;regards,\n&gt;\n&gt;bruce douglas\n&gt;bedouglas@...\n&gt;(925) 866-2790\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n\n\nYahoo! Groups Sponsor\nADVERTISEMENT\n\n\n\n\n\n\nYahoo! Groups Links\n\nTo visit your group on the web, go to:\nhttp://groups.yahoo.com/group/archive-crawler/\n\nTo unsubscribe from this group, send an email to:\narchive-crawler-unsubscribe@yahoogroups.com\n\nYour use of Yahoo! Groups is subject to the Yahoo! Terms of Service.\n\n\n"}}