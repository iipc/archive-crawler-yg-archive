{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":163406187,"authorName":"Kristinn Sigur√∞sson","from":"=?iso-8859-1?q?Kristinn_Sigur=F0sson?= &lt;kris@...&gt;","profile":"kristsi25","replyTo":"LIST","senderId":"A9YzL4innqtfSm_NdQmSlYTTphkOA6xo4fyqasbx_hW5Xda4OMo11oDFHmp5HN49w-EyQIzL6LZy8ClhZ0m2fSnlc3USlmoBMYgU_vO44Tp1FTjIVIainihwpBbQxz0a","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Incremeal crawling ...?","postDate":"1186051161","msgId":4487,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGY4c2M4cCsydTBkQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGY4cnZubSsyOXE5QGVHcm91cHMuY29tPg=="},"prevInTopic":4486,"nextInTopic":0,"prevInTime":4486,"nextInTime":4488,"topicId":4486,"numMessagesInTopic":2,"msgSnippet":"This is a somewhat loaded question as incremental crawling can be a vague term. It may help to explain what you hope to achieve (reduce data volume etc.) For","rawEmail":"Return-Path: &lt;kris@...&gt;\r\nX-Sender: kris@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 20917 invoked from network); 2 Aug 2007 10:40:23 -0000\r\nReceived: from unknown (66.218.66.71)\n  by m44.grp.scd.yahoo.com with QMQP; 2 Aug 2007 10:40:23 -0000\r\nReceived: from unknown (HELO n11e.bullet.scd.yahoo.com) (66.218.67.71)\n  by mta13.grp.scd.yahoo.com with SMTP; 2 Aug 2007 10:40:23 -0000\r\nReceived: from [66.218.69.6] by n21.bullet.scd.yahoo.com with NNFMP; 02 Aug 2007 10:39:22 -0000\r\nReceived: from [66.218.66.81] by t6.bullet.scd.yahoo.com with NNFMP; 02 Aug 2007 10:39:22 -0000\r\nDate: Thu, 02 Aug 2007 10:39:21 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;f8sc8p+2u0d@...&gt;\r\nIn-Reply-To: &lt;f8rvnm+29q9@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: =?iso-8859-1?q?Kristinn_Sigur=F0sson?= &lt;kris@...&gt;\r\nSubject: Re: Incremeal crawling ...?\r\nX-Yahoo-Group-Post: member; u=163406187; y=RCP7xzE4kbRNMbiiWyReKL8coXcjkMyhHGyCHR5wCDDnXqoP\r\nX-Yahoo-Profile: kristsi25\r\n\r\nThis is a somewhat loaded question as &#39;incremental crawling&#39; can be a\nvague=\r\n term. It may help to explain what you hope to achieve (reduce\ndata volume =\r\netc.) \n\nFor truly continuous incremental crawling you may be out of luck. I=\r\n&#39;ve\ndone some work on that front (detailed in\nhttp://vefsofnun.bok.hi.is/up=\r\nload/3/article.pdf). Unfortunately the\nresults are less then encouraging.\n\n=\r\nA more successful approach at simply reducing duplicates in a series\nof &#39;sn=\r\napshot&#39; crawls is discussed in this paper:\nhttp://vefsofnun.bok.hi.is/uploa=\r\nd/3/ManagingDuplicatesAcrossSequentialCrawls.pdf\n(See also: http://deduplic=\r\nator.sourceforge.net)\n\nThat approach is not truly &#39;incremental&#39; but provide=\r\ns a reasonable\napproximation with none of the serious drawbacks of continuo=\r\nus crawling. \n\nIn addition to the DeDuplicator add-on for Heritrix discusse=\r\nd in the\npaper, The Internet Archive have also added a similar tool to Heri=\r\ntrix\nas of 1.12.0. It operates on the same principle but implements it\nusin=\r\ng different logging and data structures.\n\n- Kris\n\n--- In archive-crawler@ya=\r\nhoogroups.com, &quot;vretr&quot; &lt;vretr@...&gt; wrote:\n&gt;\n&gt; Hi, all:\n&gt;   I have met a que=\r\nstion. I  Want to use Heirtrix  to realize\n&gt; increasemetal  crawling, but  =\r\ni  don&#39;t know how to do it . \n&gt;   does anyone know how to solve this questi=\r\non  ? How to dispose the\n&gt; related parameter=A1=A3\n&gt; \n&gt; many thanks.\n&gt;\n\n\n\n"}}