{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":163406187,"authorName":"Kristinn Sigurdsson","from":"&quot;Kristinn Sigurdsson&quot; &lt;kris@...&gt;","profile":"kristsi25","replyTo":"LIST","senderId":"YDFUDw3P6ZxUFvrWrd9rxJDEzwYcxZmVijh2UIrHO15PZiGQVmGbbwF6rssoUdc5jmg8TsubITFgtBG3yzWbqcyyBjnS7jiHoMmY9gey6g","spamInfo":{"isSpam":false,"reason":"0"},"subject":"RE: [archive-crawler] continuous crawling proposal","postDate":"1107248824","msgId":1454,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDA2NzhEQjE5NjhFQUM3NDA5Q0MzRDBBQjdBMTFCODRBMDZFQzQwQHNrYXJmdXIuYm9rLmxvY2FsPg==","inReplyToHeader":"PDQxRkY0MzVFLjUwNDAwMDFAc3RhdHNiaWJsaW90ZWtldC5kaz4="},"prevInTopic":1453,"nextInTopic":1455,"prevInTime":1453,"nextInTime":1455,"topicId":1452,"numMessagesInTopic":24,"msgSnippet":"Yes, the AR module (currently available as a branch of the Heritrix project, http://crawltools.archive.org:8080/cruisecontrol/buildresults/BRANCH-heritri ","rawEmail":"Return-Path: &lt;kris@...&gt;\r\nX-Sender: kris@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 63325 invoked from network); 1 Feb 2005 09:09:11 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m8.grp.scd.yahoo.com with QMQP; 1 Feb 2005 09:09:11 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (207.241.224.172)\n  by mta4.grp.scd.yahoo.com with SMTP; 1 Feb 2005 09:09:11 -0000\r\nReceived: (qmail 27301 invoked by uid 100); 1 Feb 2005 08:51:22 -0000\r\nReceived: from forritun-4.bok.hi.is (HELO forritun4) (kris@...@130.208.152.83)\n  by mail-dev.archive.org with SMTP; 1 Feb 2005 08:51:22 -0000\r\nTo: &lt;archive-crawler@yahoogroups.com&gt;\r\nDate: Tue, 1 Feb 2005 09:07:04 -0000\r\nMessage-ID: &lt;0678DB1968EAC7409CC3D0AB7A11B84A06EC40@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: multipart/alternative;\n\tboundary=&quot;----=_NextPart_000_0001_01C5083D.6733C340&quot;\r\nX-Priority: 3 (Normal)\r\nX-MSMail-Priority: Normal\r\nX-Mailer: Microsoft Outlook, Build 10.0.4510\r\nIn-reply-to: &lt;41FF435E.5040001@...&gt;\r\nImportance: Normal\r\nX-MimeOLE: Produced By Microsoft MimeOLE V6.00.2800.1441\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=0.7 required=6.5 tests=AWL,HTML_20_30,\n\tHTML_FONTCOLOR_BLUE,HTML_MESSAGE autolearn=no version=2.63\r\nX-eGroups-Remote-IP: 207.241.224.172\r\nFrom: &quot;Kristinn Sigurdsson&quot; &lt;kris@...&gt;\r\nSubject: RE: [archive-crawler] continuous crawling proposal\r\nX-Yahoo-Group-Post: member; u=163406187\r\nX-Yahoo-Profile: kristsi25\r\n\r\n\r\n------=_NextPart_000_0001_01C5083D.6733C340\r\nContent-Type: text/plain;\n\tcharset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nYes, the AR module (currently available as a branch of the Heritrix project=\r\n,\nhttp://crawltools.archive.org:8080/cruisecontrol/buildresults/BRANCH-heri=\r\ntri\nx-Kris-ARbranch2) provides the functionality required for incrimental\nc=\r\nrawling.  \n \nTo do this it implements a new Frontier that uses priority que=\r\nues for the\nURIs (this also does away with the &#39;already included fingerprin=\r\nts of URIs). \n \nA processor (dubbed a WaitEvaluator) is inserted to calcula=\r\nte the &#39;time of\nnext processing&#39; before a URI is returned to the Frontier. =\r\nCurrently the\nWaitEvaluator uses a much simpler algorithm than John discuss=\r\nes, but a more\nsophisticated one could easily replace it.\n \nCurrently it re=\r\nlies on a strict hash for content changes (although a\nprocessor for prestri=\r\npping problematic sections using regular expressions is\nprovided). If you h=\r\nave ideas for better content hashes, I&#39;d love to hear\nthem.\n \nCurrently thi=\r\ns add on to Heritrix is being tested, if all goes well it will\nbecome a par=\r\nt of of the next Heritrix release.\n \n- Kris\n\n-----Original Message-----\nFro=\r\nm: Bjarne Andersen [mailto:bja@...] \nSent: 1. febr=FAar 200=\r\n5 08:53\nTo: archive-crawler@yahoogroups.com\nSubject: Re: [archive-crawler] =\r\ncontinuous crawling proposal\n\n\nYou might want to take a look at the Automat=\r\ned Revisiting Module being \ndeveloped at the moment by kris@...\n\nIt=\r\n does implement a new Frontier including a new Queing-mechanism along \nwith=\r\n a simple algoritm to decide when to bring URI&#39;s to the top of the \nqueue (=\r\nbased on historical results - next-ready-time goes either up or \ndown every=\r\ntime a page is fetched and compared to the last fetch)\n\nIt is available fro=\r\nm the continous build box at crawler.archive.org (a \nCVS-brach called *_AR.=\r\n...)\n\nbest\nBjarne Andersen\n\nJohn R. Frank wrote:\n&gt; Stack,\n&gt; \n&gt; What do you =\r\nthink of these three steps as a possible way to implement\n&gt; continuous craw=\r\nling in Heritrix?  Details for each of these three are\n&gt; discussed below.\n&gt;=\r\n \n&gt; 1) extend the work queue&#39;s logic to only dequeue &quot;ready&quot; URLs\n&gt; \n&gt; 2) d=\r\necide when to recheck a given page based on a simple model\n&gt; \n&gt; 3) detect s=\r\nubstantive page changes and store the info in AlreadySeen\n&gt; \n&gt; \n&gt; \n&gt; 1) To =\r\ndo this, we need a queueing mechanism that blocks the dequeuing of a\n&gt; Craw=\r\nlURI until we are past its assigned next &quot;okay to crawl&quot; moment.\n&gt; Where sh=\r\nould we store this timestamp?  As you said, the BDB keys are\n&gt; overloaded w=\r\nith too much meaning already, so putting a seconds since the\n&gt; epoch in the=\r\nre is not so good:\n&gt;\nhttp://crawler.archive.org/xref/org/archive/crawler/fr=\r\nontier/BdbMultipleWork\nQueues.html#246\n&gt; \n&gt; Perhaps this timestamp belongs =\r\nin CandidateURI where the\n&gt; schedulingDirective pieces are?  For example, i=\r\nf the schedulingDirective\n&gt; is negative, then it could be interpreted as a =\r\ntimestamp.  So for a\n&gt; document next Wednesday, it would get:\n&gt; \n&gt; jrf@loca=\r\nlhost~$ date +%s -d &quot;Feb 9 01:20:29 EST 2005&quot;\n&gt; 1107930029\n&gt; \n&gt; with a minu=\r\ns sign in front:  -1107930029\n&gt; \n&gt; Adding `date +%s -d now` now to that wil=\r\nl give a positive number when it\n&gt; is okay to crawl.  This would require mo=\r\ndifications to the four-bit\n&gt; interpretation of priority in the BDB key com=\r\nputation.  An escape value\n&gt; of 1111 might tell the queue that it needs to =\r\nlook in the object to find\n&gt; the value of the timestamp.\n&gt; \n&gt; The problem w=\r\nith this is that suddenly the queue is not a queue, because\n&gt; the keys are =\r\nthe sorting mechanism on the queue in the BDB implementation,\n&gt; right?  Do =\r\nyou see a way fix to this besides cycling through all the curi\n&gt; with 1111 =\r\nlooking at the full value of the timestamp?\n&gt; \n&gt; \n&gt; \n&gt; 2) To compute the ti=\r\nme at which to refetch, we can predict the likelihood\n&gt; that the page has b=\r\neen modified as a function of time since last modified.\n&gt; See below for dis=\r\ncussion of detecting last modified.  An easy function to\n&gt; use for this mod=\r\neling comes from the Michaelis-Menton model of enzyme\n&gt; kinetics:\n&gt; \n&gt;     =\r\n  t is time elapsed after a modification of the content\n&gt; \n&gt;       P(t) is =\r\nthe probability that the page has changed by time t\n&gt; \n&gt;                   =\r\n       a\n&gt;                       k t\n&gt;              P(t) =3D  -------------=\r\n--\n&gt;                            a\n&gt;                    1  + k t\n&gt; \n&gt; At sma=\r\nll t, P is small.  At large t, P tends to 1, i.e. certainty of\n&gt; change.  I=\r\nt is easiest to choose a=3D2, which is the smallest integer value\n&gt; that gi=\r\nves step-like behavior.  We can then set k by fitting this function\n&gt; to an=\r\ny given page&#39;s history (details below).\n&gt; \n&gt; Given k, we can use P(t) to pr=\r\nedict when to refetch a document.  We pick a\n&gt; threshold probability above =\r\nwhich we want to refetch.  If we set it low,\n&gt; then we want to recheck more=\r\n often.  If we set it high, that means we&#39;re\n&gt; willing to tolerate more sta=\r\nle content in order to not recheck as often.\n&gt; \n&gt; When P(t) exceeds the cho=\r\nsen threshold, then we want to recheck it.  By\n&gt; inverting the probability =\r\nfunction, this threshold gives us a time to\n&gt; wait before rechecking the pa=\r\nge:\n&gt; \n&gt;                  k                (-1/a)\n&gt;        t =3D ( --------=\r\n--   -   k )\n&gt;              threshold\n&gt; \n&gt;    For clarity that is:\n&gt;    t =\r\n=3D (((k / threshold) - k ) ^ (-1/a))\n&gt; \n&gt; t is the time interval between t=\r\nhe most recent known modification event\n&gt; and that time in the future when =\r\nthe expected probability of change is\n&gt; just above threshold.  For robustne=\r\nss, we should define a time within\n&gt; which all pages must be rechecked.  In=\r\n python, the function might look\n&gt; like:\n&gt; \n&gt; def delay(k, threshold):\n&gt;   =\r\n  Days =3D 60 * 60 * 24\n&gt;     maxRecheckDelay =3D 20 * Days\n&gt;     threshold=\r\nDelay =3D (((k / threshold) - k ) ^ (-1/alpha))\n&gt;     return minimum(maxRec=\r\nheckDelay, thresholdDelay)\n&gt; \n&gt; \n&gt; 3. Since last-modified information is no=\r\nt universally provided by document\n&gt; repositories, we need a mechanism to d=\r\netect substantive content changes\n&gt; and record them in the BDB.  I&#39;m lookin=\r\ng into tools for this kind of\n&gt; content hashing that could be run in the ex=\r\ntractor chain and stored in the\n&gt; object that gets into BDB.\n&gt; \n&gt; Suppose w=\r\ne have such a content hash, then the interval of time between two\n&gt; known m=\r\nodification events is an upper bound because there could have been\n&gt; a modi=\r\nfication event that we did not observe between these observed\n&gt; events.  If=\r\n these upper bounds are not far off the real value, then we can\n&gt; accuratel=\r\ny approximate the probability of modification at half the\n&gt; observed interv=\r\nal as being 50%.  That is, we use the previously observed\n&gt; modification in=\r\ntervals to estimate what the next actual interval will be.\n&gt; If the average=\r\n of the last, say, five observed intervals is T, then we\n&gt; estimate that at=\r\n (T/2) in the future, the probability of modification will\n&gt; be 50%.  This =\r\nlet&#39;s us estimate a value for k based on previously observed\n&gt; modification=\r\n intervals:\n&gt; \n&gt;                -a\n&gt;        k =3D (T/2)    which for a=3D2 =\r\nis (two over T) squared.\n&gt; \n&gt; \n&gt; Some logic is required to make sure that o=\r\nnly the last few, say five,\n&gt; meaningful modification intervals are average=\r\nd to make T.  This moving\n&gt; window average allows Heritrix to more rapidly =\r\nadapt to pages that have\n&gt; varying update frequencies, which is most pages.=\r\n\n&gt; \n&gt; \n&gt; Thoughts?  Reactions?\n&gt; \n&gt; John\n&gt; \n&gt; -----------------------------=\r\n-------------------------------------------\n&gt; *Yahoo! Groups Links*\n&gt; \n&gt;   =\r\n  * To visit your group on the web, go to:\n&gt;       http://groups.yahoo.com/=\r\ngroup/archive-crawler/\n&gt;        \n&gt;     * To unsubscribe from this group, se=\r\nnd an email to:\n&gt;       archive-crawler-unsubscribe@yahoogroups.com\n&gt;\n&lt;mail=\r\nto:archive-crawler-unsubscribe@yahoogroups.com?subject=3DUnsubscribe&gt;\n&gt;    =\r\n    \n&gt;     * Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt; =\r\n      Service &lt;http://docs.yahoo.com/info/terms/&gt;. \n&gt; \n&gt; \n\n\n  _____  \n\nYaho=\r\no! Groups Links\n\n\n*\tTo visit your group on the web, go to:\nhttp://groups.ya=\r\nhoo.com/group/archive-crawler/\n  \n\n*\tTo unsubscribe from this group, send a=\r\nn email to:\narchive-crawler-unsubscribe@yahoogroups.com\n&lt;mailto:archive-cra=\r\nwler-unsubscribe@yahoogroups.com?subject=3DUnsubscribe&gt; \n  \n\n*\tYour use of =\r\nYahoo! Groups is subject to the Yahoo! Terms of Service\n&lt;http://docs.yahoo.=\r\ncom/info/terms/&gt; . \n\n\n\r\n------=_NextPart_000_0001_01C5083D.6733C340\r\nContent-Type: text/html;\n\tcharset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.0 Transitional//EN&quot;&gt;\n&lt;HTML&gt;&lt;HEAD&gt;=\r\n&lt;TITLE&gt;Message&lt;/TITLE&gt;\n&lt;META http-equiv=3DContent-Type content=3D&quot;text/html=\r\n; charset=3Diso-8859-1&quot;&gt;\n&lt;META content=3D&quot;MSHTML 6.00.2800.1476&quot; name=3DGEN=\r\nERATOR&gt;&lt;/HEAD&gt;\n&lt;BODY&gt;\n&lt;DIV&gt;&lt;SPAN class=3D720265808-01022005&gt;&lt;FONT face=3DAr=\r\nial color=3D#0000ff size=3D2&gt;Yes, \nthe AR module (currently available as a =\r\nbranch of the Heritrix project, &lt;A \nhref=3D&quot;http://crawltools.archive.org:8=\r\n080/cruisecontrol/buildresults/BRANCH-heritrix-Kris-ARbranch2&quot;&gt;http://crawl=\r\ntools.archive.org:8080/cruisecontrol/buildresults/BRANCH-heritrix-Kris-ARbr=\r\nanch2&lt;/A&gt;) \nprovides the functionality required for incrimental crawling.&n=\r\nbsp; \n&lt;/FONT&gt;&lt;/SPAN&gt;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;SPAN class=3D720265808-01022005&gt;&lt;FONT face=\r\n=3DArial color=3D#0000ff \nsize=3D2&gt;&lt;/FONT&gt;&lt;/SPAN&gt;&nbsp;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;SPAN cl=\r\nass=3D720265808-01022005&gt;&lt;FONT face=3DArial color=3D#0000ff size=3D2&gt;To do =\r\n\nthis it implements a new Frontier that uses priority queues for the URIs (=\r\nthis \nalso does away with the &#39;already included fingerprints of URIs). \n&lt;/F=\r\nONT&gt;&lt;/SPAN&gt;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;SPAN class=3D720265808-01022005&gt;&lt;FONT face=3DArial =\r\ncolor=3D#0000ff \nsize=3D2&gt;&lt;/FONT&gt;&lt;/SPAN&gt;&nbsp;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;SPAN class=3D720=\r\n265808-01022005&gt;&lt;FONT face=3DArial color=3D#0000ff size=3D2&gt;A \nprocessor (d=\r\nubbed a WaitEvaluator) is inserted to calculate the &#39;time of next \nprocessi=\r\nng&#39; before a URI is returned to the Frontier. Currently the \nWaitEvaluator =\r\nuses a much simpler algorithm than John discusses, but a more \nsophisticate=\r\nd one could easily replace it.&lt;/FONT&gt;&lt;/SPAN&gt;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;SPAN class=3D72026=\r\n5808-01022005&gt;&lt;FONT face=3DArial color=3D#0000ff \nsize=3D2&gt;&lt;/FONT&gt;&lt;/SPAN&gt;&n=\r\nbsp;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;SPAN class=3D720265808-01022005&gt;&lt;FONT face=3DArial color=\r\n=3D#0000ff \nsize=3D2&gt;Currently it relies on a strict hash for content chang=\r\nes (although a \nprocessor for prestripping problematic sections using regul=\r\nar expressions is \nprovided). If you have ideas for better content hashes, =\r\nI&#39;d love to hear \nthem.&lt;/FONT&gt;&lt;/SPAN&gt;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;SPAN class=3D720265808-01=\r\n022005&gt;&lt;FONT face=3DArial color=3D#0000ff \nsize=3D2&gt;&lt;/FONT&gt;&lt;/SPAN&gt;&nbsp;&lt;/D=\r\nIV&gt;\n&lt;DIV&gt;&lt;SPAN class=3D720265808-01022005&gt;&lt;FONT face=3DArial color=3D#0000f=\r\nf \nsize=3D2&gt;Currently this add on to Heritrix is being tested, if all goes =\r\nwell it \nwill become a part of of the next Heritrix release.&lt;/FONT&gt;&lt;/SPAN&gt;&lt;=\r\n/DIV&gt;\n&lt;DIV&gt;&lt;SPAN class=3D720265808-01022005&gt;&lt;FONT face=3DArial color=3D#000=\r\n0ff \nsize=3D2&gt;&lt;/FONT&gt;&lt;/SPAN&gt;&nbsp;&lt;/DIV&gt;\n&lt;DIV&gt;&lt;SPAN class=3D720265808-01022=\r\n005&gt;&lt;FONT face=3DArial color=3D#0000ff size=3D2&gt;- \nKris&lt;/FONT&gt;&lt;/SPAN&gt;&lt;/DIV&gt;=\r\n\n&lt;BLOCKQUOTE \nstyle=3D&quot;PADDING-LEFT: 5px; MARGIN-LEFT: 5px; BORDER-LEFT: #0=\r\n000ff 2px solid; MARGIN-RIGHT: 0px&quot;&gt;\n  &lt;DIV&gt;&lt;/DIV&gt;\n  &lt;DIV class=3DOutlookMe=\r\nssageHeader lang=3Den-us dir=3Dltr align=3Dleft&gt;&lt;FONT \n  face=3DTahoma size=\r\n=3D2&gt;-----Original Message-----&lt;BR&gt;&lt;B&gt;From:&lt;/B&gt; Bjarne Andersen \n  [mailto:=\r\nbja@...] &lt;BR&gt;&lt;B&gt;Sent:&lt;/B&gt; 1. febr=FAar 2005 \n  08:53&lt;BR&gt;&lt;B&gt;=\r\nTo:&lt;/B&gt; archive-crawler@yahoogroups.com&lt;BR&gt;&lt;B&gt;Subject:&lt;/B&gt; Re: \n  [archive-=\r\ncrawler] continuous crawling proposal&lt;BR&gt;&lt;BR&gt;&lt;/FONT&gt;&lt;/DIV&gt;&lt;TT&gt;You \n  might =\r\nwant to take a look at the Automated Revisiting Module being \n  &lt;BR&gt;develop=\r\ned at the moment by kris@...&lt;BR&gt;&lt;BR&gt;It does implement a new \n  Fron=\r\ntier including a new Queing-mechanism along &lt;BR&gt;with a simple algoritm to \n=\r\n  decide when to bring URI&#39;s to the top of the &lt;BR&gt;queue (based on historic=\r\nal \n  results - next-ready-time goes either up or &lt;BR&gt;down everytime a page=\r\n is \n  fetched and compared to the last fetch)&lt;BR&gt;&lt;BR&gt;It is available from =\r\nthe \n  continous build box at crawler.archive.org (a &lt;BR&gt;CVS-brach called \n=\r\n  *_AR....)&lt;BR&gt;&lt;BR&gt;best&lt;BR&gt;Bjarne Andersen&lt;BR&gt;&lt;BR&gt;John R. Frank wrote:&lt;BR&gt;&=\r\ngt; \n  Stack,&lt;BR&gt;&gt; &lt;BR&gt;&gt; What do you think of these three steps as a =\r\npossible \n  way to implement&lt;BR&gt;&gt; continuous crawling in Heritrix?&nbsp;=\r\n Details for \n  each of these three are&lt;BR&gt;&gt; discussed below.&lt;BR&gt;&gt; &lt;B=\r\nR&gt;&gt; 1) extend \n  the work queue&#39;s logic to only dequeue &quot;ready&quot; URLs&lt;BR&gt;=\r\n&gt; &lt;BR&gt;&gt; 2) decide \n  when to recheck a given page based on a simple m=\r\nodel&lt;BR&gt;&gt; &lt;BR&gt;&gt; 3) \n  detect substantive page changes and store the i=\r\nnfo in AlreadySeen&lt;BR&gt;&gt; \n  &lt;BR&gt;&gt; &lt;BR&gt;&gt; &lt;BR&gt;&gt; 1) To do this, we =\r\nneed a queueing mechanism that \n  blocks the dequeuing of a&lt;BR&gt;&gt; CrawlUR=\r\nI until we are past its assigned next \n  &quot;okay to crawl&quot; moment.&lt;BR&gt;&gt; Wh=\r\nere should we store this timestamp?&nbsp; As \n  you said, the BDB keys are&lt;=\r\nBR&gt;&gt; overloaded with too much meaning already, \n  so putting a seconds s=\r\nince the&lt;BR&gt;&gt; epoch in there is not so good:&lt;BR&gt;&gt; \n  &lt;A \n  href=3D&quot;ht=\r\ntp://crawler.archive.org/xref/org/archive/crawler/frontier/BdbMultipleWorkQ=\r\nueues.html#246&quot;&gt;http://crawler.archive.org/xref/org/archive/crawler/frontie=\r\nr/BdbMultipleWorkQueues.html#246&lt;/A&gt;&lt;BR&gt;&gt; \n  &lt;BR&gt;&gt; Perhaps this times=\r\ntamp belongs in CandidateURI where the&lt;BR&gt;&gt; \n  schedulingDirective piece=\r\ns are?&nbsp; For example, if the \n  schedulingDirective&lt;BR&gt;&gt; is negative=\r\n, then it could be interpreted as a \n  timestamp.&nbsp; So for a&lt;BR&gt;&gt; do=\r\ncument next Wednesday, it would \n  get:&lt;BR&gt;&gt; &lt;BR&gt;&gt; jrf@localhost~$ da=\r\nte +%s -d &quot;Feb 9 01:20:29 EST \n  2005&quot;&lt;BR&gt;&gt; 1107930029&lt;BR&gt;&gt; &lt;BR&gt;&gt; =\r\nwith a minus sign in front:&nbsp; \n  -1107930029&lt;BR&gt;&gt; &lt;BR&gt;&gt; Adding `d=\r\nate +%s -d now` now to that will give a \n  positive number when it&lt;BR&gt;&gt; =\r\nis okay to crawl.&nbsp; This would require \n  modifications to the four-bit=\r\n&lt;BR&gt;&gt; interpretation of priority in the BDB \n  key computation.&nbsp; An=\r\n escape value&lt;BR&gt;&gt; of 1111 might tell the queue \n  that it needs to look=\r\n in the object to find&lt;BR&gt;&gt; the value of the \n  timestamp.&lt;BR&gt;&gt; &lt;BR&gt;&=\r\ngt; The problem with this is that suddenly the queue \n  is not a queue, bec=\r\nause&lt;BR&gt;&gt; the keys are the sorting mechanism on the \n  queue in the BDB =\r\nimplementation,&lt;BR&gt;&gt; right?&nbsp; Do you see a way fix to \n  this beside=\r\ns cycling through all the curi&lt;BR&gt;&gt; with 1111 looking at the \n  full val=\r\nue of the timestamp?&lt;BR&gt;&gt; &lt;BR&gt;&gt; &lt;BR&gt;&gt; &lt;BR&gt;&gt; 2) To compute \n  th=\r\ne time at which to refetch, we can predict the likelihood&lt;BR&gt;&gt; that the =\r\n\n  page has been modified as a function of time since last modified.&lt;BR&gt;&gt=\r\n; See \n  below for discussion of detecting last modified.&nbsp; An easy fun=\r\nction \n  to&lt;BR&gt;&gt; use for this modeling comes from the Michaelis-Menton m=\r\nodel of \n  enzyme&lt;BR&gt;&gt; kinetics:&lt;BR&gt;&gt; &lt;BR&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp=\r\n;&nbsp;&nbsp; \n  t is time elapsed after a modification of the content&lt;BR&gt;&=\r\ngt; \n  &lt;BR&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; P(t) is the probability=\r\n that the \n  page has changed by time t&lt;BR&gt;&gt; \n  &lt;BR&gt;&gt;&nbsp;&nbsp;&nbs=\r\np;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=\r\nnbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \n  a&lt;BR&gt;&gt;&nb=\r\nsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \n  k \n  t&lt;BR&gt;&gt;&nb=\r\nsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=\r\n \n  P(t) =3D&nbsp; \n  ---------------&lt;BR&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=\r\nsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \n  a&lt;BR&gt;&gt;&nbsp=\r\n;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=\r\nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \n  1&nbsp; + k t&lt;BR&gt;&gt; &lt;BR&gt;&gt; At sma=\r\nll t, P is small.&nbsp; At large t, P \n  tends to 1, i.e. certainty of&lt;BR&gt;&=\r\ngt; change.&nbsp; It is easiest to choose \n  a=3D2, which is the smallest i=\r\nnteger value&lt;BR&gt;&gt; that gives step-like \n  behavior.&nbsp; We can then se=\r\nt k by fitting this function&lt;BR&gt;&gt; to any \n  given page&#39;s history (detail=\r\ns below).&lt;BR&gt;&gt; &lt;BR&gt;&gt; Given k, we can use \n  P(t) to predict when to r=\r\nefetch a document.&nbsp; We pick a&lt;BR&gt;&gt; threshold \n  probability above w=\r\nhich we want to refetch.&nbsp; If we set it low,&lt;BR&gt;&gt; \n  then we want to=\r\n recheck more often.&nbsp; If we set it high, that means \n  we&#39;re&lt;BR&gt;&gt; w=\r\nilling to tolerate more stale content in order to not recheck \n  as often.&lt;=\r\nBR&gt;&gt; &lt;BR&gt;&gt; When P(t) exceeds the chosen threshold, then we \n  want to=\r\n recheck it.&nbsp; By&lt;BR&gt;&gt; inverting the probability function, this \n  t=\r\nhreshold gives us a time to&lt;BR&gt;&gt; wait before rechecking the page:&lt;BR&gt;&gt=\r\n; \n  &lt;BR&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=\r\nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \n  k&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \n  (-1/a)&lt;BR&gt;&=\r\ngt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; t =3D ( \n  ----------&nbsp;&n=\r\nbsp; -&nbsp;&nbsp; k \n  )&lt;BR&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \n  threshold&lt;BR&gt;&gt; &lt;BR&gt;&gt;&nbsp;&nb=\r\nsp;&nbsp; For clarity that \n  is:&lt;BR&gt;&gt;&nbsp;&nbsp;&nbsp; t =3D (((k / th=\r\nreshold) - k ) ^ (-1/a))&lt;BR&gt;&gt; \n  &lt;BR&gt;&gt; t is the time interval between=\r\n the most recent known modification \n  event&lt;BR&gt;&gt; and that time in the f=\r\nuture when the expected probability of \n  change is&lt;BR&gt;&gt; just above thre=\r\nshold.&nbsp; For robustness, we should define \n  a time within&lt;BR&gt;&gt; whic=\r\nh all pages must be rechecked.&nbsp; In python, the \n  function might look&lt;=\r\nBR&gt;&gt; like:&lt;BR&gt;&gt; &lt;BR&gt;&gt; def delay(k, \n  threshold):&lt;BR&gt;&gt;&nbsp;&nb=\r\nsp;&nbsp;&nbsp; Days =3D 60 * 60 * \n  24&lt;BR&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp; ma=\r\nxRecheckDelay =3D 20 * \n  Days&lt;BR&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp; thresholdDel=\r\nay =3D (((k / threshold) - k ) \n  ^ (-1/alpha))&lt;BR&gt;&gt;&nbsp;&nbsp;&nbsp;&n=\r\nbsp; return minimum(maxRecheckDelay, \n  thresholdDelay)&lt;BR&gt;&gt; &lt;BR&gt;&gt; &lt;B=\r\nR&gt;&gt; 3. Since last-modified information \n  is not universally provided by=\r\n document&lt;BR&gt;&gt; repositories, we need a \n  mechanism to detect substantiv=\r\ne content changes&lt;BR&gt;&gt; and record them in the \n  BDB.&nbsp; I&#39;m looking =\r\ninto tools for this kind of&lt;BR&gt;&gt; content hashing \n  that could be run in=\r\n the extractor chain and stored in the&lt;BR&gt;&gt; object that \n  gets into BDB=\r\n.&lt;BR&gt;&gt; &lt;BR&gt;&gt; Suppose we have such a content hash, then the \n  interva=\r\nl of time between two&lt;BR&gt;&gt; known modification events is an upper \n  boun=\r\nd because there could have been&lt;BR&gt;&gt; a modification event that we did \n =\r\n not observe between these observed&lt;BR&gt;&gt; events.&nbsp; If these upper bo=\r\nunds \n  are not far off the real value, then we can&lt;BR&gt;&gt; accurately appr=\r\noximate the \n  probability of modification at half the&lt;BR&gt;&gt; observed int=\r\nerval as being \n  50%.&nbsp; That is, we use the previously observed&lt;BR&gt;&gt=\r\n; modification \n  intervals to estimate what the next actual interval will =\r\nbe.&lt;BR&gt;&gt; If the \n  average of the last, say, five observed intervals is =\r\nT, then we&lt;BR&gt;&gt; \n  estimate that at (T/2) in the future, the probability=\r\n of modification \n  will&lt;BR&gt;&gt; be 50%.&nbsp; This let&#39;s us estimate a val=\r\nue for k based on \n  previously observed&lt;BR&gt;&gt; modification intervals:&lt;BR=\r\n&gt;&gt; \n  &lt;BR&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=\r\np;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \n  -a&lt;BR&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp=\r\n;&nbsp;&nbsp; k =3D \n  (T/2)&nbsp;&nbsp;&nbsp; which for a=3D2 is (two over=\r\n T) squared.&lt;BR&gt;&gt; \n  &lt;BR&gt;&gt; &lt;BR&gt;&gt; Some logic is required to make su=\r\nre that only the last few, \n  say five,&lt;BR&gt;&gt; meaningful modification int=\r\nervals are averaged to make \n  T.&nbsp; This moving&lt;BR&gt;&gt; window average =\r\nallows Heritrix to more rapidly \n  adapt to pages that have&lt;BR&gt;&gt; varying=\r\n update frequencies, which is most \n  pages.&lt;BR&gt;&gt; &lt;BR&gt;&gt; &lt;BR&gt;&gt; Thou=\r\nghts?&nbsp; Reactions?&lt;BR&gt;&gt; &lt;BR&gt;&gt; \n  John&lt;BR&gt;&gt; &lt;BR&gt;&gt; \n  -------=\r\n-----------------------------------------------------------------&lt;BR&gt;&gt; \n=\r\n  *Yahoo! Groups Links*&lt;BR&gt;&gt; &lt;BR&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp; * To visit=\r\n your \n  group on the web, go to:&lt;BR&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=\r\np; &lt;A \n  href=3D&quot;http://groups.yahoo.com/group/archive-crawler/&quot;&gt;http://gro=\r\nups.yahoo.com/group/archive-crawler/&lt;/A&gt;&lt;BR&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nb=\r\nsp;&nbsp;&nbsp; \n  &lt;BR&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp; * To unsubscribe from t=\r\nhis group, send an \n  email to:&lt;BR&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=\r\n \n  archive-crawler-unsubscribe@yahoogroups.com&lt;BR&gt;&gt;&nbsp;&nbsp;&nbsp;&n=\r\nbsp;&nbsp;&nbsp; \n  &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?=\r\nsubject=3DUnsubscribe&gt;&lt;BR&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=\r\n \n  &lt;BR&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp; * Your use of Yahoo! Groups is subject=\r\n to the \n  Yahoo! Terms of&lt;BR&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Serv=\r\nice &lt;&lt;A \n  href=3D&quot;http://docs.yahoo.com/info/terms/&quot;&gt;http://docs.yahoo.=\r\ncom/info/terms/&lt;/A&gt;&gt;. \n  &lt;BR&gt;&gt; &lt;BR&gt;&gt; &lt;BR&gt;&lt;/TT&gt;&lt;/BODY&gt;&lt;/HTML&gt;\n\r\n------=_NextPart_000_0001_01C5083D.6733C340--\r\n\n"}}