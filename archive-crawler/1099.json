{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"stack","from":"stack &lt;stack@...&gt;","replyTo":"LIST","senderId":"CZa8TB7YBlEqaVPZHCktIYNdsKg1TJISWDSj2IW9c08RTB2T-y91K1vk1kVryndd7Cs3tex_mZSJav3nPvqqcw","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Redirections OK but not extracting actual pages","postDate":"1098284431","msgId":1099,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQxNzY3RDhGLjQwNjA4MDlAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGNsNXQ3bCtmcmhiQGVHcm91cHMuY29tPg==","referencesHeader":"PGNsNXQ3bCtmcmhiQGVHcm91cHMuY29tPg=="},"prevInTopic":1098,"nextInTopic":1100,"prevInTime":1098,"nextInTime":1100,"topicId":1097,"numMessagesInTopic":11,"msgSnippet":"Hey Jim: In the past a gentleman on the list had a problem crawling via a proxy. I was unable to reproduce though I setup a proxy here on my end. Send over","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 76174 invoked from network); 20 Oct 2004 14:58:49 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m1.grp.scd.yahoo.com with QMQP; 20 Oct 2004 14:58:49 -0000\r\nReceived: from unknown (HELO dns.duboce.net) (63.203.238.114)\n  by mta4.grp.scd.yahoo.com with SMTP; 20 Oct 2004 14:58:49 -0000\r\nReceived: from archive.org ([192.168.1.105])\n\t(authenticated)\n\tby dns-eth1.duboce.net (8.10.2/8.10.2) with ESMTP id i9KEFFB29727\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Wed, 20 Oct 2004 07:15:15 -0700\r\nMessage-ID: &lt;41767D8F.4060809@...&gt;\r\nDate: Wed, 20 Oct 2004 08:00:31 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; PPC Mac OS X Mach-O; en-US; rv:1.7b) Gecko/20040421\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;cl5t7l+frhb@...&gt;\r\nIn-Reply-To: &lt;cl5t7l+frhb@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Remote-IP: 63.203.238.114\r\nFrom: stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] Redirections OK but not extracting actual pages\r\nX-Yahoo-Group-Post: member; u=168599281\r\n\r\nHey Jim:\n\nIn the past a gentleman on the list had a problem crawling via a proxy.  \nI was unable to reproduce though I setup a proxy here on my end.\n\nSend over your order file and seeds.\n\nTake a look in the arc files -- they&#39;re under the &#39;jobs&#39; directory in a \ndirectory named for the job with a date suffix.  Look in the arcs \ndirectory.  Do they show downloaded content?\n\nSt.Ack\n\n\njkilleen74 wrote:\n\n&gt;I&#39;m running Heritrix 1.0.4 on a PC (Windows XP); I&#39;m having a problem \n&gt;where any crawl jobs seem to start fine - retrieve the DNS and \n&gt;robots.txt as appropriate, redirect as appropriate etc. But once they \n&gt;hit an actual page e.g. somewebsite/index.html, the crawl comes to an \n&gt;end. It&#39;s as if the page contained no data or links, yet I know this \n&gt;is not the case (I can browse to it through IE perfectly normally.)\n&gt;In my crawl.log, I see something like the following e.g.:\n&gt;\n&gt;20041020142929438     1         62 dns:www.st-andrews.ac.uk P \n&gt;http://www.st-andrews.ac.uk/study.shtml text/dns #000 0 - -\n&gt;\n&gt;20041020142930190   404          0 http://www.st-\n&gt;andrews.ac.uk/robots.txt P http://www.st-andrews.ac.uk/study.shtml \n&gt;text/html #000 251 - -\n&gt;\n&gt;20041020142931601   200          0 http://www.st-\n&gt;andrews.ac.uk/study.shtml - - text/html #000 142 - 3t\n&gt;\n&gt;Note the figures in the second column, for amount of data downloaded. \n&gt;For the front page (study.shtml), it seems to have downloaded zero \n&gt;data. Yet the crawl completes without any obvious errors or alerts - \n&gt;it seems to have found this front page, then decided that not only \n&gt;are there no links to follow, but not even any data to retrieve. The \n&gt;same pattern is seen whether I respect or ignore robots.txt, for any \n&gt;number of sites I&#39;ve tried to examine so far. I&#39;m not applying any \n&gt;unusual filters, just a standard crawl.\n&gt;\n&gt;I&#39;m running this behind a firewall, so am using the Proxy server \n&gt;patch proved a while back, which seems to be working (without it, any \n&gt;crawl job just stalled on the very first step.)\n&gt;\n&gt;I&#39;m probably missing something obvious, but any suggestions \n&gt;appreciated!\n&gt;\n&gt;Jim K\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; \n&gt;Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n&gt; \n&gt;\n&gt;\n&gt;\n&gt;  \n&gt;\n\n\n"}}