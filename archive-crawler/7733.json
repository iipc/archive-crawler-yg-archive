{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":445716684,"authorName":"Elverton","from":"&quot;Elverton&quot; &lt;uelverton@...&gt;","profile":"elvertonfazzion","replyTo":"LIST","senderId":"Ko7HpPy3e7i5PJI6YiVETuV3uq2rzqtDY-INv9vcf_8-cEYIIgbgpFMZtFEKf_NZ5OtVsVmEddv6VH7_HPV50NaN4TO7EbeQbA","spamInfo":{"isSpam":false,"reason":"3"},"subject":"Re: Stucked in 690 million discovered.","postDate":"1343479521","msgId":7733,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGp2MG10MSs4OWNoQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDUwMTJDQjc4LjQwODAzMDVAYmF5YXJlYS5uZXQ+"},"prevInTopic":7732,"nextInTopic":7739,"prevInTime":7732,"nextInTime":7734,"topicId":7731,"numMessagesInTopic":6,"msgSnippet":"Hello John, Well, I use Heritrix 1 (1.14.4). I always split those as well, to get  things done in finite time. Can you tell me how do you do it? I have no","rawEmail":"Return-Path: &lt;uelverton@...&gt;\r\nX-Sender: uelverton@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 13219 invoked from network); 28 Jul 2012 12:45:22 -0000\r\nX-Received: from unknown (98.137.35.160)\n  by m16.grp.sp2.yahoo.com with QMQP; 28 Jul 2012 12:45:22 -0000\r\nX-Received: from unknown (HELO ng8-vm5.bullet.mail.gq1.yahoo.com) (98.136.219.96)\n  by mta4.grp.sp2.yahoo.com with SMTP; 28 Jul 2012 12:45:22 -0000\r\nX-Received: from [98.137.0.82] by ng8.bullet.mail.gq1.yahoo.com with NNFMP; 28 Jul 2012 12:45:21 -0000\r\nX-Received: from [98.137.34.34] by tg2.bullet.mail.gq1.yahoo.com with NNFMP; 28 Jul 2012 12:45:21 -0000\r\nDate: Sat, 28 Jul 2012 12:45:21 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;jv0mt1+89ch@...&gt;\r\nIn-Reply-To: &lt;5012CB78.4080305@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 2:3:4:0:0\r\nFrom: &quot;Elverton&quot; &lt;uelverton@...&gt;\r\nSubject: Re: Stucked in 690 million discovered.\r\nX-Yahoo-Group-Post: member; u=445716684; y=M4fq_xafJ2uiEfLZNrG-AFSKFsX1t33yg2UpHuIEReAeEFd4IXtDi-K_\r\nX-Yahoo-Profile: elvertonfazzion\r\n\r\nHello John,\n\nWell, I use Heritrix 1 (1.14.4).\n\n&quot;I always split those as wel=\r\nl, to get  things done in finite time.&quot;\n\nCan you tell me how do you do it? =\r\nI have no ideia. \n\nThanks for the answer. It was very helpful.\nElverton.\n\n\n=\r\n--- In archive-crawler@yahoogroups.com, John Lekashman &lt;lekash@...&gt; wrote:\n=\r\n&gt;\n&gt; Hi,\n&gt; You still on Heretrix 1?\n&gt; \n&gt; I know that H 1 had a problem of an=\r\n upper limit of around 700M urls per \n&gt; crawler.\n&gt; Split the crawl with a h=\r\nashmapper.\n&gt; \n&gt; Don&#39;t know if H 3 has that problem, I always split those as=\r\n well, to get \n&gt; things done\n&gt; in finite time.\n&gt; \n&gt; John\n&gt; \n&gt; On 7/27/12 7:=\r\n35 AM, Elverton wrote:\n&gt; &gt;\n&gt; &gt; Hello everybody.\n&gt; &gt;\n&gt; &gt; Well, I&#39;m having a =\r\nbig trouble this time. Before I explain the \n&gt; &gt; problem, here is the syste=\r\nm configuration:\n&gt; &gt;\n&gt; &gt; - 24 GB RAM\n&gt; &gt; - Intel(R) Xeon(R) CPU E5520 @ 2.2=\r\n7GHz\n&gt; &gt; - 1.8TB hard disk for Heritrix. (I don&#39;t use warc in this crawl. M=\r\ny \n&gt; &gt; only target is to know how many (approx.) URLs a domain has.) The \n&gt;=\r\n &gt; usage of the disk is: used 500GB, free 1.3TB.\n&gt; &gt; - 16GB java heap size =\r\nfor heritrix.\n&gt; &gt; - Java 1.7.0_05\n&gt; &gt;\n&gt; &gt; Here is the Heritrix configuratio=\r\nn that I consider helpful to the\n&gt; &gt; problem:\n&gt; &gt;\n&gt; &gt; - bdb-cache-percent =\r\n=3D 25\n&gt; &gt; - frontier =3D BdbFrontier\n&gt; &gt; - max-delay-ms =3D 10000\n&gt; &gt; - mi=\r\nn-delay-ms =3D 2000\n&gt; &gt; - respect-crawl-delay-up-to-secs =3D 300\n&gt; &gt; - max-=\r\nretries =3D 10\n&gt; &gt; - retry-delay-seconds =3D 30\n&gt; &gt; - timeout-seconds =3D 1=\r\n200\n&gt; &gt; - sotimeout-ms =3D 20000\n&gt; &gt;\n&gt; &gt; % --------------------------------=\r\n--------------------------\n&gt; &gt;\n&gt; &gt; So, my problem is: the crawl stucked in =\r\n690 million discovered. \n&gt; &gt; (Queued it&#39;s around 520 million and downloaded=\r\n is around 170 million).\n&gt; &gt;\n&gt; &gt; The strange thing is the download/uri rate=\r\n.\n&gt; &gt;\n&gt; &gt; Docs/s(avg): 53.2(60.77)\n&gt; &gt; KB/s(avg): 2069(3205)\n&gt; &gt;\n&gt; &gt; It con=\r\ntinues, in some way, good in theory (about 3 or 4 million uri \n&gt; &gt; crawled =\r\nper day if you have 53.2 uri&#39;s during all day), but the real \n&gt; &gt; crawled p=\r\ner day is below 500.000 (discovered).\n&gt; &gt;\n&gt; &gt; Looking at some number in the=\r\n last five days:\n&gt; &gt; Queued Downloaded\n&gt; &gt; 541054381 133121289\n&gt; &gt; 53532218=\r\n5 138522175\n&gt; &gt; 530280577 143176680\n&gt; &gt; 525907149 147086865\n&gt; &gt; 520568517 1=\r\n51604201\n&gt; &gt;\n&gt; &gt; Notice that the queued decreases at the &quot;same&quot; rate that d=\r\nownloaded \n&gt; &gt; increases. The problem could be getting URIs to the queue. A=\r\n possible \n&gt; &gt; is the URIs discovered now had be crawled before, and doesn&#39;=\r\nt go the \n&gt; &gt; the queue anymore. But the domain I&#39;m crawling has about 2 mi=\r\nllion \n&gt; &gt; domains and I got only 70.000, so there&#39;re many URI&#39;s to be craw=\r\nled \n&gt; &gt; yet. :)\n&gt; &gt;\n&gt; &gt; Other possibility I thought could be a swap proble=\r\nm (too much I/O). \n&gt; &gt; For my surprise (using vmstat), the swpd is 0.\n&gt; &gt;\n&gt;=\r\n &gt; Another problem could be know if a URI was crawled already.\n&gt; &gt; Before t=\r\nhe URI goes to the frontier, heritrix verifies it in a queue, \n&gt; &gt; using th=\r\ne hash technique. If the crawling is big enough, the search \n&gt; &gt; get slower=\r\n, even using hash, because there are many URI&#39;s for a key in \n&gt; &gt; hash tabl=\r\ne.\n&gt; &gt;\n&gt; &gt; But, I really don&#39;t know the exactly problem. Anyone had this pr=\r\noblem \n&gt; &gt; or could point a direction?\n&gt; &gt;\n&gt; &gt; Thanks,\n&gt; &gt; Elverton.\n&gt; &gt;\n&gt; =\r\n&gt;\n&gt;\n\n\n\n"}}