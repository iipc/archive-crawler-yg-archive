{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"&quot;Gordon Mohr&quot; &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"nD590NDsiiYXRCrnDAvcedPylaUAT5s4CRLn9AnZ3DlQvrX5P-zTFsKt9dPJrUrJ6AlZA-9vTitZm85DLOXHdu4sVI9kHAiBkw","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Re: Memory Pool manager update !!","postDate":"1052762809","msgId":56,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDAwOTcwMWMzMThiMSQ0MjQ0NWI4MCQ0OGYwZWRkMUBXT1JLU1RBVElPTjIxPg==","referencesHeader":"PDIyYWYwMWMzMDk1NCRkNzE4Yjc5MCRkNTAwYThjMEB0aWRlbHBhcmsuaXNvZnR0ZWNoaW5kaWEuY29tPiA8MDBmOTAxYzMwOWUwJDMyZmFiMDAwJDQ4ZjBlZGQxQFdPUktTVEFUSU9OMjE+IDwyNGY3MDFjMzBhODQkMDg3MmZiZTAkZDUwMGE4YzBAdGlkZWxwYXJrLmlzb2Z0dGVjaGluZGlhLmNvbT4gPDMyNTQwMWMzMGVhNSRmZTJlYWI5MCRkNTAwYThjMEB0aWRlbHBhcmsuaXNvZnR0ZWNoaW5kaWEuY29tPiA8M2VlZTAxYzMxMzEwJGRjNDc3MWEwJGQ1MDBhOGMwQHRpZGVscGFyay5pc29mdHRlY2hpbmRpYS5jb20+"},"prevInTopic":55,"nextInTopic":57,"prevInTime":55,"nextInTime":57,"topicId":53,"numMessagesInTopic":6,"msgSnippet":"Sorry for not getting back to you sooner while I was travelling. Re: VirtualBuffers I think that initially, it is OK to assume that the virtualbuffers are only","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (EGP: mail-8_2_6_6); 12 May 2003 18:06:56 -0000\r\nReceived: (qmail 86667 invoked from network); 12 May 2003 18:06:55 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m13.grp.scd.yahoo.com with QMQP; 12 May 2003 18:06:55 -0000\r\nReceived: from unknown (HELO mail.archive.org) (209.237.232.56)\n  by mta1.grp.scd.yahoo.com with SMTP; 12 May 2003 18:06:54 -0000\r\nReceived: from WORKSTATION21 (b116-dyn-72.archive.org [209.237.240.72])\n\tby iahost-232-56.archive.org (8.12.8/8.10.2) with SMTP id h4CHLfgP007036\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Mon, 12 May 2003 10:21:41 -0700\r\nMessage-ID: &lt;009701c318b1$42445b80$48f0edd1@WORKSTATION21&gt;\r\nTo: &lt;archive-crawler@yahoogroups.com&gt;\r\nReferences: &lt;22af01c30954$d718b790$d500a8c0@...&gt; &lt;00f901c309e0$32fab000$48f0edd1@WORKSTATION21&gt; &lt;24f701c30a84$0872fbe0$d500a8c0@...&gt; &lt;325401c30ea5$fe2eab90$d500a8c0@...&gt; &lt;3eee01c31310$dc4771a0$d500a8c0@...&gt;\r\nSubject: Re: [archive-crawler] Re: Memory Pool manager update !!\r\nDate: Mon, 12 May 2003 11:06:49 -0700\r\nMIME-Version: 1.0\r\nContent-Type: text/plain;\n\tcharset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: 7bit\r\nX-Priority: 3\r\nX-MSMail-Priority: Normal\r\nX-Mailer: Microsoft Outlook Express 6.00.2800.1158\r\nX-MimeOLE: Produced By Microsoft MimeOLE V6.00.2800.1165\r\nFrom: &quot;Gordon Mohr&quot; &lt;gojomo@...&gt;\r\nX-Yahoo-Group-Post: member; u=137285340\r\nX-Yahoo-Profile: gojomo\r\n\r\nSorry for not getting back to you sooner while I was travelling.\n\nRe: VirtualBuffers\n\nI think that initially, it is OK to assume that the virtualbuffers\nare only read after all writing has finished -- and to enforce this\nassumption only by documentation. However, it might someday be useful\nto allow reading -- by the same or other processes -- of written\nmaterial before all writing finishes, so I wouldn&#39;t foreclose that\npossibility completely.\n\nRe: Potential utility subclasses\n\nFor example, an HTTPResponseBuffer would somehow know the ranges of\nits response-line, its headers, its body. (Maybe it would discover\nthese while first being written; or maybe only later when asked to.)\n\nIt would have convenience methods for accessing key info (eg response\ncode, content-type, etc) and even methods for accessing the subparts\nas constrained views; eg:\n\n  public VirtualBuffer getContentBody();\n  public VirtualBuffer getHeaders();\n\nDoes this clarify what I meant? This is really a matter of providing\nmaximal convenience to our core classes -- and someday third-party add-ons --\nfor post-retrieval content-processing.\n\n- Gordon\n\n----- Original Message ----- \nFrom: G.B.Reddy\nTo: archive-crawler@yahoogroups.com\nSent: Monday, May 05, 2003 7:16 AM\nSubject: Re: [archive-crawler] Re: Memory Pool manager update !!\n\n\nGordon,\n\nI am presently working on doing buffered i/o over RandomAccessFile on the spilled files. On some of the other issues listed below,\nplease send in your thoughts about it.\n\n-- I assume that virtual buffer read will happen only after write completes. Meaning, the InputStreams should be asked for only\nafter the output stream is flushed and closed. Is this right or will other processes keep reading it as and when it is being\ndownloaded. Probably, some processes might be interested in the header alone; so they need not wait till the end.\n\n-- Subclassing the VirtualBuffers : You had said that a subclasses such as HTTPResponseBuffer could be written with functionalities\nto rewind to the header, rewind to the content-body, etc. How would this be done ? Would we want to take the approach of allowing\nthe internal output stream to be subclassed and overriden so that the parsing could happen during the download itself and we would\nfind the indices at which the header starts, the body starts, etc during the parsing.\n\nWe may not need a conf call this week; an e-mail with your comments would do.\n\nI will not be available tomorrow (6th May) since I am visiting an university for campus recruitment. I would not be accessing mails\ntomorrow. So, please send do not send mails to my personal id. Send it to the yahoogroups id so that I would come to know through my\nproject manager.\n\nThanks,\nReddy\n\n----- Original Message ----- \nFrom: G.B.Reddy\nTo: archive-crawler@yahoogroups.com\nSent: Wednesday, April 30, 2003 4:50 AM\nSubject: Re: [archive-crawler] Re: Memory Pool manager update !!\n\n\nGordon,\n\nThe MemPoolManager updates are checked into the CVS in the ArchiveOpenCrawler module ( in the same org.archive.crawler.io package ).\n\nSome of the outstanding issues are\n\n-- I assume that virtual buffer read will happen only after write completes. Meaning, the InputStreams should be asked for only\nafter the output stream is flushed and closed. Is this right or will other processes keep reading it as and when it is being\ndownloaded.\n\n-- Subclassing the VirtualBuffers : You had said that a subclasses such as HTTPResponseBuffer could be written with functionalities\nto rewind to the header, rewind to the content-body, etc. How would this be done ? Would we want to take the approach of allowing\nthe internal output stream to be subclassed and overriden so that the parsing could happen during the download itself and we would\nfind the indices at which the header starts, the body starts, etc during the parsing.\n\n-- Using a RandomAccessFile for i/o on the spilled file so as to provide seek capability : Operations on this RandomAccessFile needs\nto be a buffered i/o. Not sure what would be the optimal size of this buffer. Taking a 4K block from the pool for the sake of this\nbuffer may be too big. We may have to think of having some RAMOnlyBuffers allocated from the pool for such purposes. These may be of\n1K or 2K size.\n\n-- In the implementation that is checked in, the streams have a close knowledge of the DiskedVirtualBuffer. May have to find another\nway of doing it.\n\n-- The clarification needed on contiguous 8K allocations - Raymie to clarify on my previous mail.\n\nIf possible, I would have a quick chat with Raymie sometime late evening today on yahoo messenger to discuss these.\n\nIn the mean time, some of the other activities done were.\n\n-- The complete directory structure created for the ArchiveOpenCrawler module.\n-- A Do&#39;s and Don&#39;ts Readme is written and checked into the docs directory of the ArchiveOpenCrawler module. This talks about the\nnotions to be adhered while using this module.\n-- Made the JAnt build.xml file more flexible and configurable so as to make it suitable for running unit tests.\n-- As of now, the JAnt build script would run the nightly unit testing only if the previous day&#39;s nightly build passes. Will have to\nmake it do unit test on the existing latest nightly build.\n-- Archives last one week unit test results.\n-- An Unit test summary report would be given in the nightly build mail with a link to the detailed report. Some problems still\nexist in getting this work.\n\nWe may have to start planning on setting up the &quot;Synthetic crawl environment: ~4 in house machines running web servers&quot;, and the\nother internet/intranet crawl setups as discussed earlier.\n\nI would be on leave on 1st of May being our Labour Day.\n\nThanks,\nReddy\n\n----- Original Message ----- \nFrom: G.B.Reddy\nTo: archive-crawler@yahoogroups.com\nSent: Thursday, April 24, 2003 10:37 PM\nSubject: Re: [archive-crawler] Re: Memory Pool manager attached !!\n\n\nRaymie,\n\nOn the first day we discussed about the memory pool manager, we decided that the 8MB big chunk of memory will be broken into pieces\nof 4K each. And the writer would incrementally get 4K blocks one after the other until he reaches the max 32K. These 4K blocks need\nnot be contiguous. After the 32K max is reached, the whole of it would be written into a tmp file and we would procure a contiguous\n8K block from the pool. This 8K block as we discussed will hold the first 8KB data of the fetched page. Knowing that Linux uses only\na 4KB default page size, we are not very clear why you suggested that we use a contiguous 8K in this case. Can&#39;t it be a non\ncontiguous 4K + 4K, so that we can hold the first 4K data in it and use the other 4K for buffered i/o on the tmp file. If there is\nany reason behind it being a contiguous 8K, we will additionally need another 4K to use as a buffer for the i/o. If there isn&#39;t any\nreason, then should the pool manager necessarily support contiguous 8K allocations ?\n\nThanks,\nReddy\n\n----- Original Message ----- \nFrom: Gordon Mohr\nTo: G.B.Reddy ; archive-crawler@yahoogroups.com\nSent: Thursday, April 24, 2003 3:05 AM\nSubject: [archive-crawler] Re: Memory Pool manager attached !!\n\n\nThanks!\n\nSome thoughts:\n\nI&#39;d like to approach this part of the system -- buffers/streams for\nmulti-Kb entities across one processing cycle -- at three separate\nlevels, in order:\n\n(1) The basic interface offered to other crawler components,\n    hiding implementation details.\n\n(2) The trick of using disk space for large files, because\n    it is impractical to keep so many large files in RAM\n    through all processing stages.\n\n(3) The optimization of using recycled internal objects, to\n    minimize garbage collection overhead.\n\nPart (1) needs to be right and relatively constant early; parts (2)\nand (3) can be tweaked down the road -- and I&#39;m reluctant to evaluate\napproaches to (3) just yet, because it is only after seeing the latest\nJava allocators/garbage-collectors do poorly on a naive implementation\nthat we&#39;ll be able to make sensible pool-management choices.\n\nFor part (1), please take a look at the abstract classes I&#39;ve placed\nin the ArchiveOpenCrawler module, src/org/archive/crawler/io [*]:\n\n   VirtualBuffer\n   SeekableInputStream\n   SeekableInputSubstream\n\nI think the &#39;VirtualBuffer&#39; object is useful to tie together the\nconstruction of the data stream and its later use, rather than\nusing a [Something]OutputStream first and then only at the end asking\nit for one [Something]InputStream on the results. Also, it better\nsupports the idea there could be multiple independent InputStreams\n(or CharSequences) on the same read-only buffer.\n\nFleshing out the potential connections between the abstract classes\nabove and the concrete classes you&#39;ve proposed:\n\n  class RewindableSpreadInputStream extends SeekableInputStream\n\n  class DiskedVirtualBuffer extends VirtualBuffer {\n    // naive implementation of VirtualBuffer with associated Streams/CharSequence classes\n    // that is, &quot;level (2)&quot; above\n    // likely uses a RandomAccessFile to augment any in-memory buffer(s)\n    // ... //\n  }\n\n  class EconomizingDiskedVirtualBuffer extends DiskedVirtualBuffer {\n    // recycling/optimizable implementation of VirtualBuffer\n    // that is, &quot;level (3)&quot; above\n    // somehow utilizes one or more managed MemoryArea instances\n\n    public SpreadOutputStream getOutputStream() { /* ... */ }\n    public RewindableSpreadInputStream getInputStream() { /* ... */ }\n  }\n\nDoes this make sense to everyone?\n\n- Gordon\n\n[*] http://cvs.sourceforge.net/cgi-bin/viewcvs.cgi/archive-crawler/ArchiveOpenCrawler/src/org/archive/crawler/io/\n\n----- Original Message ----- \nFrom: G.B.Reddy\nTo: Gordon Mohr\nSent: Tuesday, April 22, 2003 9:57 PM\nSubject: Memory Pool manager attached !!\n\n\nGordon,\n\nAs requested, I am attaching the javadoc/code which we did when Raymie was here in India. Some changes which are to be done are\n\n- Support for Multiple MemPoolManager instances. (don&#39;t make it static)\n- Use a free list instead of a bitmap to track the allocated/free areas.\n\nThanks,\nReddy\n\n\nTo unsubscribe from this group, send an email to:\narchive-crawler-unsubscribe@yahoogroups.com\n\n\n\nYour use of Yahoo! Groups is subject to the Yahoo! Terms of Service.\n\n\n\nTo unsubscribe from this group, send an email to:\narchive-crawler-unsubscribe@yahoogroups.com\n\n\n\nYour use of Yahoo! Groups is subject to the Yahoo! Terms of Service.\n\n\nYahoo! Groups Sponsor\n\n\n\nTo unsubscribe from this group, send an email to:\narchive-crawler-unsubscribe@yahoogroups.com\n\n\n\nYour use of Yahoo! Groups is subject to the Yahoo! Terms of Service.\n\n\n"}}