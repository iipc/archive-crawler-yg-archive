{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"stack","from":"stack &lt;stack@...&gt;","replyTo":"LIST","senderId":"ofV_wiAM5MqCGNRyBsXwdhGrwUOFuji3picfpu6EQ_ROK4szkGiyj-crrf9lU-A__LDQyeQnb89AwcwnYZEPAw","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Heritrix stoped when crawle large sites","postDate":"1095822467","msgId":1017,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQxNTBFQzgzLjIwMzA1MDVAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDQ4NDM2NTMyMDQwOTE2MjEwMjQ5MDc0NzY0QG1haWwuZ21haWwuY29tPg==","referencesHeader":"PDE2NzA5LjQ1OTIwLjg3NTg3Ni4zODEyNDRAdGlwaGFyZXMuYmFzaXN0ZWNoLm5ldD4JIDw0MTQ1QzEyNC4zMDcwMjA0QGFyY2hpdmUub3JnPgkgPDE2NzA5LjYyNjI4LjgxMDAzNC40MDMyODRAdGlwaGFyZXMuYmFzaXN0ZWNoLm5ldD4JIDw0MTQ2NDdGMS4yMDIwMjA3QGFyY2hpdmUub3JnPgkgPDE2NzEwLjUzNjM2LjMzNDg2Ny45MjQ1OTFAdGlwaGFyZXMuYmFzaXN0ZWNoLm5ldD4JIDw0ODQzNjUzMjA0MDkxNTAzMjM2OTdhODY1N0BtYWlsLmdtYWlsLmNvbT4JIDw0MTRBM0IwRS43MDAwNzAyQGFyY2hpdmUub3JnPiA8NDg0MzY1MzIwNDA5MTYyMTAyNDkwNzQ3NjRAbWFpbC5nbWFpbC5jb20+"},"prevInTopic":1003,"nextInTopic":1018,"prevInTime":1016,"nextInTime":1018,"topicId":978,"numMessagesInTopic":19,"msgSnippet":"... Things in HEAD should be better now Ansi (And Tom).  Using your order and seeds I can get well past 20k pages. I m still running tests so haven t closed","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 79222 invoked from network); 22 Sep 2004 03:14:38 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m20.grp.scd.yahoo.com with QMQP; 22 Sep 2004 03:14:38 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (209.237.232.202)\n  by mta2.grp.scd.yahoo.com with SMTP; 22 Sep 2004 03:14:38 -0000\r\nReceived: (qmail 14838 invoked by uid 100); 22 Sep 2004 03:04:10 -0000\r\nReceived: from debord.archive.org (HELO ?207.241.238.140?) (stack@...@207.241.238.140)\n  by mail-dev.archive.org with SMTP; 22 Sep 2004 03:04:10 -0000\r\nMessage-ID: &lt;4150EC83.2030505@...&gt;\r\nDate: Tue, 21 Sep 2004 20:07:47 -0700\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.7.2) Gecko/20040820 Debian/1.7.2-4\r\nX-Accept-Language: en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;16709.45920.875876.381244@...&gt;\t &lt;4145C124.3070204@...&gt;\t &lt;16709.62628.810034.403284@...&gt;\t &lt;414647F1.2020207@...&gt;\t &lt;16710.53636.334867.924591@...&gt;\t &lt;484365320409150323697a8657@...&gt;\t &lt;414A3B0E.7000702@...&gt; &lt;48436532040916210249074764@...&gt;\r\nIn-Reply-To: &lt;48436532040916210249074764@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=0.2 required=7.0 tests=AWL,HTML_MESSAGE,\n\tNORMAL_HTTP_TO_IP autolearn=ham version=2.63\r\nX-eGroups-Remote-IP: 209.237.232.202\r\nFrom: stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] Heritrix stoped when crawle large sites\r\nX-Yahoo-Group-Post: member; u=168599281\r\n\r\nansi wrote:\n\n&gt;Yes.\n&gt;When there are no running threads,pls click the report tab of the WUI.\n&gt;the same error appeared.\n&gt;\n&gt;Heritrix 1.0.2 works fine on this profile.\n&gt;  \n&gt;\nThings in HEAD should be better now Ansi (And Tom).  Using your order \nand seeds I can get well past 20k pages.\n\nI&#39;m still running tests so haven&#39;t closed the issue just yet \n(https://sourceforge.net/tracker/index.php?func=detail&aid=1031607&group_id=73833&atid=539099).\n\nJust a note to let you know latest.\n\nSt.Ack\n\n&gt;ansi.\n&gt;\n&gt;\n&gt;\n&gt;On Thu, 16 Sep 2004 18:17:02 -0700, stack &lt;stack@...&gt; wrote:\n&gt;  \n&gt;\n&gt;&gt;ansi wrote:\n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;&gt;&gt;hi,all\n&gt;&gt;&gt;\n&gt;&gt;&gt;I update Heritrix from the lastest CVS, and run it for about  50 sites.\n&gt;&gt;&gt;After collect about 10000 pages,the WUI display there are 0 of 0 active\n&gt;&gt;&gt;threads,and the crawl process stoped.\n&gt;&gt;&gt;\n&gt;&gt;&gt;I have run the same profile under heritrix 1.0.\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;I just tried your order and seeds.  After 2500 docs., no threads\n&gt;&gt;running.  When I look in heritrix_out.log, I see this:\n&gt;&gt;\n&gt;&gt;KeyedQueue server&lt;-&gt;key mismatch noted: pfbuser&lt;-&gt;mprsrv.agri.gov.cn\n&gt;&gt;java.util.NoSuchElementException\n&gt;&gt;   at org.archive.queue.TieredQueue.peek(TieredQueue.java(Inlined\n&gt;&gt;Compiled Code))\n&gt;&gt;   at org.archive.queue.TieredQueue.dequeue(TieredQueue.java(Inlined\n&gt;&gt;Compiled Code))\n&gt;&gt;   at\n&gt;&gt;org.archive.crawler.frontier.KeyedQueue.dequeue(KeyedQueue.java(Inlined\n&gt;&gt;Compiled Code))\n&gt;&gt;   at\n&gt;&gt;org.archive.crawler.frontier.HostQueuesFrontier.dequeueFromReady(HostQueuesFrontier.java(Compiled\n&gt;&gt;Code))\n&gt;&gt;   at\n&gt;&gt;org.archive.crawler.frontier.HostQueuesFrontier.next(HostQueuesFrontier.java(Compiled\n&gt;&gt;Code))\n&gt;&gt;   at org.archive.crawler.framework.ToeThread.run(ToeThread.java:115)\n&gt;&gt;\n&gt;&gt;Do you see this Ansi?\n&gt;&gt;St.Ack\n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;&gt;&gt;the attachment is the order.xml and seeds.txt .\n&gt;&gt;&gt;\n&gt;&gt;&gt;Can anyone  run it and to discover can heritrix crawl more than 20000 pages?\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;&gt;&gt;ansi\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;Yahoo! Groups Links\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;------------------------------------------------------------------------\n&gt;&gt;&gt;\n&gt;&gt;&gt;&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&gt;&gt;&gt;&lt;crawl-order xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;heritrix_settings.xsd&quot;&gt;\n&gt;&gt;&gt; &lt;meta&gt;\n&gt;&gt;&gt;   &lt;name&gt;nxt&lt;/name&gt;\n&gt;&gt;&gt;   &lt;description&gt;Profile: Simple crawl&lt;/description&gt;\n&gt;&gt;&gt;   &lt;operator&gt;Admin&lt;/operator&gt;\n&gt;&gt;&gt;   &lt;organization/&gt;\n&gt;&gt;&gt;   &lt;audience/&gt;\n&gt;&gt;&gt;   &lt;date&gt;20040915015254&lt;/date&gt;\n&gt;&gt;&gt; &lt;/meta&gt;\n&gt;&gt;&gt; &lt;controller&gt;\n&gt;&gt;&gt;   &lt;string name=&quot;settings-directory&quot;&gt;settings&lt;/string&gt;\n&gt;&gt;&gt;   &lt;string name=&quot;disk-path&quot;/&gt;\n&gt;&gt;&gt;   &lt;string name=&quot;logs-path&quot;&gt;logs&lt;/string&gt;\n&gt;&gt;&gt;   &lt;string name=&quot;checkpoints-path&quot;&gt;checkpoints&lt;/string&gt;\n&gt;&gt;&gt;   &lt;string name=&quot;state-path&quot;&gt;state&lt;/string&gt;\n&gt;&gt;&gt;   &lt;string name=&quot;scratch-path&quot;&gt;scratch&lt;/string&gt;\n&gt;&gt;&gt;   &lt;long name=&quot;max-bytes-download&quot;&gt;0&lt;/long&gt;\n&gt;&gt;&gt;   &lt;long name=&quot;max-document-download&quot;&gt;0&lt;/long&gt;\n&gt;&gt;&gt;   &lt;long name=&quot;max-time-sec&quot;&gt;0&lt;/long&gt;\n&gt;&gt;&gt;   &lt;integer name=&quot;max-toe-threads&quot;&gt;50&lt;/integer&gt;\n&gt;&gt;&gt;   &lt;newObject name=&quot;scope&quot; class=&quot;org.archive.crawler.scope.DomainScope&quot;&gt;\n&gt;&gt;&gt;     &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;     &lt;string name=&quot;seedsfile&quot;&gt;seeds.txt&lt;/string&gt;\n&gt;&gt;&gt;     &lt;integer name=&quot;max-link-hops&quot;&gt;25&lt;/integer&gt;\n&gt;&gt;&gt;     &lt;integer name=&quot;max-trans-hops&quot;&gt;5&lt;/integer&gt;\n&gt;&gt;&gt;     &lt;newObject name=&quot;exclude-filter&quot; class=&quot;org.archive.crawler.filter.OrFilter&quot;&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;if-matches-return&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;         &lt;newObject name=&quot;pathdepth&quot; class=&quot;org.archive.crawler.filter.PathDepthFilter&quot;&gt;\n&gt;&gt;&gt;           &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;           &lt;integer name=&quot;max-path-depth&quot;&gt;20&lt;/integer&gt;\n&gt;&gt;&gt;           &lt;boolean name=&quot;path-less-or-equal-return&quot;&gt;false&lt;/boolean&gt;\n&gt;&gt;&gt;         &lt;/newObject&gt;\n&gt;&gt;&gt;         &lt;newObject name=&quot;pathologicalpath&quot; class=&quot;org.archive.crawler.filter.PathologicalPathFilter&quot;&gt;\n&gt;&gt;&gt;           &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;           &lt;integer name=&quot;repetitions&quot;&gt;3&lt;/integer&gt;\n&gt;&gt;&gt;         &lt;/newObject&gt;\n&gt;&gt;&gt;         &lt;newObject name=&quot;onlyhtml&quot; class=&quot;org.archive.crawler.filter.URIRegExpFilter&quot;&gt;\n&gt;&gt;&gt;           &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;           &lt;boolean name=&quot;if-match-return&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;           &lt;string name=&quot;regexp&quot;&gt;^.*(?i)&#92;.(bmp|cab|gif|jpe|jpg|jpeg|png|tiff|mid|mp2|mp3|mp4|wav|avi|mov|mpeg|ram|rm|smil|wmv|doc|pdf|ppt|swf)$ &lt;/string&gt;\n&gt;&gt;&gt;         &lt;/newObject&gt;\n&gt;&gt;&gt;       &lt;/map&gt;\n&gt;&gt;&gt;     &lt;/newObject&gt;\n&gt;&gt;&gt;     &lt;newObject name=&quot;additionalScopeFocus&quot; class=&quot;org.archive.crawler.filter.FilePatternFilter&quot;&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;if-match-return&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;string name=&quot;use-default-patterns&quot;&gt;All&lt;/string&gt;\n&gt;&gt;&gt;       &lt;string name=&quot;regexp&quot;/&gt;\n&gt;&gt;&gt;     &lt;/newObject&gt;\n&gt;&gt;&gt;     &lt;newObject name=&quot;transitiveFilter&quot; class=&quot;org.archive.crawler.filter.TransclusionFilter&quot;&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;integer name=&quot;max-speculative-hops&quot;&gt;1&lt;/integer&gt;\n&gt;&gt;&gt;       &lt;integer name=&quot;max-referral-hops&quot;&gt;2147483647&lt;/integer&gt;\n&gt;&gt;&gt;       &lt;integer name=&quot;max-embed-hops&quot;&gt;2147483647&lt;/integer&gt;\n&gt;&gt;&gt;     &lt;/newObject&gt;\n&gt;&gt;&gt;   &lt;/newObject&gt;\n&gt;&gt;&gt;   &lt;map name=&quot;http-headers&quot;&gt;\n&gt;&gt;&gt;     &lt;string name=&quot;user-agent&quot;&gt;Mozilla/5.0 (compatible; heritrix/1.0 +http://www.sina.com.cn)&lt;/string&gt;\n&gt;&gt;&gt;     &lt;string name=&quot;from&quot;&gt;webmaster@...&lt;/string&gt;\n&gt;&gt;&gt;   &lt;/map&gt;\n&gt;&gt;&gt;   &lt;newObject name=&quot;robots-honoring-policy&quot; class=&quot;org.archive.crawler.datamodel.RobotsHonoringPolicy&quot;&gt;\n&gt;&gt;&gt;     &lt;string name=&quot;type&quot;&gt;classic&lt;/string&gt;\n&gt;&gt;&gt;     &lt;boolean name=&quot;masquerade&quot;&gt;false&lt;/boolean&gt;\n&gt;&gt;&gt;     &lt;text name=&quot;custom-robots&quot;/&gt;\n&gt;&gt;&gt;     &lt;stringList name=&quot;user-agents&quot;&gt;\n&gt;&gt;&gt;     &lt;/stringList&gt;\n&gt;&gt;&gt;   &lt;/newObject&gt;\n&gt;&gt;&gt;   &lt;newObject name=&quot;frontier&quot; class=&quot;org.archive.crawler.frontier.HostQueuesFrontier&quot;&gt;\n&gt;&gt;&gt;     &lt;float name=&quot;delay-factor&quot;&gt;5.0&lt;/float&gt;\n&gt;&gt;&gt;     &lt;integer name=&quot;max-delay-ms&quot;&gt;5000&lt;/integer&gt;\n&gt;&gt;&gt;     &lt;integer name=&quot;min-delay-ms&quot;&gt;500&lt;/integer&gt;\n&gt;&gt;&gt;     &lt;integer name=&quot;max-retries&quot;&gt;30&lt;/integer&gt;\n&gt;&gt;&gt;     &lt;long name=&quot;retry-delay-seconds&quot;&gt;900&lt;/long&gt;\n&gt;&gt;&gt;     &lt;boolean name=&quot;hold-queues&quot;&gt;false&lt;/boolean&gt;\n&gt;&gt;&gt;     &lt;integer name=&quot;preference-embed-hops&quot;&gt;1&lt;/integer&gt;\n&gt;&gt;&gt;     &lt;integer name=&quot;host-valence&quot;&gt;1&lt;/integer&gt;\n&gt;&gt;&gt;     &lt;integer name=&quot;total-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt;&gt;&gt;     &lt;integer name=&quot;max-per-host-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt;&gt;&gt;     &lt;integer name=&quot;host-queues-memory-capacity&quot;&gt;200&lt;/integer&gt;\n&gt;&gt;&gt;   &lt;/newObject&gt;\n&gt;&gt;&gt;   &lt;map name=&quot;pre-fetch-processors&quot;&gt;\n&gt;&gt;&gt;     &lt;newObject name=&quot;Preselector&quot; class=&quot;org.archive.crawler.prefetch.Preselector&quot;&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;       &lt;/map&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;recheck-scope&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;block-all&quot;&gt;false&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;string name=&quot;block-by-regexp&quot;/&gt;\n&gt;&gt;&gt;     &lt;/newObject&gt;\n&gt;&gt;&gt;     &lt;newObject name=&quot;Preprocessor&quot; class=&quot;org.archive.crawler.prefetch.PreconditionEnforcer&quot;&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;       &lt;/map&gt;\n&gt;&gt;&gt;       &lt;integer name=&quot;ip-validity-duration-seconds&quot;&gt;21600&lt;/integer&gt;\n&gt;&gt;&gt;       &lt;integer name=&quot;robot-validity-duration-seconds&quot;&gt;86400&lt;/integer&gt;\n&gt;&gt;&gt;     &lt;/newObject&gt;\n&gt;&gt;&gt;   &lt;/map&gt;\n&gt;&gt;&gt;   &lt;map name=&quot;fetch-processors&quot;&gt;\n&gt;&gt;&gt;     &lt;newObject name=&quot;DNS&quot; class=&quot;org.archive.crawler.fetcher.FetchDNS&quot;&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;       &lt;/map&gt;\n&gt;&gt;&gt;     &lt;/newObject&gt;\n&gt;&gt;&gt;     &lt;newObject name=&quot;HTTP&quot; class=&quot;org.archive.crawler.fetcher.FetchHTTP&quot;&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;       &lt;/map&gt;\n&gt;&gt;&gt;       &lt;integer name=&quot;timeout-seconds&quot;&gt;1200&lt;/integer&gt;\n&gt;&gt;&gt;       &lt;integer name=&quot;sotimeout-ms&quot;&gt;20000&lt;/integer&gt;\n&gt;&gt;&gt;       &lt;long name=&quot;max-length-bytes&quot;&gt;9223372036854775807&lt;/long&gt;\n&gt;&gt;&gt;       &lt;string name=&quot;load-cookies-from-file&quot;/&gt;\n&gt;&gt;&gt;       &lt;string name=&quot;save-cookies-to-file&quot;/&gt;\n&gt;&gt;&gt;       &lt;string name=&quot;trust-level&quot;&gt;open&lt;/string&gt;\n&gt;&gt;&gt;       &lt;stringList name=&quot;accept-headers&quot;&gt;\n&gt;&gt;&gt;       &lt;/stringList&gt;\n&gt;&gt;&gt;       &lt;string name=&quot;http-proxy-host&quot;/&gt;\n&gt;&gt;&gt;       &lt;string name=&quot;http-proxy-port&quot;/&gt;\n&gt;&gt;&gt;       &lt;string name=&quot;default-encoding&quot;&gt;ISO-8859-1&lt;/string&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;sha1-content&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;     &lt;/newObject&gt;\n&gt;&gt;&gt;   &lt;/map&gt;\n&gt;&gt;&gt;   &lt;map name=&quot;extract-processors&quot;&gt;\n&gt;&gt;&gt;     &lt;newObject name=&quot;ExtractorHTTP&quot; class=&quot;org.archive.crawler.extractor.ExtractorHTTP&quot;&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;       &lt;/map&gt;\n&gt;&gt;&gt;     &lt;/newObject&gt;\n&gt;&gt;&gt;     &lt;newObject name=&quot;ExtractorHTML&quot; class=&quot;org.archive.crawler.extractor.ExtractorHTML&quot;&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;       &lt;/map&gt;\n&gt;&gt;&gt;     &lt;/newObject&gt;\n&gt;&gt;&gt;     &lt;newObject name=&quot;ExtractorJS&quot; class=&quot;org.archive.crawler.extractor.ExtractorJS&quot;&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;       &lt;/map&gt;\n&gt;&gt;&gt;     &lt;/newObject&gt;\n&gt;&gt;&gt;   &lt;/map&gt;\n&gt;&gt;&gt;   &lt;map name=&quot;write-processors&quot;&gt;\n&gt;&gt;&gt;     &lt;newObject name=&quot;Archiver&quot; class=&quot;org.archive.crawler.writer.ARCWriterProcessor&quot;&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;       &lt;/map&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;compress&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;string name=&quot;prefix&quot;&gt;IAH&lt;/string&gt;\n&gt;&gt;&gt;       &lt;string name=&quot;suffix&quot;&gt;${HOSTNAME}&lt;/string&gt;\n&gt;&gt;&gt;       &lt;integer name=&quot;max-size-bytes&quot;&gt;100000000&lt;/integer&gt;\n&gt;&gt;&gt;       &lt;string name=&quot;path&quot;&gt;/opt/esearchdata/arcs&lt;/string&gt;\n&gt;&gt;&gt;       &lt;integer name=&quot;pool-max-active&quot;&gt;5&lt;/integer&gt;\n&gt;&gt;&gt;       &lt;integer name=&quot;pool-max-wait&quot;&gt;300000&lt;/integer&gt;\n&gt;&gt;&gt;     &lt;/newObject&gt;\n&gt;&gt;&gt;   &lt;/map&gt;\n&gt;&gt;&gt;   &lt;map name=&quot;post-processors&quot;&gt;\n&gt;&gt;&gt;     &lt;newObject name=&quot;Updater&quot; class=&quot;org.archive.crawler.postprocessor.CrawlStateUpdater&quot;&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;       &lt;/map&gt;\n&gt;&gt;&gt;     &lt;/newObject&gt;\n&gt;&gt;&gt;     &lt;newObject name=&quot;Postselector&quot; class=&quot;org.archive.crawler.postprocessor.Postselector&quot;&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;       &lt;/map&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;seed-redirects-new-seed&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;     &lt;/newObject&gt;\n&gt;&gt;&gt;   &lt;/map&gt;\n&gt;&gt;&gt;   &lt;map name=&quot;loggers&quot;&gt;\n&gt;&gt;&gt;     &lt;newObject name=&quot;crawl-statistics&quot; class=&quot;org.archive.crawler.admin.StatisticsTracker&quot;&gt;\n&gt;&gt;&gt;       &lt;integer name=&quot;interval-seconds&quot;&gt;20&lt;/integer&gt;\n&gt;&gt;&gt;     &lt;/newObject&gt;\n&gt;&gt;&gt;   &lt;/map&gt;\n&gt;&gt;&gt;   &lt;string name=&quot;recover-path&quot;/&gt;\n&gt;&gt;&gt;   &lt;newObject name=&quot;credential-store&quot; class=&quot;org.archive.crawler.datamodel.CredentialStore&quot;&gt;\n&gt;&gt;&gt;     &lt;map name=&quot;credentials&quot;&gt;\n&gt;&gt;&gt;     &lt;/map&gt;\n&gt;&gt;&gt;   &lt;/newObject&gt;\n&gt;&gt;&gt; &lt;/controller&gt;\n&gt;&gt;&gt;&lt;/crawl-order\n&gt;&gt;&gt;\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;------------------------------------------------------------------------\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;# Seed URIs\n&gt;&gt;&gt;&gt;# enter one per line\n&gt;&gt;&gt;&gt;http://www.bjagri.gov.cn\n&gt;&gt;&gt;&gt;http://www.bjaginfo.gov.cn\n&gt;&gt;&gt;&gt;http://www.tjagri.gov.cn\n&gt;&gt;&gt;&gt;http://www.heagri.gov.cn\n&gt;&gt;&gt;&gt;http://www.sxagri.gov.cn\n&gt;&gt;&gt;&gt;http://www.nmagri.gov.cn\n&gt;&gt;&gt;&gt;http://www.96116.net\n&gt;&gt;&gt;&gt;http://www.jlagri.gov.cn\n&gt;&gt;&gt;&gt;http://www.hljagri.gov.cn\n&gt;&gt;&gt;&gt;http://www.shac.gov.cn\n&gt;&gt;&gt;&gt;http://www.shaf.gov.cn\n&gt;&gt;&gt;&gt;http://www.jsagri.gov.cn\n&gt;&gt;&gt;&gt;http://www.zjagri.gov.cn\n&gt;&gt;&gt;&gt;http://www.ah.agri.gov.cn\n&gt;&gt;&gt;&gt;http://www.fjagri.gov.cn\n&gt;&gt;&gt;&gt;http://www.jx-agri.gov.cn\n&gt;&gt;&gt;&gt;http://www.sdny.gov.cn\n&gt;&gt;&gt;&gt;http://www.haagri.gov.cn\n&gt;&gt;&gt;&gt;http://www.cnhubei.gov.cn\n&gt;&gt;&gt;&gt;http://www.hbagri.gov.cn\n&gt;&gt;&gt;&gt;http://www.hnagri.gov.cn\n&gt;&gt;&gt;&gt;http://61.140.230.18\n&gt;&gt;&gt;&gt;http://www.gxny.gov.cn\n&gt;&gt;&gt;&gt;http://www.hiagri.com\n&gt;&gt;&gt;&gt;http://www.cqagri.gov.cn\n&gt;&gt;&gt;&gt;http://www.scagri.gov.cn\n&gt;&gt;&gt;&gt;http://www.scnjw.gov.cn\n&gt;&gt;&gt;&gt;http://www.qagri.gov.cn\n&gt;&gt;&gt;&gt;http://www.gznw.gov.cn\n&gt;&gt;&gt;&gt;http://www.ynagri.gov.cn\n&gt;&gt;&gt;&gt;http://www.xz-agri.gov.cn\n&gt;&gt;&gt;&gt;http://www.agri.sn.cn\n&gt;&gt;&gt;&gt;http://www.gsny.gov.cn\n&gt;&gt;&gt;&gt;http://www.qhsjyagri.gov.cn\n&gt;&gt;&gt;&gt;http://www.nxny.gov.cn\n&gt;&gt;&gt;&gt;http://www.neooasis.com\n&gt;&gt;&gt;&gt;http://www.agri.gov.cn\n&gt;&gt;&gt;&gt;http://www.aweb.com.cn\n&gt;&gt;&gt;&gt;http://www.agridoor.com.cn\n&gt;&gt;&gt;&gt;http://www.agriweb.com.cn\n&gt;&gt;&gt;&gt;http://www1.cnhubei.gov.cn/\n&gt;&gt;&gt;&gt;http://www.hiagri.com/html/nytindex.asp\n&gt;&gt;&gt;&gt;http://www1.cnhubei.gov.cn/oadata/webindex.nsf/fowebindex?openform\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;        \n&gt;&gt;&gt;&gt;\n&gt;&gt;Yahoo! Groups Links\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;\n&gt;\n&gt; \n&gt;Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n&gt; \n&gt;\n&gt;\n&gt;\n&gt;  \n&gt;\n\n\n"}}