{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":496150545,"authorName":"Markus Mirsberger","from":"Markus Mirsberger &lt;markus.mirsberger@...&gt;","profile":"mirschi74","replyTo":"LIST","senderId":"w89Q-ClZFRJ0S3O44hZ2qCH3OStu1EXZJ_T-ogxqoZcp1ZhPBxj_8NCtF_nu4PSHbtiPuZ-4DU5XRHxIsWb7xKzuOvOY7D4O8RLzyXE4hCg_udY","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Limit the crawls to e.g. 100 URLs/Host","postDate":"1348035511","msgId":7778,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDUwNTk2M0I3LjMwMzAyQGdteC5kZT4=","inReplyToHeader":"PDIyOUQ2NDcxLURFQ0EtNDQ0Ni1CMEY4LTUxNzkzMjZCRTk0REBzdGF0c2JpYmxpb3Rla2V0LmRrPg==","referencesHeader":"PGsxcXFyOSthZm9pQGVHcm91cHMuY29tPiA8NTA1MjY3QUQuNjAyMDgwNkBhcmNoaXZlLm9yZz4gPDUwNTk1MzM0LjYwNDA2MDhAZ214LmRlPiA8MzcyMEU0NTItOEY0OS00QkZCLUE0MEYtRDYwQkMyMDkxNDVEQHN0YXRzYmlibGlvdGVrZXQuZGs+IDw1MDU5NUIxOS43MDQwMDAzQGdteC5kZT4gPDIyOUQ2NDcxLURFQ0EtNDQ0Ni1CMEY4LTUxNzkzMjZCRTk0REBzdGF0c2JpYmxpb3Rla2V0LmRrPg=="},"prevInTopic":7777,"nextInTopic":7783,"prevInTime":7777,"nextInTime":7779,"topicId":7755,"numMessagesInTopic":8,"msgSnippet":"omg ... yes you right.....I forgot that....maxdocuments I just first thought about another requirement where I need the queuetotalbudget...but there I have","rawEmail":"Return-Path: &lt;markus.mirsberger@...&gt;\r\nX-Sender: markus.mirsberger@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 55715 invoked from network); 19 Sep 2012 06:19:29 -0000\r\nX-Received: from unknown (98.137.35.160)\n  by m3.grp.sp2.yahoo.com with QMQP; 19 Sep 2012 06:19:29 -0000\r\nX-Received: from unknown (HELO mailout-de.gmx.net) (213.165.64.22)\n  by mta4.grp.sp2.yahoo.com with SMTP; 19 Sep 2012 06:19:29 -0000\r\nX-Received: (qmail invoked by alias); 19 Sep 2012 06:18:35 -0000\r\nX-Received: from mx-ll-14.207.114-14.dynamic.3bb.co.th (EHLO [192.168.1.11]) [14.207.114.14]\n  by mail.gmx.net (mp012) with SMTP; 19 Sep 2012 08:18:35 +0200\r\nX-Authenticated: #10074639\r\nX-Provags-ID: V01U2FsdGVkX1/DaUMBFv/DTRUt+Nv4RwIk2UXazodz8kdHKqUQxb\n\tV7NzxRqoEYcr8g\r\nMessage-ID: &lt;505963B7.30302@...&gt;\r\nDate: Wed, 19 Sep 2012 13:18:31 +0700\r\nUser-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:15.0) Gecko/20120827 Thunderbird/15.0\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;k1qqr9+afoi@...&gt; &lt;505267AD.6020806@...&gt; &lt;50595334.6040608@...&gt; &lt;3720E452-8F49-4BFB-A40F-D60BC209145D@...&gt; &lt;50595B19.7040003@...&gt; &lt;229D6471-DECA-4446-B0F8-5179326BE94D@...&gt;\r\nIn-Reply-To: &lt;229D6471-DECA-4446-B0F8-5179326BE94D@...&gt;\r\nContent-Type: multipart/alternative;\n boundary=&quot;------------080704050504010801040609&quot;\r\nX-Y-GMX-Trusted: 0\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Markus Mirsberger &lt;markus.mirsberger@...&gt;\r\nSubject: Re: [archive-crawler] Limit the crawls to e.g. 100 URLs/Host\r\nX-Yahoo-Group-Post: member; u=496150545; y=BI_QHRzhP3Po0nZPiUS7Qe4IgatuutXe_WE1s_uUhRwF5vxsT72JjMpks3JGE6TRvnB4bqdsj7Swumk\r\nX-Yahoo-Profile: mirschi74\r\n\r\n\r\n--------------080704050504010801040609\r\nContent-Type: text/plain; charset=UTF-8; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\n\r\nomg ... yes you right.....I forgot that....maxdocuments\nI just first thought about another requirement where I need the \nqueuetotalbudget...but there I have only one queue/host and I forgot \nthat. Here I can use maxdocuments\n\nThanks alot :)\nMarkus\n\n\n\nOn 09/19/2012 01:02 PM, Bjarne Andersen wrote:\n&gt; IF one job is only crawling one host and you want to limit that host \n&gt; in total to a number you should just use the global setting for \n&gt; limiting the entire job (I Think I remember there is one although I \n&gt; never used it)\n&gt; -\n&gt; Bjarne\n&gt;\n&gt; Sendt fra min iPhone\n&gt;\n&gt; Den 19/09/2012 kl. 07.42 skrev &quot;Markus Mirsberger&quot; \n&gt; &lt;markus.mirsberger@... &lt;mailto:markus.mirsberger@...&gt;&gt;:\n&gt;\n&gt;&gt; Yes I think that too.\n&gt;&gt; But with one job I&#39;m only crawling one host and I not follow external \n&gt;&gt; hosts (with a custom decide rule).\n&gt;&gt; So in every queue should be the same hostname since I think the \n&gt;&gt; external hosts should not be moved to the queue when filtered out \n&gt;&gt; with a decide rule.\n&gt;&gt;\n&gt;&gt; Regards,\n&gt;&gt; Markus\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; On 09/19/2012 12:23 PM, Bjarne Andersen wrote:\n&gt;&gt;&gt; IF your queues does not exactly match hostnames the queuetotalbudget \n&gt;&gt;&gt; does not really make sense in your setup. This setting limits the \n&gt;&gt;&gt; number of URIs taken off each queue so if a queue can have URIs from \n&gt;&gt;&gt; more than one host, the limit just means that every URI could be \n&gt;&gt;&gt; from the same host as long as the total budget is not yet spent. If \n&gt;&gt;&gt; URIs from the same host gets randomly put into different queues it \n&gt;&gt;&gt; makes even less sense in your setting\n&gt;&gt;&gt;\n&gt;&gt;&gt; AFAIK there is no existing solution for you with heritrix :(\n&gt;&gt;&gt; You could write your own limiter module off cause that holds an \n&gt;&gt;&gt; alternative datastructure side by side the current queues\n&gt;&gt;&gt;\n&gt;&gt;&gt; Best\n&gt;&gt;&gt; Bjarne Andersen\n&gt;&gt;&gt; Netarchive.dk &lt;http://Netarchive.dk&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; Sendt fra min iPhone\n&gt;&gt;&gt;\n&gt;&gt;&gt; Den 19/09/2012 kl. 07.08 skrev &quot;Markus Mirsberger&quot; \n&gt;&gt;&gt; &lt;markus.mirsberger@... &lt;mailto:markus.mirsberger@...&gt;&gt;:\n&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Hello Noah,\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; thanks for your reply. This works well when I only use one thread \n&gt;&gt;&gt;&gt; for one host.\n&gt;&gt;&gt;&gt; Unfortunately I am crawling most hosts with parallel queues and \n&gt;&gt;&gt;&gt; this setting affects every queue.\n&gt;&gt;&gt;&gt; I thought first .... ok no problem..just part the amount of sites \n&gt;&gt;&gt;&gt; to the queues .. e.g. if I like to crawl 10.000 URLs with 10 \n&gt;&gt;&gt;&gt; parallel queues so I set queueTotalBudget to 1000.\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; This worked in tests with small hosts but now I tried it with a \n&gt;&gt;&gt;&gt; bigger host and the result is completely different from what I \n&gt;&gt;&gt;&gt; expected.\n&gt;&gt;&gt;&gt; With 30 parallelQueues I tried to get a maximum of 250.000 URIs \n&gt;&gt;&gt;&gt; (out of 2.000.000) from one host. So I set the queueTotalBudgt to \n&gt;&gt;&gt;&gt; 8334 but the result are only about 55.000 crawled URIs.\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Did I use this in a wrong way or do I have to use another setting \n&gt;&gt;&gt;&gt; when I use parallel queues?\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Thanks and regarads,\n&gt;&gt;&gt;&gt; Markus\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; On 09/14/2012 06:09 AM, Noah Levitt wrote:\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt; Hello Markus,\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt; You can set the value of queueTotalBudget to 100 on your frontier. \n&gt;&gt;&gt;&gt;&gt; Since\n&gt;&gt;&gt;&gt;&gt; by default each queue corresponds to one host, the effect is what you\n&gt;&gt;&gt;&gt;&gt; describe.\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt; Noah\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt; On 08/31/2012 10:04 AM, mirschi74 wrote:\n&gt;&gt;&gt;&gt;&gt; &gt; Hi,\n&gt;&gt;&gt;&gt;&gt; &gt;\n&gt;&gt;&gt;&gt;&gt; &gt; I have a seed file filled with hosts, but want only crawl e.g. \n&gt;&gt;&gt;&gt;&gt; 100 URLs from each host.\n&gt;&gt;&gt;&gt;&gt; &gt; Can you please give me a hint where I can configure that?\n&gt;&gt;&gt;&gt;&gt; &gt; I think it should be somewhere in the BDBFrontier, but I cant \n&gt;&gt;&gt;&gt;&gt; find any documentation about that.\n&gt;&gt;&gt;&gt;&gt; &gt; There is another setting that limits the maxdocuments. But this \n&gt;&gt;&gt;&gt;&gt; is a global setting and limits the crawls for a jobrun and not \n&gt;&gt;&gt;&gt;&gt; meant to limit crawls by host.\n&gt;&gt;&gt;&gt;&gt; &gt;\n&gt;&gt;&gt;&gt;&gt; &gt; Thanks in advance,\n&gt;&gt;&gt;&gt;&gt; &gt; Markus\n&gt;&gt;&gt;&gt;&gt; &gt;\n&gt;&gt;&gt;&gt;&gt; &gt;\n&gt;&gt;&gt;&gt;&gt; &gt;\n&gt;&gt;&gt;&gt;&gt; &gt; ------------------------------------\n&gt;&gt;&gt;&gt;&gt; &gt;\n&gt;&gt;&gt;&gt;&gt; &gt; Yahoo! Groups Links\n&gt;&gt;&gt;&gt;&gt; &gt;\n&gt;&gt;&gt;&gt;&gt; &gt;\n&gt;&gt;&gt;&gt;&gt; &gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;\n&gt;&gt;\n&gt; \n\n\r\n--------------080704050504010801040609\r\nContent-Type: text/html; charset=UTF-8\r\nContent-Transfer-Encoding: 8bit\r\n\r\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;meta content=&quot;text/html; charset=UTF-8&quot; http-equiv=&quot;Content-Type&quot;&gt;\n  &lt;/head&gt;\n  &lt;body bgcolor=&quot;#FFFFFF&quot; text=&quot;#000000&quot;&gt;\n    omg ... yes you right.....I forgot that....maxdocuments&lt;br&gt;\n    I just first thought about another requirement where I need the\n    queuetotalbudget...but there I have only one queue/host and I forgot\n    that. Here I can use maxdocuments&lt;br&gt;\n    &lt;br&gt;\n    Thanks alot :)&lt;br&gt;\n    Markus&lt;br&gt;\n    &lt;br&gt;\n    &lt;br&gt;\n    &lt;br&gt;\n    &lt;div class=&quot;moz-cite-prefix&quot;&gt;On 09/19/2012 01:02 PM, Bjarne Andersen\n      wrote:&lt;br&gt;\n    &lt;/div&gt;\n    &lt;blockquote\n      cite=&quot;mid:229D6471-DECA-4446-B0F8-5179326BE94D@...&quot;\n      type=&quot;cite&quot;&gt;\n      &lt;span style=&quot;display:none&quot;&gt; &lt;/span&gt;\n      \n          &lt;div id=&quot;ygrp-text&quot;&gt;\n            &lt;div&gt;IF one job is only crawling one host and you want to\n              limit that host in total to a number you should just use\n              the global setting for limiting the entire job (I Think I\n              remember there is one although I never used it)&lt;/div&gt;\n            &lt;div&gt;-&lt;/div&gt;\n            &lt;div&gt;Bjarne&lt;br&gt;\n              &lt;br&gt;\n              Sendt fra min iPhone&lt;/div&gt;\n            &lt;div&gt;&lt;br&gt;\n              Den 19/09/2012 kl. 07.42 skrev &quot;Markus Mirsberger&quot; &lt;&lt;a\n                moz-do-not-send=&quot;true&quot;\n                href=&quot;mailto:markus.mirsberger@...&quot;&gt;markus.mirsberger@...&lt;/a&gt;&gt;:&lt;br&gt;\n              &lt;br&gt;\n            &lt;/div&gt;\n            &lt;blockquote type=&quot;cite&quot;&gt;\n              &lt;div&gt;\n                &lt;span&gt; &lt;/span&gt;\n                &lt;div id=&quot;ygrp-text&quot;&gt;\n                  &lt;p&gt; Yes I think that too. &lt;br&gt;\n                    But with one job I&#39;m only crawling one host and I\n                    not follow external hosts (with a custom decide\n                    rule).&lt;br&gt;\n                    So in every queue should be the same hostname since\n                    I think the external hosts should not be moved to\n                    the queue when filtered out with a decide rule.&lt;br&gt;\n                    &lt;br&gt;\n                    Regards,&lt;br&gt;\n                    Markus&lt;br&gt;\n                    &lt;br&gt;\n                    &lt;br&gt;\n                  &lt;/p&gt;\n                  &lt;div class=&quot;moz-cite-prefix&quot;&gt;On 09/19/2012 12:23 PM,\n                    Bjarne Andersen wrote:&lt;br&gt;\n                  &lt;/div&gt;\n                  &lt;blockquote\n                    cite=&quot;mid:3720E452-8F49-4BFB-A40F-D60BC209145D@...&quot;\n                    type=&quot;cite&quot;&gt; &lt;span&gt; &lt;/span&gt;\n                    &lt;div id=&quot;ygrp-text&quot;&gt;\n                      &lt;div&gt;IF your queues does not exactly match\n                        hostnames the queuetotalbudget does not really\n                        make sense in your setup. This setting limits\n                        the number of URIs taken off each queue so if a\n                        queue can have URIs from more than one host, the\n                        limit just means that every URI could be from\n                        the same host as long as the total budget is not\n                        yet spent. If URIs from the same host gets\n                        randomly put into different queues it makes even\n                        less sense in your setting&lt;/div&gt;\n                      &lt;div&gt;&lt;br&gt;\n                      &lt;/div&gt;\n                      &lt;div&gt;AFAIK there is no existing solution for you\n                        with heritrix :( &lt;/div&gt;\n                      &lt;div&gt;You could write your own limiter module off\n                        cause that holds an alternative datastructure\n                        side by side the current queues&lt;/div&gt;\n                      &lt;div&gt;&lt;br&gt;\n                      &lt;/div&gt;\n                      &lt;div&gt;Best&lt;/div&gt;\n                      &lt;div&gt;Bjarne Andersen&lt;/div&gt;\n                      &lt;div&gt;&lt;a moz-do-not-send=&quot;true&quot; moz=&quot;true&quot;\n                          href=&quot;http://Netarchive.dk&quot;&gt;Netarchive.dk&lt;/a&gt;&lt;/div&gt;\n                      &lt;div&gt;&lt;br&gt;\n                        &lt;br&gt;\n                        Sendt fra min iPhone&lt;/div&gt;\n                      &lt;div&gt;&lt;br&gt;\n                        Den 19/09/2012 kl. 07.08 skrev &quot;Markus\n                        Mirsberger&quot; &lt;&lt;a moz-do-not-send=&quot;true&quot;\n                          moz=&quot;true&quot;\n                          href=&quot;mailto:markus.mirsberger@...&quot;&gt;markus.mirsberger@...&lt;/a&gt;&gt;:&lt;br&gt;\n                        &lt;br&gt;\n                      &lt;/div&gt;\n                      &lt;blockquote type=&quot;cite&quot;&gt;\n                        &lt;div&gt; &lt;span&gt; &lt;/span&gt;\n                          &lt;div id=&quot;ygrp-text&quot;&gt;\n                            &lt;p&gt; Hello Noah,&lt;br&gt;\n                              &lt;br&gt;\n                              thanks for your reply. This works well\n                              when I only use one thread for one host.&lt;br&gt;\n                              Unfortunately I am crawling most hosts\n                              with parallel queues and this setting\n                              affects every queue.&lt;br&gt;\n                              I thought first .... ok no problem..just\n                              part the amount of sites to the queues ..\n                              e.g. if I like to crawl 10.000 URLs with\n                              10 parallel queues so I set\n                              queueTotalBudget to 1000.&lt;br&gt;\n                              &lt;br&gt;\n                              This worked in tests with small hosts but\n                              now I tried it with a bigger host and the\n                              result is completely different from what I\n                              expected. &lt;br&gt;\n                              With 30 parallelQueues I tried to get a\n                              maximum of 250.000 URIs (out of 2.000.000)\n                              from one host. So I set the\n                              queueTotalBudgt to 8334 but the result are\n                              only about 55.000 crawled URIs.&lt;br&gt;\n                              &lt;br&gt;\n                              Did I use this in a wrong way or do I have\n                              to use another setting when I use parallel\n                              queues?&lt;br&gt;\n                              &lt;br&gt;\n                              &lt;br&gt;\n                              Thanks and regarads,&lt;br&gt;\n                              Markus&lt;br&gt;\n                              &lt;br&gt;\n                              &lt;br&gt;\n                            &lt;/p&gt;\n                            &lt;div class=&quot;moz-cite-prefix&quot;&gt;On 09/14/2012\n                              06:09 AM, Noah Levitt wrote:&lt;br&gt;\n                            &lt;/div&gt;\n                            &lt;blockquote\n                              cite=&quot;mid:505267AD.6020806@...&quot;\n                              type=&quot;cite&quot;&gt; &lt;span&gt; &lt;/span&gt;\n                              &lt;div id=&quot;ygrp-text&quot;&gt;\n                                &lt;p&gt;Hello Markus,&lt;br&gt;\n                                  &lt;br&gt;\n                                  You can set the value of\n                                  queueTotalBudget to 100 on your\n                                  frontier. Since &lt;br&gt;\n                                  by default each queue corresponds to\n                                  one host, the effect is what you &lt;br&gt;\n                                  describe.&lt;br&gt;\n                                  &lt;br&gt;\n                                  Noah&lt;br&gt;\n                                  &lt;br&gt;\n                                  On 08/31/2012 10:04 AM, mirschi74\n                                  wrote:&lt;br&gt;\n                                  &gt; Hi,&lt;br&gt;\n                                  &gt;&lt;br&gt;\n                                  &gt; I have a seed file filled with\n                                  hosts, but want only crawl e.g. 100\n                                  URLs from each host.&lt;br&gt;\n                                  &gt; Can you please give me a hint\n                                  where I can configure that?&lt;br&gt;\n                                  &gt; I think it should be somewhere in\n                                  the BDBFrontier, but I cant find any\n                                  documentation about that.&lt;br&gt;\n                                  &gt; There is another setting that\n                                  limits the maxdocuments. But this is a\n                                  global setting and limits the crawls\n                                  for a jobrun and not meant to limit\n                                  crawls by host.&lt;br&gt;\n                                  &gt;&lt;br&gt;\n                                  &gt; Thanks in advance,&lt;br&gt;\n                                  &gt; Markus&lt;br&gt;\n                                  &gt;&lt;br&gt;\n                                  &gt;&lt;br&gt;\n                                  &gt;&lt;br&gt;\n                                  &gt;\n                                  ------------------------------------&lt;br&gt;\n                                  &gt;&lt;br&gt;\n                                  &gt; Yahoo! Groups Links&lt;br&gt;\n                                  &gt;&lt;br&gt;\n                                  &gt;&lt;br&gt;\n                                  &gt;&lt;br&gt;\n                                  &lt;br&gt;\n                                &lt;/p&gt;\n                              &lt;/div&gt;\n                              &lt;!-- end group email --&gt; &lt;/blockquote&gt;\n                            &lt;br&gt;\n                          &lt;/div&gt;\n                          &lt;!-- end group email --&gt; &lt;/div&gt;\n                      &lt;/blockquote&gt;\n                    &lt;/div&gt;\n                    &lt;!-- end group email --&gt; &lt;/blockquote&gt;\n                  &lt;br&gt;\n                &lt;/div&gt;\n                &lt;!-- end group email --&gt;\n              &lt;/div&gt;\n            &lt;/blockquote&gt;\n          &lt;/div&gt;\n          \n      \n      &lt;!-- end group email --&gt;\n    &lt;/blockquote&gt;\n    &lt;br&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\r\n--------------080704050504010801040609--\r\n\n"}}