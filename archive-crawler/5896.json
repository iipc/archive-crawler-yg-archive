{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"P-AFgapOY2DNyx08sQUncgumttcs1EPLNCHPjCUagwOnCP1LkP0u1iA4poPXUhgNrZOMuioGRLtXnGDZVKrMiskl0oqPieI","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] twitter crawling","postDate":"1245360523","msgId":5896,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRBM0FCMThCLjMwNzAyMDVAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDRBM0EzOUVGMDIwMDAwMTIwMDNCOEJDNEBudGd3Z2F0ZS5sb2MuZ292Pg==","referencesHeader":"PDRBM0EzOUVGMDIwMDAwMTIwMDNCOEJDNEBudGd3Z2F0ZS5sb2MuZ292Pg=="},"prevInTopic":5895,"nextInTopic":5897,"prevInTime":5895,"nextInTime":5897,"topicId":5893,"numMessagesInTopic":4,"msgSnippet":"... Are you just interested in a sampling, or are you hoping to capture every relevant tweet during the collection period? (If your chief aim was complete","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 33854 invoked from network); 18 Jun 2009 21:29:47 -0000\r\nX-Received: from unknown (69.147.108.201)\n  by m7.grp.re1.yahoo.com with QMQP; 18 Jun 2009 21:29:47 -0000\r\nX-Received: from unknown (HELO relay03.pair.com) (209.68.5.17)\n  by mta2.grp.re1.yahoo.com with SMTP; 18 Jun 2009 21:29:47 -0000\r\nX-Received: (qmail 20653 invoked from network); 18 Jun 2009 21:28:46 -0000\r\nX-Received: from 67.170.223.242 (HELO ?192.168.1.91?) (67.170.223.242)\n  by relay03.pair.com with SMTP; 18 Jun 2009 21:28:46 -0000\r\nX-pair-Authenticated: 67.170.223.242\r\nMessage-ID: &lt;4A3AB18B.3070205@...&gt;\r\nDate: Thu, 18 Jun 2009 14:28:43 -0700\r\nUser-Agent: Thunderbird 2.0.0.21 (Windows/20090302)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;4A3A39EF02000012003B8BC4@...&gt;\r\nIn-Reply-To: &lt;4A3A39EF02000012003B8BC4@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] twitter crawling\r\nX-Yahoo-Group-Post: member; u=137285340; y=1ZCov4poadX2ZC0YOlAM-Azc_xGrgmL6JUnEhh5Dp_e_\r\nX-Yahoo-Profile: gojomo\r\n\r\nGina Jones wrote:\n&gt; I am trying to crawl twitter to get a search query\n&gt; http://search.twitter.com/search?q=sotomayor \n&gt; as part of a new collection that the Library of Congress is doing on the supreme court nominations.  Intent is to do a daily crawl to capture the tweets about sotomayor.\n\nAre you just interested in a sampling, or are you hoping to capture \nevery relevant tweet during the collection period?\n\n(If your chief aim was complete coverage, you might want to crawl more \nthan once per day, but make the number of &#39;pages&#39; you dig dependent on \nwhether you&#39;ve started getting repeats from your last capture. At the \nextreme, this could involve a custom Beanshell script to analyze in-page \ncontent before following the &#39;older&#39; link.)\n\n&gt; Twitter provides up to 100 pages of what has been tweeted about the query term.  Unfortunately, the max-id for the additional 99 pages always start with the number of the latest tweet on the fly so I can&#39;t really specify that because I have to be concerned with users accessing it via wayback as part of the collection.\n\nI&#39;m not sure why the tweet-number-in-URL is an issue. Can you explain in \nmore detail?\n\nIf (for example) you get &lt;http://search.twitter.com/search?q=sotomayor&gt; \neach night at midnight, then later users of the archive via the Wayback \nwould see those daily captures, and starting from any of them, be able \nto page through the &#39;older&#39; links -- because paging from any one crawl \nwould use consistent &#39;max_id&#39; values.\n\nIf you offered full-text search, there would be a chance for users to \njump directly to deeper results pages, when those pages appear in search \nresults.\n\n&gt; \n&gt; I am trying to maximize the efficiency of this crawl, limiting the extraneous stuff.\n&gt; \n&gt; My surt prefix associations are\n&gt; http://(com,twitter,search,)/search?max_id= \n&gt; http://(com,twitter,search,)/search?q=sotomayor \n&gt; \n&gt; Using the standard global sheet for deep seed crawl.\n&gt; \n&gt; Is this the best way to do this crawl?  And yes, Gordon, Heritrix rel. 2.\n&gt; \n&gt; suggestions on the sheet settings?\n&gt; I am getting a lot of garbage.\n\nThe standard advice regarding H2 applies: unless you need to use or \nlearn the new prioritization features, H1.14.x is still recommended for \nproduction crawls.\n\nWhat sort of garbage are you getting? Since Twitter doesn&#39;t include \nuser-contributed HTML, and everything inline on their site \n(images/js/css/etc) is from their servers, I would think your scope (as \nI understand it) wouldn&#39;t stray from material necessary to render the \nsearch results page.\n\nMy colleague Steve&#39;s suggestion, to eliminate the \nTransclusionDecideRule, is a standard thing to consider when crawls are \nwandering from the focal sites. (Or, similarly, tightening the \nhop-limits used by the TransclusionDecideRule.) However, since I think \nyou care about rendering fidelity in the Wayback, and the Twitter result \npage HTML is already tightly controlled by Twitter, you probably want to \nkeep it. (For example, it appears Twitter users&#39; avatar images come from \ns3.amazonaws.com, and those will only be fetched if you leave the \nTransclusionDecideRule in.)\n\nVarious other thoughts triggered by your project:\n\n- Duplication in repeated queries may not be that big a deal; tweets are \nsmall, and since a real user, querying each day, would see some \nduplicates it&#39;s fair for the archive to reflect that as well.\n\n- It seems like misspellings of &#39;Sotomayor&#39; are common; you might want \nto grab &#39;Sotomayer&#39; (at least) too.\n\n- Often a Tweet includes a cryptic shortened-link, and can only be \nunderstood after visiting the link. So this might be a place to do a \n&quot;plus-one&quot; crawl, intentionally visiting all the pages on other sites \nlinked from the Twitter results. Of course, this means a lot more \n&#39;garbage&#39; -- indeed could swamp the Twitter results -- but could make \nthe archive much more complete/comprehendable.\n\nHope this helps,\n\n- Gordon @ IA\n\n"}}