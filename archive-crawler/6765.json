{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":465980601,"authorName":"Zach Bailey","from":"Zach Bailey &lt;zach.bailey@...&gt;","replyTo":"LIST","senderId":"w_nXkeSn60g_BpP3bxWUUYwBX7fREXeUn9YpBn1p0BIrAmJuLNgPcLzoYdRWRqPN1anECpVKVTXQqAsdpdYiIi9WOxCREUkanAvTXik","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Limit pages fetched per seed?","postDate":"1286726519","msgId":6765,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEFBTkxrVGltbTBWNFlTUENDLVZTZmpjUUxlWnlmTkJaLStRSmdFOT1rUUpla0BtYWlsLmdtYWlsLmNvbT4="},"prevInTopic":0,"nextInTopic":6766,"prevInTime":6764,"nextInTime":6766,"topicId":6765,"numMessagesInTopic":2,"msgSnippet":"Is there a configuration option available for limiting the number of documents/URIs fetched per seed? I know an overall limit can be set for the entire crawl,","rawEmail":"Return-Path: &lt;zach.bailey@...&gt;\r\nX-Sender: zach.bailey@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 77821 invoked from network); 10 Oct 2010 16:02:01 -0000\r\nX-Received: from unknown (98.137.34.45)\n  by m6.grp.sp2.yahoo.com with QMQP; 10 Oct 2010 16:02:01 -0000\r\nX-Received: from unknown (HELO mail-iw0-f177.google.com) (209.85.214.177)\n  by mta2.grp.sp2.yahoo.com with SMTP; 10 Oct 2010 16:02:00 -0000\r\nX-Received: by iwn5 with SMTP id 5so684690iwn.36\n        for &lt;archive-crawler@yahoogroups.com&gt;; Sun, 10 Oct 2010 09:01:59 -0700 (PDT)\r\nMIME-Version: 1.0\r\nX-Received: by 10.42.90.82 with SMTP id j18mr1445377icm.64.1286726519603; Sun,\n 10 Oct 2010 09:01:59 -0700 (PDT)\r\nX-Received: by 10.42.174.68 with HTTP; Sun, 10 Oct 2010 09:01:59 -0700 (PDT)\r\nDate: Sun, 10 Oct 2010 12:01:59 -0400\r\nMessage-ID: &lt;AANLkTimm0V4YSPCC-VSfjcQLeZyfNBZ-+QJgE9=kQJek@...&gt;\r\nTo: archive-crawler &lt;archive-crawler@yahoogroups.com&gt;\r\nContent-Type: multipart/alternative; boundary=90e6ba6148021fc0f80492455dda\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Zach Bailey &lt;zach.bailey@...&gt;\r\nSubject: Limit pages fetched per seed?\r\nX-Yahoo-Group-Post: member; u=465980601\r\n\r\n\r\n--90e6ba6148021fc0f80492455dda\r\nContent-Type: text/plain; charset=ISO-8859-1\r\n\r\nIs there a configuration option available for limiting the number of\ndocuments/URIs fetched per seed? I know an overall limit can be set for the\nentire crawl, but is it possible to set this on a seed basis?\n\nWe are using Heritrix 3 with the spring configuration options.\n\nThanks,\n-Zach\n\r\n--90e6ba6148021fc0f80492455dda\r\nContent-Type: text/html; charset=ISO-8859-1\r\n\r\nIs there a configuration option available for limiting the number of documents/URIs fetched per seed? I know an overall limit can be set for the entire crawl, but is it possible to set this on a seed basis?&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;\nWe are using Heritrix 3 with the spring configuration options.&lt;br&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks,&lt;/div&gt;&lt;div&gt;-Zach&lt;/div&gt;&lt;/div&gt;\n\r\n--90e6ba6148021fc0f80492455dda--\r\n\n"}}