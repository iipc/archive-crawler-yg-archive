{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"aARA1KoFaB6vxv93nmACcOO2MwvSdu9GfSwvmZY_ilj2dXjSmeYXXlsG6eK0DuCGGdKurnzmlDAJGB-wFT8w9FUxkhA62HU","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: about continous crawl(rescheduling seeds)","postDate":"1294792196","msgId":6977,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDREMkNGNjA0LjEwNzA3MDRAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDIwMTEwMTEwMTA0MzQ0MjY1MDc1MUBnbWFpbC5jb20+","referencesHeader":"PDIwMTEwMTEwMTA0MzQ0MjY1MDc1MUBnbWFpbC5jb20+"},"prevInTopic":6975,"nextInTopic":0,"prevInTime":6976,"nextInTime":6978,"topicId":6975,"numMessagesInTopic":2,"msgSnippet":"Thanks for your report; there were a couple problems with the reenqueuing of URIs from futureUris in a crawl that had otherwise emptied all its queues. I","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 69415 invoked from network); 12 Jan 2011 00:29:58 -0000\r\nX-Received: from unknown (66.196.94.107)\n  by m6.grp.sp2.yahoo.com with QMQP; 12 Jan 2011 00:29:58 -0000\r\nX-Received: from unknown (HELO relay00.pair.com) (209.68.5.9)\n  by mta3.grp.re1.yahoo.com with SMTP; 12 Jan 2011 00:29:57 -0000\r\nX-Received: (qmail 87902 invoked by uid 0); 12 Jan 2011 00:29:56 -0000\r\nX-Received: from 208.70.27.190 (HELO silverbook.local) (208.70.27.190)\n  by relay00.pair.com with SMTP; 12 Jan 2011 00:29:56 -0000\r\nX-pair-Authenticated: 208.70.27.190\r\nMessage-ID: &lt;4D2CF604.1070704@...&gt;\r\nDate: Tue, 11 Jan 2011 16:29:56 -0800\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.6; en-US; rv:1.9.2.13) Gecko/20101207 Thunderbird/3.1.7\r\nMIME-Version: 1.0\r\nTo: =?UTF-8?B?6YOt6Iq4?= &lt;mickey.guoyun@...&gt;\r\nCc: Heritrix &lt;archive-crawler@yahoogroups.com&gt;\r\nReferences: &lt;201101101043442650751@...&gt;\r\nIn-Reply-To: &lt;201101101043442650751@...&gt;\r\nContent-Type: text/plain; charset=UTF-8; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: about continous crawl(rescheduling seeds)\r\nX-Yahoo-Group-Post: member; u=137285340; y=h7mT2zuYhZnvs12hMZJAkQhec_s5QKFTYe7nDQSLtdiI\r\nX-Yahoo-Profile: gojomo\r\n\r\nThanks for your report; there were a couple problems with the \nreenqueuing of URIs from &#39;futureUris&#39; in a crawl that had otherwise \nemptied all its queues.\n\nI made an issue to track the bug, and have committed an initial fix to \nthe development branch. See:\n\nhttps://webarchive.jira.com/browse/HER-1858\n\nThis fix will become part of the next official H3 release, expected in \nFebruary.\n\nYou could run a development version before then, but there are many \nchanges there still being tested and debugged, so you are likely to hit \nother problems in the next few weeks.\n\nAnother possible workaround would be the other technique I mentioned in \nmy email of 12/30, creating a custom bean that watches for certain crawl \nstates (like an empty/paused crawl) and then triggers reenqueueing of \nseeds at that point. (You could also do this via an external script \nhitting the crawl&#39;s web UI: poll the interface, notice a paused/empty \ncrawl, at that moment drop your new seeds into the &#39;action&#39; directory \nthen unpause the crawl.)\n\nHope this helps... good luck!\n\n- Gordon @ IA\n\nOn 1/9/11 6:43 PM, 郭芸 wrote:\n&gt; Hi Gordon,\n&gt; In Heritrix3.0,we can use curi.setRescheduleTime(36*1000*1000) to\n&gt; rescheduling seeds.and i have read the source code.I found some problems.\n&gt; the next source codes determine the urls to rescheduling.\n&gt; protected void checkFutures() {\n&gt; assert Thread.currentThread() == managerThread;\n&gt; // TODO: consider only checking this every set interval\n&gt; Iterator&lt;CrawlURI&gt; iter =\n&gt; futureUris.headMap(System.currentTimeMillis())\n&gt; .values().iterator();\n&gt; while(iter.hasNext()) {\n&gt; CrawlURI curi = iter.next();\n&gt; curi.setRescheduleTime(-1); // unless again set elsewhere\n&gt; iter.remove();\n&gt; futureUriCount.decrementAndGet();\n&gt; receive(curi);\n&gt; }\n&gt; }\n&gt; these code run at the finish of every url.but once there have no url to\n&gt; process when the futureUris have url need to rescheduling,this funciton\n&gt; will never to trigger.so the urls(maybe are seeds) what in futureUris\n&gt; will never to rescheduling.\n&gt; Is there have a way to resolve or avoid this problem?for example,we can\n&gt; use TimerTask.\n&gt; Thank you!\n&gt; 2011-01-10\n&gt; ------------------------------------------------------------------------\n&gt; 郭芸\n\n"}}