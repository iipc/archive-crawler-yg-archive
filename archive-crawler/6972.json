{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"yHbh18GcRdbMJEbZTGYgc9-2cjvHLoa0xHO03-BEpwnDdioEnwKwZ0OWL6dbBsX5JYutcEbm6dD-b0kUEsH9ljhBuIi-8R4","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] crawl only seed urls in Heritrix","postDate":"1294357392","msgId":6972,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDREMjY1MzkwLjYwMTA1MDdAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDREMjU0MkZCLjIwNDA5MDdAZ21haWwuY29tPg==","referencesHeader":"PGlmdjF2ZCt0bzd0QGVHcm91cHMuY29tPiA8NEQyMzcxODAuOTA3MDYwOEBhcmNoaXZlLm9yZz4gPDREMjM5MUVBLjgwNjA3MDFAYXJjaGl2ZS5vcmc+IDw0RDIzRjBENS42MDkwMDA5QGdtYWlsLmNvbT4gPDREMjQwRUNDLjEwMzA0MDNAYXJjaGl2ZS5vcmc+IDw0RDI0NzE3RS42MDUwMTA2QGdtYWlsLmNvbT4gPDREMjRCNUJCLjYwNDA4QGFyY2hpdmUub3JnPiA8NEQyNTQyRkIuMjA0MDkwN0BnbWFpbC5jb20+"},"prevInTopic":6969,"nextInTopic":6976,"prevInTime":6971,"nextInTime":6973,"topicId":6955,"numMessagesInTopic":9,"msgSnippet":"Any version of Heritrix should handle 50K seeds without any problem. Can you be more specific about what you mean by picked up top 2.5K only ? Loading","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 36427 invoked from network); 6 Jan 2011 23:43:14 -0000\r\nX-Received: from unknown (98.137.34.46)\n  by m6.grp.sp2.yahoo.com with QMQP; 6 Jan 2011 23:43:14 -0000\r\nX-Received: from unknown (HELO relay03.pair.com) (209.68.5.17)\n  by mta3.grp.sp2.yahoo.com with SMTP; 6 Jan 2011 23:43:14 -0000\r\nX-Received: (qmail 27758 invoked by uid 0); 6 Jan 2011 23:43:12 -0000\r\nX-Received: from 208.70.27.190 (HELO silverbook.local) (208.70.27.190)\n  by relay03.pair.com with SMTP; 6 Jan 2011 23:43:12 -0000\r\nX-pair-Authenticated: 208.70.27.190\r\nMessage-ID: &lt;4D265390.6010507@...&gt;\r\nDate: Thu, 06 Jan 2011 15:43:12 -0800\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.6; en-US; rv:1.9.2.13) Gecko/20101207 Thunderbird/3.1.7\r\nMIME-Version: 1.0\r\nTo: arundudee gmail &lt;arundudee@...&gt;\r\nCc: Noah Levitt &lt;nlevitt@...&gt;, archive-crawler@yahoogroups.com\r\nReferences: &lt;ifv1vd+to7t@...&gt; &lt;4D237180.9070608@...&gt; &lt;4D2391EA.8060701@...&gt; &lt;4D23F0D5.6090009@...&gt; &lt;4D240ECC.1030403@...&gt; &lt;4D24717E.6050106@...&gt; &lt;4D24B5BB.60408@...&gt; &lt;4D2542FB.2040907@...&gt;\r\nIn-Reply-To: &lt;4D2542FB.2040907@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] crawl only seed urls in Heritrix\r\nX-Yahoo-Group-Post: member; u=137285340; y=I1bch19n1Y5zyTX06Fh7lpK_Q1dQFs_W-j_6g3AYshJ5\r\nX-Yahoo-Profile: gojomo\r\n\r\nAny version of Heritrix should handle 50K seeds without any problem. Can \nyou be more specific about what you mean by &quot;picked up top 2.5K only&quot;?\n\nLoading &gt;1million seeds can sometimes be a bottleneck.\n\nH3 has some improvements here, and the goal is to seamlessly support \nseed-source files of &#39;any&#39; size, but a few more pending fixes are \nnecessary to eliminate some bad interactions with garbage-collection and \nthe crawler soft-reference caches, especially when the seeds are all \nfrom unique hostnames. (If they come from a smaller number of hosts, \nthere should be no problem.)\n\nAlso, note that you may not want to use a scope which (like the \ndeciding-defaults) tries to derive scoping rules from the seeds when \ndealing with that many seeds; better to explicitly define a scope \nunaffected by seeds.\n\nSo, if your goal is feeding the crawler many millions of URLs from an \noutside source -- as seeds or during a crawl -- I&#39;d recommend getting to \nH3, keeping an eye for the next release which will have further \nimprovements, and carefully considering scope issues.\n\n- Gordon @ IA\n\n\nOn 1/5/11 8:20 PM, arundudee gmail wrote:\n&gt; Noah-\n&gt; 1)my scale is 5 million in starting and then scale to few billion.\n&gt; 2)Is there any restriction on numbers of urls seed file can have.i gave\n&gt; around 50K to test but it picked up top 2.5K only.\n&gt;\n&gt; Thanks\n&gt; Arun\n&gt; On Wednesday 05 January 2011 11:47 PM, Gordon Mohr wrote:\n&gt;&gt; On 1/5/11 5:26 AM, arundudee gmail wrote:\n&gt;&gt;&gt; Thanks Noah , i was successful in setting up job with below mentioned\n&gt;&gt;&gt; steps and its working as desired.\n&gt;&gt;&gt; please can you help on point #2 as well :\n&gt;&gt;&gt; 2. I have one more question:let say i crawled 100 seeds urls and they\n&gt;&gt;&gt; are dumped at arc folder.Is there a way i can specify url and i can get\n&gt;&gt;&gt; response body of that page from dump... or is that possible through any\n&gt;&gt;&gt; other mechanism.\n&gt;&gt;\n&gt;&gt; In addition to Noah&#39;s answer, I would note that if you only have a\n&gt;&gt; fixed list of 100 URLs to crawl -- never wanting to extract links, or\n&gt;&gt; review HTTP headers, etc. -- then Heritrix may be overkill for your\n&gt;&gt; purposes. A command-line tool like &#39;wget&#39;, &#39;curl&#39;, etc. in a small\n&gt;&gt; loop may be plenty.\n&gt;&gt;\n&gt;&gt;&gt; I also noticed then when i run job , num of active threads remain zero :\n&gt;&gt;&gt; &#39;0 active of 50 threads &#39; how can i run all threads to speed up my\n&gt;&gt;&gt; crawling.\n&gt;&gt;\n&gt;&gt; See this page in the project wiki FAQ:\n&gt;&gt;\n&gt;&gt; &quot;Why is crawling slower than expected with a not-very-busy crawling\n&gt;&gt; machine?&quot;\n&gt;&gt;\n&gt;&gt; https://webarchive.jira.com/wiki/display/Heritrix/unexpectedly+slow+crawling+on+idle+crawler\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; - Gordon @ IA\n&gt;&gt;\n&gt;&gt;&gt; Thank you so much\n&gt;&gt;&gt; Arun\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; On Wednesday 05 January 2011 11:55 AM, Noah Levitt wrote:\n&gt;&gt;&gt;&gt; You can add and remove decide rules in the Submodules tab, or edit\n&gt;&gt;&gt;&gt; order.xml directly.\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Noah\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; On 2011-01-04 20:17 , arundudee gmail wrote:\n&gt;&gt;&gt;&gt;&gt; Gordon ,Noah - Thanks a ton for reply.\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt; 1. I am newbie to heritrix please can you elaborate how to perform\n&gt;&gt;&gt;&gt;&gt; three steps you mentioned below.I am attaching a screenshot of\n&gt;&gt;&gt;&gt;&gt; setting page but i don&#39;t know how to remove these rules and where to\n&gt;&gt;&gt;&gt;&gt; add #3.\n&gt;&gt;&gt;&gt;&gt; 2. I have one more question:let say i crawled 100 seeds urls and they\n&gt;&gt;&gt;&gt;&gt; are dumped at arc folder.Is there a way i can specify url and i can\n&gt;&gt;&gt;&gt;&gt; get response body of that page from dump... or is that possible\n&gt;&gt;&gt;&gt;&gt; through any other mechanism.\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt; Thanks once again.\n&gt;&gt;&gt;&gt;&gt; Arun\n&gt;&gt;&gt;&gt;&gt; On Wednesday 05 January 2011 03:02 AM, Gordon Mohr wrote:\n&gt;&gt;&gt;&gt;&gt;&gt; One extra note about Noah&#39;s suggestion: it assumes you&#39;re starting\n&gt;&gt;&gt;&gt;&gt;&gt; from the (recommended) &#39;deciding-default&#39; example scope, rather than\n&gt;&gt;&gt;&gt;&gt;&gt; using the (deprecated, legacy) &#39;BroadScope&#39; class.\n&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt; (I think your previous max-links-hops and max-trans-hops settings\n&gt;&gt;&gt;&gt;&gt;&gt; *should* have worked, but since Noah&#39;s approach is the better base\n&gt;&gt;&gt;&gt;&gt;&gt; for the future, getting to the bottom of what might have gone wrong\n&gt;&gt;&gt;&gt;&gt;&gt; with the BroadScope approach isn&#39;t as useful as moving the\n&gt;&gt;&gt;&gt;&gt;&gt; &#39;deciding&#39; scope.)\n&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt; - Gordon @ IA\n&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt; On 1/4/11 11:14 AM, Noah Levitt wrote:\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; Here&#39;s one way to crawl seeds only, and not even embedded images or\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; anything, which seems to be what you want. Starting with the\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; default order.xml...\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; 1. remove the scope rule acceptIfSurtPrefixed\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; 2. remove the scope rule acceptIfTranscluded\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; 3. add this scope rule right after rejectByDefault\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; &lt;newObject name=&quot;acceptIfSeed&quot;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.deciderules.SeedAcceptDecideRule&quot;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; Hope this works for you.\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; Noah\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; On 2011-01-04 03:57 , arun wrote:\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; i am using Heritrix 1.14.4.\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I have around million seed urls and i just want to crawl these\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; seed urls only.\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Please any one can suggest me how to do that.\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; one more problem i am facing is that.. i tried to crawl only seed\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; urls uing broadscope and then max-link-hops: 0 and max-trans-hops:\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 0 but its not restricting to seed ulrs it crawls other urls in\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; that page too.\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Any help will be highly appreciated ..thanks a ton in advance.\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; ------------------------------------\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Yahoo! Groups Links\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; ------------------------------------\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; Yahoo! Groups Links\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n\n"}}