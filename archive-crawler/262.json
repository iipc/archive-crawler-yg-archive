{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":163894630,"authorName":"steensc42","from":"&quot;steensc42&quot; &lt;steensc42@...&gt;","profile":"steensc42","replyTo":"LIST","senderId":"hkQFUjlRtv-qm8-Klo6ymlm__8MyZC8TQ2zKLpBMQ-ypVlohbzqk3e1PLO_YKe12e-oFYlgBqijGe684_JJYLdu2a8ydfXk","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Extending ARC Re: [archive-crawler] Re: Crawler-guided form/authentication entry","postDate":"1075123332","msgId":262,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGJ2MzRhNCtpaWNiQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDQwMERBRjFELjcwMTA2MDNAYXJjaGl2ZS5vcmc+"},"prevInTopic":245,"nextInTopic":263,"prevInTime":261,"nextInTime":263,"topicId":235,"numMessagesInTopic":8,"msgSnippet":"... may ... represented ... the ... the ... the ... they ... I agree that the safe approach is to include everything into the checksum. From a retrieval point","rawEmail":"Return-Path: &lt;steensc42@...&gt;\r\nX-Sender: steensc42@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 43222 invoked from network); 26 Jan 2004 13:22:25 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m14.grp.scd.yahoo.com with QMQP; 26 Jan 2004 13:22:25 -0000\r\nReceived: from unknown (HELO n10.grp.scd.yahoo.com) (66.218.66.65)\n  by mta2.grp.scd.yahoo.com with SMTP; 26 Jan 2004 13:22:24 -0000\r\nReceived: from [66.218.67.130] by n10.grp.scd.yahoo.com with NNFMP; 26 Jan 2004 13:22:13 -0000\r\nDate: Mon, 26 Jan 2004 13:22:12 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;bv34a4+iicb@...&gt;\r\nIn-Reply-To: &lt;400DAF1D.7010603@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Transfer-Encoding: quoted-printable\r\nContent-Length: 8127\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-eGroups-Remote-IP: 66.218.66.65\r\nFrom: &quot;steensc42&quot; &lt;steensc42@...&gt;\r\nSubject: Extending ARC Re: [archive-crawler] Re: Crawler-guided form/authentication entry\r\nX-Yahoo-Group-Post: member; u=163894630\r\nX-Yahoo-Profile: steensc42\r\n\r\n--- In archive-crawler@yahoogroups.com, Gordon Mohr &lt;gojomo@a...&gt; \nwrote:\n&gt;=\r\n steensc42 wrote:\n&gt; &gt; Here is a proposal for an extension of the arc format=\r\n in order to \n&gt; &gt; accommodate more detailed metadata. \n&gt; \n&gt; I&#39;ve been think=\r\ning of something very similar; some comments below.\n&gt; \n&gt; &gt; An entry for a h=\r\nttp response currently looks like this in the ARC \n&gt; &gt; format using the url=\r\n-record-v1 format:\n&gt; &gt; \n&gt; &gt; http://&lt;url1&gt; &lt;ip1&gt; &lt;timestamp1&gt; &lt;mime-type1&gt; &lt;=\r\ndata-size1&gt;\n&gt; &gt; &lt;DATA1 =96 http header, response data&gt;\n&gt; &gt; \n&gt; &gt; When data a=\r\nre collected using the HTTP post method ambiguities \nmay \n&gt; &gt; arise as mult=\r\niple requests for different web pages may be \nrepresented \n&gt; &gt; by the same =\r\nurl. An additional header field is proposed added to \nthe \n&gt; &gt; ARC header t=\r\no resolve these ambiguities. \n&gt; &gt; \n&gt; &gt; http://&lt;url1&gt; &lt;ip1&gt; &lt;timestamp1&gt; &lt;mi=\r\nme-type1&gt; \n&gt; &gt; &lt;data-size1&gt; &lt;request-encoding1&gt;\n&gt; &gt; &lt;DATA1 =96 http header,=\r\n response data&gt;\n&gt; &gt; \n&gt; &gt; The new field request-encoding is an MD5 checksum =\r\ncreated from \nthe \n&gt; &gt; http request. This encoding can be used to distingui=\r\nsh between \n&gt; &gt; different post requests. Notice that only a relevant subset=\r\n of \nthe \n&gt; &gt; complete http request should be used to create the checksum. =\r\nThis \n&gt; &gt; subset must include the url, the message body, and possibly the \n=\r\n&gt; &gt; authentication information and cookie values. We do not want to \n&gt; &gt; in=\r\nclude fields such as Accept, Referrer, Host and User-Agent as \nthey \n&gt; &gt; do=\r\n not define the content of the requested page.\n&gt; \n&gt; I would include these h=\r\neaders, both in the captured request and in\n&gt; any checksum which maps respo=\r\nnse-to-request.\n&gt; \n&gt; Servers can vary what they return based on those reque=\r\nst headers,\n&gt; and any decision other than recording/checksumming them all r=\r\nequires\n&gt; a volatile judgemental analysis.\n&gt; \n\nI agree that the safe approa=\r\nch is to include everything into the \nchecksum.\nFrom a retrieval point of v=\r\niew this might however pose some problems.\nHow do we locate the correct rec=\r\nord in the archive to return as \nresponse to a post request?\nIt would be ni=\r\nce if we could convert the post request into a key that \nwe can locate \nin =\r\nan index of archived url-objects. If this key is dependent on all \nrequest =\r\nheaders\nit will only work for specific browsers, referrer combinations.\nI g=\r\nuess the answer here is to accept that the &lt;capture-identifier&gt; \ncan not be=\r\n\nused directly for indexing purposes - and leave the retrieval problem \nto =\r\nthe\nimplementation of the indexing mechanism.\n\n&gt; &gt; This format still lacks =\r\ndetailed information about the http \nrequest \n&gt; &gt; header and does not provi=\r\nde means to add additional meta-data \n&gt; &gt; information. It is proposed that =\r\nadditional meta-data information \nis \n&gt; &gt; stored using the format:\n&gt; &gt; \n&gt; &gt;=\r\n metadata:http://&lt;url2&gt; &lt;ip2&gt; &lt;timestamp2&gt; text/xml \n&gt; &gt; &lt;data size2&gt; &lt;requ=\r\nest-encoding2&gt;\n&gt; &gt; &lt;DATA2 =96 metadata for url&gt;\n&gt; &gt; \n&gt; &gt; Where \n&gt; &gt; &lt;url1&gt;=\r\n=3D&lt;url2&gt;\n&gt; &gt; &lt;ip1&gt; =3D &lt;ip2&gt;\n&gt; &gt; &lt;timestamp1&gt; =3D &lt;timestamp2&gt;\n&gt; &gt; &lt;reques=\r\nt-encoding1&gt;=3D&lt;request-encoding2&gt;\n&gt; &gt; \n&gt; &gt; The DATA2 section is an xml rep=\r\nresentation of various metadata \n&gt; &gt; available during collection of the url=\r\n object. This information \nmust \n&gt; &gt; as a minimum contain the complete http=\r\n request. \n&gt; \n&gt; Somewhat inspired by the Swedish archive format -- which ha=\r\ns three\n&gt; segments for each capture (the request, the response, and the \nme=\r\ntadata) --\n&gt; I would offer the option of including the entire, byte-for-byt=\r\ne\n&gt; request as another ARC record.\n\nThat works for me.\nI like the idea that=\r\n we move the (potentially xml-unfriendly) http \nrequest \nfrom the metadata =\r\nsection to its own record. \n\n&gt; \n&gt; Thus the complete set of entries for a si=\r\nngle capture could be:\n&gt; \n&gt; request:http://&lt;url&gt; &lt;source-ip&gt; &lt;timestamp&gt; &lt;m=\r\nime&gt; &lt;request-size&gt; \n&lt;capture-identifier&gt;\n&gt; &lt;DATA - exact copy of request s=\r\nent&gt;\n&gt; http://&lt;url&gt; &lt;dest-ip&gt; &lt;timestamp&gt; &lt;mime&gt; &lt;response-size&gt; &lt;capture-\n=\r\nidentifier&gt;\n&gt; &lt;DATA - exact copy of response received, as in current ARC&gt;\n&gt;=\r\n metadata:http://&lt;url&gt; &lt;dest-ip&gt; &lt;timestamp&gt; &lt;mime&gt; &lt;metadata-size&gt; \n&lt;captu=\r\nre-identifier&gt;\n&gt; &lt;DATA - XML with other crawl-time info&gt;\n&gt; \n&gt; Some notes:\n&gt;=\r\n   (1) The &lt;capture-identifier&gt; is roughly the same as the &lt;request-\nencodi=\r\nng&gt;\n&gt;       you suggest: some identifier uniquely tying together the \nthree=\r\n records,\n&gt;       perhaps based on some function of the request. If in fact=\r\n the \nformat\n&gt;       requires related records to be contiguous, it might be=\r\n \nomittable.\n\nI would really like the option to:\n\t- place the metadata reco=\r\nrd at an arbitrary position relative \nto the other capture records.\n\t- crea=\r\nte more than one metadata record per capture.\n\t\nAn example of a usage scena=\r\nrio with metadata records positioned away \nfrom the other capture records:\n=\r\n\tAfter creation of an ARC file, a (time consuming) \npostprocessing of some =\r\n\n\tof the collected data is performed.\n\tThe information extracted by this pr=\r\nocess is written as \nmetadata records appended to \n\tthe original ARC file.\n=\r\n\n\n&gt;   (1) The &quot;request&quot; and &quot;metadata&quot; records, can be left out, \nignored, =\r\nor\n&gt;       stripped (say by a preprocessing filter) -- and then you \nessent=\r\nially\n&gt;       have a classic, limited ARC.\n&gt;   (2) The actual recommended o=\r\nrdering of the three parts is to-be-\ndetermined.\n&gt;       The above matches =\r\nthe chronological order in which the data is\n&gt;       available. Putting the=\r\n metadata first might help \npostprocessing/access.\n&gt;       Putting the resp=\r\nonse first might aid backward-compatibility.\n&gt; \n&gt; --\n&gt; \n&gt; The one big wishl=\r\nist item for ARC format revision that these ideas \ndon&#39;t\n&gt; directly address=\r\n is some efficient way to indicate when one capture \nis an\n&gt; exact (or near=\r\nly exact) duplicate of another.\n&gt; \n&gt; This could be a matter of having a way=\r\n to leave out the content-\nbody on\n&gt; response-records, and instead point ba=\r\nck to the earlier encounter of\n&gt; the exact same data.\n&gt; \n&gt; This back-pointe=\r\nr could be limited to only within the same ARC. \n(Thus,\n&gt; encouraging a sys=\r\ntem where ARCs are kept open longer, and duplicates\n&gt; appended to the end o=\r\nf ARCs where they were first encountered.) Or, \nit\n&gt; could point to any ARC=\r\n from the same crawl-run. Or, it could point\n&gt; back to any historical captu=\r\nre, provided there&#39;s some confidence in\n&gt; such cross-crawl dependencies.\n\nW=\r\ne would like to use this format to record frequent (daily) captures \nof sel=\r\nected sites.\nIn this scenario we would need to be able to refer to duplicat=\r\nes \nacross crawls.\nA procedure that ensures that master records are rewritt=\r\nen \noccasionally would of\ncourse need to be implemented.\n\n&gt; \n&gt; The pointer =\r\nshould probably be based on both a symbolic capture name\n&gt; (URI+timestamp, =\r\netc.) and a content-hash.\n&gt; \nAgreed. I think it is crucial that a content-h=\r\nash is part of the \npointer as this allows usage of\nalternative copies, sho=\r\nuld the &lt;URI+timestamp,etc&gt; link get \nlost/corrupted.\n\n\n\n&gt; Responses that i=\r\nnclude such references could be recorded as:\n&gt; \n&gt; duplicate-content:http://=\r\n&lt;uri&gt; &lt;dest-ip&gt; &lt;timestamp&gt; &lt;mime&gt; \n&lt;response-record-size&gt; &lt;capture-identif=\r\nier&gt;\n&gt; &lt;DATA - only response headers, as in current ARC&gt;\n&gt; &lt;backpointer to =\r\nalternate/original location of content-body&gt;\n&gt; \n&gt; Comments?\n\nWe have anothe=\r\nr usage scenario we would like this format to support.\nSome of the data for=\r\nmats in the archive may become \nobsolete/unsupported over time. \nOne approa=\r\nch for handling this problem is storage of applications \ncapable of handlin=\r\ng/converting\nthese formats. Another approach we want to support is transfor=\r\nmation \nof (important) data at risk\nto formats still supported. An example =\r\nmight be transformation from \none graphic file format (say gif),\nto another=\r\n format (say tif). This might be achieved using &quot;transform&quot; \nto mark a tran=\r\nsformed version:\n\n\ntransform:http://&lt;url&gt; &lt;dest-ip&gt; &lt;timestamp&gt; &lt;mime&gt; &lt;res=\r\nponse-size&gt; \n&lt;capture-identifier&gt;\n&lt;DATA - transformed version of original d=\r\nata record&gt;\nmetadata:transform:http://&lt;url&gt; &lt;dest-ip&gt; &lt;timestamp&gt; &lt;mime&gt; \n&lt;=\r\nmetadata-size&gt; &lt;capture-identifier&gt;\n&lt;DATA - metadata describing details abo=\r\nut the transformation (from \nformat, to format, application, etc)&gt;\n\nEach ti=\r\nme a url-object is transformed a new pair of (transform, \nmetadata:transfor=\r\nm) records\nare created, allowing sequences of format transformations.\n\nComm=\r\nents?\n/Steen\n\n&gt; \n&gt; - Gordon\n\n\n"}}