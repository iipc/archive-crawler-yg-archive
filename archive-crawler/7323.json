{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":498616997,"authorName":"markkramer_nl","from":"&quot;markkramer_nl&quot; &lt;markkramer_nl@...&gt;","profile":"markkramer_nl","replyTo":"LIST","senderId":"y8C3ns7sTj5sFKf9_OkjNGuGq-qh1Q-viFkjeoZTOmEjpwqmDmyqD6CYUBbRZ5a0yc8SqPY4Kmgcyv5NdGsyW_jdSPYWxU-lFswTWb9DQ7w","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: Detect crawl completion for individual seeds","postDate":"1316591860","msgId":7323,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGo1YzVkays2azI1QGVHcm91cHMuY29tPg==","inReplyToHeader":"PDRFNzNBNjdCLjUwODA5MDlAYXJjaGl2ZS5vcmc+"},"prevInTopic":7317,"nextInTopic":0,"prevInTime":7322,"nextInTime":7324,"topicId":7313,"numMessagesInTopic":3,"msgSnippet":"Hi Noah, Thanks for your reply! I experimented (before reading your reply) with a similar approach. What I did was subclassing a QueueAssignmentPolicy to ","rawEmail":"Return-Path: &lt;markkramer_nl@...&gt;\r\nX-Sender: markkramer_nl@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 31882 invoked from network); 21 Sep 2011 07:57:41 -0000\r\nX-Received: from unknown (98.137.34.44)\n  by m5.grp.sp2.yahoo.com with QMQP; 21 Sep 2011 07:57:41 -0000\r\nX-Received: from unknown (HELO n45b.bullet.mail.sp1.yahoo.com) (66.163.168.159)\n  by mta1.grp.sp2.yahoo.com with SMTP; 21 Sep 2011 07:57:41 -0000\r\nX-Received: from [69.147.65.173] by n45.bullet.mail.sp1.yahoo.com with NNFMP; 21 Sep 2011 07:57:41 -0000\r\nX-Received: from [98.137.34.36] by t15.bullet.mail.sp1.yahoo.com with NNFMP; 21 Sep 2011 07:57:41 -0000\r\nDate: Wed, 21 Sep 2011 07:57:40 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;j5c5dk+6k25@...&gt;\r\nIn-Reply-To: &lt;4E73A67B.5080909@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: multipart/alternative; boundary=&quot;4-1092536063-0806193128=:3&quot;\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nFrom: &quot;markkramer_nl&quot; &lt;markkramer_nl@...&gt;\r\nSubject: Re: Detect crawl completion for individual seeds\r\nX-Yahoo-Group-Post: member; u=498616997; y=t7nYmNQKO0gQgRWiWthKK_pSiZbI3L5Ad4zuDC85iib4gzEsntk-ug\r\nX-Yahoo-Profile: markkramer_nl\r\n\r\n\r\n--4-1092536063-0806193128=:3\r\nContent-Type: text/plain; charset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nHi Noah,\nThanks for your reply! I experimented (before reading your reply) =\r\nwith a\nsimilar approach. What I did was subclassing a QueueAssignmentPolicy=\r\n to\nassign all urls belonging to a seed (using the sourceTag) to a single\nq=\r\nueue. This way all the urls will be processed in that queue. Then I\ncreated=\r\n a &#39;Monitor&#39; by implementing\nApplicationListener.onApplicationEvent. Here I=\r\n monitor the WorkQueues\nand once the queue is empty I mark the seed as comp=\r\nleted. For this last\ncheck I used the following code:\nif(event instanceof C=\r\nrawlURIDispositionEvent) { CrawlURIDispositionEvent\ndvent =3D (CrawlURIDisp=\r\nositionEvent)event; CrawlURI crawlURI =3D\ndvent.getCrawlURI(); Disposition =\r\nstate =3D dvent.getDisposition(); \n//current crawl url successfully crawled=\r\n if (state =3D=3D\nDisposition.SUCCEEDED){  // get work queue of current url=\r\n  WorkQueue wq\n=3D (WorkQueue) dvent.getCrawlURI().getHolder();  Map&lt;String=\r\n, Object&gt;\nreport =3D wq.singleLineReportData();  long queueItems =3D\nLong.p=\r\narseLong(report.get(&quot;itemCount&quot;).toString());\n// check if queue is empty, i=\r\nf so crawling the seed   // is completed\n(since one queue is created per se=\r\ned... theoretically)  if (queueItems\n&lt;=3D 0){   logger.info(crawlURI.getSou=\r\nrceTag() + &quot;COMPLETED!.&quot;);  } }}\nThis seems to work partially. It fails whe=\r\nn a seed is added twice.\nHeritrix will skip that seed because it remembers =\r\nwhich urls are already\ncrawled (which is OK). Except... I still require som=\r\ne sort of\nnotification that Heritrix skipped that seed so that I can notifi=\r\ny\nsub-systems. But maybe your suggestion of subclassing BdbFrontier can\nfix=\r\n that.\nI will look into your other suggestions (using StatisticsTracker and=\r\n\nBdbFrontier). I&#39;ll let you know my progress on this... I also feel that\nth=\r\ne functionality that I require should be possible but I do get a\nfeeling of=\r\n &quot;hacking&quot; heritrix functionallity allot to achieve this. The\nsuggestion of=\r\n using a single job for one seed might be a simpler\napproach although this =\r\nwill introduce different problems... e.g.\ncrawling urls multiple times unne=\r\ncessarily, slower crawling etc.\nAnyways I&#39;ll keep you posted.\nMark\n\n--- In =\r\narchive-crawler@yahoogroups.com, Noah Levitt &lt;nlevitt@...&gt; wrote:\n&gt;\n&gt; Hello=\r\n Mark,\n&gt;\n&gt; It&#39;s possible I&#39;m overlooking something, but I don&#39;t know of an =\r\neasy\nway to achieve this. Like anything, it&#39;s possible with some coding\ntho=\r\nugh.\n&gt;\n&gt; First off you need to make sure sourceTagSeeds is enabled on your\n=\r\nSeedModule. When that&#39;s enabled, StatisticsTracker keeps some stats on\nseed=\r\n sources, so you can start with that. You&#39;ll have to subclass\nStatisticsTra=\r\ncker to keep track of queued urls because right now it only\ntakes note of c=\r\nrawled urls. That&#39;s not trivial either because currently\nthere doesn&#39;t appe=\r\nar to be any notification when a url is enqueued. To\nmake that happen you c=\r\nould subclass BdbFrontier and override receive()\nto do something like { sup=\r\ner.receive(); appCtx.publishEvent(new\nMyCrawlURIEnqueuedEvent(curi)); }. Th=\r\nen catch that event in your\nStatisticsTracker subclass and update your stat=\r\ns. When the crawled count\ncatches up to the queued count for a given source=\r\n tag, that should\nindicate the seed is complete.\n&gt;\n&gt; Perhaps an easier way =\r\nto go would be to have a separate crawl job for\neach seed, so you know the =\r\nseed is done when the crawl is done.\n&gt;\n&gt; There are other approaches that co=\r\nuld work too, inside and outside of\nheritrix. I&#39;d be curious to know what y=\r\nou end up doing.\n&gt;\n&gt; Noah\n&gt;\n&gt; On 2011-09-13 12:49 , markkramer_nl wrote:\n&gt; =\r\n&gt;\n&gt; &gt;\n&gt; &gt; Hi\n&gt; &gt;\n&gt; &gt; In my current project I use my own SeedModule implemen=\r\ntation to\npopulate/announce new seeds based on external input (ActiveMQ / D=\r\nB etc).\nWhat I still cannot figure out is how I can detect when a crawl is\n=\r\ncompleted for a single seed. I need this because I want to notify a\nsubsyst=\r\nem that the requested seed is done so that the subsystem can\nacquire all th=\r\ne fetched (sub)pages from the storage.\n&gt; &gt;\n&gt; &gt; I tried defining a &quot;monitor&quot;=\r\n using the ApplicationListener:\n&gt; &gt;\n&gt; &gt; public void onApplicationEvent(Appl=\r\nicationEvent event) {\n&gt; &gt; if(event instanceof CrawlURIDispositionEvent) {\n&gt;=\r\n &gt; CrawlURIDispositionEvent dvent =3D (CrawlURIDispositionEvent)event;\n&gt; &gt; =\r\nDisposition state =3D dvent.getDisposition();\n&gt; &gt; if (state =3D=3DDispositi=\r\non.SUCCEEDED && dvent.getCrawlURI().isSeed()){\n&gt; &gt; // notify sub system(s) =\r\nof completed seed\n&gt; &gt; }\n&gt; &gt; }\n&gt; &gt; }\n&gt; &gt;\n&gt; &gt; But this will only notify when =\r\nthe original seed url itself is\ncrawled. But this is too early. I need a wa=\r\ny to detect when the seed\nincluding discovered sub-pages are fully crawled.=\r\n\n&gt; &gt;\n&gt; &gt; Any suggestions? Is it even possible?\n&gt; &gt;\n&gt; &gt; Many thanks! Mark.\n&gt;=\r\n &gt;\n&gt; &gt;\n&gt; &gt;\n&gt;\n\n\r\n--4-1092536063-0806193128=:3\r\nContent-Type: text/html; charset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n\n\n\n&lt;div&gt;Hi Noah,&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks for your reply! I experime=\r\nnted (before reading your reply) with a similar approach. What I did was su=\r\nbclassing a QueueAssignmentPolicy to assign all urls belonging to a seed (u=\r\nsing the sourceTag) to a single queue. This way all the urls will be proces=\r\nsed in that queue. Then I created a &#39;Monitor&#39; by implementing ApplicationLi=\r\nstener.onApplicationEvent. Here I monitor the WorkQueues and once the queue=\r\n is empty I mark the seed as completed. For this last check I used the foll=\r\nowing code:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;font class=3D&quot;Apple-style-s=\r\npan&quot; face=3D&quot;&#39;courier new&#39;&quot;&gt;&lt;div&gt;if(event instanceof CrawlURIDispositionEve=\r\nnt) {&lt;/div&gt;&lt;div&gt;&lt;span class=3D&quot;Apple-tab-span&quot; style=3D&quot;white-space:pre;&quot;&gt;\t=\r\n&lt;/span&gt;CrawlURIDispositionEvent dvent =3D (CrawlURIDispositionEvent)event;&lt;=\r\n/div&gt;&lt;div&gt;&lt;span class=3D&quot;Apple-tab-span&quot; style=3D&quot;white-space:pre;&quot;&gt;\t&lt;/span=\r\n&gt;CrawlURI crawlURI =3D dvent.getCrawlURI();&lt;/div&gt;&lt;div&gt;&lt;span class=3D&quot;Apple-=\r\ntab-span&quot; style=3D&quot;white-space:pre;&quot;&gt;\t&lt;/span&gt;Disposition state =3D dvent.ge=\r\ntDisposition();&lt;/div&gt;&lt;div&gt;&lt;span class=3D&quot;Apple-tab-span&quot; style=3D&quot;white-spa=\r\nce:pre;&quot;&gt;\t&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span class=3D&quot;Apple-tab-span&quot; style=3D&quot;white-s=\r\npace:pre;&quot;&gt;\t&lt;/span&gt;//current crawl url successfully crawled&lt;/div&gt;&lt;div&gt;&lt;span=\r\n class=3D&quot;Apple-tab-span&quot; style=3D&quot;white-space:pre;&quot;&gt;\t&lt;/span&gt;if (state =3D=\r\n=3D Disposition.SUCCEEDED){&lt;/div&gt;&lt;div&gt;&lt;span class=3D&quot;Apple-tab-span&quot; style=\r\n=3D&quot;white-space:pre;&quot;&gt;\t\t&lt;/span&gt;// get work queue of current url&lt;/div&gt;&lt;div&gt;&lt;=\r\nspan class=3D&quot;Apple-tab-span&quot; style=3D&quot;white-space:pre;&quot;&gt;\t\t&lt;/span&gt;WorkQueue=\r\n wq =3D (WorkQueue) dvent.getCrawlURI().getHolder();&lt;/div&gt;&lt;div&gt;&lt;span class=\r\n=3D&quot;Apple-tab-span&quot; style=3D&quot;white-space:pre;&quot;&gt;\t\t&lt;/span&gt;Map&lt;String, Obje=\r\nct&gt; report =3D wq.singleLineReportData();&lt;/div&gt;&lt;div&gt;&lt;span class=3D&quot;Apple=\r\n-tab-span&quot; style=3D&quot;white-space:pre;&quot;&gt;\t\t&lt;/span&gt;long queueItems =3D Long.par=\r\nseLong(report.get(&quot;itemCount&quot;).toString());&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;span =\r\nclass=3D&quot;Apple-tab-span&quot; style=3D&quot;white-space:pre;&quot;&gt;\t\t&lt;/span&gt;// check if qu=\r\neue is empty, if so crawling the seed&nbsp;&lt;/div&gt;&lt;div&gt;&lt;span class=3D&quot;Apple-=\r\ntab-span&quot; style=3D&quot;white-space:pre;&quot;&gt;\t\t&lt;/span&gt;// is completed (since one qu=\r\neue is created per seed... theoretically)&lt;/div&gt;&lt;div&gt;&lt;span class=3D&quot;Apple-ta=\r\nb-span&quot; style=3D&quot;white-space:pre;&quot;&gt;\t\t&lt;/span&gt;if (queueItems &lt;=3D 0){&lt;/div=\r\n&gt;&lt;div&gt;&lt;span class=3D&quot;Apple-tab-span&quot; style=3D&quot;white-space:pre;&quot;&gt;\t\t\t&lt;/span&gt;l=\r\nogger.info(crawlURI.getSourceTag() + &quot;COMPLETED!.&quot;);&lt;/div&gt;&lt;div&gt;&lt;span class=\r\n=3D&quot;Apple-tab-span&quot; style=3D&quot;white-space:pre;&quot;&gt;\t\t&lt;/span&gt;}&lt;/div&gt;&lt;div&gt;&lt;span c=\r\nlass=3D&quot;Apple-tab-span&quot; style=3D&quot;white-space:pre;&quot;&gt;\t&lt;/span&gt;}&lt;/div&gt;&lt;div&gt;}&lt;/d=\r\niv&gt;&lt;/font&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;This seems to work partiall=\r\ny. It fails when a seed is added twice. Heritrix will skip that seed becaus=\r\ne it remembers which urls are already crawled (which is OK). Except... I st=\r\nill require some sort of notification that Heritrix skipped that seed so th=\r\nat I can notifiy sub-systems. But maybe your suggestion of subclassing&nbsp=\r\n;BdbFrontier can fix that.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I will look into your o=\r\nther suggestions (using StatisticsTracker and&nbsp;BdbFrontier). I&#39;ll let y=\r\nou know my progress on this... I also feel that the&nbsp;functionality&nbsp=\r\n;that I require should be possible but I do get a feeling of &quot;hacking&quot; heri=\r\ntrix functionallity allot to achieve this. The suggestion of using a single=\r\n job for one seed might be a simpler approach although this will introduce =\r\ndifferent problems... e.g. crawling urls multiple times&nbsp;unnecessarily,=\r\n slower crawling etc.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Anyways I&#39;ll keep you posted=\r\n.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Mark&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;--- In a=\r\nrchive-crawler@yahoogroups.com, Noah Levitt &lt;nlevitt@...&gt; wrote:&lt;br&gt;&=\r\ngt;&lt;br&gt;&gt; Hello Mark,&lt;br&gt;&gt; &lt;br&gt;&gt; It&#39;s possible I&#39;m overlooking some=\r\nthing, but I don&#39;t know of an easy way to achieve this. Like anything, it&#39;s=\r\n possible with some coding though.&lt;br&gt;&gt; &lt;br&gt;&gt; First off you need to m=\r\nake sure sourceTagSeeds is enabled on your SeedModule. When that&#39;s enabled,=\r\n StatisticsTracker keeps some stats on seed sources, so you can start with =\r\nthat. You&#39;ll have to subclass StatisticsTracker to keep track of queued url=\r\ns because right now it only takes note of crawled urls. That&#39;s not trivial =\r\neither because currently there doesn&#39;t appear to be any notification when a=\r\n url is enqueued. To make that happen you could subclass BdbFrontier and ov=\r\nerride receive() to do something like { super.receive(); appCtx.publishEven=\r\nt(new MyCrawlURIEnqueuedEvent(curi)); }. Then catch that event in your Stat=\r\nisticsTracker subclass and update your stats. When the crawled count catche=\r\ns up to the queued count for a given source tag, that should indicate the s=\r\need is complete.&lt;br&gt;&gt; &lt;br&gt;&gt; Perhaps an easier way to go would be to h=\r\nave a separate crawl job for each seed, so you know the seed is done when t=\r\nhe crawl is done.&lt;br&gt;&gt; &lt;br&gt;&gt; There are other approaches that could wo=\r\nrk too, inside and outside of heritrix. I&#39;d be curious to know what you end=\r\n up doing.&lt;br&gt;&gt; &lt;br&gt;&gt; Noah&lt;br&gt;&gt; &lt;br&gt;&gt; On 2011-09-13 12:49 , mar=\r\nkkramer_nl wrote:&lt;br&gt;&gt; &gt;&lt;br&gt;&gt; &gt;&lt;br&gt;&gt; &gt; Hi&lt;br&gt;&gt; &gt;&lt;br=\r\n&gt;&gt; &gt; In my current project I use my own SeedModule implementation to =\r\npopulate/announce new seeds based on external input (ActiveMQ / DB etc). Wh=\r\nat I still cannot figure out is how I can detect when a crawl is completed =\r\nfor a single seed. I need this because I want to notify a subsystem that th=\r\ne requested seed is done so that the subsystem can acquire all the fetched =\r\n(sub)pages from the storage.&lt;br&gt;&gt; &gt;&lt;br&gt;&gt; &gt; I tried defining a &quot;=\r\nmonitor&quot; using the ApplicationListener:&lt;br&gt;&gt; &gt;&lt;br&gt;&gt; &gt; public vo=\r\nid onApplicationEvent(ApplicationEvent event) {&lt;br&gt;&gt; &gt; if(event insta=\r\nnceof CrawlURIDispositionEvent) {&lt;br&gt;&gt; &gt; CrawlURIDispositionEvent dve=\r\nnt =3D (CrawlURIDispositionEvent)event;&lt;br&gt;&gt; &gt; Disposition state =3D =\r\ndvent.getDisposition();&lt;br&gt;&gt; &gt; if (state =3D=3DDisposition.SUCCEEDED =\r\n&amp;&amp; dvent.getCrawlURI().isSeed()){&lt;br&gt;&gt; &gt; // notify sub system=\r\n(s) of completed seed&lt;br&gt;&gt; &gt; }&lt;br&gt;&gt; &gt; }&lt;br&gt;&gt; &gt; }&lt;br&gt;&gt; =\r\n&gt;&lt;br&gt;&gt; &gt; But this will only notify when the original seed url itse=\r\nlf is crawled. But this is too early. I need a way to detect when the seed =\r\nincluding discovered sub-pages are fully crawled.&lt;br&gt;&gt; &gt;&lt;br&gt;&gt; &gt;=\r\n Any suggestions? Is it even possible?&lt;br&gt;&gt; &gt;&lt;br&gt;&gt; &gt; Many thank=\r\ns! Mark.&lt;br&gt;&gt; &gt;&lt;br&gt;&gt; &gt;&lt;br&gt;&gt; &gt;&lt;br&gt;&gt;&lt;br&gt;\n\n\r\n--4-1092536063-0806193128=:3--\r\n\n"}}