{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":360569707,"authorName":"happyxinglele","from":"&quot;happyxinglele&quot; &lt;happyxinglele@...&gt;","profile":"happyxinglele","replyTo":"LIST","senderId":"GIrxZ2fIABbcr8ICOsnm1X2u4IIzIJy7goh-ieWu2o5qfRlniUitXB2GiOnjXbJNcaMGvVI0DHo1C4zQRIk5NJoy9tDxSJSTzzP7KwNawqOiik8","spamInfo":{"isSpam":false,"reason":"6"},"subject":"How to let Heritrix do not crawl robots.txt and DNS","postDate":"1223454589","msgId":5501,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGdjaHIxdCszdGdxQGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":5502,"prevInTime":5500,"nextInTime":5502,"topicId":5501,"numMessagesInTopic":7,"msgSnippet":"I only crawl test URLs of myself. And Heritrix need to crawl robots and DNS firstly, which is cost lots of time. I donot need the Heritrix to crawl the robots","rawEmail":"Return-Path: &lt;happyxinglele@...&gt;\r\nX-Sender: happyxinglele@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 63159 invoked from network); 8 Oct 2008 08:29:49 -0000\r\nX-Received: from unknown (66.218.67.94)\n  by m46.grp.scd.yahoo.com with QMQP; 8 Oct 2008 08:29:49 -0000\r\nX-Received: from unknown (HELO n39d.bullet.mail.sp1.yahoo.com) (66.163.169.145)\n  by mta15.grp.scd.yahoo.com with SMTP; 8 Oct 2008 08:29:49 -0000\r\nX-Received: from [69.147.65.173] by n39.bullet.mail.sp1.yahoo.com with NNFMP; 08 Oct 2008 08:29:49 -0000\r\nX-Received: from [66.218.69.3] by t15.bullet.mail.sp1.yahoo.com with NNFMP; 08 Oct 2008 08:29:49 -0000\r\nX-Received: from [69.147.65.150] by t3.bullet.scd.yahoo.com with NNFMP; 08 Oct 2008 08:29:49 -0000\r\nX-Received: from [66.218.66.78] by t7.bullet.mail.sp1.yahoo.com with NNFMP; 08 Oct 2008 08:29:49 -0000\r\nDate: Wed, 08 Oct 2008 08:29:49 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;gchr1t+3tgq@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;happyxinglele&quot; &lt;happyxinglele@...&gt;\r\nSubject: How to let Heritrix do not crawl robots.txt and DNS\r\nX-Yahoo-Group-Post: member; u=360569707; y=M1vvPgvp66z7ZJDSM1wtwr4wSxCE04t1WBROIUAbjXekF_vRyp-0cw\r\nX-Yahoo-Profile: happyxinglele\r\n\r\nI only crawl test URLs of myself. And Heritrix need to crawl robots and \nDN=\r\nS firstly, which is cost lots of time. I donot need the Heritrix to \ncrawl =\r\nthe robots file and the DNS. \n\nCould you tell me how can I let it work?\np.s=\r\n. I use Heritrix-2.0.0\n\nThanks a lot!\n\n\n"}}