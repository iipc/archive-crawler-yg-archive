{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"U2i1_HlAM2P-GO5fvAB3JhHKGqaiWRYjkv5w3P0cExbFyzk64bWE132mswJAHw1rZj-ALckqdcAMKJ_ASwKcqwjBljEko9s","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] Storing Crawl Results in Alternate (non-FS) Store","postDate":"1284523780","msgId":6727,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRDOTA0NzA0LjkwNzAyMDJAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PEFBTkxrVGk9aGt2SjlRVlM5Y1FHWEV6ejZCRllRMFdQNmV2PXhfNkhKelc3TEBtYWlsLmdtYWlsLmNvbT4=","referencesHeader":"PEFBTkxrVGk9YWJnRktrTE1FLXlPZWpYYzFFT2hWWmlKQUw5bzExb01IVzZWNEBtYWlsLmdtYWlsLmNvbT4JPDRDOEZEQUEyLjEwNDA0MDdAYXJjaGl2ZS5vcmc+IDxBQU5Ma1RpPWhrdko5UVZTOWNRR1hFeno2QkZZUTBXUDZldj14XzZISnpXN0xAbWFpbC5nbWFpbC5jb20+"},"prevInTopic":6726,"nextInTopic":6735,"prevInTime":6726,"nextInTime":6728,"topicId":6723,"numMessagesInTopic":6,"msgSnippet":"... Sure. In fact I just committed a shorter version getting rid of the nonsensical type check (cruft left over from a previous refactoring). Of course, if you","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 83266 invoked from network); 15 Sep 2010 04:09:44 -0000\r\nX-Received: from unknown (98.137.34.44)\n  by m6.grp.sp2.yahoo.com with QMQP; 15 Sep 2010 04:09:44 -0000\r\nX-Received: from unknown (HELO relay01.pair.com) (209.68.5.15)\n  by mta1.grp.sp2.yahoo.com with SMTP; 15 Sep 2010 04:09:43 -0000\r\nX-Received: (qmail 73752 invoked from network); 15 Sep 2010 04:09:42 -0000\r\nX-Received: from 67.188.34.83 (HELO silverbook.local) (67.188.34.83)\n  by relay01.pair.com with SMTP; 15 Sep 2010 04:09:42 -0000\r\nX-pair-Authenticated: 67.188.34.83\r\nMessage-ID: &lt;4C904704.9070202@...&gt;\r\nDate: Tue, 14 Sep 2010 21:09:40 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.6; en-US; rv:1.9.2.9) Gecko/20100825 Thunderbird/3.1.3\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: Zach Bailey &lt;zach.bailey@...&gt;\r\nReferences: &lt;AANLkTi=abgFKkLME-yOejXc1EOhVZiJAL9o11oMHW6V4@...&gt;\t&lt;4C8FDAA2.1040407@...&gt; &lt;AANLkTi=hkvJ9QVS9cQGXEzz6BFYQ0WP6ev=x_6HJzW7L@...&gt;\r\nIn-Reply-To: &lt;AANLkTi=hkvJ9QVS9cQGXEzz6BFYQ0WP6ev=x_6HJzW7L@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Storing Crawl Results in Alternate (non-FS)\n Store\r\nX-Yahoo-Group-Post: member; u=137285340; y=YgN9PRTMvEQ7OuW9vHpR0bHrqinlpFN19tih8hmLbjIb\r\nX-Yahoo-Profile: gojomo\r\n\r\nOn 9/14/10 3:08 PM, Zach Bailey wrote:\n&gt; Thanks a lot for your answers, Gordon.\n&gt;\n&gt; I am absolutely planning on contributing this back for others to build\n&gt; on and use, once I figure out how to make it generic enough to be useful\n&gt; to others. More than likely I will put it up on my public github account.\n&gt;\n&gt; A follow-up question - am I correct in assuming my implementation of\n&gt; Processor#shouldProcess should be pretty much identical to the one in\n&gt; WriterPoolProcessor?\n\nSure. In fact I just committed a shorter version getting rid of the\nnonsensical type check (cruft left over from a previous refactoring).\n\nOf course, if you were interested in writing something in your store \neven for nonpositive fetch codes (such as connection-failed errors), \nyou&#39;d have to loosen the first test. And if there were some theoretical \nURI type used in your crawls whose successful &#39;fetch&#39; left a zero \nrecorded-content length (perhaps an inline &#39;data:&#39; URI?) but still \nneeded to be written to your store, the second test would need to \nloosen. But the tests are reasonable for usual needs analogous to WARC \nwriting.\n\n&gt; Also, what is the best way to get at the raw page content separate from\n&gt; the headers (just the content, not the entire response)? Am I correct in\n&gt; thinking that this is what I would be provided when calling\n&gt; crawlURI.getRecorder().getRecordedInput().getContentReplayInputStream() ?\n\nFor usual HTTP response content, yes -- that will give an InputStream \ncued up to just past the protocol headers. It does *not* handle \n&#39;chunked&#39; encodings, which may be a concern. If your later analysis \nmight want the headers, you will want to write them somewhere too. Our \ngoal in the WARC (and earlier ARC) writers was to record verbatim what \ncame over the wire, to support the greatest range of possible future \nanalysis applications. (We do no decoding; no dechunking; no \ncanonicalizing; no header corrections or other alterations; etc.)\n\nYou can also use getReplayCharSequence(), with an optional specified \nencoding, to get a charset-decoded CharSequence of the content-body \n(which uses temp files and a sliding buffer to avoid decoding giant \ncontent into memory). It also does not handled dechunking properly.\n\n- Gordon @ IA\n\n\n&gt; Thanks,\n&gt; -Zach\n&gt;\n&gt; On Tue, Sep 14, 2010 at 4:27 PM, Gordon Mohr &lt;gojomo@...\n&gt; &lt;mailto:gojomo@...&gt;&gt; wrote:\n&gt;\n&gt;     Great questions! I know there&#39;s other interest in such writer\n&gt;     alternatives, so I hope you can make whatever you come up with\n&gt;     available to other users, or donate it for possible inclusion in the\n&gt;     official H3 distribution!\n&gt;\n&gt;     There also has been previous work to create an HBaseWriter for\n&gt;     Heritrix; it might already work in H3, or require only a little\n&gt;     updating. I haven&#39;t yet tried it myself. See:\n&gt;\n&gt;     http://code.google.com/p/hbase-writer/\n&gt;\n&gt;     On to your questions, interspersed below:\n&gt;\n&gt;\n&gt;     On 9/14/10 12:39 PM, Zach Bailey wrote:\n&gt;\n&gt;\n&gt;\n&gt;         Hi all,\n&gt;\n&gt;         I wanted to run some questions by you and maybe get some\n&gt;         pointers from\n&gt;         the architects of heritrix hoping I could save a little time before\n&gt;         attempting this.\n&gt;\n&gt;         What I am hoping to do is develop a custom writer to store the\n&gt;         results\n&gt;         of my crawls in a distributed database, something like Riak,\n&gt;         Cassandra,\n&gt;         or HBase for the Heritrix 3.0 code base.\n&gt;\n&gt;         I am very comfortable writing Java code and am very familiar with\n&gt;         building applications using the Spring Framework so I&#39;m thinking\n&gt;         this\n&gt;         should be a relatively easy task to get a proof of concept/prototype\n&gt;         working.\n&gt;\n&gt;         Looking through the code I had some questions:\n&gt;\n&gt;         1.) It looks like I will wire in my custom code inside the\n&gt;         DispositionChain, essentially replacing where the warcWriter bean is\n&gt;         referenced.\n&gt;\n&gt;\n&gt;     Yes; you could also have both in place for testing. (I&#39;ve often run\n&gt;     with both our ARCWriterProcessor and WARCWriterProcessor while\n&gt;     debugging things.) One common gotcha when installing your own\n&gt;     Processors, as edits to our model CXML, is that if you follow the\n&gt;     pattern there you need to both declare the bean with a name, then\n&gt;     add the bean by name to the chain&#39;s ordered list. So: two edits, a\n&gt;     short distance from each other, to have the intended effect.\n&gt;\n&gt;\n&gt;         2.) Looking at the WARCWriterProcessor it appears it uses a pooled\n&gt;         approach. I&#39;m guessing this is for performance reasons. Assuming I&#39;m\n&gt;         using a driver which already implements connection pooling, are\n&gt;         there\n&gt;         any other considerations I should think about while implementing\n&gt;         my own\n&gt;         Writer?\n&gt;\n&gt;\n&gt;     The existing pooling was motivated by the belief that having more\n&gt;     than one active open file at a time could increase throughput.\n&gt;     That&#39;s definitely the case if the files are on independent disks;\n&gt;     I&#39;m not as sure it helps to have more than one file open on the same\n&gt;     disk. This has undergone some recent simplification (eliminating the\n&gt;     dependency on Apache commons-pool) in TRUNK that will appear in\n&gt;     3.0.1, and is likely to change more in the next month as some other\n&gt;     novel policies for grouping related site captures to different WARCs\n&gt;     are added.\n&gt;\n&gt;     So I&#39;d say: keep an eye on TRUNK for ideas but don&#39;t assume anything\n&gt;     in the existing WARCWriterProcessor approach is optimal or\n&gt;     locked-in-place.\n&gt;\n&gt;     I would think writing to a remote distributed store might offer nice\n&gt;     throughput benefits by essentially fanning the IO out over many more\n&gt;     disks, whether you were writing WARCs into (eg) HDFS or individual\n&gt;     records/content-bodies into (eg) HBase.\n&gt;\n&gt;     The least-straightforward part of the current Writer is the\n&gt;     special-case handling of deduced duplicates, from headers or\n&gt;     content-hashes, to change how (or whether) individual records are\n&gt;     written. There might be an opportunity to factor that decisionmaking\n&gt;     out of WARCWriterProcessor to be shared with other non-file or even\n&gt;     non-WARC writers.\n&gt;\n&gt;\n&gt;         3.) Once I get my custom code developed, I assume all I need to\n&gt;         do to\n&gt;         make it available to heritrix is to jar it up and just drop it in\n&gt;         $HERITRIX_HOME/lib - anything else I need to be aware of there?\n&gt;\n&gt;\n&gt;     That should be all. Then, as I&#39;m sure you know, you just name the\n&gt;     classes in your crawl-configuration CXML (Spring XML) bean-declarations.\n&gt;\n&gt;     Hope this helps and let me know any other questions!\n&gt;\n&gt;     - Gordon @ IA\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; \n\n"}}