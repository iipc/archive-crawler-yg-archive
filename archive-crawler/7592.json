{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":500983475,"authorName":"David Pane","from":"David Pane &lt;dpane@...&gt;","profile":"david_pane1","replyTo":"LIST","senderId":"ioOrTZMSLiBcYg4dDWpWKR2r4_cb7bsG68bPJ14BMOOxiQ0zyjms1mcHHcquaa_5TO6zmP2tkikadD8OXgixtaTNddI","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] H3 - distributed crawling and memory/cpu utilization","postDate":"1328046834","msgId":7592,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRGMjg2MkYyLjcwNjA4MDlAY3MuY211LmVkdT4=","inReplyToHeader":"PDRFOThFQTdELjEwODA4MDZAYXJjaGl2ZS5vcmc+","referencesHeader":"PGo3NHMzNCtldWVnQGVHcm91cHMuY29tPiA8NEU5OEVBN0QuMTA4MDgwNkBhcmNoaXZlLm9yZz4="},"prevInTopic":7372,"nextInTopic":7593,"prevInTime":7591,"nextInTime":7593,"topicId":7351,"numMessagesInTopic":7,"msgSnippet":"Noah, I noticed a warning message on a recent rebuild fromt the frontier recovery logs. WARNING Bloom has reached expected limit 400,000,000; false-positive ","rawEmail":"Return-Path: &lt;dpane@...&gt;\r\nX-Sender: dpane@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 2724 invoked from network); 31 Jan 2012 21:54:01 -0000\r\nX-Received: from unknown (98.137.34.45)\n  by m14.grp.sp2.yahoo.com with QMQP; 31 Jan 2012 21:54:01 -0000\r\nX-Received: from unknown (HELO smtp.andrew.cmu.edu) (128.2.11.96)\n  by mta2.grp.sp2.yahoo.com with SMTP; 31 Jan 2012 21:54:01 -0000\r\nX-Received: from [128.2.209.200] (SAVOY.LTI.CS.CMU.EDU [128.2.209.200])\n\t(user=dpane mech=PLAIN (0 bits))\n\tby smtp.andrew.cmu.edu (8.14.4/8.14.4) with ESMTP id q0VLrsNZ009036\n\t(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NOT);\n\tTue, 31 Jan 2012 16:53:54 -0500\r\nMessage-ID: &lt;4F2862F2.7060809@...&gt;\r\nDate: Tue, 31 Jan 2012 16:53:54 -0500\r\nUser-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:9.0) Gecko/20111222 Thunderbird/9.0.1\r\nMIME-Version: 1.0\r\nTo: Noah Levitt &lt;nlevitt@...&gt;\r\nCc: archive-crawler@yahoogroups.com\r\nReferences: &lt;j74s34+eueg@...&gt; &lt;4E98EA7D.1080806@...&gt;\r\nIn-Reply-To: &lt;4E98EA7D.1080806@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-PMX-Version: 5.5.9.388399, Antispam-Engine: 2.7.2.376379, Antispam-Data: 2010.4.9.4220\r\nX-SMTP-Spam-Clean: 8% (\n KNOWN_FREEWEB_URI 0.05, ECARD_KNOWN_DOMAINS 0, __BOUNCE_CHALLENGE_SUBJ 0, __BOUNCE_NDR_SUBJ_EXEMPT 0, __CANPHARM_UNSUB_LINK 0, __CP_URI_IN_BODY 0, __CT 0, __CTE 0, __CT_TEXT_PLAIN 0, __FRAUD_MONEY 0, __FRAUD_MONEY_VALUE 0, __HAS_MSGID 0, __KNOWN_FREEWEB_URI3 0, __KNOWN_FREEWEB_URI4 0, __KNOWN_FREEWEB_URI5 0, __KNOWN_FREEWEB_URI7 0, __MIME_TEXT_ONLY 0, __MIME_VERSION 0, __MOZILLA_MSGID 0, __SANE_MSGID 0, __STOCK_PHRASE_7 0, __TO_MALFORMED_2 0, __URI_NO_WWW 0, __USER_AGENT 0)\r\nX-SMTP-Spam-Score: 8%\r\nX-Scanned-By: MIMEDefang 2.60 on 128.2.11.96\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: David Pane &lt;dpane@...&gt;\r\nSubject: Re: [archive-crawler] H3 - distributed crawling and memory/cpu utilization\r\nX-Yahoo-Group-Post: member; u=500983475; y=_m6HwZBYzc63nQoHVRAeIDOpidqaumidB8_LCTI6QmcuCKDt0wieBQ\r\nX-Yahoo-Profile: david_pane1\r\n\r\nNoah,\n\nI noticed a warning message on a recent rebuild fromt the frontier \nrecovery logs.\n\nWARNING Bloom has reached expected limit 400,000,000; false-positive \nrate will now rise above goal of 1-in-(2^30 (in thread &#39;pool-3-thread-1&#39;)\n\nThe current totals (with 164,285,847 pages crawled per instance) for \neach of our 5 instances we are seeing statistics similar to this:\n\n297,472,096 downloaded + 854,566,462 queued = 1,152,039,733 total\n\nBy the time we reach 200 million pages, we will be seeing over 1.7 \nbillion URIs (downloaded + queued) per instance.  This would mean that \nwe would need a 10GB or 11GB bloom filter.  In doing these calculations, \nI had a couple questions:\n\n1) Does each of the instances bloom filter contain only the URIs that it \nhad crawled and what is queued  or does it contain discovered URIs that \nare sent to other instances?\n\n2) When the bloom filter reaches the expected limit, what does the rate \nof false-positive increase to?\n\n--David\n\n\nOn 10/14/2011 10:05 PM, Noah Levitt wrote:\n&gt; Hello David,\n&gt;\n&gt; On 10/12/2011 01:08 PM, david_pane1 wrote:\n&gt;&gt; 1) I am using two 8 core 32GB machines for some test crawls. The\n&gt;&gt; machines are connected to the internet on a gigabit connection. The\n&gt;&gt; internal network is also a gigabit. I am writing the data from the\n&gt;&gt; crawler to a NAS which I can copy data to at an average of 70MB/sec\n&gt;&gt; transfer rate. I am trying to adjust the memory and maxToeThread\n&gt;&gt; settings to get the maximum throughput. Currently my settings are:\n&gt;&gt;\n&gt;&gt; JAVA_OPTS=&quot;-Xmx11000M\n&gt;&gt; &lt;property name=&quot;maxToeThreads&quot; value=&quot;1200&quot; /&gt;\n&gt;&gt;\n&gt;&gt; With these values, I am seeing about 50% cpu utilization (about half\n&gt;&gt; of the 8 cores) and an average of around 750MB/min or (96Mbps) network\n&gt;&gt; activity. I would like to utilize more of the cpu. Is this reasonable?\n&gt;\n&gt; If the crawl has plenty of urls to keep it busy, the limiting factor is\n&gt; typically disk, not cpu.\n&gt;\n&gt;&gt; Increasing the maxToeThreads to a higher value than 1200 causes the\n&gt;&gt; java application to fall to minimal to no cpu usage and the web\n&gt;&gt; interface to be unresponsive. Does anyone know why this is happening?\n&gt;\n&gt; Don&#39;t know without looking more closely at the logs and state of the\n&gt; java process when that happens. But 1200 threads for an 11000M heap\n&gt; seems like a lot, maybe too many depending on the rest of your config.\n&gt; The other big consumers of memory are the bdb cache and the bloom filter\n&gt; if you&#39;re using that. By default the bdb cache occupies 60% of available\n&gt; heap, so 6600M in your case.\n&gt;\n&gt; It sounds like you&#39;re doing a broad crawl, so the bloom filter is\n&gt; probably appropriate for your already-seen check. The default\n&gt; BdbUriUniqFilter can be a bottleneck in a large crawl. The bloom filter\n&gt; occupies a fixed amount of memory and does not use disk, but is\n&gt; probabilistic, and accepts a small rate of false positives. With default\n&gt; settings, it uses 495M of heap, and has an expected false-positive rate\n&gt; of 1-in-4million through the first 125 million urls it sees.\n&gt;\n&gt; There&#39;s some old but generally relevant discussion of the bloom filter\n&gt; here: http://tech.groups.yahoo.com/group/archive-crawler/message/3142\n&gt;\n&gt; I&#39;m not finding existing docs on this so just for the record, this is\n&gt; how you can configure a different sized bloom filter in h3. This example\n&gt; would use\n&gt; 1.44 * 400,000,000 * 30 / 8 = 2,160,000,000 bytes of heap with an\n&gt; expected false-postive rate of 2^-30 or about 1-in-a-billion through the\n&gt; first 400 million urls seen. Hopefully I&#39;m getting this math right. :)\n&gt;\n&gt; &lt;bean id=&quot;uriUniqFilter&quot;\n&gt; class=&quot;org.archive.crawler.util.BloomUriUniqFilter&quot;&gt;\n&gt; &lt;property name=&quot;bloomFilter&quot;&gt;\n&gt; &lt;bean class=&quot;org.archive.util.BloomFilter64bit&quot;&gt;\n&gt; &lt;constructor-arg value=&quot;400000000&quot;/&gt;\n&gt; &lt;constructor-arg value=&quot;30&quot;/&gt;\n&gt; &lt;/bean&gt;\n&gt; &lt;/property&gt;\n&gt; &lt;/bean&gt;\n&gt;\n&gt;&gt; How much of the 32GB of memory should I allocate to JAVA_OPTS?\n&gt;\n&gt; The more the merrier, as long as other processes have enough room and\n&gt; the system doesn&#39;t start swapping.\n&gt;\n&gt; There&#39;s no hard limit on the amount of heap each toe thread can use, and\n&gt; heritrix can be vulnerable to websites that do weird stuff. With default\n&gt; settings though, 5-10M per toe thread is a reasonable rule of thumb.\n&gt; Most of the time each thread will use much less than that, but sometimes\n&gt; they&#39;ll use more. If you get an OutOfMemoryError then you should reduce\n&gt; the number of toe threads.\n&gt;\n&gt; So let&#39;s say you give heritrix a 25G heap, leave the bdb cache at the\n&gt; default of 60%, and use the default .5G bloom filter. That leaves you\n&gt; with 25GB * (100% - 60%) - .5G = 9.5G for toe threads. At 7.5M per toe\n&gt; thread that comes to 1266 of them.\n&gt;\n&gt; With this config and hardware I would expect your crawl rate to be\n&gt; limited elsewhere, likely in warc writing, assuming you have that\n&gt; enabled. Presumably all these threads will be competing to write to a\n&gt; small number of disks.\n&gt;\n&gt;&gt; 2) One of the 2 crawlers stopped crawling due to a congestion ratio of\n&gt;&gt; infinity. What are some ways to overcome this? What can I do to avoid\n&gt;&gt; it happening in the future?\n&gt;\n&gt; I don&#39;t know. Not clear what you mean by &quot;stopped&quot; exactly for one\n&gt; thing. If it happens again, maybe gather more information from\n&gt; heritrix_out.log, toe thread report, frontier report, top, iostat,\n&gt; jstack, etc.\n&gt;\n&gt;&gt; 3) In http://tech.groups.yahoo.com/group/archive-crawler/message/3846\n&gt;&gt; Gordon stated:\n&gt;&gt;\n&gt;&gt; &quot;...\n&gt;&gt; HashCrawlMapper looks at the queue key of a URI -- here, the SURT\n&gt;&gt; authority part, because of the above choice -- and decides if a URI is\n&gt;&gt; handled by the current crawler or one of its siblings. If mapped to a\n&gt;&gt; sibling, the URI is dumped to a log rather than crawled locally.\n&gt;&gt; Depending on the character of your crawl, you may want to feed these\n&gt;&gt; logs to the other crawlers occasionally or it may be OK to ignore them.\n&gt;&gt; ...\n&gt;&gt; &quot;\n&gt;&gt;\n&gt;&gt; How does one feed the diverted URIs/logs to a sibling crawler?\n&gt;\n&gt; A coworker kindly put up this page yesterday:\n&gt; https://webarchive.jira.com/wiki/display/Heritrix/Multiple+Machine+Crawling\n&gt; which says, &quot;Crawl operators must set up a process where the the URIs\n&gt; contained in .divert files are copied from each crawler to their\n&gt; assigned crawlers and queued into the active crawl (putting the .divert\n&gt; file in the actions directory as a .include should be sufficient).&quot;\n&gt;\n&gt; Noah\n&gt;\n&gt;\n&gt;&gt; Any help is greatly appreciated.\n&gt;&gt;\n&gt;&gt; --David\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; ------------------------------------\n&gt;&gt;\n&gt;&gt; Yahoo! Groups Links\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;\n&gt;\n\n"}}