{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"aYUk7nxP4TJPelbMycR_beV29kg5WOA5zTwJzaaBl6byj_MiFayYIdjTPLgEBLyk7PXflp_aXoupbTMbBhDJA9DFMeFMdmw","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Question concerning ReplayInputStream.getContentSize()","postDate":"1218215143","msgId":5398,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ4OUM3Q0U3LjcwMjAzMDVAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDQ4OUMyNjUxLjIwOTA3QGdvb2dsZW1haWwuY29tPg==","referencesHeader":"PDQ4OUMyNjUxLjIwOTA3QGdvb2dsZW1haWwuY29tPg=="},"prevInTopic":5397,"nextInTopic":5400,"prevInTime":5397,"nextInTime":5399,"topicId":5397,"numMessagesInTopic":5,"msgSnippet":"... Yes, it should... and getSize() will get the full recorded data size, including headers. ... You re getting these using the JerichoExtractorHTML, right? ","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 57462 invoked from network); 8 Aug 2008 17:05:38 -0000\r\nX-Received: from unknown (66.218.67.95)\n  by m55.grp.scd.yahoo.com with QMQP; 8 Aug 2008 17:05:38 -0000\r\nX-Received: from unknown (HELO relay00.pair.com) (209.68.5.9)\n  by mta16.grp.scd.yahoo.com with SMTP; 8 Aug 2008 17:05:38 -0000\r\nX-Received: (qmail 71475 invoked from network); 8 Aug 2008 17:05:37 -0000\r\nX-Received: from unknown (HELO ?192.168.1.112?) (unknown)\n  by unknown with SMTP; 8 Aug 2008 17:05:37 -0000\r\nX-pair-Authenticated: 71.202.120.131\r\nMessage-ID: &lt;489C7CE7.7020305@...&gt;\r\nDate: Fri, 08 Aug 2008 10:05:43 -0700\r\nUser-Agent: Thunderbird 2.0.0.16 (Windows/20080708)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;489C2651.20907@...&gt;\r\nIn-Reply-To: &lt;489C2651.20907@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-15; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Question concerning ReplayInputStream.getContentSize()\r\nX-Yahoo-Group-Post: member; u=137285340; y=NM0JOJ6_QOMXYMSfoDCk4cXpW6oNbsGZOs2kyFuUYaP9\r\nX-Yahoo-Profile: gojomo\r\n\r\nChristian Krumm wrote:\n&gt; Hi,\n&gt; \n&gt; I have a question concerning the function getContentSize() in the class\n&gt; ReplayInputStream. The Java Doc indicates that the function will return\n&gt; the total number of content.\n&gt; \n&gt; So does the function deliver the total number of bytes in the content of\n&gt; this Steam?\n\nYes, it should... and getSize() will get the full recorded data size, \nincluding headers.\n\n&gt; Background:\n&gt; To reduce OOME within the HTML-Parser, I want to only handle files which\n&gt; aren&#39;t to big. I already exclude non html Documents. But sometimes the\n&gt; crawler still gets an OOME and crashes. Adding pause-on-finish doesn&#39;t\n&gt; seem to help. I can&#39;t continue the crawl after an OOME.\n&gt; So I plan to only handle files which have content smaller than 30kb.\n&gt; Or is this a to big/ small value?\n&gt; Perhaps I may also restrict the maximum size of the header to 1kb?\n&gt; Any thoughts?\n\nYou&#39;re getting these using the JerichoExtractorHTML, right?\n\n(One note for others reading this: the standard ExtractorHTML should be \nfairly OOME-proof with large heaps and a reasonable number of \nToeThreads. It only scans content with regular expressions, not building \na whole document/DOM in memory. Only the number of outlinks discovered \nconsumes extra memory, and by default the number discoverable in any one \ndocument is capped at 6000. This can be changed, and there is a notation \nin the crawl.log if this cap is reached for any document.)\n\nI can think of 3 ways you could limit the size of documents considered \nby an extractor:\n\n(1) You could use the &#39;max-length-bytes&#39; setting of FetchHTTP to cut \nshort any fetches of larer documents. This relies on the extractor \nhandling truncated content acceptably, but has the benefit of never \ncollecting/storing oversized content that won&#39;t be extracted.\n\n(2) You could use a DecideRule on the extractor to completely skip \ncontent over a certain size. Easy to set up, but doesn&#39;t even get \nanything from the ealy parts of those documents.\n\n(3) You could customize the extractor to use a clipped view of the full \nrecorded content. For example, instead of using the ReplayCharSequence \ndirectly, wrap it in a CharSubSequence that only includes the first X \nKB. Again, as long as the extractor behaves acceptably at the truncated \nend of the content, you may have effectively capped its memory use.\n\nHope this helps,\n\n- Gordon @ IA\n\n"}}