{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":325624130,"authorName":"Noah Levitt","from":"Noah Levitt &lt;nlevitt@...&gt;","profile":"nlevitt","replyTo":"LIST","senderId":"A9lNM8Jcfl3_XbpSeLNusNB2LKP5vuKmMKAJ9RwwHmVZN7o1wars7SMN97Ce9ontqWB4FBZR29f1qGJfpN1cGfQzeP9yJ8fJ","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] High performance configuration for single site","postDate":"1326411560","msgId":7517,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRGMEY2RjI4LjYwMjAzMDJAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGplbG4zMiszYTlhQGVHcm91cHMuY29tPg==","referencesHeader":"PGplbG4zMiszYTlhQGVHcm91cHMuY29tPg=="},"prevInTopic":7512,"nextInTopic":0,"prevInTime":7516,"nextInTime":7518,"topicId":7512,"numMessagesInTopic":2,"msgSnippet":"Hello, It sounds like you want to use parallelQueues, which allow multiple threads to hit the same site simultaneously. Quoting from ","rawEmail":"Return-Path: &lt;nlevitt@...&gt;\r\nX-Sender: nlevitt@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 2191 invoked from network); 12 Jan 2012 23:39:23 -0000\r\nX-Received: from unknown (98.137.34.44)\n  by m7.grp.sp2.yahoo.com with QMQP; 12 Jan 2012 23:39:23 -0000\r\nX-Received: from unknown (HELO mail.archive.org) (207.241.224.6)\n  by mta1.grp.sp2.yahoo.com with SMTP; 12 Jan 2012 23:39:23 -0000\r\nX-Received: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id E16E76840157;\n\tThu, 12 Jan 2012 15:39:22 -0800 (PST)\r\nX-Received: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id 0Ud-Pd+DgQve; Thu, 12 Jan 2012 15:39:22 -0800 (PST)\r\nX-Received: from [208.70.27.155] (desktop-nlevitt.sf.archive.org [208.70.27.155])\n\tby mail.archive.org (Postfix) with ESMTPSA id 1B0916840141;\n\tThu, 12 Jan 2012 15:39:22 -0800 (PST)\r\nMessage-ID: &lt;4F0F6F28.6020302@...&gt;\r\nDate: Thu, 12 Jan 2012 15:39:20 -0800\r\nUser-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:8.0) Gecko/20111124 Thunderbird/8.0\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: webdesignerwanted1234 &lt;webdesignerwanted1234@...&gt;\r\nReferences: &lt;jeln32+3a9a@...&gt;\r\nIn-Reply-To: &lt;jeln32+3a9a@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Noah Levitt &lt;nlevitt@...&gt;\r\nSubject: Re: [archive-crawler] High performance configuration for single site\r\nX-Yahoo-Group-Post: member; u=325624130; y=SIz05Udd5pJ7EmBFnwAK9AWSGoBwgIRgD6oOSqOc7sXmVA\r\nX-Yahoo-Profile: nlevitt\r\n\r\nHello,\n\nIt sounds like you want to use parallelQueues, which allow multiple \nthreads to hit the same site simultaneously.\n\nQuoting from \nhttps://webarchive.jira.com/wiki/display/Heritrix/H3+Dev+Notes+for+Crawl+Operators\n\n&quot;parallelQueues: default value (and historical behavior) is &#39;1&#39;. If \ninstead N, all URIs that previously went into the same single-named \nqueue will go into N related queues (via a consistent hash-mapping of \nthe path?query portion of the URL). Each queue is considered separately \nfor traditional politeness based on one-at-a-time connections and \nsnooze-delays-between-fetches -- so N queues means N fetches could be in \nprogress against a site at once. Thus, should only be used in an overlay \nsetting, applied to sites likely to handle multiple connections well.&quot;\n\nNoah\n\n\nOn 01/11/2012 08:20 PM, webdesignerwanted1234 wrote:\n&gt; How can we have H3 scan a single site as quickly as possible?  We need to spider an internal site and have a lot of room to throttle up.\n&gt;\n&gt; We&#39;ve done the simple H3 configs like decreasing the delay factor, but haven&#39;t been able to get multi-threading working (for on a single site scan) without getting really creative with manually segregated seed URLs.\n&gt;\n&gt; Ideally, we would just point H3 to a starting page of the site, and it would have multiple threads communicate to download the entire site as quickly as possible.\n&gt;\n&gt; Is something like this possible?  Or recommendations on how to get close to that functionality (using H3 or anything else)?\n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------\n&gt;\n&gt; Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n\n\n"}}