{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"29IGCsaZiUwl7iRfT4Vfr0SRjZzxgDmaK7uQvR6b1VrXZGgVsxnxUG06rsE8aUq-YOB29WH7LCbWgxpHEJIJbuxN4YWzs_U","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: OOME Re: [archive-crawler] Re: Distributed Crawling","postDate":"1176250110","msgId":4081,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ2MUMyNkZFLjcwNzAzMDRAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGV2aDZuaCtqbWY4QGVHcm91cHMuY29tPg==","referencesHeader":"PGV2aDZuaCtqbWY4QGVHcm91cHMuY29tPg=="},"prevInTopic":4080,"nextInTopic":4103,"prevInTime":4080,"nextInTime":4082,"topicId":3834,"numMessagesInTopic":26,"msgSnippet":"... Seem reasonable, though you may want to look out for the AntiCalendar policy. One other thing that cost policies do is affect URI queue insertion location","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 37695 invoked from network); 11 Apr 2007 00:06:55 -0000\r\nReceived: from unknown (66.218.67.35)\n  by m25.grp.scd.yahoo.com with QMQP; 11 Apr 2007 00:06:55 -0000\r\nReceived: from unknown (HELO mail.archive.org) (207.241.233.246)\n  by mta9.grp.scd.yahoo.com with SMTP; 11 Apr 2007 00:06:55 -0000\r\nReceived: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id 2718A1415FD61\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Tue, 10 Apr 2007 17:06:01 -0700 (PDT)\r\nReceived: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id 06640-07-24 for &lt;archive-crawler@yahoogroups.com&gt;;\n\tTue, 10 Apr 2007 17:06:00 -0700 (PDT)\r\nReceived: from [192.168.1.203] (c-76-102-230-209.hsd1.ca.comcast.net [76.102.230.209])\n\tby mail.archive.org (Postfix) with ESMTP id 855451415FD0A\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Tue, 10 Apr 2007 17:06:00 -0700 (PDT)\r\nMessage-ID: &lt;461C26FE.7070304@...&gt;\r\nDate: Tue, 10 Apr 2007 17:08:30 -0700\r\nUser-Agent: Thunderbird 1.5.0.10 (X11/20070306)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;evh6nh+jmf8@...&gt;\r\nIn-Reply-To: &lt;evh6nh+jmf8@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Virus-Scanned: Debian amavisd-new at archive.org\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: OOME Re: [archive-crawler] Re: Distributed Crawling\r\nX-Yahoo-Group-Post: member; u=137285340; y=GscNGUEuzp2H2rwFWk_ydQGZt0gbHP7pn5J4HWzIuGwN\r\nX-Yahoo-Profile: gojomo\r\n\r\njoehung302 wrote:\n&gt; Does the following parameters make sense?\n&gt; \n&gt; hold-queues: true\n&gt; balance-replenish-amount: 3000\n&gt; target-ready-backlog: 2000\n&gt; cost-policy: AntiCalendar\n&gt; \n&gt; I just randomly picked the numbers after reading your post...\n\nSeem reasonable, though you may want to look out for the AntiCalendar \npolicy.\n\nOne other thing that cost policies do is affect URI queue insertion \nlocation -- lower cost URIs are always inserted in front of higher \ncosts. And, another side effect of AntiCalendar (inherited from \nWAGCostPolicy) is that URIs with a query-string are penalized 1 unit \nabove those that do not.\n\nThus, with either WAG or AntiCalendar policies, all non-query-string \nURIs in a queue will be crawled before all query-string URIs. This has \noccasionally caused problems, if there are trap (or merely very deep) \nquery-string-free paths on a site that prevent more interesting shallow \nquery-string paths to be followed.\n\nSo if you are just getting started with adjusting budgetting, maybe just \nthe UnitPolicy is enough.\n\nOther notes:\n\nThose are the defaults for hold-queues and balance-replenish.\n\nThe number of queues in &#39;active rotation&#39; is equal to the number of \n&#39;in-process&#39; queues (busy threads), plus the number of &#39;ready&#39; queues, \nplus the number of politeness-waiting (&#39;snoozed&#39;) queues. This often \nworks out to be some smallish (politeness- and content-size-determined) \nmultiple of the number of threads, plus the backlog.\n\nSo with the default &#39;500&#39; target-backlog, the active-rotation group will \nalready be in the 1000-2000 range. Thus an increase of the target \nbacklog to 2000 isn&#39;t that big of a change. You could go a lot higher if \nyou wanted a wide rotation, and still be far from round-robining \neverything.\n\nBut, we haven&#39;t done enough testing to know anything about optimal \nsettings under different conditions... any increase in target-backlog \nwould also mean queues finishing more slowly and spending more time \nbetween fetches (and thus perhaps forcing related objects to roundtrip \nto disk under low-memory conditions).\n\nSo 2000 is reasonably close to the default and unlikely to cause \nproblems... but no guesses on whether it&#39;s &#39;good&#39;, or even in what \ndirection might be &#39;better&#39;.\n\n- Gordon @ IA\n\n&gt; \n&gt; --- In archive-crawler@yahoogroups.com, Gordon Mohr &lt;gojomo@...&gt; \n&gt; wrote:\n&gt;&gt; joehung302 wrote:\n&gt;&gt;&gt; so far there I&#39;ve got the first proof crawling (single instance \n&gt; but \n&gt;&gt;&gt; HashMap&#39;ed) going for 4 days with 12M docs downloaded. I just \n&gt; got the \n&gt;&gt;&gt; first OOME error. I wonder if it&#39;s because that I turned the \n&gt; option\n&gt;&gt;&gt;  &lt;boolean name=&quot;hold-queues&quot;&gt;false&lt;/boolean&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; to false. We were using &quot;true&quot; for the last crawl but we thought \n&gt; it \n&gt;&gt;&gt; might be a better practice to rotate the queues more frequently \n&gt; (to \n&gt;&gt;&gt; prevent the busy crawling on certain sites).\n&gt;&gt; This is likely a contributor to the problem.\n&gt;&gt;\n&gt;&gt; The &#39;hold-queues&#39; setting originally made a giant difference: for \n&gt; queues \n&gt;&gt; that went &#39;inactive&#39;, only their name (queue key) was held in \n&gt; memory, \n&gt;&gt; while all &#39;ready&#39; queue objects (significantly larger than just \n&gt; the key) \n&gt;&gt; were held in memory. (In both cases, the actual URI contents of \n&gt; the \n&gt;&gt; queues are on disk until needed.)\n&gt;&gt;\n&gt;&gt; Now, both the queue of &#39;ready&#39; queues and the queue of &#39;inactive&#39; \n&gt; queues \n&gt;&gt; are handled the same way, with only the queue name definitely in \n&gt; memory \n&gt;&gt; until the queue is needed.\n&gt;&gt;\n&gt;&gt; However, there will still be significant indirect effects. With \n&gt;&gt; &#39;hold-queues&#39; as false, all queues are created in the &#39;ready&#39; \n&gt; state. \n&gt;&gt; Essentially, *all* queues are round-robined for providing a URI to \n&gt;&gt; crawl. (As soon as one URI finishes, then the queue politeness \n&gt; wait, the \n&gt;&gt; queue goes to the back of the &#39;ready&#39; rotation.)\n&gt;&gt;\n&gt;&gt; There will be at least two large effects of this in a broad crawl:\n&gt;&gt;\n&gt;&gt; (1) little chance of keeping important in-memory object \n&gt; caches &#39;warm&#39;: \n&gt;&gt; some queue/host/server objects are in soft-reference caches \n&gt; because \n&gt;&gt; while they go unused (during politeness delay and waiting in \n&gt; the &#39;ready&#39; \n&gt;&gt; queue) for a while they&#39;ll soon be needed again. With a humongous \n&gt;&gt; &#39;ready&#39; queue, chances are they&#39;ll be dropped from the cache \n&gt; before \n&gt;&gt; reused, so every URI crawled will require a read-in and write-out \n&gt; of \n&gt;&gt; these related objects. (Lots more IO, lots more temporary-low-\n&gt; memory- \n&gt;&gt; conditions-forcing-soft-reference-clearing.)\n&gt;&gt;\n&gt;&gt; (2) small queues (eg &lt;5, &lt;20, &lt;100 URIs) won&#39;t get a chance to \n&gt; finish \n&gt;&gt; until *every* queue gets through that same number of items. That \n&gt; could \n&gt;&gt; mean a lot more nonempty queues in total -- and even with only the \n&gt; queue \n&gt;&gt; name in memory, could explain your problem in a long crawl. (A \n&gt; finished \n&gt;&gt; queue has no memory footprint, but even the smallest filled queue \n&gt; has at \n&gt;&gt; least its name in memory).\n&gt;&gt;\n&gt;&gt; So for large/broad crawls, &#39;hold-queues&#39; should definitely be true.\n&gt;&gt;\n&gt;&gt; There are other ways to get the desired &#39;broader rotation&#39; \n&gt; or &#39;less \n&gt;&gt; intense crawling&#39; effect you want, without going to round-robining \n&gt; all \n&gt;&gt; queues. Increasing politeness delays is an obvious route, but \n&gt; another is \n&gt;&gt; to increase the &#39;target-ready-backlog&#39; value.\n&gt;&gt;\n&gt;&gt; The crawler aims to always keep this many queues in the &#39;ready&#39; \n&gt; queue, \n&gt;&gt; even if all threads are busy. So it will activate queues \n&gt; from &#39;inactive&#39; \n&gt;&gt; whenever the backlog falls below this number. Making the number \n&gt; larger \n&gt;&gt; means more queues are in &#39;active&#39; rotation -- so even with fast \n&gt;&gt; politness settings, they may take a while to be hit again, while \n&gt; other \n&gt;&gt; queues are in front of them. As these finish (or deplete \n&gt; their &#39;budget&#39;, \n&gt;&gt; see below), others will come from &#39;inactive&#39; to replace them.\n&gt;&gt;\n&gt;&gt; The other useful intensity-affecting settings are the &#39;cost&#39; and \n&gt;&gt; &#39;budget&#39; related values. A queue gets a &#39;balance-replenish-amount&#39; \n&gt;&gt; session-budget whenever it first becomes &#39;ready&#39;. Each URI crawled \n&gt;&gt; depletes that budget in accordance with the &#39;cost-policy&#39;. When \n&gt; the \n&gt;&gt; session-budget reaches 0, the queue goes to the back of \n&gt; the &#39;inactive&#39; \n&gt;&gt; queues to give others a chance to crawl.\n&gt;&gt;\n&gt;&gt; Assuming a UnitCostAssignmentPolicy (every URI costs 1), a \n&gt;&gt; &#39;balance-replenish-amount&#39; of 1 would be a degenerate case much \n&gt; like \n&gt;&gt; &#39;hold-queues&#39; being false: each queue would contribute one URI to \n&gt; be \n&gt;&gt; crawled before getting to the back of one global line. With a \n&gt;&gt; &#39;balance-replenish-amount&#39; of 100, a queue would give out up to \n&gt; 100 URIs \n&gt;&gt; before deactivating. This has the nice property of letting small \n&gt; sites \n&gt;&gt; finish the first time they become &#39;active, while larger sites \n&gt; rotate in \n&gt;&gt; and out of active crawling to let newly-discovered small sites a \n&gt; chance \n&gt;&gt; to finish.\n&gt;&gt;\n&gt;&gt; So:\n&gt;&gt;   - &#39;target-ready-backlog&#39; and politeness settings affect how \n&gt; intensely \n&gt;&gt; a queue is crawled while it is &#39;active&#39;\n&gt;&gt;   - &#39;balance-replenish-amount&#39; and &#39;cost-policy&#39; affect how long a \n&gt; large \n&gt;&gt; queue stays &#39;active&#39; before making way for other queues\n&gt;&gt;   - &#39;hold-queues&#39; at false makes all queues round-robin in \n&gt; the &#39;ready&#39; \n&gt;&gt; state; a minimum &#39;balance-replenish-amount&#39; (with a nonzero cost \n&gt; policy) \n&gt;&gt; makes all queues round-robin through the &#39;inactive&#39; state. In \n&gt; either \n&gt;&gt; case, the queue load (and memory load) can get much higher because \n&gt;&gt; queues neither finish nor get crawled frequently enough to skip \n&gt;&gt; roundtrips to disk.\n&gt;&gt;\n&gt;&gt;&gt; Do you want to look the OOME problem further? What information \n&gt; should \n&gt;&gt;&gt; I send?\n&gt;&gt; If it recurs after adjusting your queue behaviors, good info is \n&gt; always:\n&gt;&gt; - progress-statistics.log shortly before and after OOME\n&gt;&gt;\n&gt;&gt; - &#39;jmap -histo&#39; of heap, at times as close (before and after) OOME \n&gt; as \n&gt;&gt; possible\n&gt;&gt;\n&gt;&gt; - if reproduceable in JDK 1.6, the better error stack dump at time \n&gt; of \n&gt;&gt; OOME (to confirm if it is in fact heap-related), and if necessary \n&gt; the \n&gt;&gt; HeapDumpOnOutOfMemoryError automatic full heap dump, for later \n&gt; analysis \n&gt;&gt; of what&#39;s overgrown\n&gt;&gt;\n&gt;&gt; - Gordon @ IA\n&gt;&gt;\n&gt; \n&gt; \n&gt; \n&gt; \n&gt;  \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n\n"}}