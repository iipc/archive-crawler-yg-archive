{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"Michael Stack","from":"Michael Stack &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"Ixj7QVFtSbCpTm8w9mlnQbxkVL1IjnxRoreWYJHJVssL4nAhEyJVlSWeNmT0lmTx95_l8ALJvVwB1WbNTC18pykEFHqbSQbH","spamInfo":{"isSpam":false,"reason":"3"},"subject":"Re: [archive-crawler] arc.gz file is corrupted","postDate":"1170432469","msgId":3771,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ1QzM2MUQ1LjEwMTA4MDZAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGVwdmNjOCs0dXNiQGVHcm91cHMuY29tPg==","referencesHeader":"PGVwdmNjOCs0dXNiQGVHcm91cHMuY29tPg=="},"prevInTopic":3770,"nextInTopic":0,"prevInTime":3770,"nextInTime":3772,"topicId":3770,"numMessagesInTopic":2,"msgSnippet":"Read about the ARC file format here, http://crawler.archive.org/articles/developer_manual/arcs.html, in the Developer s Manual.  Its not a zip file.  Use gzip","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 58619 invoked from network); 2 Feb 2007 16:04:02 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m42.grp.scd.yahoo.com with QMQP; 2 Feb 2007 16:04:02 -0000\r\nReceived: from unknown (HELO dns.duboce.net) (63.203.238.117)\n  by mta1.grp.scd.yahoo.com with SMTP; 2 Feb 2007 16:04:01 -0000\r\nReceived: by dns.duboce.net (Postfix, from userid 1008)\n\tid 9DE69C565; Fri,  2 Feb 2007 06:43:17 -0800 (PST)\r\nX-Spam-Checker-Version: SpamAssassin 3.1.4 (2006-07-26) on dns.duboce.net\r\nX-Spam-Level: \r\nX-Spam-Status: No, score=-4.3 required=5.0 tests=ALL_TRUSTED,AWL,BAYES_00,\n\tNORMAL_HTTP_TO_IP autolearn=ham version=3.1.4\r\nReceived: from [192.168.1.105] (unknown [192.168.1.105])\n\tby dns.duboce.net (Postfix) with ESMTP id F12E7C51B;\n\tFri,  2 Feb 2007 06:43:06 -0800 (PST)\r\nMessage-ID: &lt;45C361D5.1010806@...&gt;\r\nDate: Fri, 02 Feb 2007 08:07:49 -0800\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; PPC Mac OS X Mach-O; en-US; rv:1.8.0.4) Gecko/20060516 SeaMonkey/1.0.2\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;epvcc8+4usb@...&gt;\r\nIn-Reply-To: &lt;epvcc8+4usb@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 2:3:4:0\r\nFrom: Michael Stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] arc.gz file is corrupted\r\nX-Yahoo-Group-Post: member; u=168599281; y=sMllq4xJQyyyWPaDT6RXj4WMqEg9jp7h1j_xJOpip7RN3jHyfWJu8RSJ\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\nRead about the ARC file format here, \nhttp://crawler.archive.org/articles/developer_manual/arcs.html, in the \nDeveloper&#39;s Manual.  Its not a zip file.  Use gzip to inflate.\n\nRegards Heritrix never finishing, study the frontier report and logs to \nfigure why its not completing.  Usually its stuck in a retry loop \ndoggedly trying to fetch a last few pages with long pauses between \nattempts.  When Heritrix reaches this state, its &#39;normal&#39; that an \noperator will intervene and manually terminate the crawl.\n\nYours,\nSt.Ack\n\n\nvjsjolly wrote:\n&gt;\n&gt; Am using heritrix-1.10.1 on windows xp to crawl a local site. It does\n&gt; it well but when i see it in WUI it shows me 99% completed and never\n&gt; finishes. Then I terminated the job and get the IAH-SomeName.arc.gz\n&gt; file. but if i open(unzip) this file using winrar or winzip it show me\n&gt; two errors :\n&gt;\n&gt; ! D:&#92;arcs&#92;IAH-VJS1.arc.gz: Unexpected end of archive\n&gt; ! D:&#92;arcs&#92;IAH-VJS1.arc.gz: CRC failed in IAH-VJS1.arc. The file is\n&gt; corrupt\n&gt;\n&gt; The i changes the order.xml and modified it\n&gt;\n&gt; &lt;map name=&quot;write-processors&quot;&gt;\n&gt; &lt;newObject name=&quot;Archiver&quot;\n&gt; class=&quot;org.archive.crawler.writer.ARCWriterProcessor&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;boolean name=&quot;compress&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;string name=&quot;prefix&quot;&gt;IAH&lt;/string&gt;\n&gt; &lt;string name=&quot;suffix&quot;&gt;${HOSTNAME}&lt;/string&gt;\n&gt; &lt;integer name=&quot;max-size-bytes&quot;&gt;100000000&lt;/integer&gt;\n&gt; &lt;stringList name=&quot;path&quot;&gt;\n&gt; &lt;string&gt;arcs&lt;/string&gt;\n&gt; &lt;/stringList&gt;\n&gt; &lt;integer name=&quot;pool-max-active&quot;&gt;5&lt;/integer&gt;\n&gt; &lt;integer name=&quot;pool-max-wait&quot;&gt;300000&lt;/integer&gt;\n&gt; &lt;long name=&quot;total-bytes-to-write&quot;&gt;620000&lt;/long&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;/map&gt;\n&gt;\n&gt; now the crawl completed by itself but again if i open it using winrar\n&gt; and winzip it gives me the same problems.\n&gt;\n&gt; Below i have pasted the whole order.xml\n&gt;\n&gt; &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;crawl-order\n&gt; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance \n&gt; &lt;http://www.w3.org/2001/XMLSchema-instance&gt;&quot;\n&gt; xsi:noNamespaceSchemaLocation=&quot;heritrix_settings.xsd&quot;&gt;\n&gt; &lt;meta&gt;\n&gt; &lt;name&gt;VJS1&lt;/name&gt;\n&gt; &lt;description&gt;VJS1 Profile&lt;/description&gt;\n&gt; &lt;operator&gt;Admin&lt;/operator&gt;\n&gt; &lt;organization&gt;ADVANCE&lt;/organization&gt;\n&gt; &lt;audience&gt;&lt;/audience&gt;\n&gt; &lt;date&gt;20070123062353&lt;/date&gt;\n&gt; &lt;/meta&gt;\n&gt; &lt;controller&gt;\n&gt; &lt;string name=&quot;settings-directory&quot;&gt;settings&lt;/string&gt;\n&gt; &lt;string name=&quot;disk-path&quot;&gt;&lt;/string&gt;\n&gt; &lt;string name=&quot;logs-path&quot;&gt;logs&lt;/string&gt;\n&gt; &lt;string name=&quot;checkpoints-path&quot;&gt;checkpoints&lt;/string&gt;\n&gt; &lt;string name=&quot;state-path&quot;&gt;state&lt;/string&gt;\n&gt; &lt;string name=&quot;scratch-path&quot;&gt;scratch&lt;/string&gt;\n&gt; &lt;long name=&quot;max-bytes-download&quot;&gt;0&lt;/long&gt;\n&gt; &lt;long name=&quot;max-document-download&quot;&gt;0&lt;/long&gt;\n&gt; &lt;long name=&quot;max-time-sec&quot;&gt;0&lt;/long&gt;\n&gt; &lt;integer name=&quot;max-toe-threads&quot;&gt;50&lt;/integer&gt;\n&gt; &lt;integer name=&quot;recorder-out-buffer-bytes&quot;&gt;4096&lt;/integer&gt;\n&gt; &lt;integer name=&quot;recorder-in-buffer-bytes&quot;&gt;65536&lt;/integer&gt;\n&gt; &lt;integer name=&quot;bdb-cache-percent&quot;&gt;0&lt;/integer&gt;\n&gt; &lt;newObject name=&quot;scope&quot;\n&gt; class=&quot;org.archive.crawler.deciderules.DecidingScope&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;string name=&quot;seedsfile&quot;&gt;seeds.txt&lt;/string&gt;\n&gt; &lt;boolean name=&quot;reread-seeds-on-config&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;newObject name=&quot;decide-rules&quot;\n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt; &lt;map name=&quot;rules&quot;&gt;\n&gt; &lt;newObject name=&quot;rejectByDefault&quot;\n&gt; class=&quot;org.archive.crawler.deciderules.RejectDecideRule&quot;&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;acceptIfSurtPrefixed&quot;\n&gt; class=&quot;org.archive.crawler.deciderules.SurtPrefixedDecideRule&quot;&gt;\n&gt; &lt;string name=&quot;decision&quot;&gt;ACCEPT&lt;/string&gt;\n&gt; &lt;string name=&quot;surts-source-file&quot;&gt;&lt;/string&gt;\n&gt; &lt;boolean name=&quot;seeds-as-surt-prefixes&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;string name=&quot;surts-dump-file&quot;&gt;&lt;/string&gt;\n&gt; &lt;boolean name=&quot;also-check-via&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;rebuild-on-reconfig&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;rejectIfTooManyHops&quot;\n&gt; class=&quot;org.archive.crawler.deciderules.TooManyHopsDecideRule&quot;&gt;\n&gt; &lt;integer name=&quot;max-hops&quot;&gt;10&lt;/integer&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;acceptIfTranscluded&quot;\n&gt; class=&quot;org.archive.crawler.deciderules.TransclusionDecideRule&quot;&gt;\n&gt; &lt;integer name=&quot;max-trans-hops&quot;&gt;2&lt;/integer&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;rejectIfPathological&quot;\n&gt; class=&quot;org.archive.crawler.deciderules.PathologicalPathDecideRule&quot;&gt;\n&gt; &lt;integer name=&quot;max-repetitions&quot;&gt;2&lt;/integer&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;rejectIfTooManyPathSegs&quot;\n&gt; class=&quot;org.archive.crawler.deciderules.TooManyPathSegmentsDecideRule&quot;&gt;\n&gt; &lt;integer name=&quot;max-path-depth&quot;&gt;10&lt;/integer&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;acceptIfPrerequisite&quot;\n&gt; class=&quot;org.archive.crawler.deciderules.PrerequisiteAcceptDecideRule&quot;&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;map name=&quot;http-headers&quot;&gt;\n&gt; &lt;string name=&quot;user-agent&quot;&gt;Mozilla/5.0 (compatible;\n&gt; heritrix/1.10.1 +http://192.168.1.8:8081/mysite \n&gt; &lt;http://192.168.1.8:8081/mysite&gt;)&lt;/string&gt;\n&gt; &lt;string name=&quot;from&quot;&gt;vjsjolly@... \n&gt; &lt;mailto:vjsjolly%40yahoo.com&gt;&lt;/string&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;newObject name=&quot;robots-honoring-policy&quot;\n&gt; class=&quot;org.archive.crawler.datamodel.RobotsHonoringPolicy&quot;&gt;\n&gt; &lt;string name=&quot;type&quot;&gt;classic&lt;/string&gt;\n&gt; &lt;boolean name=&quot;masquerade&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;text name=&quot;custom-robots&quot;&gt;&lt;/text&gt;\n&gt; &lt;stringList name=&quot;user-agents&quot;&gt;\n&gt; &lt;/stringList&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;frontier&quot;\n&gt; class=&quot;org.archive.crawler.frontier.BdbFrontier&quot;&gt;\n&gt; &lt;float name=&quot;delay-factor&quot;&gt;4.0&lt;/float&gt;\n&gt; &lt;integer name=&quot;max-delay-ms&quot;&gt;20000&lt;/integer&gt;\n&gt; &lt;integer name=&quot;min-delay-ms&quot;&gt;2000&lt;/integer&gt;\n&gt; &lt;integer name=&quot;max-retries&quot;&gt;10&lt;/integer&gt;\n&gt; &lt;long name=&quot;retry-delay-seconds&quot;&gt;300&lt;/long&gt;\n&gt; &lt;integer name=&quot;preference-embed-hops&quot;&gt;1&lt;/integer&gt;\n&gt; &lt;integer name=&quot;total-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt; &lt;integer name=&quot;max-per-host-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt; &lt;string\n&gt; name=&quot;queue-assignment-policy&quot;&gt;org.archive.crawler.frontier.HostnameQueueAssignmentPolicy&lt;/string&gt;\n&gt; &lt;string name=&quot;force-queue-assignment&quot;&gt;&lt;/string&gt;\n&gt; &lt;boolean name=&quot;pause-at-start&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;pause-at-finish&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;source-tag-seeds&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;recovery-log-enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;hold-queues&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;integer name=&quot;balance-replenish-amount&quot;&gt;3000&lt;/integer&gt;\n&gt; &lt;integer name=&quot;error-penalty-amount&quot;&gt;100&lt;/integer&gt;\n&gt; &lt;long name=&quot;queue-total-budget&quot;&gt;-1&lt;/long&gt;\n&gt; &lt;string\n&gt; name=&quot;cost-policy&quot;&gt;org.archive.crawler.frontier.ZeroCostAssignmentPolicy&lt;/string&gt;\n&gt; &lt;long name=&quot;snooze-deactivate-ms&quot;&gt;300000&lt;/long&gt;\n&gt; &lt;integer name=&quot;target-ready-backlog&quot;&gt;50&lt;/integer&gt;\n&gt; &lt;string\n&gt; name=&quot;uri-included-structure&quot;&gt;org.archive.crawler.util.BdbUriUniqFilter&lt;/string&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;map name=&quot;uri-canonicalization-rules&quot;&gt;\n&gt; &lt;newObject name=&quot;Lowercase&quot;\n&gt; class=&quot;org.archive.crawler.url.canonicalize.LowercaseRule&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;Userinfo&quot;\n&gt; class=&quot;org.archive.crawler.url.canonicalize.StripUserinfoRule&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;WWW[0-9]*&quot;\n&gt; class=&quot;org.archive.crawler.url.canonicalize.StripWWWNRule&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;SessionIDs&quot;\n&gt; class=&quot;org.archive.crawler.url.canonicalize.StripSessionIDs&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;SessionCFIDs&quot;\n&gt; class=&quot;org.archive.crawler.url.canonicalize.StripSessionCFIDs&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;QueryStrPrefix&quot;\n&gt; class=&quot;org.archive.crawler.url.canonicalize.FixupQueryStr&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;map name=&quot;pre-fetch-processors&quot;&gt;\n&gt; &lt;newObject name=&quot;Preselector&quot;\n&gt; class=&quot;org.archive.crawler.prefetch.Preselector&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;boolean name=&quot;override-logger&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;recheck-scope&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;block-all&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;string\n&gt; name=&quot;block-by-regexp&quot;&gt;.*(?i)&#92;.(a|ai|aif|aifc|aiff|asc|au|avi|bcpio|bin|bmp|bz2|c|cdf|cgi|cgm|class|cpio|cpp?|cpt|csh|css|cxx|dcr|dif|dir|djv|djvu|dll|dmg|dms|doc|dtd|dv|dvi|dxr|eps|etx|exe|ez|gif|gram|grxml|gtar|h|hdf|hqx|ice|ico|ics|ief|ifb|iges|igs|iso|jnlp|jp2|jpe|jpeg|jpg|js|kar|latex|lha|lzh|m3u|mac|man|mathml|me|mesh|mid|midi|mif|mov|movie|mp2|mp3|mp4|mpe|mpeg|mpg|mpga|ms|msh|mxu|nc|o|oda|ogg|pbm|pct|pdb|pdf|pgm|pgn|pic|pict|pl|png|pnm|pnt|pntg|ppm|ppt|ps|py|qt|qti|qtif|ra|ram|ras|rdf|rgb|rm|roff|rpm|rtf|rtx|s|sgm|sgml|sh|shar|silo|sit|skd|skm|skp|skt|smi|smil|snd|so|spl|src|srpm|sv4cpio|sv4crc|svg|swf|t|tar|tcl|tex|texi|texinfo|tgz|tif|tiff|tr|tsv|ustar|vcd|vrml|vxml|wav|wbmp|wbxml|wml|wmlc|wmls|wmlsc|wmv|wrl|xbm|xht|xhtml|xls|xml|xpm|xsl|xslt|xwd|xyz|z|zip)$&lt;/string&gt;\n&gt; &lt;string name=&quot;allow-by-regexp&quot;&gt;&lt;/string&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;Preprocessor&quot;\n&gt; class=&quot;org.archive.crawler.prefetch.PreconditionEnforcer&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;integer name=&quot;ip-validity-duration-seconds&quot;&gt;21600&lt;/integer&gt;\n&gt; &lt;integer name=&quot;robot-validity-duration-seconds&quot;&gt;86400&lt;/integer&gt;\n&gt; &lt;boolean name=&quot;calculate-robots-only&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;map name=&quot;fetch-processors&quot;&gt;\n&gt; &lt;newObject name=&quot;DNS&quot; class=&quot;org.archive.crawler.fetcher.FetchDNS&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;boolean name=&quot;accept-non-dns-resolves&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;sha1-content&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;HTTP&quot;\n&gt; class=&quot;org.archive.crawler.fetcher.FetchHTTP&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;map name=&quot;midfetch-filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;integer name=&quot;timeout-seconds&quot;&gt;1200&lt;/integer&gt;\n&gt; &lt;integer name=&quot;sotimeout-ms&quot;&gt;20000&lt;/integer&gt;\n&gt; &lt;integer name=&quot;fetch-bandwidth&quot;&gt;0&lt;/integer&gt;\n&gt; &lt;long name=&quot;max-length-bytes&quot;&gt;0&lt;/long&gt;\n&gt; &lt;boolean name=&quot;ignore-cookies&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;use-bdb-for-cookies&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;string name=&quot;load-cookies-from-file&quot;&gt;&lt;/string&gt;\n&gt; &lt;string name=&quot;save-cookies-to-file&quot;&gt;&lt;/string&gt;\n&gt; &lt;string name=&quot;trust-level&quot;&gt;open&lt;/string&gt;\n&gt; &lt;stringList name=&quot;accept-headers&quot;&gt;\n&gt; &lt;/stringList&gt;\n&gt; &lt;string name=&quot;http-proxy-host&quot;&gt;&lt;/string&gt;\n&gt; &lt;string name=&quot;http-proxy-port&quot;&gt;&lt;/string&gt;\n&gt; &lt;string name=&quot;default-encoding&quot;&gt;ISO-8859-1&lt;/string&gt;\n&gt; &lt;boolean name=&quot;sha1-content&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;send-connection-close&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;send-referer&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;send-range&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;string name=&quot;bind-address&quot;&gt;&lt;/string&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;map name=&quot;extract-processors&quot;&gt;\n&gt; &lt;newObject name=&quot;ExtractorHTTP&quot;\n&gt; class=&quot;org.archive.crawler.extractor.ExtractorHTTP&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;ExtractorHTML&quot;\n&gt; class=&quot;org.archive.crawler.extractor.ExtractorHTML&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;boolean name=&quot;treat-frames-as-embed-links&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;ignore-form-action-urls&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;overly-eager-link-detection&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;ignore-unexpected-html&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;ExtractorCSS&quot;\n&gt; class=&quot;org.archive.crawler.extractor.ExtractorCSS&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;ExtractorJS&quot;\n&gt; class=&quot;org.archive.crawler.extractor.ExtractorJS&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;ExtractorSWF&quot;\n&gt; class=&quot;org.archive.crawler.extractor.ExtractorSWF&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;map name=&quot;write-processors&quot;&gt;\n&gt; &lt;newObject name=&quot;Archiver&quot;\n&gt; class=&quot;org.archive.crawler.writer.ARCWriterProcessor&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;boolean name=&quot;compress&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;string name=&quot;prefix&quot;&gt;IAH&lt;/string&gt;\n&gt; &lt;string name=&quot;suffix&quot;&gt;${HOSTNAME}&lt;/string&gt;\n&gt; &lt;integer name=&quot;max-size-bytes&quot;&gt;100000000&lt;/integer&gt;\n&gt; &lt;stringList name=&quot;path&quot;&gt;\n&gt; &lt;string&gt;arcs&lt;/string&gt;\n&gt; &lt;/stringList&gt;\n&gt; &lt;integer name=&quot;pool-max-active&quot;&gt;5&lt;/integer&gt;\n&gt; &lt;integer name=&quot;pool-max-wait&quot;&gt;300000&lt;/integer&gt;\n&gt; &lt;long name=&quot;total-bytes-to-write&quot;&gt;0&lt;/long&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;map name=&quot;post-processors&quot;&gt;\n&gt; &lt;newObject name=&quot;Updater&quot;\n&gt; class=&quot;org.archive.crawler.postprocessor.CrawlStateUpdater&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;LinksScoper&quot;\n&gt; class=&quot;org.archive.crawler.postprocessor.LinksScoper&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;boolean name=&quot;override-logger&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;seed-redirects-new-seed&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;integer name=&quot;preference-depth-hops&quot;&gt;-1&lt;/integer&gt;\n&gt; &lt;map name=&quot;scope-rejected-url-filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;Scheduler&quot;\n&gt; class=&quot;org.archive.crawler.postprocessor.FrontierScheduler&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;map name=&quot;loggers&quot;&gt;\n&gt; &lt;newObject name=&quot;crawl-statistics&quot;\n&gt; class=&quot;org.archive.crawler.admin.StatisticsTracker&quot;&gt;\n&gt; &lt;integer name=&quot;interval-seconds&quot;&gt;20&lt;/integer&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;string name=&quot;recover-path&quot;&gt;&lt;/string&gt;\n&gt; &lt;boolean name=&quot;checkpoint-copy-bdbje-logs&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;recover-retain-failures&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;newObject name=&quot;credential-store&quot;\n&gt; class=&quot;org.archive.crawler.datamodel.CredentialStore&quot;&gt;\n&gt; &lt;map name=&quot;credentials&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;/controller&gt;\n&gt; &lt;/crawl-order&gt;\n&gt;\n&gt; any idea is helpful.\n&gt;\n&gt;  \n\n\n"}}