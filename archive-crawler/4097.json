{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":305432243,"authorName":"louisleiyu","from":"&quot;louisleiyu&quot; &lt;yul@...&gt;","profile":"louisleiyu","replyTo":"LIST","senderId":"EijiLHJi7xdvFtpudy6PG42cZSV1PkG6jZy5K1xck0kMQBjOYnh-spfFB8eEhIDzG8eCywLn7RERH9vOPPdj9iU","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Constructing a web graph","postDate":"1176329051","msgId":4097,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGV2am0wcitmaXBqQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDVhMWMzNGFhMDcwNDExMTEzM3AyODVjZjQzNnEzZjkzMzE0YmRhOTA2NWFlQG1haWwuZ21haWwuY29tPg=="},"prevInTopic":4096,"nextInTopic":4098,"prevInTime":4096,"nextInTime":4098,"topicId":4059,"numMessagesInTopic":8,"msgSnippet":"right, exactly, to actually contruct a webgraph, I need to know the url, and also ALL the parents of the url, not just the first parent that gave birth and got","rawEmail":"Return-Path: &lt;yul@...&gt;\r\nX-Sender: yul@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 1165 invoked from network); 11 Apr 2007 22:07:57 -0000\r\nReceived: from unknown (66.218.67.33)\n  by m36.grp.scd.yahoo.com with QMQP; 11 Apr 2007 22:07:57 -0000\r\nReceived: from unknown (HELO n11d.bullet.scd.yahoo.com) (66.218.67.60)\n  by mta7.grp.scd.yahoo.com with SMTP; 11 Apr 2007 22:07:57 -0000\r\nReceived: from [66.218.69.4] by n22.bullet.scd.yahoo.com with NNFMP; 11 Apr 2007 22:04:11 -0000\r\nReceived: from [66.218.66.77] by t4.bullet.scd.yahoo.com with NNFMP; 11 Apr 2007 22:04:11 -0000\r\nDate: Wed, 11 Apr 2007 22:04:11 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;evjm0r+fipj@...&gt;\r\nIn-Reply-To: &lt;5a1c34aa0704111133p285cf436q3f93314bda9065ae@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;louisleiyu&quot; &lt;yul@...&gt;\r\nSubject: Re: Constructing a web graph\r\nX-Yahoo-Group-Post: member; u=305432243; y=8qh4wjH_HDE_erNTJ71KHnmpdhr-OqgdYpXvxEMRBKpjeUEK6Q\r\nX-Yahoo-Profile: louisleiyu\r\n\r\nright, exactly, to actually contruct a webgraph, I need to know the \nurl, a=\r\nnd also ALL the parents of the url, not just the first parent \nthat gave bi=\r\nrth and got logged in. Thus, url that already existed in \nthe log, but have=\r\n different parents, should at lease have the parent \nand the url recorded. =\r\n\n\nPerhaps we can try looking into this (implment, or look for existed \nway =\r\nto do this); whomever comes up with a solution, be sure to post.\n\n\n--- In a=\r\nrchive-crawler@yahoogroups.com, &quot;Andrea Goethals&quot; \n&lt;andrea_goethals@...&gt; wr=\r\note:\n&gt;\n&gt; If I understand the original post correctly - this is something we=\r\n \nalso want\n&gt; to implement (logging of &quot;intra&quot;-harvest duplicates not \ndown=\r\nloaded).\n&gt; \n&gt; The heritrix 1.12 supports deduping *between* crawls but olde=\r\nr \nheritrixs\n&gt; dedupe *within* crawls already. Ideally we would like to see=\r\n \nlogging options\n&gt; for both kinds of deduplication. We want this intra-har=\r\nvest dedupe \nlogging\n&gt; so that we can know all the parents seen for downloa=\r\nded resources -\n not just\n&gt; the one first parent that currently gets logged=\r\n in crawl.log.\n&gt; \n&gt; I haven&#39;t yet looked into where the extra logging shoul=\r\nd go - just \nwanted to\n&gt; add to this thread that this is something we want =\r\ntoo & are \nwilling to\n&gt; implement (if there&#39;s not already a way to log this=\r\n) because it \nwill effect\n&gt; how we implement our harvest q/a and takedown r=\r\nequest handling.\n&gt; \n&gt; Andrea\n&gt; \n&gt; On 11 Apr 2007 06:12:44 -0700, mbarlotta =\r\n&lt;barlotta_michael@...&gt; \nwrote:\n&gt; &gt;\n&gt; &gt;   &gt; I&#39;ve tried playing around with t=\r\nhe setting for herdrix 1.1.2 \nbut I&#39;m\n&gt; &gt; &gt; getting nowhere; I&#39;ve read that=\r\n older version of heredrix does \nnot\n&gt; &gt; &gt; have the ability to filter out d=\r\nuplicate pages, so perhaps I \nshould\n&gt; &gt; &gt; try older versions of heredrix?\n=\r\n&gt; &gt;\n&gt; &gt; The current version of Heritrix does not dedupe pages by default \ny=\r\nou\n&gt; &gt; would have to configure the job with additional processors to \nget i=\r\nt to\n&gt; &gt; do that. If you crawl sites without dedupe you get what ever your\n=\r\n&gt; &gt; decide rules allow.\n&gt; &gt;\n&gt; &gt; Read more about it here:\n&gt; &gt; \nhttp://webtea=\r\nm.archive.org/confluence/display/Heritrix/Feature+Notes+\n-\n&gt; &gt; +1.12.0\n&gt; &gt;\n=\r\n&gt; &gt; What are you using to visualize your Web Graph?\n&gt; &gt;\n&gt; &gt; HTH,\n&gt; &gt; Mike\n&gt;=\r\n &gt;\n&gt; &gt;  \n&gt; &gt;\n&gt;\n\n\n\n"}}