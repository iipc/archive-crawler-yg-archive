{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"ljBc2Wg-EBPyG2-yTdsSHG51VGGzwviB5l442pFtnG2pVSeVqi6lpov02MYrAC5tbaH2YahFOLoCNAIGkeTTfQXVDj4htYk","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Crawler-guided form/authentication entry","postDate":"1073935881","msgId":235,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQwMDJGNjA5LjUwMDA1MDRAYXJjaGl2ZS5vcmc+"},"prevInTopic":0,"nextInTopic":242,"prevInTime":234,"nextInTime":236,"topicId":235,"numMessagesInTopic":8,"msgSnippet":"We need  the crawl operator to be able to specify usernames and passwords to enable access to password-protected sites, whether those credentials are requested","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 74700 invoked from network); 12 Jan 2004 19:31:22 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m16.grp.scd.yahoo.com with QMQP; 12 Jan 2004 19:31:22 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (209.237.232.202)\n  by mta2.grp.scd.yahoo.com with SMTP; 12 Jan 2004 19:31:21 -0000\r\nReceived: (qmail 32002 invoked by uid 100); 12 Jan 2004 19:29:33 -0000\r\nReceived: from b116-dyn-43.archive.org (HELO archive.org) (gojomo@...@209.237.240.43)\n  by ia14404.archive.org with SMTP; 12 Jan 2004 19:29:33 -0000\r\nMessage-ID: &lt;4002F609.5000504@...&gt;\r\nDate: Mon, 12 Jan 2004 11:31:21 -0800\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.6b) Gecko/20031205 Thunderbird/0.4\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nContent-Type: text/plain; charset=us-ascii; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-Status: No, hits=-1.5 required=6.0\n\ttests=AWL,BAYES_01,USER_AGENT_MOZILLA_UA\n\tversion=2.55\r\nX-Spam-Level: \r\nX-Spam-Checker-Version: SpamAssassin 2.55 (1.174.2.19-2003-05-19-exp)\r\nX-eGroups-Remote-IP: 209.237.232.202\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Crawler-guided form/authentication entry\r\nX-Yahoo-Group-Post: member; u=137285340\r\nX-Yahoo-Profile: gojomo\r\n\r\nWe need  the crawl operator to be able to specify usernames and passwords\nto enable access to password-protected sites, whether those credentials\nare requested via an HTTP basic/digest authentication challenge or an\nHTML form. (And, as long as we&#39;re implementing the ability to fill our\nlogin-forms, we should try to enable the completion of other simple\nforms, as well.)\n\nOne possible UI for configuring such information might be:\n\n  - Operator uses an admin UI facility to enter a specific\n    URI as requiring special attention.\n  - Outside of normal crawling, the crawler immediately\n    visits the UI and notes whatever challenges/forms are\n    available there. These get displayed to the operator\n    in a simplified format.\n  - Operator supplies necessary values. Crawler tests\n    necessary values and shows results to operator.\n  - Operator confirms desired results, and saves special\n    handling information to crawl-configuration.\n\nAs the login info for multiple sites is likely to be useful\nacross multiple crawls, it should be in a format that is easy to\ntransfer to future crawls.\n\nDuring a crawl for which such special handling is enabled,\nthe crawler would, after fetching a page *without* special\nhandling, look to see if any &quot;standing orders&quot; exist. It\nwould verify that the standing orders are still sensible:\nthat an auth-challenge was received, or a form matching\nthe expected &quot;shape&quot;/parameters exists.\n\nOpen questions:\n\n  - This process will usually involve revisiting the exact\n    same URI, with different headers or POST data that\n    results in different content returned. Such revisits\n    can easily be stored in ARC files but may confuse some\n    post-crawl reporting and access practices.\n\n  - Request-headers (including HTTP-authentication or\n    cookies) and POST data are not currently stored in\n    ARC files, but may be necessary for understanding the\n    (different) results returned. The ARC format must\n    be extended soon.\n\n  - When it does become possible to record the outgoing\n    auth/form info, there may be reasons that it should\n    be left out (or directed to a file separate from the\n    main archives) -- for example if it utilizes login\n    info which must be kept secret. In some cases,\n    leakage of such secret info may be very difficult\n    to prevent, if the website echoes back login info\n    in plaintext-equivalent forms in cookies or hidden\n    form variables.\n\n  - Often a successful login will change how a whole set\n    of pages render, though there is no way to automatically\n    determine such changes -- and thus decide which URIs\n    to revisit after login. At first, we should require\n    operators to design their crawls around this problem:\n    for example, by adding login pages to the seed list\n    to be visited before pages requiring login. Later,\n    we may be able to offer a facility which lets the\n    operator set rules like, &quot;after login, consider all\n    pages on same domain as revisitable.&quot;\n\nAre there other considerations or approaches people have\nseen used elsewhere?\n\n- Gordon\n\n"}}