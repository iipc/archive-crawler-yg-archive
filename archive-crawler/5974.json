{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"QHYanyhNsPvDGJi2PqueWSnnki75OZNmoj-gdadiPj8CAdMhbDR_xMcWy2s8iJxb1yYgQYzgSoqYMkyx7ki2fJ68v5jOfLw","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] domain scope with millions of seeds","postDate":"1250109202","msgId":5974,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRBODMyNzEyLjcwNDAyMDVAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGg1c2djYis5Nmw4QGVHcm91cHMuY29tPg==","referencesHeader":"PGg1c2djYis5Nmw4QGVHcm91cHMuY29tPg=="},"prevInTopic":5969,"nextInTopic":5977,"prevInTime":5973,"nextInTime":5975,"topicId":5969,"numMessagesInTopic":5,"msgSnippet":"I d need more profiling info to know why the crawl slowed compared to earlier crawls, or earlier in the same crawl, compared to your prior expectations. The","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 13614 invoked from network); 12 Aug 2009 20:33:23 -0000\r\nX-Received: from unknown (69.147.108.201)\n  by m1.grp.re1.yahoo.com with QMQP; 12 Aug 2009 20:33:23 -0000\r\nX-Received: from unknown (HELO relay00.pair.com) (209.68.5.9)\n  by mta2.grp.re1.yahoo.com with SMTP; 12 Aug 2009 20:33:23 -0000\r\nX-Received: (qmail 86560 invoked from network); 12 Aug 2009 20:33:21 -0000\r\nX-Received: from 70.137.152.95 (HELO ?10.0.13.17?) (70.137.152.95)\n  by relay00.pair.com with SMTP; 12 Aug 2009 20:33:21 -0000\r\nX-pair-Authenticated: 70.137.152.95\r\nMessage-ID: &lt;4A832712.7040205@...&gt;\r\nDate: Wed, 12 Aug 2009 13:33:22 -0700\r\nUser-Agent: Thunderbird 2.0.0.22 (Windows/20090605)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;h5sgcb+96l8@...&gt;\r\nIn-Reply-To: &lt;h5sgcb+96l8@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] domain scope with millions of seeds\r\nX-Yahoo-Group-Post: member; u=137285340; y=fTBBhuyOGoKpLxeXSaHR-pMLGBWxWnP9WURdn9r2YbXX\r\nX-Yahoo-Profile: gojomo\r\n\r\nI&#39;d need more profiling info to know why the crawl slowed compared to \nearlier crawls, or earlier in the same crawl, compared to your prior \nexpectations.\n\nThe data-structure most prone to slowdown is the frontier&#39;s already-seen \nfilter -- though if you&#39;ve converted the crawl to the Bloom Filter \noption, that should not get any slower with time (just more likely to \nmistakenly reject new URIs, as the filter approaches saturation).\n\nA DecidingScope with a SurtPrefixDecideRule is likely better -- or at \nleast most modern/maintained -- than anything based on the earlier \nSurtPrefixScope.\n\nBut in either case, a list of millions of in-scope domains may present \nproblems. The whole list is kept in RAM (perhaps triggering more \nfrequent GCs if it fits at all), and every scope-check requires a \n(logarithmic in size) lookup in the sorted-set.\n\nIt seems your general goal is &quot;get a lot (or everything) from \nseeds/distinguished-domains, a little from everything else&quot;.\n\nThe model for this in H3 will be to have your global settings limit \nfairly strictly how many URIs (or how much &#39;active&#39; queue time) any \nindividual site gets, by default. But then, set up an alternate &#39;sheet&#39; \nof settings, let&#39;s call it &#39;deeper&#39;, that is then associated with every \none of the domains of interest, so they get more &#39;active&#39; time or \ncontinue long past the small quota. (In H1, these alternate settings \nwould have to be repeated in millions of separate override settings, \ninstead of one shared sheet.)\n\nTo simulate in H1, having a giant SURT-prefix-like structure in memory \nmay be unavoidable. However, this could take the form of a custom \nDecideRule that uses the prefix-matching not to definitively rule a URI \nin or out, but to apply a different hops-length cutoff. For example, a \nsubclass of SurtPrefixedDecideRule, reading its prefixes from either \nseeds or a hand-tuned file, which if super.innerAccepts()==true applies \na 20-hops rule, but if super.innerAccepts()==false applies a 3-hops rule.\n\n- Gordon @ IA\n\njoehung302 wrote:\n&gt; Hi there,\n&gt; \n&gt; Has anybody done any crawls with \n&gt; 1) domain-based scope (implemented using SurtPrefixScope with seeds-as-surt-prefixes == true)\n&gt; 2) millions of seeds. E.g. ~10MM.\n&gt; \n&gt; We&#39;re starting to experiment the above crawl...in the hope that the crawl would concentrate more on the seeds rather than a broad crawl which might get too much &quot;random&quot; Internet.\n&gt; \n&gt; After 4 or 5 days, the crawl speed starting to drop. We&#39;ve set the crawl limit to 2300KB/sec, on day 5 we&#39;ve dropped to 1764KB/s on average.\n&gt; \n&gt; We used to do broad crawl with .5 MM seeds and we were getting consist 2300KB/s for at least 2 weeks into the crawl.\n&gt; \n&gt; Any guesses on what caused the crawl to slow down? \n&gt; \n&gt; Thanks,\n&gt; -Joe\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; ------------------------------------\n&gt; \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n"}}