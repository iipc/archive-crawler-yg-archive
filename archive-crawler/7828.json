{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":385173050,"authorName":"Coram, Roger","from":"&quot;Coram, Roger&quot; &lt;Roger.Coram@...&gt;","replyTo":"LIST","senderId":"Oeh6tc2EeDofTvKphbC0v9Zhnle4GJhJoVaOeYg-6LxZ4tdgJ4ivfOwMOCICe-tbYh7eiQQTWWqjQivwzimS5707a-WRtvzMNA","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Recrawl?","postDate":"1350997989","msgId":7828,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDc0Qzk3RTdERjVBNzc4NEQ5OTcyMTdGRjc1RDEyMTY2MEZFRDZBQ0FAdzJrMy1ic3BleDE+"},"prevInTopic":0,"nextInTopic":7831,"prevInTime":7827,"nextInTime":7829,"topicId":7828,"numMessagesInTopic":2,"msgSnippet":"Is it possible to recrawl a host within a single job (without a relaunch)? I know you can use a .force file to recrawl a single URL but is there a way of","rawEmail":"Return-Path: &lt;Roger.Coram@...&gt;\r\nX-Sender: Roger.Coram@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 94098 invoked from network); 23 Oct 2012 13:13:10 -0000\r\nX-Received: from unknown (98.137.34.46)\n  by m6.grp.sp2.yahoo.com with QMQP; 23 Oct 2012 13:13:10 -0000\r\nX-Received: from unknown (HELO w2k3-bspex1.bl.uk) (194.66.236.30)\n  by mta3.grp.sp2.yahoo.com with SMTP; 23 Oct 2012 13:13:10 -0000\r\nX-MimeOLE: Produced By Microsoft Exchange V6.5\r\nContent-class: urn:content-classes:message\r\nMIME-Version: 1.0\r\nContent-Type: multipart/alternative;\n\tboundary=&quot;----_=_NextPart_001_01CDB120.259156E7&quot;\r\nDate: Tue, 23 Oct 2012 14:13:09 +0100\r\nMessage-ID: &lt;74C97E7DF5A7784D997217FF75D121660FED6ACA@w2k3-bspex1&gt;\r\nX-MS-Has-Attach: \r\nX-MS-TNEF-Correlator: \r\nThread-Topic: Recrawl?\r\nThread-Index: Ac2xH7yoXnlNKMh9QlS4wYWqviHFfA==\r\nTo: &lt;archive-crawler@yahoogroups.com&gt;\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;Coram, Roger&quot; &lt;Roger.Coram@...&gt;\r\nSubject: Recrawl?\r\nX-Yahoo-Group-Post: member; u=385173050\r\n\r\n\r\n------_=_NextPart_001_01CDB120.259156E7\r\nContent-Type: text/plain;\n\tcharset=&quot;us-ascii&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nIs it possible to recrawl a host within a single job (without a\nrelaunch)?\n=\r\n\n \n\nI know you can use a &quot;.force&quot; file to recrawl a single URL but is there=\r\n\na way of saying, for example, all URLs matching &quot;http://(uk,bl,&quot; should\nbe=\r\n re-downloaded if seen again in X days?\n\n \n\nI guess this is similar to the =\r\n&quot;Continuous Crawling&quot; discussions that\nhave occurred but I&#39;m not sure wheth=\r\ner any of this was ever implemented?\n\n \n\nThanks,\n\nRoger \n\n \n\n\r\n------_=_NextPart_001_01CDB120.259156E7\r\nContent-Type: text/html;\n\tcharset=&quot;us-ascii&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n&lt;html xmlns:v=3D&quot;urn:schemas-microsoft-com:vml&quot; xmlns:o=3D&quot;urn:schemas-micr=\r\nosoft-com:office:office&quot; xmlns:w=3D&quot;urn:schemas-microsoft-com:office:word&quot; =\r\nxmlns:x=3D&quot;urn:schemas-microsoft-com:office:excel&quot; xmlns:m=3D&quot;http://schema=\r\ns.microsoft.com/office/2004/12/omml&quot; xmlns=3D&quot;http://www.w3.org/TR/REC-html=\r\n40&quot;&gt;&lt;head&gt;&lt;META HTTP-EQUIV=3D&quot;Content-Type&quot; CONTENT=3D&quot;text/html; charset=\r\n=3Dus-ascii&quot;&gt;&lt;meta name=3DGenerator content=3D&quot;Microsoft Word 14 (filtered =\r\nmedium)&quot;&gt;&lt;style&gt;&lt;!--\n/* Font Definitions */\n@font-face\n\t{font-family:Calibr=\r\ni;\n\tpanose-1:2 15 5 2 2 2 4 3 2 4;}\n/* Style Definitions */\np.MsoNormal, li=\r\n.MsoNormal, div.MsoNormal\n\t{margin:0cm;\n\tmargin-bottom:.0001pt;\n\tfont-size:=\r\n11.0pt;\n\tfont-family:&quot;Calibri&quot;,&quot;sans-serif&quot;;\n\tmso-fareast-language:EN-US;}\n=\r\na:link, span.MsoHyperlink\n\t{mso-style-priority:99;\n\tcolor:blue;\n\ttext-decor=\r\nation:underline;}\na:visited, span.MsoHyperlinkFollowed\n\t{mso-style-priority=\r\n:99;\n\tcolor:purple;\n\ttext-decoration:underline;}\nspan.EmailStyle17\n\t{mso-st=\r\nyle-type:personal-compose;\n\tfont-family:&quot;Calibri&quot;,&quot;sans-serif&quot;;\n\tcolor:wind=\r\nowtext;}\n.MsoChpDefault\n\t{mso-style-type:export-only;\n\tfont-family:&quot;Calibri=\r\n&quot;,&quot;sans-serif&quot;;\n\tmso-fareast-language:EN-US;}\n@page WordSection1\n\t{size:612=\r\n.0pt 792.0pt;\n\tmargin:72.0pt 72.0pt 72.0pt 72.0pt;}\ndiv.WordSection1\n\t{page=\r\n:WordSection1;}\n--&gt;&lt;/style&gt;&lt;!--[if gte mso 9]&gt;&lt;xml&gt;\n&lt;o:shapedefaults v:ext=\r\n=3D&quot;edit&quot; spidmax=3D&quot;1026&quot; /&gt;\n&lt;/xml&gt;&lt;![endif]--&gt;&lt;!--[if gte mso 9]&gt;&lt;xml&gt;\n&lt;o=\r\n:shapelayout v:ext=3D&quot;edit&quot;&gt;\n&lt;o:idmap v:ext=3D&quot;edit&quot; data=3D&quot;1&quot; /&gt;\n&lt;/o:shap=\r\nelayout&gt;&lt;/xml&gt;&lt;![endif]--&gt;&lt;/head&gt;&lt;body lang=3DEN-GB link=3Dblue vlink=3Dpur=\r\nple&gt;&lt;div class=3DWordSection1&gt;&lt;p class=3DMsoNormal&gt;Is it possible to recraw=\r\nl a host within a single job (without a relaunch)?&lt;o:p&gt;&lt;/o:p&gt;&lt;/p&gt;&lt;p class=\r\n=3DMsoNormal&gt;&lt;o:p&gt;&nbsp;&lt;/o:p&gt;&lt;/p&gt;&lt;p class=3DMsoNormal&gt;I know you can use a=\r\n &#8220;.force&#8221; file to recrawl a single URL but is there a way of sa=\r\nying, for example, all URLs matching &#8220;http://(uk,bl,&#8221; should be=\r\n re-downloaded if seen again in X days?&lt;o:p&gt;&lt;/o:p&gt;&lt;/p&gt;&lt;p class=3DMsoNormal&gt;=\r\n&lt;o:p&gt;&nbsp;&lt;/o:p&gt;&lt;/p&gt;&lt;p class=3DMsoNormal&gt;I guess this is similar to the &#=\r\n8220;Continuous Crawling&#8221; discussions that have occurred but I&#8217;=\r\nm not sure whether any of this was ever implemented?&lt;o:p&gt;&lt;/o:p&gt;&lt;/p&gt;&lt;p class=\r\n=3DMsoNormal&gt;&lt;o:p&gt;&nbsp;&lt;/o:p&gt;&lt;/p&gt;&lt;p class=3DMsoNormal&gt;Thanks,&lt;o:p&gt;&lt;/o:p&gt;&lt;/=\r\np&gt;&lt;p class=3DMsoNormal&gt;Roger &lt;o:p&gt;&lt;/o:p&gt;&lt;/p&gt;&lt;p class=3DMsoNormal&gt;&lt;o:p&gt;&nbsp=\r\n;&lt;/o:p&gt;&lt;/p&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\r\n------_=_NextPart_001_01CDB120.259156E7--\r\n\n"}}