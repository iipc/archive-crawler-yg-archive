{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":345464853,"authorName":"Ryan Smith","from":"Ryan Smith &lt;ryan.justin.smith@...&gt;","replyTo":"LIST","senderId":"pQj27yJRMqv5xpRC5kIck3xJAxQ-NEkaVJ9QuoknW4zfJCLNZBAtz6F6IhxwNXJHvAluhU2QfR_qDGZ06FOBg662ZNnCiWbyYhpyl7U5fA","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] What Version/Addons of Heritrix to use for web \tscale clustered crawls?","postDate":"1255016580","msgId":6087,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGFlNDc2N2QxMDkxMDA4MDg0M2tkYTIwMDEyeWY5MjhjZTJjYjVlNzNiM2RAbWFpbC5nbWFpbC5jb20+","inReplyToHeader":"PGhha28waytqbnZoQGVHcm91cHMuY29tPg==","referencesHeader":"PGhha28waytqbnZoQGVHcm91cHMuY29tPg=="},"prevInTopic":6086,"nextInTopic":0,"prevInTime":6086,"nextInTime":6088,"topicId":6086,"numMessagesInTopic":2,"msgSnippet":"Hello farbgeist, Sounds like you are looking for something like a project I maintain that is a plugin for heritrix2.  It allows you to write crawls to a","rawEmail":"Return-Path: &lt;ryan.justin.smith@...&gt;\r\nX-Sender: ryan.justin.smith@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 45877 invoked from network); 8 Oct 2009 15:43:02 -0000\r\nX-Received: from unknown (98.137.34.45)\n  by m4.grp.re1.yahoo.com with QMQP; 8 Oct 2009 15:43:02 -0000\r\nX-Received: from unknown (HELO mail-ew0-f211.google.com) (209.85.219.211)\n  by mta2.grp.sp2.yahoo.com with SMTP; 8 Oct 2009 15:43:02 -0000\r\nX-Received: by ewy7 with SMTP id 7so6327508ewy.41\n        for &lt;archive-crawler@yahoogroups.com&gt;; Thu, 08 Oct 2009 08:43:00 -0700 (PDT)\r\nMIME-Version: 1.0\r\nX-Received: by 10.216.91.13 with SMTP id g13mr456900wef.36.1255016580795; Thu, \n\t08 Oct 2009 08:43:00 -0700 (PDT)\r\nIn-Reply-To: &lt;hako0k+jnvh@...&gt;\r\nReferences: &lt;hako0k+jnvh@...&gt;\r\nDate: Thu, 8 Oct 2009 11:43:00 -0400\r\nMessage-ID: &lt;ae4767d10910080843kda20012yf928ce2cb5e73b3d@...&gt;\r\nTo: archive-crawler@yahoogroups.com\r\nContent-Type: multipart/alternative; boundary=0016e6d975e17c4e2604756e51cd\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Ryan Smith &lt;ryan.justin.smith@...&gt;\r\nSubject: Re: [archive-crawler] What Version/Addons of Heritrix to use for web \n\tscale clustered crawls?\r\nX-Yahoo-Group-Post: member; u=345464853\r\n\r\n\r\n--0016e6d975e17c4e2604756e51cd\r\nContent-Type: text/plain; charset=ISO-8859-1\r\n\r\nHello farbgeist,\n\nSounds like you are looking for something like a project I maintain that is\na plugin for heritrix2.  It allows you to write crawls to a webscale\ndatabase, HBase\n\nhttp://code.google.com/p/hbase-writer\n\nEnjoy,\n-Ryan\n\n\n\nOn Thu, Oct 8, 2009 at 9:04 AM, farbgeist &lt;Farbgeist@...&gt; wrote:\n\n&gt;\n&gt;\n&gt; Hello guys,\n&gt;\n&gt; I have dug through this mailing list and found no satisfying answer to my\n&gt; questions, so here I am:\n&gt;\n&gt; We would like to perform a broad crawl of the web, collecting billions of\n&gt; pages and saving just a part of the content for data analysis.\n&gt;\n&gt; For this task we are going to use a number of servers within a cluster. My\n&gt; biggest concern is long time crawl performance as &quot;Already included Uris&quot; as\n&gt; in the pdf &quot;An Introduction to Heretrix&quot; will grow beyond ram size. Is\n&gt; Heretrix 3.0 still using Berkeley DB for this task (which will degrade\n&gt; massively in performance as it outgrows memory)?\n&gt;\n&gt; My second concern is indeed a premise to the first one:\n&gt; How is clustering managed? Is Heretrix 2.0 or 3.0 capable of being\n&gt; clustered using Hadoop? Is NetarchiveSuite the only open project supporting\n&gt; clustering of Heretrix?\n&gt;\n&gt; Best regards\n&gt; farbgeist\n&gt;\n&gt;  \n&gt;\n\r\n--0016e6d975e17c4e2604756e51cd\r\nContent-Type: text/html; charset=ISO-8859-1\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nHello farbgeist,&lt;br&gt;&lt;br&gt;Sounds like you are looking for something like a pr=\r\noject I maintain that is a plugin for heritrix2.=A0 It allows you to write =\r\ncrawls to a webscale database, HBase&lt;br&gt;&lt;br&gt;&lt;a href=3D&quot;http://code.google.c=\r\nom/p/hbase-writer&quot;&gt;http://code.google.com/p/hbase-writer&lt;/a&gt;&lt;br&gt;\n&lt;br&gt;Enjoy,=\r\n&lt;br&gt;-Ryan&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;div class=3D&quot;gmail_quote&quot;&gt;On Thu, Oct 8, 2009 at =\r\n9:04 AM, farbgeist &lt;span dir=3D&quot;ltr&quot;&gt;&lt;&lt;a href=3D&quot;mailto:Farbgeist@...=\r\n&quot;&gt;Farbgeist@...&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt;&lt;blockquote class=3D&quot;gmail_quot=\r\ne&quot; style=3D&quot;border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt =\r\n0.8ex; padding-left: 1ex;&quot;&gt;\n\n\n\n\n\n\n\n\n\n\n\n&lt;div style=3D&quot;background-color: rgb(=\r\n255, 255, 255);&quot;&gt;\n&lt;span&gt;=A0&lt;/span&gt;\n\n&lt;div style=3D&quot;width: 655px;&quot;&gt;\n&lt;div styl=\r\ne=3D&quot;margin: 0pt; padding: 0pt 25px 0pt 0pt; width: 470px; float: left;&quot;&gt;\n\n=\r\n    &lt;div&gt;\n                  &lt;p&gt;Hello guys,&lt;br&gt;\n&lt;br&gt;\nI have dug through this=\r\n mailing list and found no satisfying answer to my questions, so here I am:=\r\n&lt;br&gt;\n&lt;br&gt;\nWe would like to perform a broad crawl of the web, collecting bil=\r\nlions of pages and saving just a part of the content for data analysis. &lt;br=\r\n&gt;\n&lt;br&gt;\nFor this task we are going to use a number of servers within a clust=\r\ner. My biggest concern is long time crawl performance as &quot;Already incl=\r\nuded Uris&quot; as in the pdf &quot;An Introduction to Heretrix&quot; will =\r\ngrow beyond ram size. Is Heretrix 3.0 still using Berkeley DB for this task=\r\n (which will degrade massively in performance as it outgrows memory)?&lt;br&gt;\n\n=\r\n&lt;br&gt;\nMy second concern is indeed a premise to the first one:&lt;br&gt;\nHow is clu=\r\nstering managed? Is Heretrix 2.0 or 3.0 capable of being clustered using Ha=\r\ndoop? Is NetarchiveSuite the only open project supporting clustering of Her=\r\netrix?&lt;br&gt;\n&lt;br&gt;\nBest regards&lt;br&gt;\nfarbgeist&lt;br&gt;\n&lt;br&gt;\n&lt;/p&gt;\n \n\n    &lt;/div&gt;  \n\n =\r\n   \n    &lt;div width=3D&quot;1&quot; style=3D&quot;color: white; clear: both;&quot;&gt;&lt;/div&gt;\n\t\n\t&lt;/d=\r\niv&gt;\n\t\n\t\n\n\n\t\n\n\n\t\n\t\n\t\n\t\n\t\n\n&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;\n\r\n--0016e6d975e17c4e2604756e51cd--\r\n\n"}}