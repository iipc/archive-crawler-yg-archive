{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"QSGaXnELWFniTNYqQ0gcgw74_JsoL7YcyaB84X5vmnovoUqd4whJTRzn2UZfYT6WdxIzgzu_vko9fWZSrUYoofCYs_WfFIo","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] surtprefixscope","postDate":"1191019486","msgId":4573,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ2RkQ4M0RFLjcwODAzMDdAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGZkaHFkMStsMmFyQGVHcm91cHMuY29tPg==","referencesHeader":"PGZkaHFkMStsMmFyQGVHcm91cHMuY29tPg=="},"prevInTopic":4570,"nextInTopic":4577,"prevInTime":4572,"nextInTime":4574,"topicId":4570,"numMessagesInTopic":3,"msgSnippet":"This comes up occasionally, so I started a new FAQ on the project wiki. Let me know if this addresses your question: ","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 95031 invoked from network); 28 Sep 2007 22:44:35 -0000\r\nReceived: from unknown (69.147.108.200)\n  by m49.grp.scd.yahoo.com with QMQP; 28 Sep 2007 22:44:35 -0000\r\nReceived: from unknown (HELO mail.archive.org) (207.241.233.246)\n  by mta1.grp.re1.yahoo.com with SMTP; 28 Sep 2007 22:44:35 -0000\r\nReceived: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id 40FE714199A24\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Fri, 28 Sep 2007 15:44:32 -0700 (PDT)\r\nReceived: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id 26935-10-65 for &lt;archive-crawler@yahoogroups.com&gt;;\n\tFri, 28 Sep 2007 15:44:31 -0700 (PDT)\r\nReceived: from [192.168.1.203] (c-76-102-230-209.hsd1.ca.comcast.net [76.102.230.209])\n\tby mail.archive.org (Postfix) with ESMTP id 21ECE141996CA\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Fri, 28 Sep 2007 15:44:31 -0700 (PDT)\r\nMessage-ID: &lt;46FD83DE.7080307@...&gt;\r\nDate: Fri, 28 Sep 2007 15:44:46 -0700\r\nUser-Agent: Thunderbird 1.5.0.13 (X11/20070824)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;fdhqd1+l2ar@...&gt;\r\nIn-Reply-To: &lt;fdhqd1+l2ar@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Virus-Scanned: Debian amavisd-new at archive.org\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] surtprefixscope\r\nX-Yahoo-Group-Post: member; u=137285340; y=PS6v9hF21K5tmAGmq8c4kqeM4G-n9nUrBEyn7p6bcH1G\r\nX-Yahoo-Profile: gojomo\r\n\r\nThis comes up occasionally, so I started a new FAQ on the project wiki.\n\nLet me know if this addresses your question:\n\nhttp://webteam.archive.org/confluence/display/Heritrix/FAQ#FAQ-gotoffsite\n\n- Gordon @ IA\n\nnickzwk wrote:\n&gt; i want to crawl the following part:\n&gt; \n&gt; http://cn.autoblog.com/category/china/\n&gt; \n&gt; and i set it to the seeds.txt\n&gt; \n&gt; there are 58 page under the\n&gt; http://cn.autoblog.com/category/china/\n&gt; \n&gt; but the crawl results contain 26 page,the mirror has many other host,\n&gt; \n&gt; like&quot;www.google-analytics.com&quot;,&quot;www.gtrnissan.com&quot; and so on,in the \n&gt; folder has no content,just js,php,and asp file, i don&#39;t know the \n&gt; reason why?\n&gt; \n&gt; here is my order.xml,could anyone help analysis it,i don&#39;t know what \n&gt; is \n&gt; \n&gt; the best combination of parameters.\n&gt; \n&gt; order.xml\n&gt; \n&gt; &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;crawl-order \n&gt; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; \n&gt; xsi:noNamespaceSchemaLocation=&quot;heritrix_settings.xsd&quot;&gt;\n&gt;   &lt;meta&gt;\n&gt;     &lt;name&gt;surtprefix_p&lt;/name&gt;\n&gt;     &lt;description&gt;p&lt;/description&gt;\n&gt;     &lt;operator&gt;Admin&lt;/operator&gt;\n&gt;     &lt;organization&gt;&lt;/organization&gt;\n&gt;     &lt;audience&gt;&lt;/audience&gt;\n&gt;     &lt;date&gt;20070928010202&lt;/date&gt;\n&gt;   &lt;/meta&gt;\n&gt;   &lt;controller&gt;\n&gt;     &lt;string name=&quot;settings-directory&quot;&gt;settings&lt;/string&gt;\n&gt;     &lt;string name=&quot;disk-path&quot;&gt;&lt;/string&gt;\n&gt;     &lt;string name=&quot;logs-path&quot;&gt;logs&lt;/string&gt;\n&gt;     &lt;string name=&quot;checkpoints-path&quot;&gt;checkpoints&lt;/string&gt;\n&gt;     &lt;string name=&quot;state-path&quot;&gt;state&lt;/string&gt;\n&gt;     &lt;string name=&quot;scratch-path&quot;&gt;scratch&lt;/string&gt;\n&gt;     &lt;long name=&quot;max-bytes-download&quot;&gt;0&lt;/long&gt;\n&gt;     &lt;long name=&quot;max-document-download&quot;&gt;0&lt;/long&gt;\n&gt;     &lt;long name=&quot;max-time-sec&quot;&gt;0&lt;/long&gt;\n&gt;     &lt;integer name=&quot;max-toe-threads&quot;&gt;50&lt;/integer&gt;\n&gt;     &lt;integer name=&quot;recorder-out-buffer-bytes&quot;&gt;4096&lt;/integer&gt;\n&gt;     &lt;integer name=&quot;recorder-in-buffer-bytes&quot;&gt;65536&lt;/integer&gt;\n&gt;     &lt;integer name=&quot;bdb-cache-percent&quot;&gt;0&lt;/integer&gt;\n&gt;     &lt;newObject name=&quot;scope&quot; \n&gt; class=&quot;org.archive.crawler.scope.SurtPrefixScope&quot;&gt;\n&gt;       &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;string name=&quot;seedsfile&quot;&gt;seeds.txt&lt;/string&gt;\n&gt;       &lt;boolean name=&quot;reread-seeds-on-config&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;integer name=&quot;max-link-hops&quot;&gt;25&lt;/integer&gt;\n&gt;       &lt;integer name=&quot;max-trans-hops&quot;&gt;5&lt;/integer&gt;\n&gt;       &lt;newObject name=&quot;exclude-filter&quot; \n&gt; class=&quot;org.archive.crawler.filter.OrFilter&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;if-matches-return&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;map name=&quot;filters&quot;&gt;\n&gt;         &lt;/map&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;force-accept-filter&quot; \n&gt; class=&quot;org.archive.crawler.filter.OrFilter&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;if-matches-return&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;map name=&quot;filters&quot;&gt;\n&gt;         &lt;/map&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;additionalScopeFocus&quot; \n&gt; class=&quot;org.archive.crawler.filter.FilePatternFilter&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;if-match-return&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;string name=&quot;use-default-patterns&quot;&gt;All&lt;/string&gt;\n&gt;         &lt;string name=&quot;regexp&quot;&gt;&lt;/string&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;transitiveFilter&quot; \n&gt; class=&quot;org.archive.crawler.filter.TransclusionFilter&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;integer name=&quot;max-speculative-hops&quot;&gt;1&lt;/integer&gt;\n&gt;         &lt;integer name=&quot;max-referral-hops&quot;&gt;-1&lt;/integer&gt;\n&gt;         &lt;integer name=&quot;max-embed-hops&quot;&gt;-1&lt;/integer&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;string name=&quot;surts-source-file&quot;&gt;&lt;/string&gt;\n&gt;       &lt;boolean name=&quot;seeds-as-surt-prefixes&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;string name=&quot;surts-dump-file&quot;&gt;&lt;/string&gt;\n&gt;       &lt;boolean name=&quot;also-check-via&quot;&gt;false&lt;/boolean&gt;\n&gt;     &lt;/newObject&gt;\n&gt;     &lt;map name=&quot;http-headers&quot;&gt;\n&gt;       &lt;string name=&quot;user-agent&quot;&gt;Mozilla/5.0 (compatible; \n&gt; heritrix/1.12.1 +http://sktest.com)&lt;/string&gt;\n&gt;       &lt;string name=&quot;from&quot;&gt;test@...&lt;/string&gt;\n&gt;     &lt;/map&gt;\n&gt;     &lt;newObject name=&quot;robots-honoring-policy&quot; \n&gt; class=&quot;org.archive.crawler.datamodel.RobotsHonoringPolicy&quot;&gt;\n&gt;       &lt;string name=&quot;type&quot;&gt;classic&lt;/string&gt;\n&gt;       &lt;boolean name=&quot;masquerade&quot;&gt;false&lt;/boolean&gt;\n&gt;       &lt;text name=&quot;custom-robots&quot;&gt;&lt;/text&gt;\n&gt;       &lt;stringList name=&quot;user-agents&quot;&gt;\n&gt;       &lt;/stringList&gt;\n&gt;     &lt;/newObject&gt;\n&gt;     &lt;newObject name=&quot;frontier&quot; \n&gt; class=&quot;org.archive.crawler.frontier.BdbFrontier&quot;&gt;\n&gt;       &lt;float name=&quot;delay-factor&quot;&gt;4.0&lt;/float&gt;\n&gt;       &lt;integer name=&quot;max-delay-ms&quot;&gt;20000&lt;/integer&gt;\n&gt;       &lt;integer name=&quot;min-delay-ms&quot;&gt;2000&lt;/integer&gt;\n&gt;       &lt;integer name=&quot;max-retries&quot;&gt;30&lt;/integer&gt;\n&gt;       &lt;long name=&quot;retry-delay-seconds&quot;&gt;900&lt;/long&gt;\n&gt;       &lt;integer name=&quot;preference-embed-hops&quot;&gt;1&lt;/integer&gt;\n&gt;       &lt;integer name=&quot;total-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt;       &lt;integer name=&quot;max-per-host-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt;       &lt;string name=&quot;queue-assignment-\n&gt; policy&quot;&gt;org.archive.crawler.frontier.HostnameQueueAssignmentPolicy&lt;/st\n&gt; ring&gt;\n&gt;       &lt;string name=&quot;force-queue-assignment&quot;&gt;&lt;/string&gt;\n&gt;       &lt;boolean name=&quot;pause-at-start&quot;&gt;false&lt;/boolean&gt;\n&gt;       &lt;boolean name=&quot;pause-at-finish&quot;&gt;false&lt;/boolean&gt;\n&gt;       &lt;boolean name=&quot;source-tag-seeds&quot;&gt;false&lt;/boolean&gt;\n&gt;       &lt;boolean name=&quot;recovery-log-enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;boolean name=&quot;hold-queues&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;integer name=&quot;balance-replenish-amount&quot;&gt;3000&lt;/integer&gt;\n&gt;       &lt;integer name=&quot;error-penalty-amount&quot;&gt;100&lt;/integer&gt;\n&gt;       &lt;long name=&quot;queue-total-budget&quot;&gt;-1&lt;/long&gt;\n&gt;       &lt;string name=&quot;cost-\n&gt; policy&quot;&gt;org.archive.crawler.frontier.ZeroCostAssignmentPolicy&lt;/string&gt;\n&gt;       &lt;long name=&quot;snooze-deactivate-ms&quot;&gt;300000&lt;/long&gt;\n&gt;       &lt;integer name=&quot;target-ready-backlog&quot;&gt;50&lt;/integer&gt;\n&gt;       &lt;string name=&quot;uri-included-\n&gt; structure&quot;&gt;org.archive.crawler.util.BdbUriUniqFilter&lt;/string&gt;\n&gt;     &lt;/newObject&gt;\n&gt;     &lt;map name=&quot;uri-canonicalization-rules&quot;&gt;\n&gt;       &lt;newObject name=&quot;Lowercase&quot; \n&gt; class=&quot;org.archive.crawler.url.canonicalize.LowercaseRule&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;Userinfo&quot; \n&gt; class=&quot;org.archive.crawler.url.canonicalize.StripUserinfoRule&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;WWW[0-9]*&quot; \n&gt; class=&quot;org.archive.crawler.url.canonicalize.StripWWWNRule&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;SessionIDs&quot; \n&gt; class=&quot;org.archive.crawler.url.canonicalize.StripSessionIDs&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;SessionCFIDs&quot; \n&gt; class=&quot;org.archive.crawler.url.canonicalize.StripSessionCFIDs&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;QueryStrPrefix&quot; \n&gt; class=&quot;org.archive.crawler.url.canonicalize.FixupQueryStr&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;/newObject&gt;\n&gt;     &lt;/map&gt;\n&gt;     &lt;map name=&quot;pre-fetch-processors&quot;&gt;\n&gt;       &lt;newObject name=&quot;Preselector&quot; \n&gt; class=&quot;org.archive.crawler.prefetch.Preselector&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;Preselector#decide-rules&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;         &lt;boolean name=&quot;override-logger&quot;&gt;false&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;recheck-scope&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;block-all&quot;&gt;false&lt;/boolean&gt;\n&gt;         &lt;string name=&quot;block-by-regexp&quot;&gt;&lt;/string&gt;\n&gt;         &lt;string name=&quot;allow-by-regexp&quot;&gt;&lt;/string&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;Preprocessor&quot; \n&gt; class=&quot;org.archive.crawler.prefetch.PreconditionEnforcer&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;Preprocessor#decide-rules&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;         &lt;integer name=&quot;ip-validity-duration-seconds&quot;&gt;21600&lt;/integer&gt;\n&gt;         &lt;integer name=&quot;robot-validity-duration-\n&gt; seconds&quot;&gt;86400&lt;/integer&gt;\n&gt;         &lt;boolean name=&quot;calculate-robots-only&quot;&gt;false&lt;/boolean&gt;\n&gt;       &lt;/newObject&gt;\n&gt;     &lt;/map&gt;\n&gt;     &lt;map name=&quot;fetch-processors&quot;&gt;\n&gt;       &lt;newObject name=&quot;DNS&quot; \n&gt; class=&quot;org.archive.crawler.fetcher.FetchDNS&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;DNS#decide-rules&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;         &lt;boolean name=&quot;accept-non-dns-resolves&quot;&gt;false&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;digest-content&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;string name=&quot;digest-algorithm&quot;&gt;sha1&lt;/string&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;HTTP&quot; \n&gt; class=&quot;org.archive.crawler.fetcher.FetchHTTP&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;HTTP#decide-rules&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;         &lt;newObject name=&quot;midfetch-decide-rules&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;         &lt;integer name=&quot;timeout-seconds&quot;&gt;1200&lt;/integer&gt;\n&gt;         &lt;integer name=&quot;sotimeout-ms&quot;&gt;20000&lt;/integer&gt;\n&gt;         &lt;integer name=&quot;fetch-bandwidth&quot;&gt;0&lt;/integer&gt;\n&gt;         &lt;long name=&quot;max-length-bytes&quot;&gt;0&lt;/long&gt;\n&gt;         &lt;boolean name=&quot;ignore-cookies&quot;&gt;false&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;use-bdb-for-cookies&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;string name=&quot;load-cookies-from-file&quot;&gt;&lt;/string&gt;\n&gt;         &lt;string name=&quot;save-cookies-to-file&quot;&gt;&lt;/string&gt;\n&gt;         &lt;string name=&quot;trust-level&quot;&gt;open&lt;/string&gt;\n&gt;         &lt;stringList name=&quot;accept-headers&quot;&gt;\n&gt;         &lt;/stringList&gt;\n&gt;         &lt;string name=&quot;http-proxy-host&quot;&gt;&lt;/string&gt;\n&gt;         &lt;string name=&quot;http-proxy-port&quot;&gt;&lt;/string&gt;\n&gt;         &lt;string name=&quot;default-encoding&quot;&gt;ISO-8859-1&lt;/string&gt;\n&gt;         &lt;boolean name=&quot;digest-content&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;string name=&quot;digest-algorithm&quot;&gt;sha1&lt;/string&gt;\n&gt;         &lt;boolean name=&quot;send-if-modified-since&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;send-if-none-match&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;send-connection-close&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;send-referer&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;send-range&quot;&gt;false&lt;/boolean&gt;\n&gt;         &lt;string name=&quot;bind-address&quot;&gt;&lt;/string&gt;\n&gt;       &lt;/newObject&gt;\n&gt;     &lt;/map&gt;\n&gt;     &lt;map name=&quot;extract-processors&quot;&gt;\n&gt;       &lt;newObject name=&quot;ExtractorHTTP&quot; \n&gt; class=&quot;org.archive.crawler.extractor.ExtractorHTTP&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;ExtractorHTTP#decide-rules&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;ExtractorHTML&quot; \n&gt; class=&quot;org.archive.crawler.extractor.ExtractorHTML&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;ExtractorHTML#decide-rules&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;         &lt;boolean name=&quot;extract-javascript&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;treat-frames-as-embed-links&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;ignore-form-action-urls&quot;&gt;false&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;overly-eager-link-detection&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;ignore-unexpected-html&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;/newObject&gt;\n&gt;     &lt;/map&gt;\n&gt;     &lt;map name=&quot;write-processors&quot;&gt;\n&gt;       &lt;newObject name=&quot;MirrorWriter&quot; \n&gt; class=&quot;org.archive.crawler.writer.MirrorWriterProcessor&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;MirrorWriter#decide-rules&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;         &lt;boolean name=&quot;case-sensitive&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;stringList name=&quot;character-map&quot;&gt;\n&gt;         &lt;/stringList&gt;\n&gt;         &lt;stringList name=&quot;content-type-map&quot;&gt;\n&gt;         &lt;/stringList&gt;\n&gt;         &lt;string name=&quot;directory-file&quot;&gt;index.html&lt;/string&gt;\n&gt;         &lt;string name=&quot;dot-begin&quot;&gt;%2E&lt;/string&gt;\n&gt;         &lt;string name=&quot;dot-end&quot;&gt;.&lt;/string&gt;\n&gt;         &lt;stringList name=&quot;host-map&quot;&gt;\n&gt;         &lt;/stringList&gt;\n&gt;         &lt;boolean name=&quot;host-directory&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;string name=&quot;path&quot;&gt;mirror&lt;/string&gt;\n&gt;         &lt;integer name=&quot;max-path-length&quot;&gt;1023&lt;/integer&gt;\n&gt;         &lt;integer name=&quot;max-segment-length&quot;&gt;255&lt;/integer&gt;\n&gt;         &lt;boolean name=&quot;port-directory&quot;&gt;false&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;suffix-at-end&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;string name=&quot;too-long-directory&quot;&gt;LONG&lt;/string&gt;\n&gt;         &lt;stringList name=&quot;underscore-set&quot;&gt;\n&gt;         &lt;/stringList&gt;\n&gt;       &lt;/newObject&gt;\n&gt;     &lt;/map&gt;\n&gt;     &lt;map name=&quot;post-processors&quot;&gt;\n&gt;       &lt;newObject name=&quot;Updater&quot; \n&gt; class=&quot;org.archive.crawler.postprocessor.CrawlStateUpdater&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;Updater#decide-rules&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;LinksScoper&quot; \n&gt; class=&quot;org.archive.crawler.postprocessor.LinksScoper&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;LinksScoper#decide-rules&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;         &lt;boolean name=&quot;override-logger&quot;&gt;false&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;seed-redirects-new-seed&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;integer name=&quot;preference-depth-hops&quot;&gt;-1&lt;/integer&gt;\n&gt;         &lt;newObject name=&quot;scope-rejected-url-rules&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;Scheduler&quot; \n&gt; class=&quot;org.archive.crawler.postprocessor.FrontierScheduler&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;Scheduler#decide-rules&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;       &lt;/newObject&gt;\n&gt;     &lt;/map&gt;\n&gt;     &lt;map name=&quot;loggers&quot;&gt;\n&gt;       &lt;newObject name=&quot;crawl-statistics&quot; \n&gt; class=&quot;org.archive.crawler.admin.StatisticsTracker&quot;&gt;\n&gt;         &lt;integer name=&quot;interval-seconds&quot;&gt;20&lt;/integer&gt;\n&gt;       &lt;/newObject&gt;\n&gt;     &lt;/map&gt;\n&gt;     &lt;string name=&quot;recover-path&quot;&gt;&lt;/string&gt;\n&gt;     &lt;boolean name=&quot;checkpoint-copy-bdbje-logs&quot;&gt;true&lt;/boolean&gt;\n&gt;     &lt;boolean name=&quot;recover-retain-failures&quot;&gt;false&lt;/boolean&gt;\n&gt;     &lt;newObject name=&quot;credential-store&quot; \n&gt; class=&quot;org.archive.crawler.datamodel.CredentialStore&quot;&gt;\n&gt;       &lt;map name=&quot;credentials&quot;&gt;\n&gt;       &lt;/map&gt;\n&gt;     &lt;/newObject&gt;\n&gt;   &lt;/controller&gt;\n&gt; &lt;/crawl-order&gt;\n&gt; \n&gt; crawl-report.txt\n&gt; \n&gt; Crawl Name: surtprefix_p\n&gt; Crawl Status: Finished\n&gt; Duration Time: 1h36m39s656ms\n&gt; Total Seeds Crawled: 1\n&gt; Total Seeds not Crawled: 0\n&gt; Total Hosts Crawled: 17\n&gt; Total Documents Crawled: 965\n&gt; Processed docs/sec: 0.17\n&gt; Bandwidth in Kbytes/sec: 2\n&gt; Total Raw Data Size in Bytes: 17555749 (17 MB) \n&gt; Novel Bytes: 17555749 (17 MB) \n&gt; \n&gt; and i want to know why the speed is slow,\n&gt; \n&gt; tks!\n&gt; \n&gt; \n&gt; \n&gt; \n&gt;  \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n\n"}}