{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":557609883,"authorName":"James Bergamin","from":"James Bergamin &lt;james@...&gt;","profile":"jpbergamin@ymail.com","replyTo":"LIST","senderId":"nlnjaebIJlZZl3e8kg6PXxv5r4Zz7AaOP3wWHb8IgCX5z_OhF3cLmYqdQKy3yCLquzdJBoYIcJ9DxUwcFXq2Hu3Jhp-tHzKS","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Meaning of &quot;Job&quot; and params tweaking","postDate":"1380783930","msgId":8354,"canDelete":false,"contentTrasformed":false,"systemMessage":true,"headers":{"messageIdInHeader":"PENFNzJFMDE0LjdFQkYlamFtZXNAcmFjdGl2ZS5jaD4=","inReplyToHeader":"PDUyNEI0NThFLjIwMEBhcmNoaXZlLm9yZz4="},"prevInTopic":8353,"nextInTopic":0,"prevInTime":8353,"nextInTime":8355,"topicId":8352,"numMessagesInTopic":3,"msgSnippet":"Thank you very much for this detailed explanation, Gordon. I really appreciate that. ... Has there been any work done on making this decision automatically?","rawEmail":"Return-Path: &lt;james@...&gt;\r\nReceived: (qmail 22895 invoked by uid 102); 3 Oct 2013 16:51:54 -0000\r\nReceived: from unknown (HELO mtaq5.grp.bf1.yahoo.com) (10.193.84.36)\n  by m2.grp.bf1.yahoo.com with SMTP; 3 Oct 2013 16:51:54 -0000\r\nReceived: (qmail 27953 invoked from network); 3 Oct 2013 16:51:54 -0000\r\nReceived: from unknown (HELO n5-vm8.bullet.mail.bf1.yahoo.com) (72.30.235.60)\n  by mtaq5.grp.bf1.yahoo.com with SMTP; 3 Oct 2013 16:51:54 -0000\r\nDKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoogroups.com; s=echoe; t=1380819114; bh=jS5y3pzLOsArGkVyMLSmBfLypSmXQGHxVGVcXpbagTw=; h=Received:Received:Received:X-Sender:X-Apparently-To:X-Received:X-Received:X-Received:X-Received:X-No-Relay:X-Received:User-Agent:Date:Message-ID:Thread-Topic:In-Reply-To:Mime-version:Content-type:Content-transfer-encoding:X-Originating-IP:X-eGroups-Msg-Info:From:Subject:X-Yahoo-Group-Post:X-Yahoo-Profile:X-YGroups-SubInfo:To:Sender:X-Yahoo-Newman-Property:X-Yahoo-Newman-Id:X-eGroups-Approved-By:X-eGroups-Auth; b=bQZsrGOCibcZgbDw05rrVKLYktE/N0+vIle/B9s7rRi5/izG4p41LAkCB/fCZ8Wohf5ctJ7nkf8IlgDRIda/xs8g8OktNXtBkizBlbKYYzXAX25MAYv+CGKE+BlJQXxykwROipL/eXZphjCZP/5B1Wq1uf+INY7Mtw0NekrVmUI=\r\nReceived: from [66.196.81.178] by n5.bullet.mail.bf1.yahoo.com with NNFMP; 03 Oct 2013 16:51:54 -0000\r\nReceived: from [10.193.242.235] by t8.bullet.mail.bf1.yahoo.com with NNFMP; 03 Oct 2013 16:51:54 -0000\r\nReceived: from [127.0.0.1] by gapi8.grp.bf1.yahoo.com with NNFMP; 03 Oct 2013 16:49:28 -0000\r\nX-Sender: james@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 35405 invoked by uid 102); 3 Oct 2013 07:05:36 -0000\r\nX-Received: from unknown (HELO mtaq5.grp.bf1.yahoo.com) (10.193.84.36)\n  by m6.grp.bf1.yahoo.com with SMTP; 3 Oct 2013 07:05:36 -0000\r\nX-Received: (qmail 5785 invoked from network); 3 Oct 2013 07:05:35 -0000\r\nX-Received: from unknown (HELO server03.hostfactory.ch) (80.190.246.92)\n  by mtaq5.grp.bf1.yahoo.com with SMTP; 3 Oct 2013 07:05:35 -0000\r\nX-No-Relay: not in my network\r\nX-Received: from [10.183.0.63] (unknown [77.109.141.114])\n\tby server03.hostfactory.ch (Postfix) with ESMTPSA id 6841D1A40F3\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Thu,  3 Oct 2013 09:05:31 +0200 (CEST)\r\nUser-Agent: Microsoft-MacOutlook/14.3.7.130812\r\nDate: Thu, 03 Oct 2013 09:05:30 +0200\r\nMessage-ID: &lt;CE72E014.7EBF%james@...&gt;\r\nThread-Topic: [archive-crawler] Meaning of &quot;Job&quot; and params tweaking\r\nIn-Reply-To: &lt;524B458E.200@...&gt;\r\nMime-version: 1.0\r\nContent-type: text/plain;\n\tcharset=&quot;ISO-8859-1&quot;\r\nContent-transfer-encoding: quoted-printable\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: James Bergamin &lt;james@...&gt;\r\nSubject: Re: [archive-crawler] Meaning of &quot;Job&quot; and params tweaking\r\nX-Yahoo-Group-Post: member; u=557609883; y=OfuT1T91466xB30fkGUt9sanlMyYGfX__5SSaHUMiYDnVQGX53of1QpwjDorSQU\r\nX-Yahoo-Profile: jpbergamin@...\r\nTo: archive-crawler@yahoogroups.com\r\nX-Yahoo-Newman-Property: groups-system\r\nX-Yahoo-Newman-Id: groups-system\r\nX-eGroups-Approved-By: nlevitt via web; 03 Oct 2013 09:49:28 -0000\r\n\r\nThank you very much for this detailed explanation, Gordon. I really\nappreci=\r\nate that.\n\n\n&gt; Historically we thought of jobs as something that would run t=\r\no either\n&gt; completion (emptying of all known queues, via either URI success=\r\n or\n&gt; failure-after-configured-retries), or to a time limit, or to a point\n=\r\n&gt; where the crawl operator looked at the current queues/activity/errors\n&gt; a=\r\nnd decided, &quot;enough for this one&quot;. (Usually, the pattern of\n&gt; success/failu=\r\nre shown in the crawl.log, and names/sizes of remaining\n&gt; non-empty queues,=\r\n are the major factors in such a decision.)\n\n\nHas there been any work done =\r\non making this decision automatically? E.g.\nStop the crawling if the succes=\r\ns/failure ration drops below x percent?\n\n\n&gt; A later launch could either sta=\r\nrt fresh from the same configuration and\n&gt; seeds, as if the prior crawl had=\r\nn&#39;t happened, or with some extra effort\n&gt; import some state from the prior =\r\nlaunch to help avoid collecting or\n&gt; storing duplicate content.\n\n\nWhat need=\r\ns to be done to import this state so that not everything is\ncrawled again i=\r\nn the next run? This could be an interesting use-case for\nus. Something lik=\r\ne an &quot;incremental crawl&quot;.\n\n\n\n\nBest regards,\nJames\n\n\n\n\n\n\n\n\nFrom:  Gordon Moh=\r\nr &lt;gojomo@...&gt;\nReply-To:  &lt;archive-crawler@yahoogroups.com&gt;\nDate:  =\r\nDienstag, 1. Oktober 2013 23:58\nTo:  &lt;archive-crawler@yahoogroups.com&gt;\nSubj=\r\nect:  Re: [archive-crawler] Meaning of &quot;Job&quot; and params\ntweaking\n=\r\n\n\n\n     \n\n      On 9/30/13 12:30 AM, james@... wrote:\n&gt; Hello everyo=\r\nne\n&gt;\n&gt;\n&gt; I just set up heritrix in eclipse and wrote a sample Processor,\n&gt; =\r\nconfigured a job that uses this processor and started a crawling job.\n&gt; Eve=\r\nrything works ok so far.\n&gt;\n&gt; I&#39;m a still not sure about the meaning of a &quot;j=\r\nob&quot;. I setup a test crawl\n&gt; job for 100 URLs and let it run over the weeken=\r\nd. On monday morning, the\n&gt; job still was running. It still tried to crawl =\r\nsome pages that probably\n&gt; had some errors while fetching.\n\n\nA Heritrix &#39;jo=\r\nb&#39; is a grouping of configuration for a particular\npurpose. When you &#39;launc=\r\nh&#39; it, you start a crawl with those settings.\n\n\nOnly some very small and si=\r\nmple jobs, of very narrowly-defined scopes\n(URIs/domains of interest), are =\r\nlikely to run to definitive completion\nin a small amount of time.\n\n\n&gt; So if=\r\n a job with 100 URLs won&#39;t finish after two days, a job with\n&gt; ~100&#39;000 wil=\r\nl definitively will run for weeks. I&#39;m not quite sure how to\n&gt; understand a=\r\n job. Is it something that is long running and new URLs etc.\n&gt; should be ad=\r\nded to a running job? How do I know when it&#39;s a good time to\n&gt; terminate a =\r\njob, e.g. so that only previously failed URLs will be\n&gt; enqueued again?\n\n\nI=\r\nt depends on your goals and judgement. There are infinite paths on the\nweb =\r\n- crawl traps - that can only be heuristically and imperfectly\nassessed. Th=\r\nere are sites that aren&#39;t responding.... but might come back\ntomorrow or ne=\r\nxt week - so it&#39;s a judgement call how many retries to\nallow the crawler.\n\n=\r\n\nHistorically we thought of jobs as something that would run to either\ncomp=\r\nletion (emptying of all known queues, via either URI success or\nfailure-aft=\r\ner-configured-retries), or to a time limit, or to a point\nwhere the crawl o=\r\nperator looked at the current queues/activity/errors\nand decided, &quot;enough f=\r\nor this one&quot;. (Usually, the pattern of\nsuccess/failure shown in the crawl.l=\r\nog, and names/sizes of remaining\nnon-empty queues, are the major factors in=\r\n such a decision.)\n\n\nA later launch could either start fresh from the same =\r\nconfiguration and\nseeds, as if the prior crawl hadn&#39;t happened, or with som=\r\ne extra effort\nimport some state from the prior launch to help avoid collec=\r\nting or\n\nstoring duplicate content.\n\n\nThe faster checkpointing in Heritrix =\r\npost-3.0, and some other features,\ncreate the possibility for running an &quot;e=\r\nternal&quot; job. Sometimes you might\npause it, checkpoint it, turn off its hard=\r\nware or move it to entirely\nnew systems... but then it could resume from wh=\r\nere it left off, and\nperhaps then be prodded into revisiting URIs occording=\r\n to some desired\nschedule. I don&#39;t know of a group doing this quite yet, bu=\r\nt it remains a\npossible idealized mode of operation.\n\n\n&gt; Which params would=\r\n I have to tweak to achieve what we are planning to do?\n&gt; Our use case look=\r\ns as follows:\n&gt;\n&gt;   * Fetch the content of ~100&#39;000 URLs (seeds) once a mon=\r\nth\n&gt;   * Post-process and analyze the content of those URLs and write an\n&gt; =\r\n    index in solr\n\n\nDo you want to fetch only those exact 100,000 URIs, or =\r\na much larger set\nof URIs discoverable from those seed points? That questio=\r\nn will\ndetermine your &#39;scope&#39;. (You could get just those URIs. Or those URI=\r\ns\nplus &#39;inline&#39; embeds, like images, CSS, and JS. Or those URIs and N\nextra=\r\n link-hops away (no matter what domains). Or those URIs and other\nURIs that=\r\n seem to share the same URI-domain/path-prefix as the seeds. Etc.)\n\n\nWatchi=\r\nng what your initial setup achieves after a few days or weeks may\ngive you =\r\nides for how the various politeness, retry, and scope-filtering\nsettings sh=\r\nould be adjusted to get more of what you want, less of what\nyou don&#39;t, acco=\r\nrding to your own preferences for\nerring-towards-inclusion or erring-toward=\r\ns-exclusion. Your target sites\nmight be very different in size, responsiven=\r\ness, crawl-friendliness, etc\nthan other projects&#39; sites... so there&#39;s no on=\r\ne-size-fits-all approach.\n\n\nPost-processing/indexing of the content is a ma=\r\ntter for other tools and\nprocesses... you might be able to feed partial res=\r\nults (while the crawl\nis still in progress) to your indexing, or you might =\r\nneed a &quot;complete&quot;\ndataset.\n\n\n- Gordon\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}}