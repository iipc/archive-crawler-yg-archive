{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"8Nfv_sTetBgyZ_iVYa_OId5qSWxOujq4TsiFqF5jd3ToKvRAO76xVD5v99jtAtBjzW9qr0J_F_cd3HuAlwbb6A7tsOAuyzM","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] Crawl data size discrepancy","postDate":"1282172630","msgId":6686,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRDNkM2NkQ2LjQwNTAwMDZAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGk0Mzk4bStkcmNlQGVHcm91cHMuY29tPg==","referencesHeader":"PGk0Mzk4bStkcmNlQGVHcm91cHMuY29tPg=="},"prevInTopic":6680,"nextInTopic":0,"prevInTime":6685,"nextInTime":6687,"topicId":6680,"numMessagesInTopic":2,"msgSnippet":"I m not saying the choices have been optimal, but by way of explanation: - it hasn t been a goal to make sure reports are re-calculable from the crawl.log -","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 91209 invoked from network); 18 Aug 2010 23:03:54 -0000\r\nX-Received: from unknown (66.196.94.107)\n  by m11.grp.re1.yahoo.com with QMQP; 18 Aug 2010 23:03:54 -0000\r\nX-Received: from unknown (HELO relay03.pair.com) (209.68.5.17)\n  by mta3.grp.re1.yahoo.com with SMTP; 18 Aug 2010 23:03:52 -0000\r\nX-Received: (qmail 63012 invoked from network); 18 Aug 2010 23:03:51 -0000\r\nX-Received: from 208.70.27.190 (HELO silverbook.local) (208.70.27.190)\n  by relay03.pair.com with SMTP; 18 Aug 2010 23:03:51 -0000\r\nX-pair-Authenticated: 208.70.27.190\r\nMessage-ID: &lt;4C6C66D6.4050006@...&gt;\r\nDate: Wed, 18 Aug 2010 16:03:50 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.6; en-US; rv:1.9.2.8) Gecko/20100802 Thunderbird/3.1.2\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: kristsi25 &lt;kris@...&gt;\r\nReferences: &lt;i4398m+drce@...&gt;\r\nIn-Reply-To: &lt;i4398m+drce@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Crawl data size discrepancy\r\nX-Yahoo-Group-Post: member; u=137285340; y=pgg_IqxEjc20-B_TFdnnJBzEZsNJik0mHVzQr-R7WVbu\r\nX-Yahoo-Profile: gojomo\r\n\r\nI&#39;m not saying the choices have been optimal, but by way of explanation:\n\n- it hasn&#39;t been a goal to make sure reports are re-calculable from the \ncrawl.log\n\n- the crawl.log includes protocol-reported content-lengths whenever \npossible so there is an easy 1:1 correlation of numbers from visible \nprotocol fields to crawl.log lines. In particular, for debugging, it&#39;s \nusually more interesting to see that an URL had a &#39;0&#39; or very-small \ncontent-length, than to see a number fuzzed by the somewhat random \nheader-lengths and other overhead.\n\n- the report&#39;s totals have been intended to roughly track two \nsomewhat-conflicting values:\n   - total storage space used/needed\n   - &#39;virtual&#39; content size considered but perhaps not actually \ndownloaded (due a conditional-fetch) or actually stored (because it was \ndeemed to be redundant)\n\nRegarding that last point: we wanted a total-size number reflecting \n&#39;coverage&#39; that would remain comparable between crawls even if later \ncrawls were fetching/storing much less due to deduplication features.\n\nAdjusting the reports (either the labels or tallies) to improve their \nunderstandability and relation to other values is definitely a \npossibility, though for consistency of reporting, that might initially \ntake the form of new, additional report values (so that the old values \nremain comparable to historic values).\n\n- Gordon @ IA\n\nOn 8/13/10 4:11 AM, kristsi25 wrote:\n&gt; There appears to be a discrepancy between the size totals reported in\n&gt; the crawl.log and crawl-report.txt (at least in H3).\n&gt;\n&gt; The crawl-report.txt always relies on CrawlURI.getContentSize() while\n&gt; the crawl.log will use CrawlURI.getContentLength() for most HTTP\n&gt; transactions.\n&gt;\n&gt; At least when deduplication is being used (by hash) there can be a\n&gt; very substantial difference between the value reported in the\n&gt; crawl-report and in the crawl.log, with the crawl.log being much\n&gt; lower.\n&gt;\n&gt; Possibly this is because the size value for duplicate content has\n&gt; been truncated in the recorder underlying curi.getContentLength()?\n&gt; Perhaps when the WarcWriter writes a revisit record? It is not set to\n&gt; zero but the size of detected duplicate is very substantially lower\n&gt; based on the crawl.log than either the crawl-report or the\n&gt; deduplicator processor-report indicate (the latter two both relying\n&gt; on the contentSize are in full agreement about the volume of\n&gt; duplicate data).\n&gt;\n&gt; This discrepancy makes it impossible to rebuild the crawl-report from\n&gt; the crawl.log if a crawl terminates abnormally. Furthermore, it means\n&gt; that the crawl log (at least in some circumstances) is not accurately\n&gt; reflecting the downloaded content.\n&gt;\n&gt; Data example:\n&gt;\n&gt; Both agree on number of URIs\n&gt;\n&gt; novel URIs: 3292190 duplicate-by-hash URIs: 444040 not-modified URIs:\n&gt; 5\n&gt;\n&gt; Total bytes crawl.log:    223672578008 Total bytes crawl-report:\n&gt; 302636807118\n&gt;\n&gt; Novel bytes crawl.log:    199360070847 Novel bytes crawl-report:\n&gt; 200401249064\n&gt;\n&gt; Duplicate bytes crawl.log:     24312507161 Duplicate bytes\n&gt; crawl-report: 102235557274\n&gt;\n&gt; - Kris\n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------\n&gt;\n&gt; Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n\n"}}