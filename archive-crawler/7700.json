{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"8FLvy6dYrieNI1qmLj0D9I2McgTHUHlLHmgPTsN3PnyFwZ-pP-xtB6IkwSNWxmCg3hv2YwpZSQhwTWaW-qC6g-Zf8vQIh0k","spamInfo":{"isSpam":false,"reason":"12"},"subject":"HashCrawlMapper & -63 failures Re: [archive-crawler] Re: Slow (?) loading millions of seeds","postDate":"1337620704","msgId":7700,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRGQkE3OEUwLjgwMDA2MDhAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGpwZGQxNCt0a2w0QGVHcm91cHMuY29tPg==","referencesHeader":"PGpwZGQxNCt0a2w0QGVHcm91cHMuY29tPg=="},"prevInTopic":7699,"nextInTopic":0,"prevInTime":7699,"nextInTime":7701,"topicId":7645,"numMessagesInTopic":9,"msgSnippet":"... Looking up the code in the FetchStatusCodes class which collects such constants, -63 means a URI failed because its own prerequisitite URI (such as a","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 73690 invoked from network); 21 May 2012 17:18:27 -0000\r\nX-Received: from unknown (98.137.34.45)\n  by m14.grp.sp2.yahoo.com with QMQP; 21 May 2012 17:18:27 -0000\r\nX-Received: from unknown (HELO relay03.pair.com) (209.68.5.17)\n  by mta2.grp.sp2.yahoo.com with SMTP; 21 May 2012 17:18:27 -0000\r\nX-Received: (qmail 60495 invoked by uid 0); 21 May 2012 17:12:45 -0000\r\nX-Received: from 76.126.34.95 (HELO ?192.168.1.132?) (76.126.34.95)\n  by relay03.pair.com with SMTP; 21 May 2012 17:12:45 -0000\r\nX-pair-Authenticated: 76.126.34.95\r\nMessage-ID: &lt;4FBA78E0.8000608@...&gt;\r\nDate: Mon, 21 May 2012 10:18:24 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.7; rv:12.0) Gecko/20120428 Thunderbird/12.0.1\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: &quot;Mahmoud A. Mubarak&quot; &lt;mahmoudmubarak@...&gt;\r\nReferences: &lt;jpdd14+tkl4@...&gt;\r\nIn-Reply-To: &lt;jpdd14+tkl4@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: HashCrawlMapper & -63 failures Re: [archive-crawler] Re: Slow (?)\n loading millions of seeds\r\nX-Yahoo-Group-Post: member; u=137285340; y=oP8iX29cUmydIvvmoKU8SCBkGlWFEm7CvFWeG8LVRs48\r\nX-Yahoo-Profile: gojomo\r\n\r\nOn 5/21/12 5:39 AM, Mahmoud A. Mubarak wrote:\n&gt; Thanks Kris,\n&gt;\n&gt; But I have configured crawler-beans.cxml as the link as follows:\n&gt;\n&gt; &lt;bean id=&quot;hashCrawlMapper&quot;\n&gt; class=&quot;org.archive.crawler.processor.HashCrawlMapper&quot;&gt;\n&gt; &lt;property name=&quot;enabled&quot; value=&quot;true&quot; /&gt;\n&gt; &lt;property name=&quot;localName&quot; value=&quot;Crawler_00001&quot; /&gt;\n&gt; &lt;property name=&quot;diversionDir&quot; value=&quot;diversions&quot; /&gt;\n&gt; &lt;property name=&quot;checkUri&quot; value=&quot;true&quot; /&gt;\n&gt; &lt;property name=&quot;checkOutlinks&quot; value=&quot;false&quot;/&gt;\n&gt; &lt;property name=&quot;rotationDigits&quot; value=&quot;10&quot; /&gt;--&gt;\n&gt; &lt;!-- Number of crawlers being used in the multi-machine setup--&gt;\n&gt; &lt;property name=&quot;crawlerCount&quot; value=&quot;2&quot; /&gt;\n&gt; &lt;/bean&gt;\n&gt;\n&gt; &lt;bean id=&quot;candidateProcessors&quot; class=&quot;org.archive.modules.CandidateChain&quot;&gt;\n&gt; &lt;property name=&quot;processors&quot;&gt;\n&gt; &lt;list&gt;\n&gt; .\n&gt; .\n&gt; .\n&gt; &lt;ref bean=&quot;hashCrawlMapper&quot;/&gt;\n&gt; &lt;/list&gt;\n&gt; &lt;/property&gt;\n&gt; &lt;/bean&gt;\n&gt;\n&gt; But the crawl gives status code -63 for all domains on the two machines. I don&#39;t know how to solve this problem.\n\nLooking up the code in the FetchStatusCodes class which collects such \nconstants, -63 means a URI failed because its own prerequisitite URI \n(such as a DNS-lookup or robots-fetch) couldn&#39;t even be tried. That \nsuggests some customization of the settings has prevented normal handling.\n\nLooking at your HashCrawlMapper setup, I see you&#39;ve set the &#39;localName&#39; \nto a descriptive string. Actually, the operation of the mapper expects \nthe name to be a number in the range from 0 to (crawlerCount-1) -- \nessentially the bucket-name into which URIs are hashed. Thus if running \ntwo nodes using this mechanism, their &#39;localName&#39; values should be &#39;0&#39; \nand &#39;1&#39;.\n\nAfter making this change, approximately half your seeds (and other URIs) \nwill be &#39;kept&#39; at the same node, so they (and their prerequisites) \nshould get normal treatment.\n\nHope this helps,\n\n- Gordon\n\n\n\n&gt; Your help is appreciated.\n&gt;\n&gt; --- In archive-crawler@yahoogroups.com, Kris Carpenter Negulescu&lt;kcarpenter@...&gt;  wrote:\n&gt;&gt;\n&gt;&gt; For very large crawls you will want to consider using the HashCrawlMapper to spread the crawl over multiple crawl instances.\n&gt;&gt;\n&gt;&gt; https://webarchive.jira.com/wiki/display/Heritrix/Multiple+Machine+Crawling\n&gt;&gt;\n&gt;&gt; For the volume of seeds you describe, you will want to distribute across 10 or more crawl instances.\n&gt;&gt;\n&gt;&gt; Let us know if you need more detail/help in getting started.\n&gt;&gt;\n&gt;&gt; Kris\n&gt;&gt;\n&gt;&gt; Kris Carpenter Negulescu\n&gt;&gt; Director, Web Group\n&gt;&gt; Internet Archive\n&gt;&gt; kcarpenter@...\n&gt;&gt; skypeid: kris.carpenter\n&gt;&gt;\n&gt;&gt; On Apr 11, 2012, at 12:55 AM, Coram, Roger wrote:\n&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; We&#39;re trying to begin a slash-page crawl of 10,000,000+ seeds using Heritrix 3.0.0. While the initial few million load relatively quickly after a few hours the rate slows to a (pardon the pun) crawl. The time take thus far is now measurable in days.\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; We&#39;ve tried doubling the memory allocated to the JVM, switching to the latest version of Java and tried launching a crawl with Heritrix 3.1.0 for comparison but the results don&#39;t seem noticeably improved. Is this to be expected? How long should 10 or even 20 million seeds optimally take to read? Is there anything obvious we can do to improve things?\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; Many thanks,\n&gt;&gt;&gt;\n&gt;&gt;&gt; Roger\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------\n&gt;\n&gt; Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n\n"}}