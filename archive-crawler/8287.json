{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"mSggWyFzCmHdum2fIvmPX4SkeJ-KmY9auibuUIHEpZE-fcEyWMwEndwgdX92BTsK6KRn2OC74AwfryZU48pCYSSK9y-_TjE","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Re: Heritix doesn&#39;t observe limit on number of documents","postDate":"1375847078","msgId":8287,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDUyMDFDMkE2LjQwMTA5MDZAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGt0cXBlbCtxcmtoQGVHcm91cHMuY29tPg==","referencesHeader":"PGt0cXBlbCtxcmtoQGVHcm91cHMuY29tPg=="},"prevInTopic":8286,"nextInTopic":0,"prevInTime":8286,"nextInTime":8288,"topicId":8278,"numMessagesInTopic":5,"msgSnippet":"... For all of these, you ll want to review the User Guide... https://webarchive.jira.com/wiki/display/Heritrix/Heritrix+3.0+and+3.1+User+Guide ...and","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 88557 invoked by uid 102); 7 Aug 2013 03:44:43 -0000\r\nX-Received: from unknown (HELO mtaq2.grp.bf1.yahoo.com) (10.193.84.33)\n  by m3.grp.bf1.yahoo.com with SMTP; 7 Aug 2013 03:44:43 -0000\r\nX-Received: (qmail 16902 invoked from network); 7 Aug 2013 03:44:43 -0000\r\nX-Received: from unknown (HELO relay02.pair.com) (209.68.5.16)\n  by mtaq2.grp.bf1.yahoo.com with SMTP; 7 Aug 2013 03:44:43 -0000\r\nX-Received: (qmail 7689 invoked by uid 0); 7 Aug 2013 03:44:41 -0000\r\nX-Received: from 12.46.132.146 (HELO silverbook.local) (12.46.132.146)\n  by relay02.pair.com with SMTP; 7 Aug 2013 03:44:41 -0000\r\nX-pair-Authenticated: 12.46.132.146\r\nMessage-ID: &lt;5201C2A6.4010906@...&gt;\r\nDate: Tue, 06 Aug 2013 20:44:38 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.8; rv:17.0) Gecko/20130620 Thunderbird/17.0.7\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;ktqpel+qrkh@...&gt;\r\nIn-Reply-To: &lt;ktqpel+qrkh@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Re: Heritix doesn&#39;t observe limit on number\n of documents\r\nX-Yahoo-Group-Post: member; u=137285340; y=NQAUty2N3UUsPKyeHQlVLZgpff-SB3VIrxQ10y8HD-u4\r\nX-Yahoo-Profile: gojomo\r\n\r\nOn 8/6/13 5:16 AM, Arian wrote:\n&gt; I didn&#39;t know of anything other than CrawlLimitEnforcer. Could you\n&gt; please tell how can I add a QuotaEnforcer? Here&#39;s another question:\n&gt; how can I exclude pictures and videos from crawl results? (I\n&gt; apologize if I should&#39;ve started another thread to ask that.) Is\n&gt; there a place I can learn more about Heritrix? Like what I just\n&gt; asked, there&#39;s a lot I don&#39;t know about setting a crawl up and\n&gt; running the way I want, and I couldn&#39;t get much out of the wiki.\n\nFor all of these, you&#39;ll want to review the User Guide...\n\nhttps://webarchive.jira.com/wiki/display/Heritrix/Heritrix+3.0+and+3.1+User+Guide\n\n...and especially any sections on &#39;scoping&#39;/DecideRules (which control \nwhich URIs are eligible for enqueuing) and the individual &#39;processing \nchains&#39;, where you can add extra modules which work on a URI at a time, \nfor new features.\n\nIn particular, the QuotaEnforcer is a module added early to the \n&#39;fetching&#39; chain that considers (and possibly early-rejects) URIs before \na fetch is attempted.\n\nThe &#39;common heritrix use cases&#39; pages there have some scenarios vaguely \nsimilar to your needs which might help:\n\nhttps://webarchive.jira.com/wiki/display/Heritrix/Common+Heritrix+Use+Cases\n\nAs do some of the  other FAQs:\n\nhttps://webarchive.jira.com/wiki/display/Heritrix/FAQs\n\nUltimately to best understand the advanced options -- modules like \nQuotaEnforcer -- it helps to be able to skim the source code and its \n&#39;javadoc&#39; comments, and understand how the &#39;cxml&#39; configuration format \nis used to plug objects together (which is explained in the Spring \nproject&#39;s developer documentation).\n\nHope this helps a bit,\n\n- Gordon\n\n&gt; --- In archive-crawler@yahoogroups.com, Gordon Mohr &lt;gojomo@...&gt;\n&gt; wrote:\n&gt;&gt;\n&gt;&gt; On 8/3/13 11:02 PM, Arian wrote:\n&gt;&gt;&gt; Hi Everyone,\n&gt;&gt;&gt;\n&gt;&gt;&gt; I&#39;m using Heritrix 3.1.1 to crawl the contents of a number of\n&gt;&gt;&gt; sites. I want it to get 10 pages from each seed, not including\n&gt;&gt;&gt; pages from outlinks of the seed. I set the number of documents\n&gt;&gt;&gt; limit in the configuration file to 10, and it passed that. Set it\n&gt;&gt;&gt; to 20, passed it again. If that&#39;s not the right tweak, where\n&gt;&gt;&gt; should I set the limit for it to work? About leaving out external\n&gt;&gt;&gt; pages, I have 100+ sites to crawl, so I can&#39;t set regexes\n&gt;&gt;&gt; matching every single URL (and don&#39;t know if there&#39;s a better way\n&gt;&gt;&gt; rather than that.)\n&gt;&gt;&gt;\n&gt;&gt;&gt; I&#39;d appreciate any help.\n&gt;&gt;\n&gt;&gt; It&#39;s unclear what you&#39;ve tried. There&#39;s no setting in the standard\n&gt;&gt; configuration which would exactly limit the crawl to 10 &quot;pages&quot;\n&gt;&gt; &quot;from each seed&quot; and &quot;not including outlinks of the seed&quot;. (Those\n&gt;&gt; descriptions could mean a variety of things.)\n&gt;&gt;\n&gt;&gt; (If the crawl seems to be getting URIs from more sites than you\n&gt;&gt; expected, you should check out the FAQ entry at:\n&gt;&gt;\n&gt;&gt; https://webarchive.jira.com/wiki/display/Heritrix/unexpected+offsite+content\n&gt;&gt;\n&gt;&gt;\n)\n&gt;&gt;\n&gt;&gt; The &#39;CrawlLimitEnforcer&#39; which you may have seen sets\n&gt;&gt; count/size/time limits for the entire crawl, not individual sites.\n&gt;&gt;\n&gt;&gt; The optional QuotaEnforcer processor can be added to the\n&gt;&gt; &#39;prefetch&#39; chain, and then can reject URIs after certain configured\n&gt;&gt; counts of URIs per hostname/server/&#39;group&#39; are reached. (Server =\n&gt;&gt; hostname+port; &#39;group&#39; is usually the same as server unless using\n&gt;&gt; some advanced frontier configuration.)\n&gt;&gt;\n&gt;&gt; QuotaEnforcer is probably what you want... is this what you tried?\n&gt;&gt;\n&gt;&gt; (An alternate way to get a similar effect is by adjusting the\n&gt;&gt; &#39;queueTotalBudget&#39; frontier setting, which stops crawling URIs from\n&gt;&gt; a queue -- same as &#39;group&#39; above -- after a certain amount of\n&gt;&gt; effort is expended, with the usual policy being roughly one URI\n&gt;&gt; equals one unit of effort. But, QuotaEnforcer is likely the better\n&gt;&gt; approach unless you need to understand the frontier internals.)\n&gt;&gt;\n&gt;&gt; - Gordon\n&gt;&gt;\n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------\n&gt;\n&gt; Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n\n"}}