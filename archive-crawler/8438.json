{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"p-2OxdBv2tDru5vlGrAmEt76aik-dIi67Q5DOjux5fEeBGuxaPhd1fAh_KlJUaDeLVXfzmsR17-kYFxa7mQbCImfcc3v-K4","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Heritrix 3.1.0 CSS crawling problem","postDate":"1387416878","msgId":8438,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDUyQjI0RDJFLjUwMzA4MDVAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGw4c29qditxOWY5cHBAWWFob29Hcm91cHMuY29tPg==","referencesHeader":"PGw4c29qditxOWY5cHBAWWFob29Hcm91cHMuY29tPg=="},"prevInTopic":8437,"nextInTopic":8439,"prevInTime":8437,"nextInTime":8439,"topicId":8437,"numMessagesInTopic":5,"msgSnippet":"... Did you let the crawl run until all discovered URIs were collected, or perhaps stop it early? Have you looked through all the other logs of the crawl to","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 47265 invoked by uid 102); 19 Dec 2013 01:34:44 -0000\r\nX-Received: from unknown (HELO mtaq3.grp.bf1.yahoo.com) (10.193.84.142)\n  by m9.grp.bf1.yahoo.com with SMTP; 19 Dec 2013 01:34:44 -0000\r\nX-Received: (qmail 9677 invoked from network); 19 Dec 2013 01:34:44 -0000\r\nX-Received: from unknown (HELO relay00.pair.com) (209.68.5.9)\n  by mtaq3.grp.bf1.yahoo.com with SMTP; 19 Dec 2013 01:34:44 -0000\r\nX-Received: (qmail 45365 invoked by uid 0); 19 Dec 2013 01:34:42 -0000\r\nX-Received: from 50.0.190.26 (HELO probook.local) (50.0.190.26)\n  by relay00.pair.com with SMTP; 19 Dec 2013 01:34:42 -0000\r\nX-pair-Authenticated: 50.0.190.26\r\nMessage-ID: &lt;52B24D2E.5030805@...&gt;\r\nDate: Wed, 18 Dec 2013 17:34:38 -0800\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:24.0) Gecko/20100101 Thunderbird/24.2.0\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;l8sojv+q9f9pp@...&gt;\r\nIn-Reply-To: &lt;l8sojv+q9f9pp@...&gt;\r\nContent-Type: text/plain; charset=UTF-8; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Heritrix 3.1.0 CSS crawling problem\r\nX-Yahoo-Group-Post: member; u=137285340; y=HiwVRKTNTQmSNZ85vTjt8cUlt47U2q-_0KNhkl3m2bo9\r\nX-Yahoo-Profile: gojomo\r\n\r\nOn 12/18/13, 10:13 AM, abey.uma7@... wrote:\n&gt; I&#39;m using Heritrix 3.1.0 and I have a seed http://www.mrt.ac.lk/web/.\n&gt; But when I try to recreate this in wayback, I could see some css files\n&gt; are missing. Then I checked in the crawl log and there is no entries for\n&gt; those URI.\n\nDid you let the crawl run until all discovered URIs were collected, or \nperhaps stop it early?\n\nHave you looked through all the other logs of the crawl to see if these \nURIs are mentioned elsewhere, as possible errors that didn&#39;t result in a \ncrawl.log success/failure line?\n\n&gt; I have set max-path-depth = 13.\n\nThere&#39;s no &quot;max-path-depth&quot; property, though there is &quot;maxPathDepth&quot; - \ngetting the names precisely right is important. But, since the URI \n&#39;path&#39; this setting refers to is essentially &quot;count of slashes after the \nhostname in the URI&quot;, and your example missed-URIs do not have 13 or \nmore slashes, this property would not affect their selection/collection.\n\nHowever, if you&#39;ve customized the scope in other ways, perhaps these \nURIs were eliminated from consideration. Discovered URIs that fail \nscope-testing aren&#39;t logged in the crawl.log.\n\n&gt; The URI which are not in the crawl log are as follows.\n&gt;\n&gt; http://www.mrt.ac.lk/web/sites/all/themes/nucleus/nucleus/nucleus/css/base.css?mupdwq\n&gt; http://www.mrt.ac.lk/web/sites/all/themes/nucleus/nucleus/nucleus/css/messages.css?mupdwq\n&gt; http://www.mrt.ac.lk/web/sites/all/themes/nucleus/nucleus/nucleus/js/jquery.cookie.js?mupdwq\n&gt;\n&gt; Can you please tell me a reason for this and a solution for this?\n\nThere is no general solution: you have to zoom in on the specifics of \nyour settings and target site.\n\nFor a URI to be collected it has to be (1) discovered via seeds or \nanother visited URI; (2) accepted by the scope rules and thus enqueued \nfor collection; (3) fetched when the crawler gets around to it.\n\nIf an expected URI isn&#39;t in your crawl.log and collected material, it \nfailed one of these three steps.\n\nOne technique that is often helpful when figuring out why a specific \npage and its included materials isn&#39;t collected as expected is to create \na reduced test crawl, based on your real settings, of a single page and \nits outlinks.\n\nSo, for one of the CSS URIs that are missing, discover the URI that \nreferences it and is in your collection. Try a test crawl, with your \nusual settings, of just that single URI â€“ but adjust the the \nTooManyHopsDecideRule &#39;maxHops&#39; value to 1. (Such a crawl of a page and \nits own 1-hop outlinks will finish quite quickly.)\n\nThen you have much smaller activity and error logs to look over. If such \na simple crawl doesn&#39;t get the CSS, you need to look more closely why \nthat might be, in your crawl customizations and the specific \nsingle-page&#39;s design. (Are the URIs created by Javascript the crawler \ndoesn&#39;t interpret? Are other similar CSS URIs on the page retrieved but \nyour targets aren&#39;t, and if so is there something unique about the \nmissed ones?) If the simple crawl does get the CSS, then something went \nwrong with the larger crawl preventing it from getting-around the \nfetching the CSS. (Maybe it was stopped early.)\n\nGood luck!\n\n- Gordon\n\n"}}