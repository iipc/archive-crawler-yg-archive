{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":172190008,"authorName":"Andy Boyko","from":"Andy Boyko &lt;aboy@...&gt;","profile":"andyboyko","replyTo":"LIST","senderId":"9iOmoubatwwEXPz6pPhT18owbdYTMhpne7sysTYxCoHNvj4EVYa45KxKVN4F_kotcB97IMMAm0OKuVtnqhcfwg","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Out-of-the-box defaults?","postDate":"1087936783","msgId":550,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQwRDg5OTBGLjgwOTAyMDRAbG9jLmdvdj4=","inReplyToHeader":"PDQwQzhGNkUxLjkwOUBhcmNoaXZlLm9yZz4=","referencesHeader":"PDQwQzhEN0ZBLjUwNTAyQGxvYy5nb3Y+IDw0MEM4RjZFMS45MDlAYXJjaGl2ZS5vcmc+"},"prevInTopic":529,"nextInTopic":561,"prevInTime":549,"nextInTime":551,"topicId":528,"numMessagesInTopic":4,"msgSnippet":"I m belatedly responding to Igor s thoughtful response about what the out-of-the-box configuration should be like.  Based on his comments, I ve got a patch to","rawEmail":"Return-Path: &lt;aboy@...&gt;\r\nX-Sender: aboy@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 35186 invoked from network); 22 Jun 2004 20:43:55 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m15.grp.scd.yahoo.com with QMQP; 22 Jun 2004 20:43:55 -0000\r\nReceived: from unknown (HELO sun8.loc.gov) (140.147.249.48)\n  by mta1.grp.scd.yahoo.com with SMTP; 22 Jun 2004 20:43:55 -0000\r\nReceived: from [140.147.131.81] (amerprt1.loc.gov [140.147.131.81])\n\tby sun8.loc.gov  with ESMTP id i5MKdhVT023138\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Tue, 22 Jun 2004 16:39:44 -0400 (EDT)\r\nMessage-ID: &lt;40D8990F.8090204@...&gt;\r\nDate: Tue, 22 Jun 2004 16:39:43 -0400\r\nUser-Agent: Mozilla Thunderbird 0.7 (Windows/20040616)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;40C8D7FA.50502@...&gt; &lt;40C8F6E1.909@...&gt;\r\nIn-Reply-To: &lt;40C8F6E1.909@...&gt;\r\nContent-Type: multipart/mixed;\n boundary=&quot;------------040507010806080507040709&quot;\r\nX-eGroups-Remote-IP: 140.147.249.48\r\nFrom: Andy Boyko &lt;aboy@...&gt;\r\nSubject: Re: [archive-crawler] Out-of-the-box defaults?\r\nX-Yahoo-Group-Post: member; u=172190008\r\nX-Yahoo-Profile: andyboyko\r\n\r\n\r\n--------------040507010806080507040709\r\nContent-Type: text/plain; charset=us-ascii; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\n\r\nI&#39;m belatedly responding to Igor&#39;s thoughtful response about what the \nout-of-the-box configuration should be like.  Based on his comments, \nI&#39;ve got a patch to the initial profile&#39;s order.xml (as of Heritrix \n0.10.0) which makes the following changes:\n\n  - enables the CSS and SWF extractors\n  - adds the PathDepth filter and PathologicalPath filters to the\n    exclude filter of the scope, with the default depth of 20 and\n    default path repetitions of 3.\n  - enables recheck-scope in the Preselector, which was necessary\n    to support the above filters correctly\n\nShould this patch be applied to the initial profile?  I&#39;d like the \nextractors turned on, and am agnostic about the filters (but note that \nit&#39;s tricky to get those filters configured so they actually work, so if \nit&#39;s not on in the default, it needs documenting).\n\nNote that there are a few other changes in there, as the profile was \nedited by the Web UI, and so it reflects the values written by the code. \n  Nothing significant except for the addition of what I guess are a few \nnew configurations.\n\nRegards,\nAndy Boyko  aboy@...\nLibrary of Congress\n\n\nIgor Ranitovic wrote:\n&gt;&gt;- Invocation: it seems pretty clear that crawls are safest with some \n&gt;&gt;memory headroom.  Can the bin/heritrix script default JAVA_OPTS to \n&gt;&gt;&quot;-Xmx256m&quot; if it&#39;s not otherwise set?\n&gt; \n&gt; \n&gt; Sure. Maybe we should adopt IBM&#39;s JVM approach where default size of the heap is a half of a \n&gt; system&#39;s physical memory.\n&gt; \n&gt; \n&gt;&gt;- Extractors: how experimental are the non-enabled variants?  I recall \n&gt;&gt;that in February, we were encouraged to use HTML2 and CSS, but that some \n&gt;&gt;leaked memory (PDF?  DOC?  SWF?).  Is it safe to change the defaults to, \n&gt;&gt;at the least, include CSS?  Of the potentially leaky ones, SWF seems the \n&gt;&gt;most compelling for enabling by default.\n&gt; \n&gt; \n&gt; We should have HTTP, HTML, CSS, JS and SWF be defualt extractors.\n&gt; We changed SWF extractor to use memory more efficiently and I have not have memory problems with it \n&gt; since.\n&gt; PDF and DOC extractors are still problematic. I have been working on a new, more memory efficient \n&gt; PDF extractor but is not ready yet. DOC parsing is a problem since DOCs cannot be parsed by treating \n&gt; them as randomly accesable streams. Beacause of this it is necessary to load entire DOCs into memory \n&gt; in order to parse them.\n&gt; HTML2 extractor(horrible name btw) is making two passes on javascript code. One pass examains all \n&gt; strings in javascript code and second pass parses javascript code as html. HTML extractor is making \n&gt; only the fisrt pass. I believe that HTML extracotr got better and that there is no need of HTML2 \n&gt; anymore.\n&gt; I will have to do some comparison to confirm this.\n&gt; \n&gt; \n&gt;&gt;- Filters: If I understand the &quot;recheck-scope&quot; setting on the \n&gt;&gt;preselector, it needs to be set for scope changes during the crawl to be \n&gt;&gt;detected and honored.  Assuming it doesn&#39;t affect performance too much, \n&gt;&gt;can it default to on?\n&gt; \n&gt; \n&gt; I have no preferences on this one. Though, it seems right as is.\n&gt; \n&gt; \n&gt;&gt;Is it worthwhile to enable by default either PathDepth or \n&gt;&gt;PathologicalPath filters, presumably with generous but non-infinite values?\n&gt; \n&gt; \n&gt; I agree. I usually set PathDepth to 20 and PathologicalPath to max of 3 repetitions of a pattern.\n&gt; \n&gt; \n&gt;&gt;- Politeness: I know per-host bandwidth usage got moved to the &quot;expert&quot; \n&gt;&gt;section, but it might be good to default the per-host cap to something \n&gt;&gt;maybe T1-like (thus, perhaps 150KBps or so) to avoid pummelling sites \n&gt;&gt;with large files, when crawling from a large pipe.  (Is the per-host cap \n&gt;&gt;like the total-bandwidth cap, in that it doesn&#39;t actually constrain \n&gt;&gt;instantaneous traffic, only the average?)\n&gt; \n&gt; \n&gt; I am not sure if need to do this. It seems that default values of dynamic politeness will \n&gt; significantly delay request to sites with large files when crawling from a large pipe.\n&gt; During fetching we just might be OK by relying on TCP&#39;s congestion control and not worry about \n&gt; solely saturating the sites&#39; bandwidth.\n&gt; \n&gt; Take care.\n&gt; i.\n&gt; \n&gt; \n&gt; \n&gt;  \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n&gt;  \n&gt; \n&gt; \n\n\r\n--------------040507010806080507040709\r\nContent-Type: text/plain;\n name=&quot;order.xml.patch&quot;\r\nContent-Disposition: inline;\n filename=&quot;order.xml.patch&quot;\r\n\r\n[ Attachment content not displayed ]\r\n--------------040507010806080507040709--\r\n\n"}}