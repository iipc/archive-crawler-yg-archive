{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"stack","from":"stack &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"zIv7Gad1h1eq02FFmtsvvwDnjVVB_DjQUMbb5ftuZC1CP1O2BWK_KOhdl1YPbKrE8GhZsheXksO_rwSsH_SY3w","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] keeping threads active during crawls","postDate":"1109706291","msgId":1632,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQyMjRDNjMzLjUwNzA3MDBAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDYuMi4wLjE0LjIuMjAwNTAyMjgxNDA1MzAuMDJiM2YxZThAdmhvc3Q2LmF0b21pY3NlcnZlcnMuY29tPg==","referencesHeader":"PDYuMi4wLjE0LjIuMjAwNTAyMjgxNDA1MzAuMDJiM2YxZThAdmhvc3Q2LmF0b21pY3NlcnZlcnMuY29tPg=="},"prevInTopic":1622,"nextInTopic":1633,"prevInTime":1631,"nextInTime":1633,"topicId":1622,"numMessagesInTopic":8,"msgSnippet":"... We re looking into adding accounting that will allow the running of multiple crawls inside of a single running instance -- More to follow on this after it","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 31645 invoked from network); 1 Mar 2005 19:53:41 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m24.grp.scd.yahoo.com with QMQP; 1 Mar 2005 19:53:41 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (207.241.224.172)\n  by mta5.grp.scd.yahoo.com with SMTP; 1 Mar 2005 19:53:41 -0000\r\nReceived: (qmail 25103 invoked by uid 100); 1 Mar 2005 19:36:41 -0000\r\nReceived: from debord.archive.org (HELO ?207.241.238.140?) (stack@...@207.241.238.140)\n  by mail-dev.archive.org with SMTP; 1 Mar 2005 19:36:41 -0000\r\nMessage-ID: &lt;4224C633.5070700@...&gt;\r\nDate: Tue, 01 Mar 2005 11:44:51 -0800\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.7.3) Gecko/20041007 Debian/1.7.3-5\r\nX-Accept-Language: en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;6.2.0.14.2.20050228140530.02b3f1e8@...&gt;\r\nIn-Reply-To: &lt;6.2.0.14.2.20050228140530.02b3f1e8@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=0.7 required=6.0 tests=AWL,CLICK_BELOW autolearn=no \n\tversion=2.63\r\nX-eGroups-Remote-IP: 207.241.224.172\r\nFrom: stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] keeping threads active during crawls\r\nX-Yahoo-Group-Post: member; u=168599281\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\nMike Schwartz wrote:\n\n&gt; hi,\n&gt;\n&gt; I need to run a series of DomainScope crawls.  I notice that each such \n&gt; crawl gets good thread parallelism for quite a while but then gets to \n&gt; a point where most of what&#39;s left to do is crawling many pages within \n&gt; a small number of sites (e.g., all the product pages at each of a few \n&gt; sites).  At that point only a few points are active, and make very \n&gt; slow progress because I only visit each site once every few seconds.\n\n&gt;\n&gt; This problem wouldn&#39;t arise if I were doing a broad-scope crawl, since \n&gt; at any point in time there are more sites left to crawl than there are \n&gt; available threads.\n&gt;\n&gt; Does anyone have a suggestion how I could keep most/all of the threads \n&gt; active during a sequence of DomainScope crawls?  I could try adding a \n&gt; new set of sites when I get down to the state of many pages left \n&gt; within just a few sites, but it seems to me that&#39;s a problem because \n&gt; in essence I&#39;m running one much larger crawl instead of a set of \n&gt; limited scope crawls - and if that crawl gets into a bad state and I \n&gt; have to kill it, I don&#39;t end up knowing exactly which parts of which \n&gt; sites have completed being crawled.\n\nWe&#39;re looking into adding accounting that will allow the running of \nmultiple crawls inside of a single running instance -- More to follow on \nthis after it gets flushed out -- but until then, running an instance \nper crawl seems to be your only option.\n\nDo you have sufficent resources to start up a new crawl instance to go \nagainst a new domain on the machine that has the trailing-off crawl \nrunning on it?  Or are your crawls up against Heritrix bounds? \n\nWhen we have a checkpointing system in place, you&#39;ll be able to \ncheckpoint the dying crawl, stop it, and then restart it inside of a \nsmaller heap letting it crawl to completion making room to run the new \ncrawl.\n\nSt.Ack\n\n&gt;\n&gt; (I&#39;ve tried restarting crawls from recover.gz, but haven&#39;t been \n&gt; sucessful with that - I get out-of-memory errors, even when I set the \n&gt; JVM to have 1 GB of RAM or more.)\n\n\n\n\n&gt;\n&gt; thanks\n&gt;  - Mike Schwartz\n&gt;    Aptas, Inc.\n&gt; *Yahoo! Groups Sponsor*\n&gt; ADVERTISEMENT\n&gt; click here \n&gt; &lt;http://us.ard.yahoo.com/SIG=129jkuth1/M=298184.6018725.7038619.3001176/D=groups/S=1705004924:HM/EXP=1109711161/A=2593423/R=0/SIG=11el9gslf/*http://www.netflix.com/Default?mqso=60190075&gt; \n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------------------------------------------\n&gt; *Yahoo! Groups Links*\n&gt;\n&gt;     * To visit your group on the web, go to:\n&gt;       http://groups.yahoo.com/group/archive-crawler/\n&gt;        \n&gt;     * To unsubscribe from this group, send an email to:\n&gt;       archive-crawler-unsubscribe@yahoogroups.com\n&gt;       &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;        \n&gt;     * Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;.\n&gt;\n&gt;\n\n\n"}}