{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":325624130,"authorName":"Noah Levitt","from":"Noah Levitt &lt;nlevitt@...&gt;","profile":"nlevitt","replyTo":"LIST","senderId":"KcHiH7ioOhI_jADU7RgmGtAy7UgE4ldnY0-mN5RRXNqPL0oqT3EuqQduzNb18jknq8E-KM30GV6b99DVQlKMTIw7D7UpiyBF","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Crawling forever - vs. nutch","postDate":"1323741075","msgId":7432,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRFRTZBRjkzLjcwODA4MDZAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGpiZDZtNys1NW42QGVHcm91cHMuY29tPg==","referencesHeader":"PGpiZDZtNys1NW42QGVHcm91cHMuY29tPg=="},"prevInTopic":7416,"nextInTopic":0,"prevInTime":7431,"nextInTime":7433,"topicId":7416,"numMessagesInTopic":2,"msgSnippet":"Hello Unreal, Your configuration rejects images based on the url. But it s possible, in fact very common, for a gif url to end in something other than .gif. ","rawEmail":"Return-Path: &lt;nlevitt@...&gt;\r\nX-Sender: nlevitt@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 51617 invoked from network); 13 Dec 2011 01:51:18 -0000\r\nX-Received: from unknown (98.137.34.45)\n  by m5.grp.sp2.yahoo.com with QMQP; 13 Dec 2011 01:51:18 -0000\r\nX-Received: from unknown (HELO mail.archive.org) (207.241.224.6)\n  by mta2.grp.sp2.yahoo.com with SMTP; 13 Dec 2011 01:51:18 -0000\r\nX-Received: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id 58F016841079;\n\tMon, 12 Dec 2011 17:51:18 -0800 (PST)\r\nX-Received: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id J3AHpVMiQAYT; Mon, 12 Dec 2011 17:51:15 -0800 (PST)\r\nX-Received: from [208.70.27.155] (desktop-nlevitt.sf.archive.org [208.70.27.155])\n\tby mail.archive.org (Postfix) with ESMTPSA id 3D5646840151;\n\tMon, 12 Dec 2011 17:51:15 -0800 (PST)\r\nMessage-ID: &lt;4EE6AF93.7080806@...&gt;\r\nDate: Mon, 12 Dec 2011 17:51:15 -0800\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux x86_64; en-US; rv:1.9.2.23) Gecko/20110922 Thunderbird/3.1.15\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: Unreal &lt;gc76@...&gt;\r\nReferences: &lt;jbd6m7+55n6@...&gt;\r\nIn-Reply-To: &lt;jbd6m7+55n6@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nFrom: Noah Levitt &lt;nlevitt@...&gt;\r\nSubject: Re: [archive-crawler] Crawling forever - vs. nutch\r\nX-Yahoo-Group-Post: member; u=325624130; y=1xsfZVGdBtzljAStV45e9p5XsBi0ILNMmiZLmakklxArvg\r\nX-Yahoo-Profile: nlevitt\r\n\r\nHello Unreal,\n\nYour configuration rejects images based on the url. But it&#39;s possible, \nin fact very common, for a gif url to end in something other than .gif. \nThis probably explains your results. There are a few things you can do.\n\n- Look through the undesired urls in crawl.log and look for a pattern, \nand tailor a decide rule to that.\n- Not archive fetched images. You can put decide rules on your \nWARCWriter to prevent it from archiving images. They will still be \ncrawled, still show up in crawl.log and still slow down the rest of your \ncrawl. So this is a good option mainly if disk space is your concern.\n- Reject based on the context where the url is discovered. For instance \nif it&#39;s from an &lt;img&gt; tag, don&#39;t crawl it. Unfortunately there&#39;s not an \neasy way to do this with heritrix currently. However it should be \npossible using a ScriptedDecideRule.\n\nAnother option is to crawl the gifs and not worry about it.\n\nI&#39;m surprised nutch crawled imdb.com in 4 hours. That&#39;s a large site. I \ncan&#39;t imagine it got all of it, even if it has streamlined policies \ncompared to heritrix.\n\nNoah\n\nP.S. I&#39;d encourage you to stick with h3.\n\nOn 12/03/2011 05:03 AM, Unreal wrote:\n&gt; Hi\n&gt; Hoping someone can shed some light on this. I ran a crawl on imdb.com using nutch and it took just under 4 hours. I tried heritrix 3 and v1 but each so far have exceeded 24 hours to the point I had to terminate. The reason I switched to heritrix is the goal is to test my indexing, and nutch indexed the crawl to a format I cant use. (need arc)\n&gt; I am assuming I still can not get my decide rules correct as it appears to be downloading alot of gifs no matter where I place the rules. As I type this the crawl report is showing 29,000 gifs vs just 6000 txt/html. The ToeThreads report shows data I can not quite understand, here are the first 20 or so lines:\n&gt;\n&gt; Toe threads report - 201112031257\n&gt;   Job being crawled: imdb\n&gt;   Number of toe threads in pool: 50 (0 active)\n&gt;     ToeThread #1\n&gt; [ToeThread #1:\n&gt;   -no CrawlURI-\n&gt;      WAITING for 6m7s593ms\n&gt;      step: ABOUT_TO_GET_URI for 6m7s593ms\n&gt;      sun.misc.Unsafe.park(Native Method)\n&gt;      java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)\n&gt;      java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)\n&gt;      java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)\n&gt;      org.archive.crawler.frontier.WorkQueueFrontier.next(WorkQueueFrontier.java:643)\n&gt;      org.archive.crawler.framework.ToeThread.run(ToeThread.java:147)\n&gt; ]\n&gt;     ToeThread #2\n&gt; [ToeThread #2:\n&gt;   -no CrawlURI-\n&gt;      WAITING for 22m54s296ms\n&gt;      step: ABOUT_TO_GET_URI for 22m54s296ms\n&gt;      sun.misc.Unsafe.park(Native Method)\n&gt;      java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)\n&gt;      java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)\n&gt;      java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)\n&gt;      org.archive.crawler.frontier.WorkQueueFrontier.next(WorkQueueFrontier.java:643)\n&gt;      org.archive.crawler.framework.ToeThread\n&gt;\n&gt; My decide rules look like this:\n&gt; &lt;newObject name=&quot;decide-rules&quot; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;          &lt;map name=&quot;rules&quot;&gt;\n&gt;            &lt;newObject name=&quot;acceptbyDefault&quot; class=&quot;org.archive.crawler.deciderules.AcceptDecideRule&quot;&gt;\n&gt;            &lt;/newObject&gt;\n&gt;            &lt;newObject name=&quot;notIMDB&quot; class=&quot;org.archive.crawler.deciderules.NotMatchesRegExpDecideRule&quot;&gt;\n&gt;              &lt;string name=&quot;decision&quot;&gt;REJECT&lt;/string&gt;\n&gt;              &lt;string name=&quot;regexp&quot;&gt;.*(imdb.com).*&lt;/string&gt;\n&gt;            &lt;/newObject&gt;\n&gt;            &lt;newObject name=&quot;specific&quot; class=&quot;org.archive.crawler.deciderules.MatchesRegExpDecideRule&quot;&gt;\n&gt;              &lt;string name=&quot;decision&quot;&gt;REJECT&lt;/string&gt;\n&gt;              &lt;string name=&quot;regexp&quot;&gt;.*(login|&#92;/register|&#92;/api|&#92;/special|&#92;/click|&#92;/rss).*&lt;/string&gt;\n&gt;            &lt;/newObject&gt;\n&gt;            &lt;newObject name=&quot;notIMG&quot; class=&quot;org.archive.crawler.deciderules.MatchesFilePatternDecideRule&quot;&gt;\n&gt;              &lt;string name=&quot;decision&quot;&gt;REJECT&lt;/string&gt;\n&gt;              &lt;string name=&quot;use-preset-pattern&quot;&gt;Custom&lt;/string&gt;\n&gt;              &lt;string name=&quot;regexp&quot;&gt;.*(jpg|png|gif|css|rss|js|doc|pdf|ppt|swf)$&lt;/string&gt;\n&gt;            &lt;/newObject&gt;\n&gt;            &lt;newObject name=&quot;defaultNOimg&quot; class=&quot;org.archive.crawler.deciderules.MatchesFilePatternDecideRule&quot;&gt;\n&gt;              &lt;string name=&quot;decision&quot;&gt;REJECT&lt;/string&gt;\n&gt;              &lt;string name=&quot;use-preset-pattern&quot;&gt;Images&lt;/string&gt;\n&gt;              &lt;string name=&quot;regexp&quot;/&gt;\n&gt;            &lt;/newObject&gt;\n&gt;          &lt;/map&gt;\n&gt;        &lt;/newObject&gt;\n&gt;\n&gt; I&#39;ve tried various orders of this using custom image rejects or the preset, but I still see the image/gif increasing.\n&gt;\n&gt; Could this be the reason for the long crawl time or is it something else. Its my first time using this so I am sure the possibilities are endless.\n&gt;\n&gt; Thanks!\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------\n&gt;\n&gt; Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n\n\n"}}