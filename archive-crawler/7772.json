{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":340838211,"authorName":"dpg.hfwv","from":"&quot;dpg.hfwv&quot; &lt;davidpgross@...&gt;","profile":"dpg.hfwv","replyTo":"LIST","senderId":"6N3HJkhNyRUH2YHGdOEBr4TZ-yeQdhL2Jdkjh-GxBf42z8ihA5hRk72vhwV30VCCVL2OkKpUaL0LbevcXtfloLgsMM5N4lOimg","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Crawl Speed/Records Found","postDate":"1348001281","msgId":7772,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGszYW1tMSs2czhrQGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":7782,"prevInTime":7771,"nextInTime":7773,"topicId":7772,"numMessagesInTopic":2,"msgSnippet":"Team, I have been testing my H1.14.4 project and feeling a lttle underwhelmed by the results in terms to total records written to mysql db.  I d like to know","rawEmail":"Return-Path: &lt;davidpgross@...&gt;\r\nX-Sender: davidpgross@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 60233 invoked from network); 18 Sep 2012 20:48:01 -0000\r\nX-Received: from unknown (98.137.34.46)\n  by m7.grp.sp2.yahoo.com with QMQP; 18 Sep 2012 20:48:01 -0000\r\nX-Received: from unknown (HELO ng15-ip1.bullet.mail.ne1.yahoo.com) (98.138.215.234)\n  by mta3.grp.sp2.yahoo.com with SMTP; 18 Sep 2012 20:48:01 -0000\r\nX-Received: from [98.138.217.178] by ng15.bullet.mail.ne1.yahoo.com with NNFMP; 18 Sep 2012 20:48:01 -0000\r\nX-Received: from [98.137.34.36] by tg3.bullet.mail.ne1.yahoo.com with NNFMP; 18 Sep 2012 20:48:01 -0000\r\nDate: Tue, 18 Sep 2012 20:48:01 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;k3amm1+6s8k@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;dpg.hfwv&quot; &lt;davidpgross@...&gt;\r\nSubject: Crawl Speed/Records Found\r\nX-Yahoo-Group-Post: member; u=340838211; y=1OcBDNtnOUAxg4lj9El2KQ7ZGryOpvR1yHDxlSEbJS3dP1Y\r\nX-Yahoo-Profile: dpg.hfwv\r\n\r\nTeam,\n\nI have been testing my H1.14.4 project and feeling a lttle underwhel=\r\nmed by the results in terms to total records written to mysql db.  I&#39;d like=\r\n to know what if anything I should look at to increase output.\n\nMy heritrix=\r\n jobs setup:\n\n1000 seeds, broad crawl extraction based on specific keywords=\r\n\n25 threads\nJVM=3D512\ndedicated server Xeon E3-1240(4x3.33GHz,8MB with 8gb =\r\nRAM\nMy servers are running smoothly and barely loaded.  MYSQL performance s=\r\nhould no problems receiving data from five different crawlers.\n\nMy H1 setup=\r\n allows me to run n+1 Heritrix instances simultaneously.  \n\nI had five inst=\r\nances as above each with its own seeds and keyword and let them run for 7 d=\r\nays.  Each time a url for a keyword was found either in title or content, t=\r\nhis information was written to a MYSQL db.\n\nAfter one week, &quot;only&quot; 110,000 =\r\nURLs have been written to the database.  \n\nInstance #1 downloaded 1759243, =\r\n15703582 queued 8831 congestion\nInstance #2 downloaded 1283326, 20974651 qu=\r\neued 14,313 congestion\nInstance #3 downloaded 2794900, 31181373 queued, 173=\r\n,657 congestion\netc...\n\nMy seeds are keyword/topic specific, and I understa=\r\nnd the Heritrix is also discovering/evaluating URLs beyond initial seeds th=\r\nat may/may not meet my simple criteria.  But, 110,000 URLs found and writte=\r\nn to the database after one week and five indpendent crawlers just seems lo=\r\nw.  I was thinking that 500k to 1M records was easily achievable with even =\r\none crawler. Are my expectations too high?\n\nWhat factors should I be lookin=\r\ng at to improve the throughput?  Is my crawl rate/records found consistent =\r\nwith your experience?\n\nThanks in advance for your thoughts.\n\nDavid\n\n\n\n\n\n\n"}}