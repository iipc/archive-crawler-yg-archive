{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"RqKnxUhk-N0ZSR5F70mEWjPL_iKJfBUq4Pw2z4fyw3snpvXl5YactONW_cfWI-dGfxUcFpWb7Nn2lUKRtfFZFmVXJx06Ayc","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] Is heritrix a good framework for crawling the web for images?","postDate":"1249328236","msgId":5955,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRBNzczQzZDLjEwNzA3MDhAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGYxMzk2OTRmMDkwNzI3MTgxOHUyOGYxMDU2MnFlMDIyY2MyOGM2Y2U1ZmVAbWFpbC5nbWFpbC5jb20+","referencesHeader":"PGYxMzk2OTRmMDkwNzI3MTgxOHUyOGYxMDU2MnFlMDIyY2MyOGM2Y2U1ZmVAbWFpbC5nbWFpbC5jb20+"},"prevInTopic":5945,"nextInTopic":5958,"prevInTime":5954,"nextInTime":5956,"topicId":5945,"numMessagesInTopic":9,"msgSnippet":"Heritrix is a reasonable choice for your goals, because it does not have the text-only focus of some other bulk crawlers, and provides many configuration","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 46474 invoked from network); 3 Aug 2009 19:38:18 -0000\r\nX-Received: from unknown (98.137.34.46)\n  by m3.grp.sp2.yahoo.com with QMQP; 3 Aug 2009 19:38:18 -0000\r\nX-Received: from unknown (HELO relay00.pair.com) (209.68.5.9)\n  by mta3.grp.sp2.yahoo.com with SMTP; 3 Aug 2009 19:38:18 -0000\r\nX-Received: (qmail 36822 invoked from network); 3 Aug 2009 19:37:18 -0000\r\nX-Received: from 67.188.14.54 (HELO ?192.168.1.119?) (67.188.14.54)\n  by relay00.pair.com with SMTP; 3 Aug 2009 19:37:18 -0000\r\nX-pair-Authenticated: 67.188.14.54\r\nMessage-ID: &lt;4A773C6C.1070708@...&gt;\r\nDate: Mon, 03 Aug 2009 12:37:16 -0700\r\nUser-Agent: Thunderbird 2.0.0.22 (Windows/20090605)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;f139694f0907271818u28f10562qe022cc28c6ce5fe@...&gt;\r\nIn-Reply-To: &lt;f139694f0907271818u28f10562qe022cc28c6ce5fe@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Is heritrix a good framework for crawling the\n web for images?\r\nX-Yahoo-Group-Post: member; u=137285340; y=WyXbxkFo8XbrUd01-7Ab3oLzVuhtYVGHT_5YIAuJiZaM\r\nX-Yahoo-Profile: gojomo\r\n\r\nHeritrix is a reasonable choice for your goals, because it does not have \nthe &#39;text-only&#39; focus of some other bulk crawlers, and provides many \nconfiguration options for controlling what is fetched, what is stored, \nand inserting extra steps at any point of the process.\n\nIt will take some custom configuration and careful oversight to run \nmultiple machines on a web-scale collection effort; there are previous \nthreads here that may help.\n\nOf course to discover images you&#39;ll have to fetch and follow a lot of \nnon-image links -- but it&#39;s up to your configuration as to whether those \nare stored or just link-extracted and discarded.\n\n- Gordon @ IA\n\nQuilby wrote:\n&gt; Hi-\n&gt; I posted this question to stackoverflow.com, but I thought that it\n&gt; would also be a good idea to ask you guys-\n&gt; \n&gt; We are in the starting phase of a project, and we are currently\n&gt; wondering whether which crawler is the best choice for us.\n&gt; \n&gt; Our project:\n&gt; \n&gt; Basically, we&#39;re going to set up Hadoop and crawl the web for images.\n&gt; We will then run our own indexing software on the images stored in\n&gt; HDFS based on the Map/Reduce facility in Hadoop. We will not use other\n&gt; indexing than our own.\n&gt; \n&gt; Some particular questions:\n&gt; \n&gt;     * Which crawler will handle crawling for images best?\n&gt;     * Which crawler will best adapt to a distributed crawling system,\n&gt; in which we use many servers conducting crawling together?\n&gt; \n&gt; Right now these look like the 3 best options-\n&gt; \n&gt;     * Nutch: Known to scale. Doesn&#39;t look like the best option because\n&gt; it seems that is it tied closely to their text searching software.\n&gt;     * Heritrix: Also scales. This one currently looks like the best\n&gt; option.\n&gt;     * Scrapy: Has not been used on a large scale (not sure though). I\n&gt; dont know if it has the basic stuff like URL canonicalization. I would\n&gt; like to use this one because it is a python framework (I like python\n&gt; more than java), but I don&#39;t know if they have implemented the\n&gt; advanced features of a web crawler.\n&gt; \n&gt; Summary:\n&gt; \n&gt; We need to get as many images as possible from the web. Which existing\n&gt; crawling framework is both scalable and efficient , but also the one\n&gt; which will be the easiest to modify to get only images?\n&gt; \n&gt; Thanks!\n&gt; \n&gt; \n&gt; ------------------------------------\n&gt; \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n"}}