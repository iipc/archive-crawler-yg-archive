{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"dZUKFlKzdktXo2W0tOgG0SIyG8Ccq_I7eIwIh-L5HgIr_1fVdhHSeGhuBYstTplB-xyunL-1SyzP6XaBSYQGL-ZQIunEcdY","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Re: How can I speed up Heretrix?","postDate":"1172254440","msgId":3843,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ1REYyRUU4LjEwNDA4MDVAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGVybjNyZytsZGhiQGVHcm91cHMuY29tPg==","referencesHeader":"PGVybjNyZytsZGhiQGVHcm91cHMuY29tPg=="},"prevInTopic":3842,"nextInTopic":3844,"prevInTime":3842,"nextInTime":3844,"topicId":3839,"numMessagesInTopic":10,"msgSnippet":"Two notes: (1) Unless you are crawling sites with permission, those delay settings are fairly aggressive, and may trigger webmaster anger or blocking. (2)","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 23652 invoked from network); 23 Feb 2007 18:14:03 -0000\r\nReceived: from unknown (66.218.67.35)\n  by m41a.grp.scd.yahoo.com with QMQP; 23 Feb 2007 18:14:03 -0000\r\nReceived: from unknown (HELO relay00.pair.com) (209.68.5.9)\n  by mta9.grp.scd.yahoo.com with SMTP; 23 Feb 2007 18:14:02 -0000\r\nReceived: (qmail 92869 invoked from network); 23 Feb 2007 18:14:01 -0000\r\nReceived: from 71.141.101.167 (HELO ?10.0.10.13?) (71.141.101.167)\n  by relay00.pair.com with SMTP; 23 Feb 2007 18:14:01 -0000\r\nX-pair-Authenticated: 71.141.101.167\r\nMessage-ID: &lt;45DF2EE8.1040805@...&gt;\r\nDate: Fri, 23 Feb 2007 10:14:00 -0800\r\nUser-Agent: Mozilla Thunderbird 1.0.8-1.1.fc4 (X11/20060501)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;ern3rg+ldhb@...&gt;\r\nIn-Reply-To: &lt;ern3rg+ldhb@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Re: How can I speed up Heretrix?\r\nX-Yahoo-Group-Post: member; u=137285340; y=CLGv5wzWBnZmFvfKWyubjn1-oDHGPbevW_oXDfrVaUC2\r\nX-Yahoo-Profile: gojomo\r\n\r\nTwo notes:\n\n(1) Unless you are crawling sites with permission, those &#39;delay&#39; \nsettings are fairly aggressive, and may trigger webmaster anger or \nblocking.\n\n(2) The usual reason for the &quot;why isn&#39;t Heritrix crawling faster&quot; \nconcern is that a crawl has made enough progress to be narrowed \ndown to just a handful of hosts remaining: typically the largest, \nslowest, or completely unresponsive hosts.\n\nEven with no delay between fetches to a host, Heritrix will only \nretrieve one URL at a time. If the content is large or the server \nslow, it may take many seconds for a single request to finish. If \nthe host does not respond at all, Heritrix goes into the longer \n&#39;retry-delay-seconds&#39; wait (which is usually many minutes) before \nreconnecting.\n\nIn addition to the info Paul mentioned, the &#39;frontier report&#39; will \nhelp determine if this is the case -- showing how many queues are \nstill active with URLs to crawl, and how many are in various \nstages of &#39;snooze&#39; (to delay the next fetch for politeness or \nwaiting-out-a-problem reasons).\n\n- Gordon @ IA\n\nnt_bdr wrote:\n&gt; I have already tried that, and does not seem to help speed up the\n&gt; crawl. Below are some of frontier settings I have\n&gt; \n&gt;  \n&gt;     &lt;long name=&quot;max-bytes-download&quot;&gt;0&lt;/long&gt;\n&gt;     &lt;long name=&quot;max-document-download&quot;&gt;0&lt;/long&gt;\n&gt;     &lt;long name=&quot;max-time-sec&quot;&gt;0&lt;/long&gt;\n&gt;     &lt;integer name=&quot;max-toe-threads&quot;&gt;100&lt;/integer&gt;\n&gt;     &lt;integer name=&quot;recorder-out-buffer-bytes&quot;&gt;4096&lt;/integer&gt;\n&gt;     &lt;integer name=&quot;recorder-in-buffer-bytes&quot;&gt;65536&lt;/integer&gt;\n&gt;     &lt;integer name=&quot;bdb-cache-percent&quot;&gt;0&lt;/integer&gt;\n&gt;     &lt;newObject name=&quot;scope&quot;\n&gt; class=&quot;org.archive.crawler.scope.SurtPrefixScope&quot;&gt;\n&gt;       &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;boolean name=&quot;reread-seeds-on-config&quot;&gt;false&lt;/boolean&gt;\n&gt;       &lt;integer name=&quot;max-link-hops&quot;&gt;25&lt;/integer&gt;\n&gt;       &lt;integer name=&quot;max-trans-hops&quot;&gt;5&lt;/integer&gt;\n&gt;       &lt;newObject name=&quot;robots-honoring-policy&quot;\n&gt; class=&quot;org.archive.crawler.datamodel.RobotsHonoringPolicy&quot;&gt;\n&gt;       &lt;string name=&quot;type&quot;&gt;classic&lt;/string&gt;\n&gt;       &lt;boolean name=&quot;masquerade&quot;&gt;false&lt;/boolean&gt;\n&gt;       &lt;text name=&quot;custom-robots&quot;&gt;&lt;/text&gt;\n&gt;       &lt;stringList name=&quot;user-agents&quot;&gt;\n&gt;         &lt;string&gt;test-bot&lt;/string&gt;\n&gt;       &lt;/stringList&gt;\n&gt;     &lt;/newObject&gt;\n&gt; \n&gt;     &lt;newObject name=&quot;frontier&quot;\n&gt; class=&quot;org.archive.crawler.frontier.BdbFrontier&quot;&gt;\n&gt;       &lt;float name=&quot;delay-factor&quot;&gt;0.4&lt;/float&gt;\n&gt;       &lt;integer name=&quot;max-delay-ms&quot;&gt;50&lt;/integer&gt;\n&gt;       &lt;integer name=&quot;min-delay-ms&quot;&gt;10&lt;/integer&gt;\n&gt;       &lt;integer name=&quot;max-retries&quot;&gt;5&lt;/integer&gt;\n&gt;       &lt;long name=&quot;retry-delay-seconds&quot;&gt;15&lt;/long&gt;\n&gt;       &lt;integer name=&quot;preference-embed-hops&quot;&gt;1&lt;/integer&gt;\n&gt;       &lt;integer name=&quot;total-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt;       &lt;integer name=&quot;max-per-host-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt;       &lt;string\n&gt; name=&quot;queue-assignment-policy&quot;&gt;org.archive.crawler.frontier.HostnameQueueAssignmentPolicy&lt;/string&gt;\n&gt;       &lt;string name=&quot;force-queue-assignment&quot;&gt;&lt;/string&gt;\n&gt;       &lt;boolean name=&quot;pause-at-start&quot;&gt;false&lt;/boolean&gt;\n&gt;       &lt;boolean name=&quot;pause-at-finish&quot;&gt;false&lt;/boolean&gt;\n&gt;       &lt;boolean name=&quot;source-tag-seeds&quot;&gt;false&lt;/boolean&gt;\n&gt;       &lt;boolean name=&quot;recovery-log-enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;boolean name=&quot;hold-queues&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;integer name=&quot;balance-replenish-amount&quot;&gt;3000&lt;/integer&gt;\n&gt;       &lt;integer name=&quot;error-penalty-amount&quot;&gt;100&lt;/integer&gt;\n&gt;       &lt;long name=&quot;queue-total-budget&quot;&gt;-1&lt;/long&gt;\n&gt;       &lt;string\n&gt; name=&quot;cost-policy&quot;&gt;org.archive.crawler.frontier.UnitCostAssignmentPolicy&lt;/string&gt;\n&gt;       &lt;long name=&quot;snooze-deactivate-ms&quot;&gt;1000&lt;/long&gt;\n&gt;       &lt;integer name=&quot;target-ready-backlog&quot;&gt;50&lt;/integer&gt;\n&gt;       &lt;string\n&gt; name=&quot;uri-included-structure&quot;&gt;org.archive.crawler.util.BdbUriUniqFilter&lt;/string&gt;\n&gt;     &lt;/newObject&gt;\n&gt; \n&gt;       &lt;integer name=&quot;timeout-seconds&quot;&gt;10&lt;/integer&gt;\n&gt;         &lt;integer name=&quot;sotimeout-ms&quot;&gt;5000&lt;/integer&gt;\n&gt;         &lt;integer name=&quot;fetch-bandwidth&quot;&gt;0&lt;/integer&gt;\n&gt;         &lt;long name=&quot;max-length-bytes&quot;&gt;0&lt;/long&gt;\n&gt;         &lt;boolean name=&quot;ignore-cookies&quot;&gt;false&lt;/boolean&gt;\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; --- In archive-crawler@yahoogroups.com, &quot;Bart Kiers&quot; &lt;bkiers@...&gt; wrote:\n&gt; \n&gt;&gt;Hi,\n&gt;&gt;\n&gt;&gt;Try changing some of your frontier-settings under the &quot;settings&quot;-tab\n&gt; \n&gt; from\n&gt; \n&gt;&gt;the WUI.\n&gt;&gt;Look at Heritrix&#39; manual paragraph 6.3.3: Frontier Settings:\n&gt;&gt;http://crawler.archive.org/articles/user_manual.html#settings\n&gt;&gt;\n&gt;&gt;Regards,\n&gt;&gt;Bart.\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;On 2/23/07, nt_bdr &lt;nt_bdr@...&gt; wrote:\n&gt;&gt;\n&gt;&gt;&gt;  I have heretrix set up on a dual core Linux box with 2.8Ghz\n&gt; \n&gt; cpu&#39;s and\n&gt; \n&gt;&gt;&gt;8G memory. And the box does not have anything else running on it but\n&gt;&gt;&gt;heretrix. Heretrix is downloading pages at at very slow rate. On an\n&gt;&gt;&gt;avg 1.03 Urls/sec. I have max_toe_threads set to 100. And I normally\n&gt;&gt;&gt;see 1 or 2 threads active at any given point. I would like to know why\n&gt;&gt;&gt;heretrix is running so slow, and what can I do to speed it up.\n&gt;&gt;&gt;\n&gt;&gt;&gt; \n&gt;&gt;&gt;\n&gt;&gt;\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt;  \n&gt; Yahoo! Groups - Join or create groups, clubs, forums &amp; communities. Links\n&gt; \n&gt; \n&gt; \n\n\n"}}