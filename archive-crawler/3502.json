{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":285106948,"authorName":"fandufunkyman","from":"&quot;fandufunkyman&quot; &lt;fandufunkyman@...&gt;","profile":"fandufunkyman","replyTo":"LIST","senderId":"tASVQPouY6bS_cnmAvtLfo5-4TtrFJkPjngy6Td2rgaoPl6l2IkhG8giRdOxHW_pSB_pkLoPDaMjABicIFTlKv5pMdhLipnaAzsxxMe0Geg","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Use scope to reject particular page","postDate":"1162816257","msgId":3502,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGVpbjl1MStlbTFsQGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":0,"prevInTime":3501,"nextInTime":3503,"topicId":3502,"numMessagesInTopic":1,"msgSnippet":"hi friends, i m using heritrix to crawl the web pages. for this i m using seed.txt and order.xml and run heritrix batch and it crawled the website specify in","rawEmail":"Return-Path: &lt;fandufunkyman@...&gt;\r\nX-Sender: fandufunkyman@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 60875 invoked from network); 6 Nov 2006 12:31:52 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m39.grp.scd.yahoo.com with QMQP; 6 Nov 2006 12:31:52 -0000\r\nReceived: from unknown (HELO n32.bullet.scd.yahoo.com) (66.94.237.26)\n  by mta5.grp.scd.yahoo.com with SMTP; 6 Nov 2006 12:31:52 -0000\r\nReceived: from [66.218.69.4] by n32.bullet.scd.yahoo.com with NNFMP; 06 Nov 2006 12:30:58 -0000\r\nReceived: from [66.218.66.86] by t4.bullet.scd.yahoo.com with NNFMP; 06 Nov 2006 12:30:58 -0000\r\nDate: Mon, 06 Nov 2006 12:30:57 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;ein9u1+em1l@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;fandufunkyman&quot; &lt;fandufunkyman@...&gt;\r\nSubject: Use scope to reject particular page\r\nX-Yahoo-Group-Post: member; u=285106948; y=A7cmnEFoNIYjZkDkRBwAsh_iSJa1ndMN9TSBrdlovOkUzKqX-KbSKQ\r\nX-Yahoo-Profile: fandufunkyman\r\n\r\nhi friends,\n\ni&#39;m using heritrix to crawl the web pages. for this i&#39;m using =\r\nseed.txt\nand order.xml and run heritrix batch and it crawled the website\nsp=\r\necify in seed.txt.\n\nin seeds.txt the url is given\nhttp://www.mysite.com/\n\nn=\r\now i don&#39;t want to crawl the few pages of my site.\nhttp://www.mysite.com/Fa=\r\nq/faq.html\nand http://www.mysite.com/documentation/documentation.html\n\ni re=\r\nad at manyplaces that we can stop it to crawl by using scope and\nreject dec=\r\nide rule and all  this can be specify by using order.xml.\n\ni&#39;m very say i c=\r\nould not get on properly that how can i use it.\n\ncan anybody give me small =\r\nsample of order.xml to reject few pages to\ncrawl or steps to use it and whe=\r\nre can i specify the url what are not\ncrawl.\n\nThanks.\nmohit\n\n\n\n"}}