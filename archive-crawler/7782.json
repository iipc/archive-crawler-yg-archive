{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"3jLl5ejkiyoUSrn1_yIBWghybIzc7c8fTUMrhk-GhWVw5V3NebrbNiO8fE_cto1OQ_b4O1-S2duT0pRz6k2Tp9jtM3tAouA","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] Crawl Speed/Records Found","postDate":"1348105877","msgId":7782,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDUwNUE3Njk1LjIwMDAzMDdAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGszYW1tMSs2czhrQGVHcm91cHMuY29tPg==","referencesHeader":"PGszYW1tMSs2czhrQGVHcm91cHMuY29tPg=="},"prevInTopic":7772,"nextInTopic":0,"prevInTime":7781,"nextInTime":7783,"topicId":7772,"numMessagesInTopic":2,"msgSnippet":"Usually attempts to crawl at high-speed hit I/O bottlenecks first, and teams that are concerned with throughput have tended to avoid having a relational","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 77381 invoked from network); 20 Sep 2012 01:51:19 -0000\r\nX-Received: from unknown (98.137.35.161)\n  by m14.grp.sp2.yahoo.com with QMQP; 20 Sep 2012 01:51:19 -0000\r\nX-Received: from unknown (HELO relay02.pair.com) (209.68.5.16)\n  by mta5.grp.sp2.yahoo.com with SMTP; 20 Sep 2012 01:51:19 -0000\r\nX-Received: (qmail 68145 invoked by uid 0); 20 Sep 2012 01:51:18 -0000\r\nX-Received: from 70.36.143.78 (HELO silverbook.local) (70.36.143.78)\n  by relay02.pair.com with SMTP; 20 Sep 2012 01:51:18 -0000\r\nX-pair-Authenticated: 70.36.143.78\r\nMessage-ID: &lt;505A7695.2000307@...&gt;\r\nDate: Wed, 19 Sep 2012 18:51:17 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.7; rv:15.0) Gecko/20120907 Thunderbird/15.0.1\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;k3amm1+6s8k@...&gt;\r\nIn-Reply-To: &lt;k3amm1+6s8k@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Crawl Speed/Records Found\r\nX-Yahoo-Group-Post: member; u=137285340; y=RL0hWxkVOeynTk_ntscjNCkDeNqwHR65B2uAhRp0UM9z\r\nX-Yahoo-Profile: gojomo\r\n\r\nUsually attempts to crawl at high-speed hit I/O bottlenecks first, and\nteams that are concerned with throughput have tended to avoid having a\nrelational database anywhere in the loop.\n\nWriting locally, I would guess a single machine of those specs capable \nof writing millions of unique resources to disk in a day, if it is not \nlimited by a dearth of independent target servers (because it only \ncollects against each remote hostname at a polite rate).\n\nIf your crawl stats show idle threads, such politeness could be the \nlimiting factor.\n\nIf all threads always seem busy (and I think those &#39;congestion&#39; numbers \nmean that they are), it&#39;s something else -- and you&#39;d want to watch your \nown machines stats of various kinds, and reports like the &#39;threads \nreport&#39; which give you an idea where the worker threads are \nbusy/blocked, to get an idea what your bottleneck is.\n\n- Gordon\n\nOn 9/18/12 1:48 PM, dpg.hfwv wrote:\n&gt; Team,\n&gt;\n&gt; I have been testing my H1.14.4 project and feeling a lttle\n&gt; underwhelmed by the results in terms to total records written to\n&gt; mysql db.  I&#39;d like to know what if anything I should look at to\n&gt; increase output.\n&gt;\n&gt; My heritrix jobs setup:\n&gt;\n&gt; 1000 seeds, broad crawl extraction based on specific keywords 25\n&gt; threads JVM=512 dedicated server Xeon E3-1240(4x3.33GHz,8MB with 8gb\n&gt; RAM My servers are running smoothly and barely loaded.  MYSQL\n&gt; performance should no problems receiving data from five different\n&gt; crawlers.\n&gt;\n&gt; My H1 setup allows me to run n+1 Heritrix instances simultaneously.\n&gt;\n&gt; I had five instances as above each with its own seeds and keyword and\n&gt; let them run for 7 days.  Each time a url for a keyword was found\n&gt; either in title or content, this information was written to a MYSQL\n&gt; db.\n&gt;\n&gt; After one week, &quot;only&quot; 110,000 URLs have been written to the\n&gt; database.\n&gt;\n&gt; Instance #1 downloaded 1759243, 15703582 queued 8831 congestion\n&gt; Instance #2 downloaded 1283326, 20974651 queued 14,313 congestion\n&gt; Instance #3 downloaded 2794900, 31181373 queued, 173,657 congestion\n&gt; etc...\n&gt;\n&gt; My seeds are keyword/topic specific, and I understand the Heritrix is\n&gt; also discovering/evaluating URLs beyond initial seeds that may/may\n&gt; not meet my simple criteria.  But, 110,000 URLs found and written to\n&gt; the database after one week and five indpendent crawlers just seems\n&gt; low.  I was thinking that 500k to 1M records was easily achievable\n&gt; with even one crawler. Are my expectations too high?\n&gt;\n&gt; What factors should I be looking at to improve the throughput?  Is my\n&gt; crawl rate/records found consistent with your experience?\n&gt;\n&gt; Thanks in advance for your thoughts.\n&gt;\n&gt; David\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------\n&gt;\n&gt; Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n\n"}}