{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"zX5ejpjjE8hz7WxjrMJMlyUvrXNyPtGsi229ODm_Upl7MOvllu1CNpI0T8gkE0yssXnL2RcC6G5K56-RIm_URXMS9SQqHHg","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] Penetration of domain-specific crawl","postDate":"1249500744","msgId":5960,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRBNzlERTQ4LjYwNzA2MDdAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDQ0MDRkMWY2MDkwODA1MDEzMnMzOWYzYmJlNXQ0NGExMDUwNmI3MGJjZDNlQG1haWwuZ21haWwuY29tPg==","referencesHeader":"PDQ0MDRkMWY2MDkwODA1MDEzMnMzOWYzYmJlNXQ0NGExMDUwNmI3MGJjZDNlQG1haWwuZ21haWwuY29tPg=="},"prevInTopic":5959,"nextInTopic":0,"prevInTime":5959,"nextInTime":5961,"topicId":5959,"numMessagesInTopic":2,"msgSnippet":"What version of Heritrix? Are there any errors/alerts in the user interface or heritrix_out.log? Does the crawler s user report as finished , paused , or","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 70668 invoked from network); 5 Aug 2009 19:33:27 -0000\r\nX-Received: from unknown (69.147.108.200)\n  by m8.grp.re1.yahoo.com with QMQP; 5 Aug 2009 19:33:27 -0000\r\nX-Received: from unknown (HELO relay01.pair.com) (209.68.5.15)\n  by mta1.grp.re1.yahoo.com with SMTP; 5 Aug 2009 19:33:26 -0000\r\nX-Received: (qmail 61504 invoked from network); 5 Aug 2009 19:32:26 -0000\r\nX-Received: from 70.137.166.253 (HELO ?10.0.13.17?) (70.137.166.253)\n  by relay01.pair.com with SMTP; 5 Aug 2009 19:32:26 -0000\r\nX-pair-Authenticated: 70.137.166.253\r\nMessage-ID: &lt;4A79DE48.6070607@...&gt;\r\nDate: Wed, 05 Aug 2009 12:32:24 -0700\r\nUser-Agent: Thunderbird 2.0.0.22 (Windows/20090605)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;4404d1f60908050132s39f3bbe5t44a10506b70bcd3e@...&gt;\r\nIn-Reply-To: &lt;4404d1f60908050132s39f3bbe5t44a10506b70bcd3e@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Penetration of domain-specific crawl\r\nX-Yahoo-Group-Post: member; u=137285340; y=4YQP4jNWVxDfJAul2dCiHl3MYBr9THrOdGb132tPdiea\r\nX-Yahoo-Profile: gojomo\r\n\r\nWhat version of Heritrix?\n\nAre there any errors/alerts in the user interface or heritrix_out.log?\n\nDoes the crawler&#39;s user report as &#39;finished&#39;, &#39;paused&#39;, or active?\n\nWhat does the 1-line frontier summary say? (This is a line like &quot;99 URI \nqueues: 15 active (2 in-process; 0 ready; 13 snoozed); 0 inactive; 0 \nineligible; 0 retired; 84 exhausted&quot;.)\n\n- Gordon @ IA\n\nElison Smith wrote:\n&gt; \n&gt; \n&gt; \n&gt; I am running Heritrix such that it crawls URLs from within a given \n&gt; domain (the domain corresponding to the seed URLs).\n&gt; \n&gt; I seed the crawler with some URLs  of the target domain by querying a \n&gt; search engine API.\n&gt; \n&gt; When running this crawler instance, I have noticed that the crawler \n&gt; &quot;freezes&quot; after some number of URLs (around 33K). While the Java process \n&gt; still keeps running, no additional URLs get crawled once the crawler \n&gt; enters this state.\n&gt; \n&gt; Note that the domain has a much larger number of URLs (evident by doing \n&gt; a search engine search) than 33K. I want to crawl a much larger number \n&gt; of URLs - upto 100s of thousands.\n&gt; \n&gt; Any immediate reasons why the crawler would stop making progress after \n&gt; this number of URLs.\n&gt; \n&gt; Does it have to do with the fact that the crawler is running in a \n&gt; domain-specific mode ?\n&gt; \n&gt; Thanks.\n&gt; \n&gt; \n&gt; \n&gt; \n\n"}}