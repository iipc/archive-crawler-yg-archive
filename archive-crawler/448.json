{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":164438524,"authorName":"Lars Clausen","from":"Lars Clausen &lt;lc@...&gt;","profile":"lrclause","replyTo":"LIST","senderId":"VHO5b7a2rcJ5x7BWlzOBzdmWiHG92J7kDVfuQNX4OIrW5rE1u8GuLlfKI03NXHoW92L6s07tSUbRcpB-it1sb4eJiPJqPTegaIbRLQ","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Re: Large scale crawling with Heritrix","postDate":"1085491881","msgId":448,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDEwODU0OTE4ODEuMTc1ODQuMTAyLmNhbWVsQHBjNzcwLnNiLnN0YXRzYmlibGlvdGVrZXQuZGs+","inReplyToHeader":"PGM4dmJvMStkbTdrQGVHcm91cHMuY29tPg==","referencesHeader":"PGM4dmJvMStkbTdrQGVHcm91cHMuY29tPg=="},"prevInTopic":447,"nextInTopic":449,"prevInTime":447,"nextInTime":449,"topicId":432,"numMessagesInTopic":9,"msgSnippet":"... Quite apart from that, it s actually very useful to be able to crawl through databases that way.  In many cases, there s no way to get the underlying","rawEmail":"Return-Path: &lt;lc@...&gt;\r\nX-Sender: lc@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 10231 invoked from network); 25 May 2004 13:31:47 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m17.grp.scd.yahoo.com with QMQP; 25 May 2004 13:31:47 -0000\r\nReceived: from unknown (HELO luna.statsbiblioteket.dk) (130.225.24.87)\n  by mta2.grp.scd.yahoo.com with SMTP; 25 May 2004 13:31:47 -0000\r\nReceived: from pc770.sb.statsbiblioteket.dk\n (pc770.sb.statsbiblioteket.dk [130.225.24.181]) by luna.statsbiblioteket.dk\n (iPlanet Messaging Server 5.2 HotFix 1.16 (built May 14 2003))\n with ESMTP id &lt;0HY90087IUW9JZ@...&gt; for\n archive-crawler@yahoogroups.com; Tue, 25 May 2004 15:31:21 +0200 (MEST)\r\nDate: Tue, 25 May 2004 15:31:21 +0200\r\nIn-reply-to: &lt;c8vbo1+dm7k@...&gt;\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-id: &lt;1085491881.17584.102.camel@...&gt;\r\nOrganization: Statsbiblioteket\r\nMIME-version: 1.0\r\nX-Mailer: Ximian Evolution 1.4.5 (1.4.5-1)\r\nContent-type: text/plain; charset=UTF-8\r\nContent-transfer-encoding: 8BIT\r\nReferences: &lt;c8vbo1+dm7k@...&gt;\r\nX-eGroups-Remote-IP: 130.225.24.87\r\nFrom: Lars Clausen &lt;lc@...&gt;\r\nSubject: Re: [archive-crawler] Re: Large scale crawling with Heritrix\r\nX-Yahoo-Group-Post: member; u=164438524\r\nX-Yahoo-Profile: lrclause\r\n\r\nOn Tue, 2004-05-25 at 13:47, Kaisa Kaunonen wrote:\n&gt; Hi,\n&gt; \n&gt; --- In archive-crawler@yahoogroups.com, Igor Ranitovic &lt;igor@a...&gt; \n&gt; wrote:\n&gt; \n&gt; &gt; &gt; *)  Reject urls with too many parameters. Set maximum number of\n&gt; &gt; &gt; parameters to some value: are 4 parameters acceptable, but 5 too \n&gt; much\n&gt; &gt; &gt; (or some other limit)?\n&gt; &gt; &gt; \n&gt; &gt; &gt; http:/wwwÂ…...net/?\n&gt; &gt; &gt; project_id=2&ykieli=fi&startfrom=0&stopto=6&commands=329&pic=\n&gt; &gt; \n&gt; &gt; I am not sure why would you want to do this?\n&gt; &gt; \n&gt; &gt; Take care.\n&gt; &gt; i.\n&gt; \n&gt; \n&gt; Just a thought :)\n&gt; \n&gt; Urls with parameters look like search results from databases. More \n&gt; parameters =&gt; (often) a larger database. If a url has six params  and \n&gt; each of them has 10 possible values =&gt; a million combinations and \n&gt; result pages. Even a lesser amount is much. \n&gt; \n&gt; A pcsuperstore may have every bolt and nut in an online catalog via \n&gt; search interface into their database. I don&#39;t know why but harvesters \n&gt; I&#39;ve known this far collect mass database entries if I don&#39;t try to \n&gt; stop them. \n&gt; \n&gt; But true, it&#39;s difficult to see what&#39;s some sort of catalog by just \n&gt; looking at the number of parameters.\n\nQuite apart from that, it&#39;s actually very useful to be able to crawl\nthrough databases that way.  In many cases, there&#39;s no way to get the\nunderlying database, so getting its entries this way means we at least\nget it in one form.  If you search for &quot;deep web&quot;, you&#39;ll see the\nproblem I&#39;m talking about.\n\nHaving the info out of the pc superstore you mention would actually be\nof interest.  The problem arises when the arguments can be switched\naround or some arguments just change details of presentation.  Very\ndifficult to deal with, not something that I&#39;d recommend making a\ngeneric solution for.\n\n-Lars\n\n\n"}}