{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"Michael Stack","from":"Michael Stack &lt;stack@...&gt;","replyTo":"LIST","senderId":"pWBE833IXd495RFWAFVGXrdAVuxJDoC8gIxbs7taC-mT8YhNyQyTKEluZqX1TEYzi0dDovqQHgaLmspwadSc8a75L768AbPB","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Re: [Fwd: Second draft of per host settings document]","postDate":"1071182595","msgId":204,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDNGRDhGMzAzLjgwMzA1MDZAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDNGRDdBQzNCLjIwNjAyMDhAYXJjaGl2ZS5vcmc+","referencesHeader":"PDNGRDc4OEJELjYwNzA2MDFAYXJjaGl2ZS5vcmc+IDwzRkQ3QUMzQi4yMDYwMjA4QGFyY2hpdmUub3JnPg=="},"prevInTopic":198,"nextInTopic":0,"prevInTime":203,"nextInTime":205,"topicId":195,"numMessagesInTopic":5,"msgSnippet":"... I m guessing they don t. ... That sounds grand. ... So there ll be a Controller -- the Frontier? -- that hands out the work but sounds like crawlers will","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 38455 invoked from network); 11 Dec 2003 22:48:55 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m11.grp.scd.yahoo.com with QMQP; 11 Dec 2003 22:48:55 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (209.237.232.202)\n  by mta4.grp.scd.yahoo.com with SMTP; 11 Dec 2003 22:48:55 -0000\r\nReceived: (qmail 19966 invoked by uid 100); 11 Dec 2003 22:48:11 -0000\r\nReceived: from b116-dyn-60.archive.org (HELO archive.org) (stack@...@209.237.240.60)\n  by ia00524.archive.org with SMTP; 11 Dec 2003 22:48:11 -0000\r\nMessage-ID: &lt;3FD8F303.8030506@...&gt;\r\nDate: Thu, 11 Dec 2003 14:43:15 -0800\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.5) Gecko/20031007\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nSubject: Re: [archive-crawler] Re: [Fwd: Second draft of per host settings\n document]\r\nReferences: &lt;3FD788BD.6070601@...&gt; &lt;3FD7AC3B.2060208@...&gt;\r\nIn-Reply-To: &lt;3FD7AC3B.2060208@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-Status: No, hits=-5.8 required=6.0\n\ttests=AWL,BAYES_01,EMAIL_ATTRIBUTION,IN_REP_TO,QUOTED_EMAIL_TEXT,\n\t      REFERENCES,REPLY_WITH_QUOTES,USER_AGENT_MOZILLA_UA\n\tautolearn=ham version=2.55\r\nX-Spam-Level: \r\nX-Spam-Checker-Version: SpamAssassin 2.55 (1.174.2.19-2003-05-19-exp)\r\nX-eGroups-Remote-IP: 209.237.232.202\r\nFrom: Michael Stack &lt;stack@...&gt;\r\nX-Yahoo-Group-Post: member; u=168599281\r\n\r\nGordon Mohr wrote:\n\n&gt;Michael Stack wrote:\n&gt;  \n&gt;\n&gt;&gt;Proposal looks good to me.  Model reminds of me of apache &#39;.htaccess&#39; \n&gt;&gt;file scheme where you can insert directory specific config. to override \n&gt;&gt;the core httpd.conf.  I like it.  Below are some general \n&gt;&gt;comments/questions:\n&gt;&gt;\n&gt;&gt;+ Does the order file change as you do a crawl?  Where is state kept?  \n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;Originally, the the order file did not change: it was only editted\n&gt;(by hand or the web UI) before the crawl began, and then consulted at\n&gt;the start of a crawl to fill in per-instance variables holding chosen\n&gt;values.\n&gt;\n&gt;Recently, Kris made several changes:\n&gt;  (1) Most places where order settings are used, the order object (or\n&gt;      portion thereof) is directly consulted each time the value is\n&gt;      needed -- rather than only at startup -- so that changes during\n&gt;      a crawl can have an effect.\n&gt;  (2) The crawl can be paused in memory, and various crawl-order fields\n&gt;      changed during the pause. The updated order is written to disk,\n&gt;      and the new values should affect the crawl when it is resumed.\n&gt;  \n&gt;\n&gt;(I&#39;m not sure everything behaves as might be desirable for all the\n&gt;crawler objects which inherit from XMLConfig, and retain direct\n&gt;references to their &#39;home node&#39; inside the overall order DOM.)\n&gt;\n&gt;  \n&gt;\nI&#39;m guessing they don&#39;t.\n\n....\n\n&gt;I suspect only changes of settings through the web UI, or some other\n&gt;manual kick/flush of existing settings, would cause a refresh of\n&gt;settings held in memory.\n&gt;\n&gt;  \n&gt;\nThat sounds grand.\n\n&gt;&gt;+ What are the plans for having multiple crawler instances working off \n&gt;&gt;the one Frontier instance?  If the frontier makes a CrawlServer to \n&gt;&gt;associate w/ a URI, how will we ensure that one crawler instance does \n&gt;&gt;one server only (Maybe frontier can do distribution between crawlers).\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;Not yet considered in depth. It&#39;s quite likely that when independent\n&gt;crawlers are cooperating, they&#39;ll each have a firm idea of which\n&gt;remote servers (host:port combos) they are to crawl, and which they\n&gt;should delegate to their siblings.\n&gt;\n&gt;  \n&gt;\nSo there&#39;ll be a Controller -- the Frontier? -- that hands out the work \nbut sounds like crawlers&#39; will need to communicate (e.g. Checkpointing).\n\n&gt;&gt;+ Won&#39;t there only be one instance of the configuration instance in \n&gt;&gt;memory? It won&#39;t be duplicated per CrawlerServer -- just a reference to \n&gt;&gt;the single instance?  Why then are we worried about XML DOM cost?  Won&#39;t \n&gt;&gt;the configuration just be read into an object tree w/ an xml serializer \n&gt;&gt;used creating the objects w/ periodic visits to the file on disk to \n&gt;&gt;check mod time?  The serializer would do something like, if a value \n&gt;&gt;exists at a certain node in the configuration hierarchy, a getter that \n&gt;&gt;returns the value at that location in the hierarchy is returned, else, \n&gt;&gt;we call super.  Or are we talking of doing per host an aggregation of \n&gt;&gt;all xml snippets to write a new configuration file to feed the crawler \n&gt;&gt;accessing a particular host?\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;If many domains/hosts/servers have their own custom settings, and\n&gt;each settings file is XML, and that XML is always loaded into a\n&gt;generic DOM and then referenced by the CrawlServer instance, the DOM\n&gt;overhead might be a concern.\n&gt;\n&gt;  \n&gt;\nFor sure.  Can avoid keeping settings in a DOM and in a particular a \ngeneric DOM.\n\nSt.Ack\n\n\n"}}