{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":90724651,"authorName":"John Lekashman","from":"John Lekashman &lt;lekash@...&gt;","profile":"lekash","replyTo":"LIST","senderId":"vTxVhVuqNetUXNbifyw9OF2oOzKwURCFCfIWGxILcqCSqQBmyM7SOxO1gTZwwiscV5oOoDdJY-Ir2DKAbveUerm2S3yJgEZszCI","spamInfo":{"isSpam":false,"reason":"2"},"subject":"Re: [archive-crawler] Need help--How to get rid of Out Of Memory","postDate":"1214674960","msgId":5337,"canDelete":false,"contentTrasformed":false,"systemMessage":true,"headers":{"messageIdInHeader":"PDQ4NjY3ODEwLjUwODA5MDJAYmF5YXJlYS5uZXQ+","inReplyToHeader":"PDIxMTg3Ny4yMjg3MC5xbUB3ZWI2NTUxMy5tYWlsLmFjNC55YWhvby5jb20+","referencesHeader":"PDIxMTg3Ny4yMjg3MC5xbUB3ZWI2NTUxMy5tYWlsLmFjNC55YWhvby5jb20+"},"prevInTopic":5336,"nextInTopic":5338,"prevInTime":5336,"nextInTime":5338,"topicId":5336,"numMessagesInTopic":3,"msgSnippet":"Hi, Ok, I m sorry to be so simplistic. Really just get more memory, allocate a bigger heap. John","rawEmail":"Return-Path: &lt;lekash@...&gt;\r\nReceived: (qmail 99001 invoked from network); 28 Jun 2008 18:58:47 -0000\r\nReceived: from unknown (66.218.67.94)\n  by m52.grp.scd.yahoo.com with QMQP; 28 Jun 2008 18:58:47 -0000\r\nReceived: from unknown (HELO n52c.bullet.mail.sp1.yahoo.com) (66.163.168.186)\n  by mta15.grp.scd.yahoo.com with SMTP; 28 Jun 2008 18:58:47 -0000\r\nReceived: from [216.252.122.216] by n52.bullet.mail.sp1.yahoo.com with NNFMP; 28 Jun 2008 18:58:47 -0000\r\nReceived: from [209.73.164.83] by t1.bullet.sp1.yahoo.com with NNFMP; 28 Jun 2008 18:58:47 -0000\r\nReceived: from [66.218.66.86] by t7.bullet.scd.yahoo.com with NNFMP; 28 Jun 2008 18:58:47 -0000\r\nX-Sender: lekash@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 25799 invoked from network); 28 Jun 2008 17:42:42 -0000\r\nX-Received: from unknown (66.218.67.96)\n  by m57.grp.scd.yahoo.com with QMQP; 28 Jun 2008 17:42:42 -0000\r\nX-Received: from unknown (HELO mail.bayarea.net) (209.128.87.230)\n  by mta17.grp.scd.yahoo.com with SMTP; 28 Jun 2008 17:42:42 -0000\r\nX-Received: from [192.168.0.104] (209-128-93-121.bayarea.net [209.128.93.121])\n\t(authenticated bits=0)\n\tby mail.bayarea.net (8.13.8/8.13.8) with ESMTP id m5SHgfIJ031030\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Sat, 28 Jun 2008 10:42:41 -0700 (PDT)\n\t(envelope-from lekash@...)\r\nMessage-ID: &lt;48667810.5080902@...&gt;\r\nDate: Sat, 28 Jun 2008 10:42:40 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; PPC Mac OS X Mach-O; en-US; rv:1.7.12) Gecko/20050915\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;211877.22870.qm@...&gt;\r\nIn-Reply-To: &lt;211877.22870.qm@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 2:2:2:0:0\r\nFrom: John Lekashman &lt;lekash@...&gt;\r\nSubject: Re: [archive-crawler] Need help--How to get rid of Out Of Memory\r\nX-Yahoo-Group-Post: member; u=90724651; y=o-D2yO7od1b7swnS-nzJs5rB8vSPi4fSkQy2sMdsDkPv\r\nX-Yahoo-Profile: lekash\r\nX-Yahoo-Marked-Not-Spam: \r\nX-Yahoo-Newman-Property: groups-system\r\nX-eGroups-Approved-By: gojomo &lt;gojomo@...&gt; via web; 28 Jun 2008 18:58:46 -0000\r\n\r\nHi,\nOk, I&#39;m sorry to be so simplistic.\nReally just get more memory, allocate a bigger heap.\n\nJohn\n\nhijbul alam wrote:\n\n&gt; Hi\n&gt;\n&gt;  \n&gt;\n&gt; I am getting OOME error continously. At first i tried with Broadscope, \n&gt; then Surtprefixscope.\n&gt;\n&gt; Now I am trying with deciding in scope. I tried about 10 times tuning \n&gt; different parameter. But all time i failed to run the crawler more \n&gt; than to 2 or 3 hour where as I am planning to do large crawl(100 \n&gt; million pages).\n&gt;\n&gt;  \n&gt;\n&gt; My System is Intel Core 2 Quad 2.4 Ghz. 2.00 GB of RAM. and i found \n&gt; that more than 1 GB physical  is not used or  free during crawling. i \n&gt; allocate 1300m java heap allocation. i use\n&gt;\n&gt;  \n&gt;\n&gt; DecidingScope with the following set of DecideRules:\n&gt;\n&gt; 1. RejectDecideRule\n&gt;\n&gt; 2. SurtPrefixedDecideRule---------------------40000 URI as seed and \n&gt; seeds as-surt-prefixes\n&gt;\n&gt; 3. TooManyHopsDecideRule----------------10\n&gt;\n&gt; 4. PathologicalPathDecideRule\n&gt;\n&gt; 5. TooManyPathSegmentsDecideRule-----10\n&gt;\n&gt; 6. NotMatchesFilePatternDecideRule---          regexp: .*(/|&#92;.html)$\n&gt;\n&gt; 7. PrerequisiteAcceptDecideRule\n&gt;\n&gt;  \n&gt;\n&gt; and BloomUriUniqfilter(default settings) and 100 toethread\n&gt;\n&gt;  \n&gt;\n&gt; with above setting it crawls 30-40 URI/sec and I would like to  \n&gt; continue crawl to about 30-40 URI/sec. I have  2MB Bandwith of \n&gt; interenet. but the crawler runs with avg 700 KB. IF i use 10-20 seeds \n&gt; it crawls 3 URI/Sec.\n&gt;\n&gt;  \n&gt;\n&gt; According to this website \n&gt; http://java.sun.com/javase/6/webnotes/trouble/TSG-VM/html/gbywc.html#gbyvh \n&gt; &lt;http://java.sun.com/javase/6/webnotes/trouble/TSG-VM/html/gbywc.html#gbyvh&gt; there \n&gt; are 3 reseaon for java.lang.OutOfMemoryError: Java heap space.\n&gt;\n&gt;  \n&gt;\n&gt; Though BloomUriUniq filter is like to support 125 miilion URI to check \n&gt; already seen. but my crawler stuck discovering 1038937 URI and \n&gt; downloading 268187 pages after before running 2 hour.\n&gt;\n&gt;  \n&gt;\n&gt; Please tell me the neccessary step to get rid of Out of memory error.\n&gt;\n&gt;  \n&gt;\n&gt; Thanks in Advance\n&gt;\n&gt;  \n&gt;\n&gt; HIJBUL\n&gt;\n&gt;  \n&gt;\n&gt; N.B\n&gt;\n&gt; caused by: java.lang.OutOfMemoryError: Java heap space\n&gt;\n&gt; at com.sleepycat.je.log.LogUtils.readByteArray(_LogUtils.java:204_)\n&gt;\n&gt; at com.sleepycat.je.tree.IN.readFromLog(_IN.java:2952_)\n&gt;\n&gt; at com.sleepycat.je.log.entry.INLogEntry.readEntry(_INLogEntry.java:91_)\n&gt;\n&gt; at \n&gt; com.sleepycat.je.log.LogManager.getLogEntryFromLogSource(_LogManager.java:678_)\n&gt;\n&gt; at com.sleepycat.je.log.LogManager.getLogEntry(_LogManager.java:595_)\n&gt;\n&gt; at com.sleepycat.je.tree.IN.fetchTarget(_IN.java:958_)\n&gt;\n&gt; at com.sleepycat.je.tree.Tree.searchSubTreeInternal(_Tree.java:1917_)\n&gt;\n&gt; at com.sleepycat.je.tree.Tree.searchSubTree(_Tree.java:1754_)\n&gt;\n&gt; at com.sleepycat.je.tree.Tree.search(_Tree.java:1619_)\n&gt;\n&gt; at \n&gt; com.sleepycat.je.dbi.CursorImpl.searchAndPosition(_CursorImpl.java:1912_)\n&gt;\n&gt; at com.sleepycat.je.Cursor.searchInternal(_Cursor.java:1188_)\n&gt;\n&gt; at com.sleepycat.je.Cursor.searchAllowPhantoms(_Cursor.java:1158_)\n&gt;\n&gt; at com.sleepycat.je.Cursor.search(_Cursor.java:1024_)\n&gt;\n&gt; at com.sleepycat.je.Cursor.getSearchKey(_Cursor.java:566_)\n&gt;\n&gt; at \n&gt; com.sleepycat.util.keyrange.RangeCursor.doGetSearchKey(_RangeCursor.java:964_)\n&gt;\n&gt; at \n&gt; com.sleepycat.util.keyrange.RangeCursor.getSearchKey(_RangeCursor.java:591_)\n&gt;\n&gt; at \n&gt; com.sleepycat.collections.DataCursor.doGetSearchKey(_DataCursor.java:577_)\n&gt;\n&gt; at com.sleepycat.collections.DataCursor.initForPut(_DataCursor.java:818_)\n&gt;\n&gt; at com.sleepycat.collections.DataCursor.put(_DataCursor.java:758_)\n&gt;\n&gt; at \n&gt; com.sleepycat.collections.StoredContainer.put(_StoredContainer.java:302_)\n&gt;\n&gt; at com.sleepycat.collections.StoredMap.put(_StoredMap.java:248_)\n&gt;\n&gt; at \n&gt; org.archive.util.CachedBdbMap.expungeStaleEntry(_CachedBdbMap.java:562_)\n&gt;\n&gt; at \n&gt; org.archive.util.CachedBdbMap.expungeStaleEntries(_CachedBdbMap.java:533_)\n&gt;\n&gt; at org.archive.util.CachedBdbMap.get(_CachedBdbMap.java:358_)\n&gt;\n&gt; at \n&gt; org.archive.crawler.datamodel.ServerCache.getHostFor(_ServerCache.java:146_)\n&gt;\n&gt; at \n&gt; org.archive.crawler.datamodel.ServerCache.getHostFor(_ServerCache.java:175_)\n&gt;\n&gt; at org.archive.crawler.fetcher.FetchHTTP.canFetch(_FetchHTTP.java:731_)\n&gt;\n&gt; at \n&gt; org.archive.crawler.fetcher.FetchHTTP.innerProcess(_FetchHTTP.java:419_)\n&gt;\n&gt; at org.archive.crawler.framework.Processor.process(_Processor.java:112_)\n&gt;\n&gt; at \n&gt; org.archive.crawler.framework.ToeThread.processCrawlUri(_ToeThread.java:302_)\n&gt;\n&gt; at org.archive.crawler.framework.ToeThread.run(_ToeThread.java:151_)\n&gt;\n&gt; Environment invalid because of previous exception: \n&gt; _com.sleepycat.je.RunRecoveryException_\n&gt;\n&gt; at \n&gt; com.sleepycat.je.dbi.EnvironmentImpl.checkIfInvalid(_EnvironmentImpl.java:976_)\n&gt;\n&gt; at com.sleepycat.je.Database.checkEnv(_Database.java:1106_)\n&gt;\n&gt; at com.sleepycat.je.Database.delete(_Database.java:404_)\n&gt;\n&gt; at \n&gt; org.archive.crawler.frontier.BdbMultipleWorkQueues.delete(_BdbMultipleWorkQueues.java:438_)\n&gt;\n&gt; at \n&gt; org.archive.crawler.frontier.BdbWorkQueue.deleteItem(_BdbWorkQueue.java:91_)\n&gt;\n&gt; at org.archive.crawler.frontier.WorkQueue.dequeue(_WorkQueue.java:161_)\n&gt;\n&gt; at \n&gt; org.archive.crawler.frontier.WorkQueueFrontier.finished(_WorkQueueFrontier.java:883_)\n&gt;\n&gt; at org.archive.crawler.framework.ToeThread.run(_ToeThread.java:157_)\n&gt;\n&gt;  \n&gt;\n&gt;  \n&gt;\n&gt;  \n&gt;\n&gt; *Crawler Status: CRAWLING JOBS* | Hold \n&gt; &lt;http://127.0.0.1:8080/console/action.jsp?action=stop&gt;\n&gt; *Memory*\n&gt; 61262 KB used\n&gt; 65088 KB current heap\n&gt; 65088 KB max heap\n&gt; *Jobs*\n&gt; Pausing: /General/\n&gt; 0 pending, 6 completed\n&gt; *Alerts:* 143 (143 new) &lt;http://127.0.0.1:8080/console/alerts.jsp&gt;\n&gt;\n&gt; *Job Status: Pausing *| Resume \n&gt; &lt;http://127.0.0.1:8080/console/action.jsp?action=resume&gt; | Checkpoint \n&gt; &lt;http://127.0.0.1:8080/console/action.jsp?action=checkpoint&gt; | Terminate\n&gt; *Load*\n&gt; 0 active of 0 threads\n&gt; 9,331.4 congestion ratio\n&gt; 27636 deepest queue\n&gt; 22 average depth\n&gt; *Rates*\n&gt; 0 URIs/sec (33.22 avg)\n&gt; 0 KB/sec (671 avg)\n&gt; *Time*\n&gt; 2h35m41s elapsed\n&gt; 10h3m9s remaining (estimated)\n&gt; *Totals*\n&gt; downloaded 268187  \t\n&gt; \t *20*% \t 1038937 queued\n&gt;\n&gt; 1307124 total downloaded and queued\n&gt; 5.2 GB crawled (5.2 GB novel)\n&gt;\n&gt;  \n&gt;\n&gt;\n&gt;  \n\n\n"}}