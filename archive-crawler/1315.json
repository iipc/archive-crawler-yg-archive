{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":191507321,"authorName":"robeger","from":"&quot;robeger&quot; &lt;reger@...&gt;","profile":"robeger","replyTo":"LIST","senderId":"J4XO63-oR91MvQJkC49s2JKK6-Q89TevOYrkgUlJQpHO8qHyosqNXQ-Gg0LM7aOIjvqguyee4G2B2hJaPvhaHWX5","spamInfo":{"isSpam":false,"reason":"0"},"subject":"SEVERE alerts: ConcurrentModificationException","postDate":"1104773475","msgId":1315,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGNyYnZoMytnOGJtQGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":1316,"prevInTime":1314,"nextInTime":1316,"topicId":1315,"numMessagesInTopic":4,"msgSnippet":"I was just running a crawl of ~500 URLs and noticed that I was getting a ton of these (almost 600 when I stopped the crawl).  I m using the max doc per site","rawEmail":"Return-Path: &lt;reger@...&gt;\r\nX-Sender: reger@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 12815 invoked from network); 3 Jan 2005 17:32:35 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m8.grp.scd.yahoo.com with QMQP; 3 Jan 2005 17:32:35 -0000\r\nReceived: from unknown (HELO n4a.bulk.scd.yahoo.com) (66.94.237.38)\n  by mta1.grp.scd.yahoo.com with SMTP; 3 Jan 2005 17:32:35 -0000\r\nReceived: from [66.218.69.5] by n4.bulk.scd.yahoo.com with NNFMP; 03 Jan 2005 17:31:16 -0000\r\nReceived: from [66.218.67.179] by mailer5.bulk.scd.yahoo.com with NNFMP; 03 Jan 2005 17:31:16 -0000\r\nDate: Mon, 03 Jan 2005 17:31:15 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;crbvh3+g8bm@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Length: 1995\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Remote-IP: 66.94.237.38\r\nFrom: &quot;robeger&quot; &lt;reger@...&gt;\r\nSubject: SEVERE alerts: ConcurrentModificationException\r\nX-Yahoo-Group-Post: member; u=191507321\r\nX-Yahoo-Profile: robeger\r\n\r\n\nI was just running a crawl of ~500 URLs and noticed that I was getting\na ton of these (almost 600 when I stopped the crawl).  I&#39;m using the\nmax doc per site frontier (RobEgerFrontier) that Oskar put together,\nStack, along with domain scope.  I&#39;ve also got Tom&#39;s file extension\nURIRegExp filter set up.  Not sure what might be causing it.  This is\nwith the 1.2 release build, not HEAD.  Might try with HEAD now and see\nif it goes away.\n\nRob.\n\nHere&#39;s the heritrix alert text for one of them:\n\nTitle:   \t Problem occured processing\n&#39;http://www.akhter.com/categories.asp?cat=57&#39;\nTime:  \tJan. 3, 2005 17:18:53 GMT\nLevel:  \tSEVERE\nMessage:  \t\n\nProblem java.util.ConcurrentModificationException occured when trying\nto process &#39;http://www.akhter.com/categories.asp?cat=57&#39; at step\nABOUT_TO_BEGIN_PROCESSOR\n\n\nAssociated Throwable: java.util.ConcurrentModificationException\n\n  Stacktrace:\njava.util.ConcurrentModificationException\n\tat\njava.util.AbstractList$Itr.checkForComodification(AbstractList.java:448)\n\tat java.util.AbstractList$Itr.next(AbstractList.java:419)\n\tat\norg.archive.crawler.settings.ComplexType$AttributeIterator.next(ComplexType.java:1034)\n\tat org.archive.crawler.filter.OrFilter.innerAccepts(OrFilter.java:95)\n\tat org.archive.crawler.framework.Filter.accepts(Filter.java:93)\n\tat\norg.archive.crawler.framework.CrawlScope.excludeAccepts(CrawlScope.java:316)\n\tat\norg.archive.crawler.framework.CrawlScope.innerAccepts(CrawlScope.java:245)\n\tat org.archive.crawler.framework.Filter.accepts(Filter.java:93)\n\tat\norg.archive.crawler.postprocessor.Postselector.schedule(Postselector.java:269)\n\tat\norg.archive.crawler.postprocessor.Postselector.handleLinkCollection(Postselector.java:358)\n\tat\norg.archive.crawler.postprocessor.Postselector.innerProcess(Postselector.java:178)\n\tat org.archive.crawler.framework.Processor.process(Processor.java:102)\n\tat\norg.archive.crawler.framework.ToeThread.processCrawlUri(ToeThread.java:255)\n\tat org.archive.crawler.framework.ToeThread.run(ToeThread.java:131)\n\n\n\n\n\n"}}