{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":502766824,"authorName":"crawltst","from":"&quot;crawltst&quot; &lt;crawltst@...&gt;","profile":"crawltst","replyTo":"LIST","senderId":"iLmo2mf8BgzxOf72QrZJf9sze0_IIS69-FXILsJH1WLCXbTz16eJTqo8TTkDQa9amkVVr-brS6qm1ANxUy14Lg5QdqbX3Q","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Can Heritrix crawl the whole web?","postDate":"1320859145","msgId":7397,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGo5ZWNtOSs0a3A1QGVHcm91cHMuY29tPg==","inReplyToHeader":"PDRFQjgwRTM5LjcwMjA1MDlAYXJjaGl2ZS5vcmc+"},"prevInTopic":7387,"nextInTopic":0,"prevInTime":7396,"nextInTime":7398,"topicId":7376,"numMessagesInTopic":6,"msgSnippet":"Hi Thank you very much","rawEmail":"Return-Path: &lt;crawltst@...&gt;\r\nX-Sender: crawltst@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 12778 invoked from network); 9 Nov 2011 17:19:08 -0000\r\nX-Received: from unknown (98.137.34.45)\n  by m6.grp.sp2.yahoo.com with QMQP; 9 Nov 2011 17:19:08 -0000\r\nX-Received: from unknown (HELO ng1-ip1.bullet.mail.ne1.yahoo.com) (98.138.215.55)\n  by mta2.grp.sp2.yahoo.com with SMTP; 9 Nov 2011 17:19:07 -0000\r\nX-Received: from [98.138.217.181] by ng1.bullet.mail.ne1.yahoo.com with NNFMP; 09 Nov 2011 17:19:07 -0000\r\nX-Received: from [69.147.65.147] by tg6.bullet.mail.ne1.yahoo.com with NNFMP; 09 Nov 2011 17:19:07 -0000\r\nX-Received: from [98.137.34.184] by t10.bullet.mail.sp1.yahoo.com with NNFMP; 09 Nov 2011 17:19:07 -0000\r\nDate: Wed, 09 Nov 2011 17:19:05 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;j9ecm9+4kp5@...&gt;\r\nIn-Reply-To: &lt;4EB80E39.7020509@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;crawltst&quot; &lt;crawltst@...&gt;\r\nSubject: Re: Can Heritrix crawl the whole web?\r\nX-Yahoo-Group-Post: member; u=502766824; y=FuD7GF_HJ_-FySE76C-Qnp-EQIKOTDw8fOK0yi3wUXJ-lUo\r\nX-Yahoo-Profile: crawltst\r\n\r\nHi \nThank you very much\n\n\n--- In archive-crawler@yahoogroups.com, Noah Levi=\r\ntt &lt;nlevitt@...&gt; wrote:\n&gt;\n&gt; Hello,\n&gt; \n&gt; To crawl broadly you should change =\r\nthe first scope rule from RejectDecideRule to AcceptDecideRule. Then you ma=\r\ny want to look through the rest of the scope and remove rules that no longe=\r\nr makes sense.\n&gt; \n&gt; There is some information on hash mapped crawl config h=\r\nere: https://webarchive.jira.com/wiki/display/Heritrix/Multiple+Machine+Cra=\r\nwling\n&gt; \n&gt; Noah\n&gt; \n&gt; On 2011-10-28 22:43 , crawltst wrote:\n&gt; &gt; Hi\n&gt; &gt; Thank=\r\ns for answer.\n&gt; &gt; I want to crawl on accessible, public&  straight URLs; so=\r\n I don&#39;t have any problem with those &quot;No&quot; answers.\n&gt; &gt; As I know Heritrix o=\r\nnly crawls on seed list and doesn&#39;t follow links that their domain is not i=\r\nn seedlist (?); What about this?\n&gt; &gt; Excuse me but my English is not so goo=\r\nd. what do you mean from:\n&gt; &gt;&gt; Expect about 150K worth of hardware, to craw=\r\nl 10B sites in 2 months.\n&gt; &gt;\n&gt; &gt; What 10B means?\n&gt; &gt;\n&gt; &gt; How can I setup a =\r\nhash mapped crawl config? any reference/tutorial/start point?\n&gt; &gt;\n&gt; &gt; Gordo=\r\nn is right! And I will thank you very much if you write that FAQ.\n&gt; &gt; Thank=\r\ns\n&gt; &gt;\n&gt; &gt; --- In archive-crawler@yahoogroups.com, John Lekashman&lt;lekash@&gt;  =\r\nwrote:\n&gt; &gt;&gt;\n&gt; &gt;&gt; This is not a simple question.\n&gt; &gt;&gt;\n&gt; &gt;&gt; 1. No.  - There a=\r\nre robots.txt, and prohibited segments, you cannot get at.\n&gt; &gt;&gt;\n&gt; &gt;&gt; 2. No.=\r\n  - There are aspects of the web that are deep, behind databases,\n&gt; &gt;&gt; that=\r\n heritrix is not designed to hit.\n&gt; &gt;&gt;\n&gt; &gt;&gt; 3. No. - There are video format=\r\ns that are problematic to get through\n&gt; &gt;&gt; normal web download, so it can&#39;t=\r\n get them.\n&gt; &gt;&gt;\n&gt; &gt;&gt; And so on.\n&gt; &gt;&gt;\n&gt; &gt;&gt; That said, yes, it can crawl ever=\r\nywhere.\n&gt; &gt;&gt;\n&gt; &gt;&gt; The configuration you use is a bunch of machines, where b=\r\nunch is defined\n&gt; &gt;&gt; as as many as you can afford.\n&gt; &gt;&gt;\n&gt; &gt;&gt; Expect about 1=\r\n50K worth of hardware, to crawl 10B sites in 2 months.\n&gt; &gt;&gt; Some good fast =\r\n4 core processor, 32G or more memory, maybe 8T - 16T disk\n&gt; &gt;&gt; on each of 2=\r\n0 - 40 systems.\n&gt; &gt;&gt; If you want to go faster, scale up your systems.\n&gt; &gt;&gt;\n=\r\n&gt; &gt;&gt; Set up a hash mapped crawl config, use some seedlist that most interes=\r\nts\n&gt; &gt;&gt; you, and go.\n&gt; &gt;&gt;\n&gt; &gt;&gt; I&#39;ve done this a few dozen times, building a=\r\nrchive sets.\n&gt; &gt;&gt;\n&gt; &gt;&gt; Maybe I&#39;ll go write a\n\n\n"}}