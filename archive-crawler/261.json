{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"Michael Stack","from":"Michael Stack &lt;stack@...&gt;","replyTo":"LIST","senderId":"3lFG0y4DN20FhJgZlZDgPoyH7h3kQ4O0ZGMpexwgLu_1ISFH7B7DWoS3yyEuu1XKQhtgFXdD5zkHpcn_TLtrW5fgMcnbDSOh","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Heritrix Checkpointing High-Level Design","postDate":"1074893821","msgId":261,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQwMTE5M0ZELjMwOTA0MDhAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDEwNzQ4OTI0NDguNDAxMThlYTAzZWNkMUBtYWlsLWRldi5hcmNoaXZlLm9yZz4=","referencesHeader":"PDQwMERBMjRELjMwMjA0MDNAYXJjaGl2ZS5vcmc+IDw0MDEwODU2OS42MDYwMUBhcmNoaXZlLm9yZz4gPDQwMTE3QjJCLjUwNDAwQGFyY2hpdmUub3JnPiA8MTA3NDg5MjQ0OC40MDExOGVhMDNlY2QxQG1haWwtZGV2LmFyY2hpdmUub3JnPg=="},"prevInTopic":260,"nextInTopic":264,"prevInTime":260,"nextInTime":262,"topicId":244,"numMessagesInTopic":13,"msgSnippet":"... I like this.  Would it get its own job directory built off the configuration from the job that ran the checkpoint?  What about the data already collected?","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 30307 invoked from network); 23 Jan 2004 21:43:10 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m14.grp.scd.yahoo.com with QMQP; 23 Jan 2004 21:43:10 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (209.237.232.202)\n  by mta5.grp.scd.yahoo.com with SMTP; 23 Jan 2004 21:43:09 -0000\r\nReceived: (qmail 2961 invoked by uid 100); 23 Jan 2004 21:40:50 -0000\r\nReceived: from b116-dyn-60.archive.org (HELO archive.org) (stack@...@209.237.240.60)\n  by mail-dev.archive.org with SMTP; 23 Jan 2004 21:40:50 -0000\r\nMessage-ID: &lt;401193FD.3090408@...&gt;\r\nDate: Fri, 23 Jan 2004 13:37:01 -0800\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.5) Gecko/20031007\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: Gordon Mohr &lt;gojomo@...&gt;\r\nReferences: &lt;400DA24D.3020403@...&gt; &lt;40108569.60601@...&gt; &lt;40117B2B.50400@...&gt; &lt;1074892448.40118ea03ecd1@...&gt;\r\nIn-Reply-To: &lt;1074892448.40118ea03ecd1@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=-3.6 required=6.0 tests=AWL,BAYES_00 autolearn=ham \n\tversion=2.63\r\nX-eGroups-Remote-IP: 209.237.232.202\r\nFrom: Michael Stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] Heritrix Checkpointing High-Level Design\r\nX-Yahoo-Group-Post: member; u=168599281\r\n\r\nkris@... wrote:\n\n&gt;Quoting Gordon Mohr &lt;gojomo@...&gt;:\n&gt;\n&gt;  \n&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;&lt;--- SNIP ---&gt;\n&gt;  \n&gt;\n&gt;&gt; &gt;\n&gt;&gt;\n&gt;&gt; &gt; So all logs for a crawl will be available under the logging directory?\n&gt;&gt; &gt; We don&#39;t want to rotate them out on a period?  Will the UI be expected\n&gt;&gt;&lt;-- More SNIPPING --&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;&gt;a checkpoint, use the software admin UI to examine it to see\n&gt;&gt;if it really is the one you&#39;d like to resume, perhaps repeat\n&gt;&gt;this several times, tinker with some settings, and then hit\n&gt;&gt;&#39;begin&#39; to pick up where it left off.\n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;Another option here is that when we resume from a checkpoint it is handled like\n&gt;any other job. Thus if the crawler was already running, it would simply be\n&gt;prepared and put into the pending queue.\n&gt;\n&gt;  \n&gt;\nI like this.  Would it get its own job directory built off the \nconfiguration from the job that ran the checkpoint?  What about the data \nalready collected?  We&#39;d just point at the same place as the  original job?\n\n&lt;-- MORE SNIPPING --&gt;\n\n&gt;&gt;\n&gt;&gt;The existing pause/terminate facility will be touched up as necessary;\n&gt;&gt;I believe it currently sets a flag indicating that a pause or termination\n&gt;&gt;has been requested, and lets the CrawlController control thread react.\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;That is correct. The CrawlController basically stops new URIs from being\n&gt;processed and eventually halt&#39;s the crawl. Currently if there is a thread that\n&gt;&#39;hangs&#39; it will hang the entire pausing, making resumes impossible.\n&gt;  \n&gt;\nThis is as I&#39;d expect and as already stated, killing threads doesn&#39;t \nbring on recovery from hung state (in my experience).\n\n&gt;  \n&gt;\n&gt;&gt; &gt; Is it completely up to the Checkpointable implementer how they checkpoint?\n&gt;&gt;\n&gt;&gt;Yes, though by convention, they should ensure all their state goes\n&gt;&gt;into the designated checkpoint directory.\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;I suggest that by default the checkpointing directory be a subdirectory of the\n&gt;job directory. Thus it would be easy to see what job any checkpoint belongs to.\n&gt;This should then be configurable in the crawl order.\n&gt;\n&gt;  \n&gt;\n+1\n\nSt.Ack\n\n&gt;- Kris\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;  \n&gt;\n&gt;&gt; &gt;&gt;Generally, the checkpointing of an object involves:\n&gt;&gt; &gt;&gt; (1) Writing its important in-memory state to\n&gt;&gt; &gt;&gt;     one or more files.\n&gt;&gt; &gt;&gt;\n&gt;&gt; &gt;&gt; (2) Duplicating any on-disk state to the checkpoint\n&gt;&gt; &gt;&gt;     directory. (In some cases, this may be possible\n&gt;&gt; &gt;&gt;     with filesystem hard-links rather than actual\n&gt;&gt; &gt;&gt;     copies.)\n&gt;&gt; &gt;&gt;\n&gt;&gt; &gt;\n&gt;&gt; &gt; Do you have examples of the above to illustrate how it would work?\n&gt;&gt;\n&gt;&gt;A trivial example of (1) would be the ARC writer knowing what\n&gt;&gt;sequence-number to assign the next ARC file to begin. When asked\n&gt;&gt;to checkpoint itself, it would write that bit of state to a file.\n&gt;&gt;Similarly, any module collecting a in-memory histogram of\n&gt;&gt;interesting resource features would dump its current data in\n&gt;&gt;a recoverable fashion to a file.\n&gt;&gt;\n&gt;&gt;For (2), an example would be the Frontier&#39;s overall pending queue\n&gt;&gt;or per-host queues. These might already substantially be on disk,\n&gt;&gt;with a small amount in memory. I believe our existing disk-backed\n&gt;&gt;Queues can be quickly checkpointed into three files with a minimum\n&gt;&gt;of disk writing by:\n&gt;&gt;    (a) creating hard links to the up-to-2 constituent backing\n&gt;&gt;        disk files (&quot;flip files&quot;)\n&gt;&gt;    (b) writing a third file which contains the current lengths of\n&gt;&gt;        those backing files, the current pointer to the &#39;head&#39; entry\n&gt;&gt;        in one of those files, and the portions of the queue which\n&gt;&gt;        live in memory.\n&gt;&gt;As activity continues after a checkpoint, the &quot;flip files&quot; grow\n&gt;&gt;but are never overwritten, just discarded when their contents are\n&gt;&gt;no longer needed. Thus, the hard links will keep the checkpoint\n&gt;&gt;data (as well as some extra cruft) alive under a different filename.\n&gt;&gt;When a resume becomes necessary the relevant excerpts of the files\n&gt;&gt;will be restored.\n&gt;&gt;\n&gt;&gt; &gt;&gt;To resume from a checkpoint, the CrawlController would\n&gt;&gt; &gt;&gt;receive a resume-request with an origin directory. It\n&gt;&gt; &gt;&gt;would reconstitute the parts of the crawl, primarily by\n&gt;&gt; &gt;&gt;constructing new instances which read their state from\n&gt;&gt; &gt;&gt;the origin directory, copying data as necessary to the\n&gt;&gt; &gt;&gt;&quot;running&quot; disk space. (A resume should not alter the\n&gt;&gt; &gt;&gt;stored checkpoint in any way.)\n&gt;&gt; &gt;\n&gt;&gt; &gt; The origin directory points at the checkpoint we want to resume from?\n&gt;&gt;\n&gt;&gt;Yes.\n&gt;&gt;\n&gt;&gt; &gt;&gt;CHECKPOINT FRAMEWORK\n&gt;&gt; &gt;&gt;\n&gt;&gt; &gt;&gt;Each ToeThread wraps its per-URI processing with:\n&gt;&gt; &gt;&gt;\n&gt;&gt; &gt;&gt;   crawlLock.acquireShared(); // crawlLock is a shared-exclusive\n&gt;&gt; &gt;&gt;                              // (AKA &#39;readwrite&#39;) lock\n&gt;&gt; &gt;&gt;   // all processing\n&gt;&gt; &gt;&gt;   crawlLock.releaseShared();\n&gt;&gt; &gt;&gt;\n&gt;&gt; &gt;&gt;(This lock may be refined later to leave out early\n&gt;&gt; &gt;&gt;processing stages, possibly up through fetching,\n&gt;&gt; &gt;&gt;which can be harmlessly considered to never have\n&gt;&gt; &gt;&gt;begun.)\n&gt;&gt; &gt;&gt;\n&gt;&gt; &gt;&gt;The CrawlController controlThread, when it detects\n&gt;&gt; &gt;&gt;a checkpoint has been requested, runs a checkpoint\n&gt;&gt; &gt;&gt;rountine which is roughly:\n&gt;&gt; &gt;&gt;\n&gt;&gt; &gt;&gt;   crawlLock.acquireExclusive();\n&gt;&gt; &gt;&gt;   versionId++;\n&gt;&gt; &gt;&gt;   prepare(versionId, checkpointDirectory); // actually does the\n&gt;&gt;checkpointing, passing\n&gt;&gt; &gt;&gt;                                            // prepare() calls to\n&gt;&gt;subcomponents\n&gt;&gt; &gt;&gt;   commit(versionId, checkpointDirectory);  // marks the checkpoint as\n&gt;&gt;complete, cleans up\n&gt;&gt; &gt;&gt;\n&gt;&gt; &gt;&gt;\n&gt;&gt; &gt;&gt;   crawlLock.releaseExclusive();\n&gt;&gt; &gt;\n&gt;&gt; &gt; Are you missing a resume here?\n&gt;&gt;\n&gt;&gt;Missing a resume() example, yes -- but in the checkpointing itself, no\n&gt;&gt;resume() is necessary: the prepare() and commit() do not destroy any\n&gt;&gt;of the crawl state.\n&gt;&gt;\n&gt;&gt;Resuming is actually much like starting a crawl for the first time,\n&gt;&gt;a close analogue to CrawlController.initialize() and\n&gt;&gt;CrawlController.startCrawl(), but I&#39;m not sure yet how the details will\n&gt;&gt;work out.\n&gt;&gt;\n&gt;&gt;Great questions! Keep them coming.\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;- Gordon\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;Yahoo! Groups Links\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;To visit your group on the web, go to:\n&gt;&gt;http://groups.yahoo.com/group/archive-crawler/\n&gt;&gt; \n&gt;&gt;To unsubscribe from this group, send an email to:\n&gt;&gt;archive-crawler-unsubscribe@yahoogroups.com\n&gt;&gt; \n&gt;&gt;Your use of Yahoo! Groups is subject to the Yahoo! Terms of Service.\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; \n&gt;\n&gt;\n&gt;Yahoo! Groups Links\n&gt;\n&gt;To visit your group on the web, go to:\n&gt; http://groups.yahoo.com/group/archive-crawler/\n&gt;\n&gt;To unsubscribe from this group, send an email to:\n&gt; archive-crawler-unsubscribe@yahoogroups.com\n&gt;\n&gt;Your use of Yahoo! Groups is subject to:\n&gt; http://docs.yahoo.com/info/terms/ \n&gt;\n&gt;\n&gt;  \n&gt;\n\n\n\n"}}