{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":334763322,"authorName":"Christian Krumm","from":"Christian Krumm &lt;signore.chrissi@...&gt;","profile":"chuk_ol","replyTo":"LIST","senderId":"idLOJF0BZiKZBWVsiKLSO1tT6ALNyqy7qwuCq2QNljWtZGTJbOhNaTzFDK10YmSdfiB04p4GjdWHoX-OYs9fZmDSIKFX5CzBNp4weEvtuIKZabwXkkSQ","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Can Any One Help me with your valuble sugessions","postDate":"1220875374","msgId":5450,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ4QzUxNDZFLjkwMzA1MDlAZ29vZ2xlbWFpbC5jb20+","inReplyToHeader":"PGdhMnNoYStoYWwyQGVHcm91cHMuY29tPg==","referencesHeader":"PGdhMnNoYStoYWwyQGVHcm91cHMuY29tPg=="},"prevInTopic":5449,"nextInTopic":0,"prevInTime":5449,"nextInTime":5451,"topicId":5449,"numMessagesInTopic":2,"msgSnippet":"... Hi, I ll have a look into my magic crystal ball to find the answer... ;-) ... Well, first of all check which urls aren t handled by heritrix. Then recheck","rawEmail":"Return-Path: &lt;signore.chrissi@...&gt;\r\nX-Sender: signore.chrissi@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 85297 invoked from network); 8 Sep 2008 12:03:23 -0000\r\nX-Received: from unknown (66.218.67.94)\n  by m42.grp.scd.yahoo.com with QMQP; 8 Sep 2008 12:03:23 -0000\r\nX-Received: from unknown (HELO smtpmx11.uni-oldenburg.de) (134.106.87.111)\n  by mta15.grp.scd.yahoo.com with SMTP; 8 Sep 2008 12:03:23 -0000\r\nX-Received: from [192.168.2.27] (p57B6DBEC.dip.t-dialin.net [87.182.219.236])\n\t(authenticated bits=0)\n\tby smtpmx11.uni-oldenburg.de (8.13.1/8.13.1) with ESMTP id m88C3JBK022251\n\t(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NO)\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Mon, 8 Sep 2008 14:03:21 +0200\r\nMessage-ID: &lt;48C5146E.9030509@...&gt;\r\nDate: Mon, 08 Sep 2008 14:02:54 +0200\r\nUser-Agent: Thunderbird 2.0.0.16 (X11/20080724)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;ga2sha+hal2@...&gt;\r\nIn-Reply-To: &lt;ga2sha+hal2@...&gt;\r\nX-Enigmail-Version: 0.95.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Transfer-Encoding: 7bit\r\nX-PMX-Version: 5.4.3.345767, Antispam-Engine: 2.6.0.325393, Antispam-Data: 2008.9.8.114324\r\nX-PerlMx-Spam: Gauge=IIIIIII, Probability=7%, Report=&#39;BODY_SIZE_1300_1399 0, BODY_SIZE_5000_LESS 0, RDNS_DYNAMIC 0, RDNS_SUSP 0, RDNS_SUSP_SPECIFIC 0, __BOUNCE_CHALLENGE_SUBJ 0, __CT 0, __CTE 0, __CT_TEXT_PLAIN 0, __FRAUD_419_WEBMAIL 0, __FRAUD_419_WEBMAIL_FROM 0, __HAS_MSGID 0, __MIME_TEXT_ONLY 0, __MIME_VERSION 0, __SANE_MSGID 0, __USER_AGENT 0&#39;\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Christian Krumm &lt;signore.chrissi@...&gt;\r\nSubject: Re: [archive-crawler] Can Any One Help me with your valuble sugessions\r\nX-Yahoo-Group-Post: member; u=334763322; y=lRxN_q2QJLy5hcksgUHKzU9WUcl9Fvvy9cB_YygCkJyx-w\r\nX-Yahoo-Profile: chuk_ol\r\n\r\navinashnash schrieb:\n&gt; Hi,\n&gt; \n&gt; I am using Heritrix crawler for crawling through the domains. The\n&gt; problem which Iam facing now is when I try to crawl through some\n&gt; domains even though the crawling is getting done its not getting fully\n&gt; done. suppose the website is having 60 pages whats happening in my\n&gt; case is like its only crawling 46 page the crawler is not at all\n&gt; identifying the other pages. I found this when  I checked the log file\n&gt; for that particular job. so pls help me with your valuable suggestion\n&gt; so that it would be a great help for me.\n&gt; \n&gt; \n&gt; \n\nHi,\n\nI&#39;ll have a look into my magic crystal ball to find the answer... ;-)\n:-D *jokingly*\n\n\nWell, first of all check which urls aren&#39;t handled by heritrix.\nThen recheck your configuration. Perhaps some uris aren&#39;t handled\nbecause some DecideRules prevents heritrix from crawling the website.\nURIs which were rejected by DecideRule aren&#39;t logged as far as I know,\nso you won&#39;t find any hints in the logs. If you need more help, add some\nmore informations:\n\n- Which version of Heritrix is in use?\n- Which domains or websites do you want to crawl?\n- Does your configuration differ from standard jobs packaged\n  with Heritrix? How?\n- Which configuration are you useing right now?\n- Which hyperlinks or websites aren&#39;t\n  recognized by Heritrix in your specific job?\n\n\nChristian\n\n"}}