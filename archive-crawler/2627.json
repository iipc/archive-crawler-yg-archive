{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr (archive.org)","from":"&quot;Gordon Mohr (archive.org)&quot; &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"ALXyTTLIrFWDjdR7QnUvzBPIgRN1MvVq1vtdmT3RAShPOtDFR6jBk3oGYU425TB7e9MXb8DH1zLuCPg1FmwKwyVw5VxKqUtYMehKUn_oofIjiB2zMUkK","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Exhausted work queues/domain","postDate":"1139525706","msgId":2627,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQzRUJDODRBLjQwMTAxMDJAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDQzRTk4ODExLjIwODAwMDdAYW9sLmNvbT4=","referencesHeader":"PDQzRTk4ODExLjIwODAwMDdAYW9sLmNvbT4="},"prevInTopic":2624,"nextInTopic":2628,"prevInTime":2626,"nextInTime":2628,"topicId":2624,"numMessagesInTopic":6,"msgSnippet":"... Programmatically, or as a crawl operator seeking a summary report? If the latter, there are not-yet-documented query-string parameters that may be added to","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 74065 invoked from network); 9 Feb 2006 22:55:11 -0000\r\nReceived: from unknown (66.218.67.36)\n  by m7.grp.scd.yahoo.com with QMQP; 9 Feb 2006 22:55:11 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (207.241.224.171)\n  by mta10.grp.scd.yahoo.com with SMTP; 9 Feb 2006 22:55:10 -0000\r\nReceived: (qmail 22974 invoked by uid 100); 9 Feb 2006 22:48:36 -0000\r\nReceived: from adsl-71-130-102-78.dsl.pltn13.pacbell.net (HELO ?192.168.1.10?) (gojomo@...@71.130.102.78)\n  by mail-dev.archive.org with SMTP; 9 Feb 2006 22:48:36 -0000\r\nMessage-ID: &lt;43EBC84A.4010102@...&gt;\r\nDate: Thu, 09 Feb 2006 14:55:06 -0800\r\nUser-Agent: Mozilla Thunderbird 1.0.7-1.1.fc3 (X11/20050929)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;43E98811.2080007@...&gt;\r\nIn-Reply-To: &lt;43E98811.2080007@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=-87.6 required=7.0 tests=AWL,USER_IN_WHITELIST \n\tautolearn=no version=2.63\r\nX-eGroups-Msg-Info: 2:12:4:0\r\nFrom: &quot;Gordon Mohr (archive.org)&quot; &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Exhausted work queues/domain\r\nX-Yahoo-Group-Post: member; u=137285340; y=nNgMhRQkDfjsvwTnmU9E5bB2Nn3iPzrusXrs6uXByOHN\r\nX-Yahoo-Profile: gojomo\r\n\r\nPrasenjit Mukherjee wrote:\n&gt; Is there a way to figure out the domains(or WorkQueues) which are \n&gt; completed(rather exhausted) ?\n\nProgrammatically, or as a crawl operator seeking a summary report?\n\nIf the latter, there are not-yet-documented query-string parameters\nthat may be added to the Frontier report URL to (1) select a non-default\nFrontier report format to use; and (2) request that the report be dumped\nto a file rather than to the browser.\n\nSpecifically:\n\n* the &#39;name&#39; parameter may be specified as &#39;nonempty&#39; or &#39;all&#39;. Each\n   of these non-default formats reports one queue per line, and does\n   not truncate the lists after a few thousand, like the default\n   report does. Thus, in a large crawl, they can take a while to dump.\n   As the names suggest, &#39;all&#39; shows all queues -- even those that\n   have been exhausted -- and &#39;nonempty&#39; only those with items remaining.\n   A legend explaining each field of the single-line display will\n   appear at top.\n* the &#39;dumpFile&#39; parameter may give the name of file, relative to the\n   crawler working directory, to which to dump the report rather than\n   to the browser.\n\nSo for example, the following URL...\n\n   http://localhost:8080/reports/frontier.jsp?name=all&dumpFile=frontier-all.report\n\n...would dump the queue-per-line all-queues Frontier report to the\nfile &#39;frontier-all.report&#39; in the working directory in which\nthe crawler was launched.\n\nSomeday, UI controls to reach these options will be added.\n\nKeep in mind that a queue can be temporarily exhausted -- with more\nURLs to be discovered from offsite inlinks right around the corner.\nThis might even be quite common early in crawls, if a few lone\nresources are referenced from a site before reaching its own\ninterlinked content.\n\nHope this helps,\n\n- Gordon @ IA\n\n\n\n"}}