{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"3XYeG_mQzppo6jzMDmAxSSMn6yUuauyuCkbWh79rzxlADQhM_hDoXDDzEp2QUcY0vlqyoRLwW-8QCd6q-q1YM9voQ5UVxV0","spamInfo":{"isSpam":false,"reason":"3"},"subject":"Re: [archive-crawler] Best way of filtering of URLs with RegExp?","postDate":"1238970229","msgId":5756,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ5RDkyRjc1LjgwNzA3MDhAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGdyNzJtdStuOGF1QGVHcm91cHMuY29tPg==","referencesHeader":"PGdyNzJtdStuOGF1QGVHcm91cHMuY29tPg=="},"prevInTopic":5753,"nextInTopic":5761,"prevInTime":5755,"nextInTime":5757,"topicId":5753,"numMessagesInTopic":4,"msgSnippet":"The midfetch-decide-rules are used only to abort a fetch midway (after the headers have been retrieved). The proper way to control which URIs are even","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 39391 invoked from network); 5 Apr 2009 22:24:19 -0000\r\nX-Received: from unknown (69.147.108.200)\n  by m8.grp.re1.yahoo.com with QMQP; 5 Apr 2009 22:24:19 -0000\r\nX-Received: from unknown (HELO mail.archive.org) (207.241.231.239)\n  by mta1.grp.re1.yahoo.com with SMTP; 5 Apr 2009 22:24:19 -0000\r\nX-Received: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id 445A52588BB\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Sun,  5 Apr 2009 15:23:49 -0700 (PDT)\r\nX-Received: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id QJkX-MB2x3M8 for &lt;archive-crawler@yahoogroups.com&gt;;\n\tSun,  5 Apr 2009 15:23:48 -0700 (PDT)\r\nX-Received: from [10.0.13.7] (adsl-70-137-133-20.dsl.snfc21.sbcglobal.net [70.137.133.20])\n\tby mail.archive.org (Postfix) with ESMTPSA id C79AD256607\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Sun,  5 Apr 2009 15:23:48 -0700 (PDT)\r\nMessage-ID: &lt;49D92F75.8070708@...&gt;\r\nDate: Sun, 05 Apr 2009 15:23:49 -0700\r\nUser-Agent: Thunderbird 2.0.0.21 (Windows/20090302)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;gr72mu+n8au@...&gt;\r\nIn-Reply-To: &lt;gr72mu+n8au@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 2:3:4:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Best way of filtering of URLs with RegExp?\r\nX-Yahoo-Group-Post: member; u=137285340; y=a7VyPkqsEbWEBB4OHhYyS_SSzbCIHL42t-u4bc0Qg622\r\nX-Yahoo-Profile: gojomo\r\n\r\nThe &#39;midfetch-decide-rules&#39; are used only to abort a fetch midway (after \nthe headers have been retrieved).\n\nThe proper way to control which URIs are even attempted is to adjust the \ncrawl&#39;s &#39;scope&#39;. You could add a late rule to the set of scoping \ndecide-rules that REJECTs URIs matching your expression. Then, those \nURIs won&#39;t even be queued for processing.\n\n- Gordon @ IA\n\nfelizimm wrote:\n&gt; Hi,\n&gt; \n&gt; I like to filter specific URLs and everything works really fine with RegExp in &quot;fetch-processor -&gt; midfetch-decide-rules&quot;. But I noticed in the logs that heritrix gets the http-header of every &quot;unwanted&quot; page.\n&gt; \n&gt; Is there a possibility to prevent crawling &quot;unwanted&quot; pages in advance, so that heritrix does not get any piece of the file? I tried the &quot;pre-fetch-processors&quot; but it didn&#39;t work with the same RegExp.\n&gt; \n&gt; Thanks!\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; ------------------------------------\n&gt; \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n"}}