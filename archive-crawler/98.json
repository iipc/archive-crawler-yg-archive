{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"&quot;Gordon Mohr&quot; &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"G8rgF3Q27dcSTGRW-G7Jf7WCPhRN9ANDh_QNqL3D1s29yOpZ7QU32_DRkMCc-idyOQfPs1S13HLGlk0vVOndf9cxRp3bM_Slfg","spamInfo":{"isSpam":false,"reason":"0"},"subject":"User-agent issues with open crawler","postDate":"1057613979","msgId":98,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDAwNTYwMWMzNDRkMCQ1NmRlMjAzMCQ0OGYwZWRkMUBXT1JLU1RBVElPTjIxPg=="},"prevInTopic":0,"nextInTopic":0,"prevInTime":97,"nextInTime":99,"topicId":98,"numMessagesInTopic":1,"msgSnippet":"An important issue that will come up with our open code base being run by outsiders is raised, in the context of Nutch, at: ","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 81798 invoked from network); 7 Jul 2003 21:42:31 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m1.grp.scd.yahoo.com with QMQP; 7 Jul 2003 21:42:31 -0000\r\nReceived: from unknown (HELO mail.archive.org) (209.237.232.56)\n  by mta2.grp.scd.yahoo.com with SMTP; 7 Jul 2003 21:42:30 -0000\r\nReceived: from WORKSTATION21 (b116-dyn-72.archive.org [209.237.240.72])\n\tby mail.archive.org (8.12.8/8.10.2) with SMTP id h67Kp5lQ004697\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Mon, 7 Jul 2003 13:51:20 -0700\r\nMessage-ID: &lt;005601c344d0$56de2030$48f0edd1@WORKSTATION21&gt;\r\nTo: &lt;archive-crawler@yahoogroups.com&gt;\r\nSubject: User-agent issues with open crawler\r\nDate: Mon, 7 Jul 2003 14:39:39 -0700\r\nMIME-Version: 1.0\r\nContent-Type: text/plain;\n\tcharset=&quot;Windows-1252&quot;\r\nContent-Transfer-Encoding: 7bit\r\nX-Priority: 3\r\nX-MSMail-Priority: Normal\r\nX-Mailer: Microsoft Outlook Express 6.00.2800.1158\r\nX-MimeOLE: Produced By Microsoft MimeOLE V6.00.2800.1165\r\nFrom: &quot;Gordon Mohr&quot; &lt;gojomo@...&gt;\r\nX-Yahoo-Group-Post: member; u=137285340\r\nX-Yahoo-Profile: gojomo\r\n\r\nAn important issue that will come up with our open code\nbase being run by outsiders is raised, in the context of \nNutch, at:\n\n  http://www.webmasterworld.com/forum23/2200.htm\n\nThey write:\n&gt; One notable exception to the above is our friends at \n&gt; Nutch.org. They have painted themselves into a corner \n&gt; recently because of the way they have specified their \n&gt; crawler&#39;s user-agent names. The user-agent for their \n&gt; development team is &quot;NutchOrg&quot; and the user-agent for \n&gt; others who wish to use their crawler is just &quot;Nutch.&quot; \n&gt; We can be reasonably sure that the development team is \n&gt; not going to allow their crawler to be abusive or use \n&gt; it for untoward purposes, but it&#39;s yet to be seen \n&gt; whether they can and will enforce requirements for \n&gt; &quot;good behaviour&quot; on the part of their licensees. \n&gt; Therefore, if we wish to err on the side of caution, \n&gt; and to allow NutchOrg but disallow unknown licensees, \n&gt; we have to use: \n&gt; \n&gt; User-agent: NutchOrg \n&gt; Disallow: \n&gt; \n&gt; User-agent: Nutch \n&gt; Disallow: / \n&gt; \n&gt; Note also that the example given on their Webmaster \n&gt; information page is technically incorrect, since a \n&gt; robot should obey the first User-agent line it matches \n&gt; in robots.txt. \n&gt; \n&gt; I have suggested to the authors that they require a \n&gt; licensing agreement for use and specify in that licensing \n&gt; agreement that users must properly identify themselves \n&gt; in the user-agent string as seen in our log files. At a \n&gt; minimum, the licensed version should carry a user-agent \n&gt; of something like NutchUsr to prevent the substring-matching \n&gt; problem cited above. I wish them luck, but they have several \n&gt; loose strings to tie up in order to avoid having their \n&gt; robot become the next Indy Library (spambot). \n\n--\n\nI don&#39;t think the license-requirement is a workable solution:\nbad agents will do what they want anyway, and we&#39;re unlikely\nto have the resources/desire to chase them down for license\nviolations. \n\nHowever, we can adopt practices that discourage bad user-agent\npractices, or practices which cause confusion with our own\ncrawling activity. \n\nSome ideas:\n\n(1) The crawling code includes a check to make sure that\n    suitable &#39;user-agent&#39; and &#39;from&#39; values have been set\n    for crawls. Suitable would include:\n    (a) A valid-looking URL in the user-agent\n    (b) A valid-looking email address in the from\n\n(2) Our default/official configuration files contain\n    *unsuitable* placeholder values, for example:\n\n     user-agent: aoc-cvs (contact-url)\n     from: contact-email-address\n\n    Any attempt to run directly from CVS results in \n    an error suggesting these values be corrected \n    before trying again. \n\nThis creates a slight extra burden on our testing and\nindividual use: we have to patch up the config files \nafter each get from CVS, and we have to be vigilant\nabout not checking working configs into CVS. \n\nThoughts? Other ideas?\n\n- Gordon\n\n\n"}}