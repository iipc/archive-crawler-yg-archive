{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"3dZgPKblosQz_VNVUKuPNNmRElLBY6QXbpZhjdMt-ehEnpIp-gRqcqHRixlIK2-MmQJqpa5eNGUcb-yyCOtopdByPi7rFMo","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] New to Heritrix and need a boost! :)","postDate":"1195578734","msgId":4728,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ3NDMxNTZFLjYwMjAzMDNAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGZodjI4ais5NGxrQGVHcm91cHMuY29tPg==","referencesHeader":"PGZodjI4ais5NGxrQGVHcm91cHMuY29tPg=="},"prevInTopic":4726,"nextInTopic":4731,"prevInTime":4727,"nextInTime":4729,"topicId":4726,"numMessagesInTopic":3,"msgSnippet":"... It s rare that most crawl operators would need to write or customize the code of a Frontier; it s a core component that s already very flexible. How many","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 99094 invoked from network); 20 Nov 2007 17:12:16 -0000\r\nX-Received: from unknown (66.218.67.96)\n  by m50.grp.scd.yahoo.com with QMQP; 20 Nov 2007 17:12:16 -0000\r\nX-Received: from unknown (HELO relay01.pair.com) (209.68.5.15)\n  by mta17.grp.scd.yahoo.com with SMTP; 20 Nov 2007 17:12:16 -0000\r\nX-Received: (qmail 23570 invoked from network); 20 Nov 2007 17:12:14 -0000\r\nX-Received: from unknown (HELO ?10.0.10.102?) (unknown)\n  by unknown with SMTP; 20 Nov 2007 17:12:14 -0000\r\nX-pair-Authenticated: 70.137.138.31\r\nMessage-ID: &lt;4743156E.6020303@...&gt;\r\nDate: Tue, 20 Nov 2007 09:12:14 -0800\r\nUser-Agent: Thunderbird 2.0.0.9 (Windows/20071031)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;fhv28j+94lk@...&gt;\r\nIn-Reply-To: &lt;fhv28j+94lk@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] New to Heritrix and need a boost! :)\r\nX-Yahoo-Group-Post: member; u=137285340; y=qlXwGH9W62-beUMSRosu5gtHwWkKFpoalvASdU5KwLKV\r\nX-Yahoo-Profile: gojomo\r\n\r\nallen.vachon wrote:\n&gt; Hi,\n&gt; \n&gt; New to Heritrix and WebCrawling with knowledge of Java.\n&gt; \n&gt; I am analyzing how things can be done for our needs.\n&gt; We want to crawl specific sites and extract data (product, price, \n&gt; description, etc).\n&gt; \n&gt; 1) Some site are multilingual, so should I use 2 seeds (2 languages)\n&gt;    for that site or should I write a &quot;Frontier&quot; or else?\n\nIt&#39;s rare that most crawl operators would need to write or customize the \ncode of a Frontier; it&#39;s a core component that&#39;s already very flexible.\n\nHow many seeds to use depends on how many are necessary to discover all \nthe content you want collected. If the site makes different-language \ncontent available via different URLs -- such as:\n\n   http://en.example.com/[content]\n   http://fr.example.com/[content]\n\n...or...\n\n   http://example.com/en/[content]\n   http://example.com/fr/content\n\n...then it&#39;s easy to crawl in many ways. Maybe one seed to a language \nselector page is enough to find all variants, or two seeds to good \nstarting points for each language, or even two crawls if you prefer \nhaving completely distinct logs/output.\n\nDeeper problems arise when a site serves alternate language content from \nthe exact same URLs, based on a cookie that can be toggled by the user. \nThen, a single crawl may show a mix of language content. In such cases, \nyou typically need to crawl twice, in one crawl ensuring that the cookie \nstays at one value, in the other the other cookie value.\n\n&gt; 2) I need different way to process a URI based on the depth level\n&gt;    by analyzing the DOM and its links:\n&gt; \n&gt;    Level 0 (root)    : Get some specific links and keep some\n&gt;                        informations for that level.\n&gt;    Level 1 (Category): {Same as Level 0}\n&gt;    Level 2 (Product) : Get information on the product plus all\n&gt;                        previous&#39; one (previous levels).\n&gt;                        Proceed for next pages (click on next page)\n&gt;                        for that level until end.\n&gt; \n&gt;    How can I do that? Do I need a &quot;Frontier&quot;?\n&gt;    It not simply as fetch everything for a site.\n\nYou could probably write a &#39;Processor&#39; module that you would insert \nsomewhere near the existing Extractor modules in the chains of \nprocessing steps. It would examine the URL pattern, page content, and \npossibly the URL&#39;s &#39;via&#39; (predecessor URL where it was discovered) and \n&#39;hops-path&#39; (symbolic string of discovery hop-types, eg &#39;LLL&#39; for 3 \nnavigational links in a row) to determine what to do, and then do your \ncustom analysis. See this portion of the Developer Manual for \ninformation on writing a Processor:\n\nhttp://crawler.archive.org/articles/developer_manual/processor.html\n\nAlternatively, you could collect all the info by a crawl, but then do \nthe custom analysis as postprocessing on the captured content.\n\n- Gordon @ IA\n\n\n"}}