{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":196199957,"authorName":"shamik_banerjee","from":"&quot;shamik_banerjee&quot; &lt;shamikb@...&gt;","profile":"shamik_banerjee","replyTo":"LIST","senderId":"CFRntJ1clHZb0xZO9NnWFxeqSxytemyUfE7T2j1DDufaniYXyiArr3ciK9dkM_x6swFxCe_mlwnpy3vDBF6fQULyCs2K1aJknpsXIg","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Newbie question on url exclusion settings","postDate":"1319739271","msgId":7374,"canDelete":false,"contentTrasformed":false,"systemMessage":true,"headers":{"messageIdInHeader":"PGo4YzcyNytkcTB0QGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":7375,"prevInTime":7373,"nextInTime":7375,"topicId":7374,"numMessagesInTopic":2,"msgSnippet":"Hi, I ve started looking into Heritrix and was able to perform some simple crawls, which works pretty well. As I m trying to transition to some advanced","rawEmail":"Return-Path: &lt;shamikb@...&gt;\r\nReceived: (qmail 88480 invoked from network); 27 Oct 2011 19:00:59 -0000\r\nReceived: from unknown (98.137.35.161)\n  by m7.grp.sp2.yahoo.com with QMQP; 27 Oct 2011 19:00:59 -0000\r\nReceived: from unknown (HELO n42b.bullet.mail.sp1.yahoo.com) (66.163.168.156)\n  by mta5.grp.sp2.yahoo.com with SMTP; 27 Oct 2011 19:00:59 -0000\r\nDKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoogroups.com; s=lima; t=1319742057; bh=PyPQMEZGVbiIqs6+lVyb0h9nWwkXbvy1RiAQUXn8+zU=; h=Received:Received:X-Sender:X-Apparently-To:X-Received:X-Received:X-Received:X-Received:X-Received:Date:To:Message-ID:User-Agent:MIME-Version:Content-Type:X-Mailer:X-Yahoo-Newman-Property:X-Originating-IP:X-eGroups-Msg-Info:X-Yahoo-Post-IP:From:Subject:X-Yahoo-Group-Post:X-Yahoo-Profile:X-YGroups-SubInfo:Sender:X-eGroups-Approved-By:X-eGroups-Auth; b=B9fllHvpUAoAhDd2LHL4TpbXhNyo/8wqwvgyzD5EH9ffp/baDN3r5GUvLKM3ZPoiom+GVIGXlQWjkSiqypHeBe0DsnQ+mK0It+55mL2qrkw1/ZE6YuNtYOX8qUPm/g2H\r\nReceived: from [69.147.65.151] by n42.bullet.mail.sp1.yahoo.com with NNFMP; 27 Oct 2011 19:00:57 -0000\r\nReceived: from [98.137.34.155] by t5.bullet.mail.sp1.yahoo.com with NNFMP; 27 Oct 2011 19:00:57 -0000\r\nX-Sender: shamikb@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 18417 invoked from network); 27 Oct 2011 18:14:33 -0000\r\nX-Received: from unknown (98.137.35.160)\n  by m11.grp.sp2.yahoo.com with QMQP; 27 Oct 2011 18:14:33 -0000\r\nX-Received: from unknown (HELO n40b.bullet.mail.sp1.yahoo.com) (66.163.168.154)\n  by mta4.grp.sp2.yahoo.com with SMTP; 27 Oct 2011 18:14:33 -0000\r\nX-Received: from [69.147.65.149] by n40.bullet.mail.sp1.yahoo.com with NNFMP; 27 Oct 2011 18:14:32 -0000\r\nX-Received: from [98.137.34.35] by t9.bullet.mail.sp1.yahoo.com with NNFMP; 27 Oct 2011 18:14:32 -0000\r\nDate: Thu, 27 Oct 2011 18:14:31 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;j8c727+dq0t@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: multipart/alternative; boundary=&quot;0-5714159722-7190356307=:7&quot;\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-system\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;shamik_banerjee&quot; &lt;shamikb@...&gt;\r\nSubject: Newbie question on url exclusion settings\r\nX-Yahoo-Group-Post: member; u=196199957; y=vH6kO93dRYZSgzMdaR8W53agV9LNzjyuOi-y-6WZcIQAFfXeoqvWYp8U\r\nX-Yahoo-Profile: shamik_banerjee\r\nX-eGroups-Approved-By: nlevitt &lt;nlevitt@...&gt; via web; 27 Oct 2011 19:00:57 -0000\r\n\r\n\r\n--0-5714159722-7190356307=:7\r\nContent-Type: text/plain; charset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n\nHi,\n\n    I&#39;ve started looking into Heritrix and was able to perform some\ns=\r\nimple crawls, which works pretty well. As I&#39;m trying to transition to\nsome =\r\nadvanced crawling, I&#39;m facing issues to figure out the right way.\nHere&#39;s wh=\r\nat I&#39;m trying to do.\n\nDuring crawl, if any of the url matches the following=\r\n pattern,\n\nhttp://test.blogs.com/between_the_lines/\n&lt;http://test.blogs.com/=\r\nbetween_the_lines/&gt;\n\nhttp://test.blogs.com/between_the_lines/page\n&lt;http://t=\r\nest.blogs.com/between_the_lines/page&gt; *\n\nhttp://test.blogs.com/between_the_=\r\nlines/archives\n&lt;http://test.blogs.com/between_the_lines/archives&gt; *\n\n*index=\r\n.html*\n\nthen, go don&#39;t allow urls for indexing except the ones ending with\n=\r\n*.html .\n\nNow, within the filtered urls based on the above condition, don&#39;t=\r\n index\nand don&#39;t follow with urls having pattern *comment* , */a/*.\n\nIt&#39;s s=\r\nort of a nested condition check for filtering out urls for\nindexing. Lookin=\r\ng into the 3.0 documentation, I&#39;m wondering if I can\nachive this using Deci=\r\ndeRules or through the fetchprocessors.\n\nI was looking for some sample craw=\r\nler bean but without any luck so far.\n\nI&#39;ll appreciate if someone can provi=\r\nde pointers to address this issue.\n\n-Thanks\n\n\r\n--0-5714159722-7190356307=:7\r\nContent-Type: text/html; charset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n&lt;P&gt;Hi,&lt;/P&gt;\n&lt;P&gt;&nbsp;&nbsp; I&#39;ve started looking into Heritrix and was able =\r\nto perform some simple crawls, which works pretty well. As I&#39;m trying to tr=\r\nansition to some advanced crawling, I&#39;m facing issues to figure out the rig=\r\nht way. Here&#39;s what I&#39;m trying to do. &lt;/P&gt;\n&lt;P&gt;During crawl, if any of the u=\r\nrl matches the following pattern,&lt;/P&gt;\n&lt;P&gt;&lt;TR&gt;&lt;TD&gt;&lt;A href=3D&quot;http://test.blo=\r\ngs.com/between_the_lines/&quot;&gt;http://test.blogs.com/between_the_lines/&lt;/A&gt;&nbs=\r\np;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width=3D&quot;5%&quot;&gt;&nbsp;&lt;/TD&gt;&lt;TD&gt; &lt;/P&gt;\n&lt;P&gt;&lt;A href=3D&quot;http://=\r\ntest.blogs.com/between_the_lines/page&quot;&gt;http://test.blogs.com/between_the_li=\r\nnes/page&lt;/A&gt;*&nbsp;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width=3D&quot;5%&quot;&gt;&nbsp;&lt;/TD&gt;&lt;TD&gt; &lt;/P&gt;\n&lt;P&gt;&lt;=\r\nA href=3D&quot;http://test.blogs.com/between_the_lines/archives&quot;&gt;http://test.blo=\r\ngs.com/between_the_lines/archives&lt;/A&gt;* &lt;/P&gt;\n&lt;P&gt;*index.html*&lt;/P&gt;\n&lt;P&gt;then, go=\r\n don&#39;t allow urls for indexing except the ones ending with *.html . &lt;/P&gt;\n&lt;P=\r\n&gt;Now, within the filtered urls based on the above condition, don&#39;t index an=\r\nd don&#39;t follow with urls having pattern *comment* , */a/*.&lt;/P&gt;\n&lt;P&gt;It&#39;s sort=\r\n of a nested condition check for filtering out urls for indexing. Looking i=\r\nnto the 3.0 documentation, I&#39;m wondering if I can achive this using &lt;STRONG=\r\n&gt;DecideRules &lt;/STRONG&gt;or through the fetchprocessors. &lt;/P&gt;\n&lt;P&gt;I was looking=\r\n for some sample crawler bean but without any luck so far. &lt;/P&gt;\n&lt;P&gt;I&#39;ll app=\r\nreciate if someone can provide pointers to address this issue.&lt;/P&gt;\n&lt;P&gt;-Than=\r\nks&lt;/P&gt;&lt;/td&gt;&lt;/tr&gt;\n\r\n--0-5714159722-7190356307=:7--\r\n\n"}}