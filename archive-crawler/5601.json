{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"5GJYoRRofi-w5VwSRifsBoQASiBR9ch3sKaKyKq6jmVy9MV2dbEk83wQWiHgun6Bu058efBi9XTHJJC18Js58ARtxqZWHPo","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Disabling Seed logging","postDate":"1228885814","msgId":5601,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ5M0Y0RjM2LjcwODAwMDhAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDQ5M0YwRUVELjYwNDA1MDFAdW1icmljaC5uZXQ+","referencesHeader":"PDQ5M0YwRUVELjYwNDA1MDFAdW1icmljaC5uZXQ+"},"prevInTopic":5600,"nextInTopic":0,"prevInTime":5600,"nextInTime":5602,"topicId":5600,"numMessagesInTopic":2,"msgSnippet":"If my guesswork on the previous post was correct, it was the requests to display seed reports (via the web UI) that created the problem -- not the mere","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 91192 invoked from network); 10 Dec 2008 05:10:16 -0000\r\nX-Received: from unknown (66.218.67.95)\n  by m35.grp.scd.yahoo.com with QMQP; 10 Dec 2008 05:10:16 -0000\r\nX-Received: from unknown (HELO relay01.pair.com) (209.68.5.15)\n  by mta16.grp.scd.yahoo.com with SMTP; 10 Dec 2008 05:10:15 -0000\r\nX-Received: (qmail 12621 invoked from network); 10 Dec 2008 05:10:14 -0000\r\nX-Received: from 70.137.138.107 (HELO ?10.0.13.7?) (70.137.138.107)\n  by relay01.pair.com with SMTP; 10 Dec 2008 05:10:14 -0000\r\nX-pair-Authenticated: 70.137.138.107\r\nMessage-ID: &lt;493F4F36.7080008@...&gt;\r\nDate: Tue, 09 Dec 2008 21:10:14 -0800\r\nUser-Agent: Thunderbird 2.0.0.18 (Windows/20081105)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;493F0EED.6040501@...&gt;\r\nIn-Reply-To: &lt;493F0EED.6040501@...&gt;\r\nContent-Type: text/plain; charset=UTF-8; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Disabling Seed logging\r\nX-Yahoo-Group-Post: member; u=137285340; y=0p-eQXTiRC9j0UqBoTc_SHPSJWjTzsfqgXP8vx27V20x\r\nX-Yahoo-Profile: gojomo\r\n\r\nIf my guesswork on the previous post was correct, it was the requests to \ndisplay seed reports (via the web UI) that created the problem -- not \nthe mere background collection of seed disposition info. So I expect \nyour crawl should just work.\n\n(Be sure not use a scope rule, like SurtPrefixedDecideRule, that is \ndefined by the seeds.)\n\nOther ways you could pre-load a crawler with URIs that are not \nspecifically marked as seeds:\n\n* start it with &#39;pause-at-start&#39;; load URIs via the JMX addUris \noperations (though that may prove awkward with millions of URIs)\n\n* synthesize a fake &#39;recovery.log&#39; with the desired URIs, and specify \nthe crawl to begin from that log. (View the log from a prior crawl to \nget a sense of the format; the lines beginning &#39;F+ &#39; will cause URIs to \nbe queued, as long as there is no other &#39;Fs &#39; or &#39;Ff &#39; line indicating \nthey already completed.)\n\nI think I&#39;d lean towards the recovery.log approach if there were \nproblems with just specifying the URIs as seeds.\n\n- Gordon @ IA\n\nJuergen Umbrich wrote:\n&gt; Hi all\n&gt; \n&gt; refering to the post with subject &quot;Broad-scope 10M seeds Xmx6G 64-Bit \n&gt; JVM: OOME: GC overhead limit exceeded&quot; and the statement that the OOME \n&gt; exception is related to the seed URI logging\n&gt; \n&gt;  &gt;&gt;As I mentioned, we haven&#39;t typically run crawls with 10 million \n&gt; seeds. (I think our largest has been closer to 1 million.) It&#39;s also \n&gt; rare for us &gt;&gt;to request a seeds report on large crawls while they are \n&gt; running. I suspect it&#39;s the building of the seeds report in memory \n&gt; that&#39;s either &gt;&gt;triggering or contributing to your issue.\n&gt;  &gt;&gt;Do you need the report, or can you get the necessary info from the logs?\n&gt;  &gt;No, we don&#39;t need the seed report. The information in the log files \n&gt; and our additional logging is more than enough.\n&gt; \n&gt;  &gt;&gt;We don&#39;t want any valid request for a seeds report to crash the \n&gt; crawler, so there&#39;s something for us to fix here. However, the answer\n&gt;  &gt;&gt;might be to cap the size of a seed report viewable by the web UI -- \n&gt; that is, protect by limiting risky functionality.  \n&gt;  &gt;Please not that in our seed list are some error lines integrated (the \n&gt; lines have a RDF-NQuad format)\n&gt;  &gt;(Just know i recognise all the warnings from the \n&gt; org.archive.util.iterator.RegexpLineIterator, and i have in mind that \n&gt; the regex handling &gt;with java can cause serious problems. Could this be \n&gt; the reason for the GC thing?)\n&gt;  \n&gt;  &gt;&gt;As noted above, the rescanning of the seeds file to compile the full \n&gt; report is likely related. There&#39;s nothing inherently troubling about \n&gt; Java &gt;&gt;regex handling, especially in this line-by-line scanning of \n&gt; well-formed input (no deep recursion, even give your error lines). It&#39;s \n&gt; more the &gt;&gt;size of the report data being assembled at the same time the \n&gt; rest of the crawl is trying to proceed.\n&gt; \n&gt; We discovered that we need to crawl a large list of URIs without \n&gt; traversing outgoing links.\n&gt; Is their a way to disable the seed reports or does this involve changes \n&gt; in the code? (We do not want to split the list into bunches of 1M URIs)\n&gt; \n&gt; Best\n&gt;   juergen\n&gt; \n&gt; ------------------------------------\n&gt; \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n"}}