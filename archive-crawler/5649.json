{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":374489704,"authorName":"peterlikarish","from":"&quot;peterlikarish&quot; &lt;peter-likarish@...&gt;","profile":"peterlikarish","replyTo":"LIST","senderId":"B03KlGiLcrnRhU6TQJ_DN4lSdZ-lHxuP5CFdLW-UbLYOlavI0C6TKWjG2Fo7UTQqYRGQpiNeskoQ19panXEK_lbyTx3BDzwJHRYKh1p7fKDs","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: using regular expressions to filter fetched content","postDate":"1232742196","msgId":5649,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGdsZDh2bCttODlqQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDQ5NjI4MTFGLjMwMjAzMDNAYXJjaGl2ZS5vcmc+"},"prevInTopic":5627,"nextInTopic":5884,"prevInTime":5648,"nextInTime":5650,"topicId":5626,"numMessagesInTopic":6,"msgSnippet":"This was very helpful, thanks. For future record, I ended up adding MatchesFilePatternDecideRules using the use-preset-pattern for audio, video and images and","rawEmail":"Return-Path: &lt;peter-likarish@...&gt;\r\nX-Sender: peter-likarish@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 19609 invoked from network); 23 Jan 2009 20:23:19 -0000\r\nX-Received: from unknown (66.218.67.97)\n  by m42.grp.scd.yahoo.com with QMQP; 23 Jan 2009 20:23:19 -0000\r\nX-Received: from unknown (HELO n15c.bullet.sp1.yahoo.com) (69.147.64.120)\n  by mta18.grp.scd.yahoo.com with SMTP; 23 Jan 2009 20:23:19 -0000\r\nX-Received: from [69.147.65.171] by n15.bullet.sp1.yahoo.com with NNFMP; 23 Jan 2009 20:23:19 -0000\r\nX-Received: from [66.218.66.91] by t13.bullet.mail.sp1.yahoo.com with NNFMP; 23 Jan 2009 20:23:19 -0000\r\nDate: Fri, 23 Jan 2009 20:23:16 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;gld8vl+m89j@...&gt;\r\nIn-Reply-To: &lt;4962811F.3020303@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;peterlikarish&quot; &lt;peter-likarish@...&gt;\r\nSubject: Re: using regular expressions to filter fetched content\r\nX-Yahoo-Group-Post: member; u=374489704; y=0Ze8WEFTdkgzT2n1jESyO4fi5rUtTwF3lYOlL3dsPphvHbrEQesgsw\r\nX-Yahoo-Profile: peterlikarish\r\n\r\nThis was very helpful, thanks. For future record, I ended up adding\nMatches=\r\nFilePatternDecideRules using the use-preset-pattern for audio,\nvideo and im=\r\nages and also did some custom filtering as well to avoid\nother types of con=\r\ntent. I included these in the scope, the MidFetch\nfilter and the ArcWriterP=\r\nrocessor. Thanks again,\n\nPeter\n\n--- In archive-crawler@yahoogroups.com, Gor=\r\ndon Mohr &lt;gojomo@...&gt; wrote:\n&gt;\n&gt; I recommend using 1.14.x unless you specif=\r\nically need 2.0 features. The \n&gt; documentation (both in the official user m=\r\nanual and various \n&gt; notes/threads) is better; there are still areas of 2.0=\r\n.x with less \n&gt; testing and awkward usability compared to 1.x; and changes =\r\nplanned in \n&gt; 2.2 mean migration from 1.14 will be just as easy (if not eas=\r\nier via a \n&gt; planned configuration-conversion tool) than 2.0-&gt;2.2.\n&gt; \n&gt; Sti=\r\nll, the techniques described in Tom Emerson&#39;s writeup should work in \n&gt; 2.0=\r\n; only the manner of setting it up is a slightly different.\n&gt; \n&gt; To prevent=\r\n certain material from being saved, install rules on the \n&gt; Processor that =\r\ndoes the saving (usually ArcWriterProcessor). If those \n&gt; rules &#39;REJECT&#39; th=\r\ne URI, that Processor will be skipped.\n&gt; \n&gt; So there are at least 3 differe=\r\nnt places where you can put rules to\nhelp \n&gt; achieve your desired aim:\n&gt; \n&gt;=\r\n (1) In the scope, to prevent a URI from being fetched at all. Of\ncourse, \n=\r\n&gt; these rules can only consider the URI&#39;s string form and discovery \n&gt; cont=\r\next, because no fetching has yet occurred.\n&gt; \n&gt; (2) In the &#39;mid-fetch&#39; rule=\r\ns of FetchHTTP, to abort a fetch after the \n&gt; headers are available, but be=\r\nfore the full (potentially large) content \n&gt; is fetched.\n&gt; \n&gt; (3) In the pr=\r\nocessor rules of the writing Processor (such as \n&gt; ArcWriterProcessor), to =\r\nskip writing of certain content. (These rules \n&gt; could even potentially tak=\r\ne into account fetched content bodies.)\n&gt; \n&gt; Hope this helps,\n&gt; \n&gt; - Gordon=\r\n @ IA\n&gt; \n&gt; peterlikarish wrote:\n&gt; &gt; Hello all,\n&gt; &gt; \n&gt; &gt; I hope I am not mis=\r\nsing something obvious. I am using Heritrix 2.0.2\n&gt; &gt; and have successfully=\r\n installed/run simple crawls. Now, I only want to\n&gt; &gt; save particular types=\r\n of content to save space/bandwidth. For\n&gt; &gt; instance, I don&#39;t need any med=\r\nia content. I&#39;ve seen the Tom Emerson&#39;s\n&gt; &gt; blog on the topic\n&gt; &gt; (http://w=\r\nww.dreamersrealm.net/~tree/blog/?s=3Dtext%2Fhtml&submit=3DGO) as\n&gt; &gt; well a=\r\ns the FAQ entry but these seem tailored for the 1.* versions of\n&gt; &gt; heritri=\r\nx. I can switch back and follow the directions but wanted to\n&gt; &gt; give 2.0 a=\r\n shot. I am guessing that I need to institute a rule under\n&gt; &gt; the Scope-&gt;R=\r\nules-&gt;list of decide rules.\n&gt; &gt; \n&gt; &gt; The logical one to pick would be the &quot;=\r\nMatchesRegExpDecideRule&quot;. I then\n&gt; &gt; place the regex filtering the unwanted=\r\n extensions, move the rule up in\n&gt; &gt; the list and set the decision to &quot;reje=\r\nct&quot;. I noted in Mr. Emerson&#39;s\n&gt; &gt; blog that he also filtered the saved cont=\r\nent. Is there a comparable\n&gt; &gt; way to do this in Heritrix 2? Is this the in=\r\ntended mechanism by which\n&gt; &gt; I should be filtering content? Thank you for =\r\nthe time and effort both\n&gt; &gt; on the crawler and reading my question,\n&gt; &gt; \n&gt;=\r\n &gt; Peter\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; ------------------------------------\n&gt; &gt; \n&gt; &gt; Yahoo!=\r\n Groups Links\n&gt; &gt; \n&gt; &gt; \n&gt; &gt;\n&gt;\n\n\n\n"}}