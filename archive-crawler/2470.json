{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":86836174,"authorName":"Samuel","from":"&quot;Samuel&quot; &lt;samendonca@...&gt;","profile":"samendonca","replyTo":"LIST","senderId":"jF2l4Y_clEmGOsREy2e1FDAiwTAs9jvlfc638sOaylgM3uxoMB4iXVZU_larmqohqilD0wp0B8oj88pGPEOZ6t-Y2jTDUpXh_g","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Parsing","postDate":"1135607065","msgId":2470,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGRvb3VlcCtoMHVzQGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":2471,"prevInTime":2469,"nextInTime":2471,"topicId":2470,"numMessagesInTopic":2,"msgSnippet":"Hi all, I ve already managed to record extracted data to a MySQL database, but now I need to extract even more specific data from that same document. So here","rawEmail":"Return-Path: &lt;samendonca@...&gt;\r\nX-Sender: samendonca@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 59293 invoked from network); 26 Dec 2005 14:24:51 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m32.grp.scd.yahoo.com with QMQP; 26 Dec 2005 14:24:51 -0000\r\nReceived: from unknown (HELO n3a.bullet.scd.yahoo.com) (66.94.237.37)\n  by mta4.grp.scd.yahoo.com with SMTP; 26 Dec 2005 14:24:50 -0000\r\nComment: DomainKeys? See http://antispam.yahoo.com/domainkeys\r\nReceived: from [66.218.69.4] by n3.bullet.scd.yahoo.com with NNFMP; 26 Dec 2005 14:24:25 -0000\r\nReceived: from [66.218.66.75] by mailer4.bullet.scd.yahoo.com with NNFMP; 26 Dec 2005 14:24:25 -0000\r\nDate: Mon, 26 Dec 2005 14:24:25 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;doouep+h0us@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: &quot;Samuel&quot; &lt;samendonca@...&gt;\r\nSubject: Parsing\r\nX-Yahoo-Group-Post: member; u=86836174; y=sTVMLZroF7arvQqAyJfMmMBIGwc3iPHYac6XKVmPuR0pFRkegA\r\nX-Yahoo-Profile: samendonca\r\n\r\nHi all,\n\nI&#39;ve already managed to record extracted data to a MySQL database,=\r\n but\nnow I need to extract even more specific data from that same document.=\r\n\nSo here it goes:\nWhat would be the most apropriate place in the processor =\r\nchain for me\nto do some relevant content extraction (like removing tags, ap=\r\nplying\nstring matching, etc), since the document I&#39;m checking may not be\nus=\r\neful at all (Im currently doing it on the same processor I write it\non the =\r\nDB). More, I was planning to parse the document using a DOM\nstructure or us=\r\ning Tidy. Am I missing something? I mean, these\ndocuments have already been=\r\n parsed, so how can I take it all in that\nsame spot to avoid unnecessary pr=\r\nocessing?\n\nThanks\n\nSamuel Mendonca\n\n\n\n\n"}}