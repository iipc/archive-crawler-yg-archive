{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"83n7eV6kLQZLK8vqlntJpfBvh95s6NeeS9y1djLXZP3KEpLHbQHtUyWtb4HEMzPaJhq_NVRugrVxCD7IuTOmmwYbkNii3z4","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] Having trouble crawling a single domain","postDate":"1316377711","msgId":7319,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRFNzY1NDZGLjIwMzA1MDhAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGo1NGQwMytxZ3ZxQGVHcm91cHMuY29tPg==","referencesHeader":"PGo1NGQwMytxZ3ZxQGVHcm91cHMuY29tPg=="},"prevInTopic":7318,"nextInTopic":7324,"prevInTime":7318,"nextInTime":7320,"topicId":7318,"numMessagesInTopic":3,"msgSnippet":"Three key ideas to keep in mind when customizing the decide-rules of a crawl scope: (1) The last rule to express a decision (like ACCEPT or REJECT rather than","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 36596 invoked from network); 18 Sep 2011 20:28:39 -0000\r\nX-Received: from unknown (98.137.35.162)\n  by m10.grp.sp2.yahoo.com with QMQP; 18 Sep 2011 20:28:39 -0000\r\nX-Received: from unknown (HELO relay03.pair.com) (209.68.5.17)\n  by mta6.grp.sp2.yahoo.com with SMTP; 18 Sep 2011 20:28:39 -0000\r\nX-Received: (qmail 67387 invoked by uid 0); 18 Sep 2011 20:28:37 -0000\r\nX-Received: from 76.218.213.38 (HELO silverbook.local) (76.218.213.38)\n  by relay03.pair.com with SMTP; 18 Sep 2011 20:28:37 -0000\r\nX-pair-Authenticated: 76.218.213.38\r\nMessage-ID: &lt;4E76546F.2030508@...&gt;\r\nDate: Sun, 18 Sep 2011 13:28:31 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:6.0.1) Gecko/20110830 Thunderbird/6.0.1\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;j54d03+qgvq@...&gt;\r\nIn-Reply-To: &lt;j54d03+qgvq@...&gt;\r\nContent-Type: text/plain; charset=windows-1252; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Having trouble crawling a single domain\r\nX-Yahoo-Group-Post: member; u=137285340; y=ElzDP3_Uti6ECXc3Zk5Q4mQXGbkge3o4nHWLDsYXn5yx\r\nX-Yahoo-Profile: gojomo\r\n\r\nThree key ideas to keep in mind when customizing the decide-rules of a \ncrawl scope:\n\n(1) The last rule to express a decision (like ACCEPT or REJECT rather \nthan just PASS) wins. So when you have a rule that should reject things \nother rules might accept, place it later.\n\n(2) When first learning how rules interact, it&#39;s best to start with the \ndefault set, and make single small changes at a time, testing each one \nto confirm it has the intended effect.\n\nWith these in mind, and looking at your ruleset:\n\n� Your placement of the &#39;rejectTaxonomy&#39; rule has no effect. At that \nstep, all URIs are already considered REJECTed, by the first rule. Only \nwhen they get to the next rule will some be flipped to ACCEPT, when they \nmatch the SURT-URI-prefix that was inferred from your seeds. But the \n&#39;rejectTaxonomy&#39; rule won&#39;t be applied again. To have the desired \neffect, it must appear after any ACCEPT rules it needs to reverse.\n\n� Also, it may be a paste artifact, but your custom regex looks like it \nstarts with two whitespace characters. No URIs that reach scope-testing \nwill still have unescaped whitespace, so even in the right position, \nthis rule might have no effect until the regex is tightened.\n\n� I don&#39;t see what, from this ruleset, what would cause wandering off \nthe initial seeds. Perhaps a stray line in the seeds file that rules-in \nmore domains than you expected?\n\n� Generally you won&#39;t need a NotOnHostsDecideRule if the (preferred) \nSurtPrefixedDecideRule is only ACCEPTing the right set of URLs. So I \nwouldn&#39;t try throwing that into the mix unless I knew exactly what was \nfailing with the prior configuration.\n\nIf these tips don&#39;t help you resolve the issue, let us know what version \nyou&#39;re using and any other changes you&#39;ve made to the default config, \nand the exact contents of your seeds file (ie seeds text-area in web UI).\n\n- Gordon\n\nOn 9/18/11 2:17 AM, Sergey Alekseev wrote:\n&gt; Hello,\n&gt;\n&gt; I may be overlooking something trivial, but I just can&#39;t get a simple crawl of a single domain working right with 1.14.4 no matter what I try. Here is my current config:\n&gt;\n&gt;      &lt;newObject name=&quot;scope&quot; class=&quot;org.archive.crawler.deciderules.DecidingScope&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;string name=&quot;seedsfile&quot;&gt;seeds.txt&lt;/string&gt;\n&gt;        &lt;boolean name=&quot;reread-seeds-on-config&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;newObject name=&quot;decide-rules&quot; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;          &lt;map name=&quot;rules&quot;&gt;\n&gt;            &lt;newObject name=&quot;rejectByDefault&quot; class=&quot;org.archive.crawler.deciderules.RejectDecideRule&quot;&gt;\n&gt;            &lt;/newObject&gt;\n&gt;            &lt;newObject name=&quot;rejectTaxonomy&quot; class=&quot;org.archive.crawler.deciderules.MatchesFilePatternDecideRule&quot;&gt;\n&gt;              &lt;string name=&quot;decision&quot;&gt;REJECT&lt;/string&gt;\n&gt;              &lt;string name=&quot;use-preset-pattern&quot;&gt;Custom&lt;/string&gt;\n&gt;              &lt;string name=&quot;regexp&quot;&gt;  .*(&#92;.(jpg|png|gif|css|rss|js|doc|pdf|ppt|swf))$&lt;/string&gt;\n&gt;            &lt;/newObject&gt;\n&gt;            &lt;newObject name=&quot;acceptIfSurtPrefixed&quot; class=&quot;org.archive.crawler.deciderules.SurtPrefixedDecideRule&quot;&gt;\n&gt;              &lt;string name=&quot;decision&quot;&gt;ACCEPT&lt;/string&gt;\n&gt;              &lt;string name=&quot;surts-source-file&quot;/&gt;\n&gt;              &lt;boolean name=&quot;seeds-as-surt-prefixes&quot;&gt;true&lt;/boolean&gt;\n&gt;              &lt;string name=&quot;surts-dump-file&quot;/&gt;\n&gt;              &lt;boolean name=&quot;also-check-via&quot;&gt;false&lt;/boolean&gt;\n&gt;              &lt;boolean name=&quot;rebuild-on-reconfig&quot;&gt;true&lt;/boolean&gt;\n&gt;            &lt;/newObject&gt;\n&gt;            &lt;newObject name=&quot;rejectIfTooManyHops&quot; class=&quot;org.archive.crawler.deciderules.TooManyHopsDecideRule&quot;&gt;\n&gt;              &lt;integer name=&quot;max-hops&quot;&gt;20&lt;/integer&gt;\n&gt;            &lt;/newObject&gt;\n&gt;            &lt;newObject name=&quot;rejectIfPathological&quot; class=&quot;org.archive.crawler.deciderules.PathologicalPathDecideRule&quot;&gt;\n&gt;              &lt;integer name=&quot;max-repetitions&quot;&gt;2&lt;/integer&gt;\n&gt;            &lt;/newObject&gt;\n&gt;            &lt;newObject name=&quot;rejectIfTooManyPathSegs&quot; class=&quot;org.archive.crawler.deciderules.TooManyPathSegmentsDecideRule&quot;&gt;\n&gt;              &lt;integer name=&quot;max-path-depth&quot;&gt;20&lt;/integer&gt;\n&gt;            &lt;/newObject&gt;\n&gt;\n&gt;          &lt;/map&gt;\n&gt;        &lt;/newObject&gt;\n&gt;\n&gt; If I understand correctly, this should limit the crawl to the\n&gt; domains\nof the seeds, and not crawl images, pdfs, etc, as specified above.\n&gt;\n&gt; Problem is: the crawler doesn&#39;t do either. It both immediately goes\noff the seeds&#39; domains (even if it&#39;s just a single TLD), ignoring the\nsurt-prefix setting, and immediately crawls files excluded in the\nrejectTaxonomy setting such as .css, .js, etc.\n&gt;\n&gt; What could be wrong here?.... &gt;\n&gt; Now, if I add a notOnHost rule like this:\n&gt;\n&gt;    &lt;newObject name=&quot;notonhostreject&quot; class=&quot;org.archive.crawler.deciderules.NotOnHostsDecideRule&quot;&gt;\n&gt;              &lt;string name=&quot;decision&quot;&gt;REJECT&lt;/string&gt;\n&gt;              &lt;string name=&quot;surts-dump-file&quot;/&gt;\n&gt;              &lt;boolean name=&quot;also-check-via&quot;&gt;false&lt;/boolean&gt;\n&gt;              &lt;boolean name=&quot;rebuild-on-reconfig&quot;&gt;true&lt;/boolean&gt;\n&gt;            &lt;/newObject&gt;\n&gt;\n&gt;\n&gt; the crawler doesn&#39;t do *anything* at all and immediately quits.\n&gt;\n&gt; My seeds are\n&gt;\n&gt; http://www.cdjapan.co.jp\n&gt; http://www.cdjapan.co.jp/anime/index.html\n&gt; http://www.cdjapan.co.jp/jpop/index.html\n&gt;\n&gt; and the whole other setup is just defaults.\n&gt;\n&gt; Am I missing something?\n&gt;\n&gt; Regards\n&gt; Sergey\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------\n&gt;\n&gt; Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n\n"}}