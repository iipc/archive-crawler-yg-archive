{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":274489225,"authorName":"molzbh","from":"&quot;molzbh&quot; &lt;anmol.bhasin@...&gt;","profile":"molzbh","replyTo":"LIST","senderId":"buU0Sq0NJulpZj5lFbNFfqXXV3QEG5wjLVygBAYL6LgGpbmyAOHenrYmnnMRVtvqeuVuchBglmw3cYvrNaxxlkPlVlg9p1nP","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Parallelizing crawler","postDate":"1152896653","msgId":3051,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGU5OGlxZCtpMXMzQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDQ0QjVCMDBCLjMwMjAxMDdAYXJjaGl2ZS5vcmc+"},"prevInTopic":3047,"nextInTopic":3052,"prevInTime":3050,"nextInTime":3052,"topicId":3043,"numMessagesInTopic":16,"msgSnippet":"Cool. Anyways my thoughts on splitting the architecture were to split the Processors across various machines. Have a Statistics server maintain statistics, and","rawEmail":"Return-Path: &lt;anmol.bhasin@...&gt;\r\nX-Sender: anmol.bhasin@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 42553 invoked from network); 14 Jul 2006 17:04:16 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m37.grp.scd.yahoo.com with QMQP; 14 Jul 2006 17:04:16 -0000\r\nReceived: from unknown (HELO n4b.bullet.sc5.yahoo.com) (66.163.187.171)\n  by mta6.grp.scd.yahoo.com with SMTP; 14 Jul 2006 17:04:16 -0000\r\nReceived: from [66.163.187.122] by n4.bullet.sc5.yahoo.com with NNFMP; 14 Jul 2006 17:04:14 -0000\r\nReceived: from [66.218.69.5] by t3.bullet.sc5.yahoo.com with NNFMP; 14 Jul 2006 17:04:14 -0000\r\nReceived: from [66.218.66.89] by t5.bullet.scd.yahoo.com with NNFMP; 14 Jul 2006 17:04:14 -0000\r\nDate: Fri, 14 Jul 2006 17:04:13 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;e98iqd+i1s3@...&gt;\r\nIn-Reply-To: &lt;44B5B00B.3020107@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;molzbh&quot; &lt;anmol.bhasin@...&gt;\r\nSubject: Re: Parallelizing crawler\r\nX-Yahoo-Group-Post: member; u=274489225; y=AKp0jiwUnC2lWgL-qTrZ-ZTr8QiXeD58kA4WI6yyQ6yG\r\nX-Yahoo-Profile: molzbh\r\n\r\nCool. Anyways my thoughts on splitting the architecture were to split\nthe P=\r\nrocessors across various machines. Have a Statistics server\nmaintain statis=\r\ntics, and a single frontier. My idea was to have\nfrontier emit a batch of U=\r\nRLS to the processore boxes, hence instead\nof next() you have nextBatch(). =\r\nAnyways, I guess this involves a lot\nof work, hence I am going in for a Pee=\r\nr2Peer setup, with fully loaded\nagents doing the URL splits and emmitting b=\r\natches to the others. I am\nwondering however on the efficiency of JMX with =\r\nRMI connectors to do\nthis Job. Do you think going the plain RMI way would b=\r\ne faster? Sorry\nfor pounding you with questions but I am still in the desig=\r\nn phase of\nthe system looking for a billion plus crawl, and since it won&#39;t =\r\nbe a\none time thing I am also looking at scalability and agent join/leave\nm=\r\nechanisms.\n\n\n\n--- In archive-crawler@yahoogroups.com, Michael Stack &lt;stack@=\r\n...&gt; wrote:\n&gt;\n&gt; Anmol Bhasin wrote:\n&gt; &gt;\n&gt; &gt; Thanks! I am wondering however =\r\nif we leave the central frontier \n&gt; &gt; machine concept out for a bit, would =\r\nthere be anybenfit to split URL \n&gt; &gt; space in place of Split Architechture.=\r\n\n&gt; &gt;\n&gt; \n&gt; \n&gt; \n&gt; &gt; I am trying to do quick big crawl, hence wondering which =\r\napproaches \n&gt; &gt; are the best ways to get moving.\n&gt; &gt;\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; If yo=\r\nu&#39;re in a hurry, split URL space (and throw hardware at it).  Some \n&gt; fairl=\r\ny large crawls have been achieved using this technique both by us \n&gt; -- 200=\r\nmillion plus -- and by others (See the testimonial cited in the \n&gt; previous=\r\n where Joe Hung and his compa=F1eros did a 1Billion+ pages).\n&gt; \n&gt; What were=\r\n you thinking regards splitting the architecture?\n&gt; \n&gt; Yours,\n&gt; St.Ack\n&gt;\n\n\n=\r\n\n\n\n\n"}}