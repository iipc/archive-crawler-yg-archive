{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":465869704,"authorName":"Mackram Raydan","from":"Mackram Raydan &lt;mackram@...&gt;","profile":"mackram.raydan@ymail.com","replyTo":"LIST","senderId":"OH5DAgI-N_86NtWyH2YTYfa7M70dxPex3Tkhuoqt7OwMWP_7-9bbj2Qvs8lIkyMEI6ofPk5C8kMBJRu4ucVNL1JyL_tACU49Jw","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Ideas to make the distributed crawling.","postDate":"1284499178","msgId":6725,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRDOEZFNkVBLjMwNTA5MDNAZ21haWwuY29tPg==","inReplyToHeader":"PDRDOEZDN0I4LjIwNzA1MDRAYXJjaGl2ZS5vcmc+","referencesHeader":"PGk2bzUwaytlaGI3QGVHcm91cHMuY29tPiA8NEM4RkM3QjguMjA3MDUwNEBhcmNoaXZlLm9yZz4="},"prevInTopic":6722,"nextInTopic":6728,"prevInTime":6724,"nextInTime":6726,"topicId":6719,"numMessagesInTopic":5,"msgSnippet":"First of all thanks for the heads up on the complexity of the Frontier component. To answer you questions: 1-The primary goal is to make a news search portal","rawEmail":"Return-Path: &lt;mackram@...&gt;\r\nX-Sender: mackram@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 65646 invoked from network); 14 Sep 2010 21:19:53 -0000\r\nX-Received: from unknown (66.196.94.106)\n  by m17.grp.re1.yahoo.com with QMQP; 14 Sep 2010 21:19:53 -0000\r\nX-Received: from unknown (HELO mail-wy0-f182.google.com) (74.125.82.182)\n  by mta2.grp.re1.yahoo.com with SMTP; 14 Sep 2010 21:19:53 -0000\r\nX-Received: by wyb33 with SMTP id 33so9338740wyb.13\n        for &lt;archive-crawler@yahoogroups.com&gt;; Tue, 14 Sep 2010 14:19:51 -0700 (PDT)\r\nX-Received: by 10.227.157.4 with SMTP id z4mr480447wbw.43.1284499191631;\n        Tue, 14 Sep 2010 14:19:51 -0700 (PDT)\r\nReturn-Path: &lt;mackram@...&gt;\r\nX-Received: from [192.168.1.65] ([89.108.187.31])\n        by mx.google.com with ESMTPS id b23sm554778wbb.16.2010.09.14.14.19.44\n        (version=SSLv3 cipher=RC4-MD5);\n        Tue, 14 Sep 2010 14:19:49 -0700 (PDT)\r\nMessage-ID: &lt;4C8FE6EA.3050903@...&gt;\r\nDate: Wed, 15 Sep 2010 00:19:38 +0300\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.2.9) Gecko/20100825 Lightning/1.0b2 Thunderbird/3.1.3\r\nMIME-Version: 1.0\r\nTo: Gordon Mohr &lt;gojomo@...&gt;\r\nCc: archive-crawler@yahoogroups.com\r\nReferences: &lt;i6o50k+ehb7@...&gt; &lt;4C8FC7B8.2070504@...&gt;\r\nIn-Reply-To: &lt;4C8FC7B8.2070504@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nFrom: Mackram Raydan &lt;mackram@...&gt;\r\nSubject: Re: [archive-crawler] Ideas to make the distributed crawling.\r\nX-Yahoo-Group-Post: member; u=465869704; y=HyPTsRX9_brYRnw6k_4r9aaHudezPckHA-0zNJ4mtqEF4BU9QdF5BU_UIgzle9AR6ovu\r\nX-Yahoo-Profile: mackram.raydan@...\r\n\r\nFirst of all thanks for the heads up on the complexity of the Frontier \ncomponent. To answer you questions:\n\n1-The primary goal is to make a news search portal for a company that I \nam contracted to help. They want to be able to throw instances at the \nproblem as the number of sites/news subjects they need to look for \nincreases.\n\n2-Why I think one crawler is not enough is because they want to come \nclose to real time logging of info which means that it would be helpful \nto run things in parallel.\n\n3- No honestly I have not looked at the CrawlMapper sublcass instance so \nI can not answer to that. I will make a through look into that further \ntomorrow. Thank you for pointing it out.\n\n\n\nOn 09/14/2010 10:06 PM, Gordon Mohr wrote:\n&gt; It is the intent of the Heritrix design that any components, including\n&gt; the frontier implementation, should be swappable. So creating new\n&gt; frontier implementations is a plausible approach.\n&gt;\n&gt; However, the frontier is the most complicated component, and many other\n&gt; features are dependent on the behavior of current implementations. So,\n&gt; offering new variants (by subclassing or offering the Frontier\n&gt; interface) should be done carefully.\n&gt;\n&gt; Backing up a bit: what is the primary goal that makes you interested in\n&gt; a distributed approach? Why is one crawler not enough?\n&gt;\n&gt; (I have my own ideas about this but would like to hear yours.)\n&gt;\n&gt; Have you thoroughly understood (and run/benchmarked) the ad-hoc\n&gt; distribution technique, making use of &#39;CrawlMapper&#39; subclass instances,\n&gt; that&#39;s been described in past list traffic? What is good or bad about\n&gt; that approach for your purposes?\n&gt;\n&gt; - Gordon @ IA\n&gt;\n&gt; On 9/14/10 8:40 AM, Mackram Raydan wrote:\n&gt;&gt; So I have spent all day looking at the Heritrix code and the info on\n&gt;&gt; its architecture. The more I read the more I realized that doing a\n&gt;&gt; change in the code directly might not be the smartest thing to do as\n&gt;&gt; it would require a huge set of changes, so I had an idea that I wanted\n&gt;&gt; to run by the group if possible.\n&gt;&gt;\n&gt;&gt; Since Heritrix so easily supports modules I am thinking that I would\n&gt;&gt; develop 2 new Frontiers that will do the distributed crawling.\n&gt;&gt;\n&gt;&gt; The master Frontier (the distributed crawling I am envisioning has a\n&gt;&gt; central master) will pretty much do the same code done with the\n&gt;&gt; following exceptions:\n&gt;&gt; 1- A socket listener which will be able to dispatch new URIs to\n&gt;&gt; schedule, to mark URIs as finished and to send out new URIs to be\n&gt;&gt; crawled when requested\n&gt;&gt;\n&gt;&gt; The slave Frontier (for each instance of Heritrix) will be the\n&gt;&gt; simplest form of a Frontier which will do the following:\n&gt;&gt; 1- When requested for a next URI it will get it send a request for the\n&gt;&gt; master for a new URI\n&gt;&gt; 2- When a new URI is discovered and should be scheduled it is sent to\n&gt;&gt; the master\n&gt;&gt; 3- When a URI is finished the slave will inform the master of that state.\n&gt;&gt;\n&gt;&gt; My idea of the above is to keep the basic code of Heritrix unchanged\n&gt;&gt; and just allow the addition of distributed code through a new module.\n&gt;&gt; I would love input on the above especially if you think it would not\n&gt;&gt; work for some reason or the other.\n&gt;&gt;\n&gt;&gt; --- In archive-crawler@yahoogroups.com, Mackram Raydan&lt;mackram@...&gt;\n&gt;&gt; wrote:\n&gt;&gt;&gt;\n&gt;&gt;&gt; Hey everyone,\n&gt;&gt;&gt;\n&gt;&gt;&gt; I have recently been looking into whether or not we can have heritrix\n&gt;&gt;&gt; run in\n&gt;&gt;&gt; a distributed manner and had opened a minor issue for it. Gordon was\n&gt;&gt;&gt; kind\n&gt;&gt;&gt; enough to point out the list here might be helpful. Also Noah was kind\n&gt;&gt;&gt; enough to point to the hcc project which as I understand is in the alpha\n&gt;&gt;&gt; stage. I was considering porting heritrixs to hadoop and would like the\n&gt;&gt;&gt; opinions of the group. My line of thought was to change the worker\n&gt;&gt;&gt; threads\n&gt;&gt;&gt; into map functions and then use reduce to manage the URLs. Arguably\n&gt;&gt;&gt; one does\n&gt;&gt;&gt; not really need map/reduce for this and could go more with the\n&gt;&gt;&gt; approach of\n&gt;&gt;&gt; the hcc project but honestly I am still going through heritrix code\n&gt;&gt;&gt; so, l\n&gt;&gt;&gt; would love the input from people on this.\n&gt;&gt;&gt;\n&gt;&gt;&gt; Thanks and best regards\n&gt;&gt;&gt;\n&gt;&gt;&gt; Mackram Raydan\n&gt;&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; ------------------------------------\n&gt;&gt;\n&gt;&gt; Yahoo! Groups Links\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n\n\n"}}