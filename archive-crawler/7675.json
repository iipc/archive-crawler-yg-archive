{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":325624130,"authorName":"Noah Levitt","from":"Noah Levitt &lt;nlevitt@...&gt;","profile":"nlevitt","replyTo":"LIST","senderId":"KfXWRcbXY9AGDWiJP11dE5p2zAIV2VD_fJdNA3gW6hpJSlIEHy9W3pT9k7fvDIBh8xK3-BxsT_NVSnColOOr5zOev0O1Ndfw","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Re: H3.0 config settings to crawl password protected pages.","postDate":"1335317594","msgId":7675,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRGOTc1NDVBLjEwNDA2MDhAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDEzMzE1NjQyODcuOTQ4MDUuWWFob29NYWlsTmVvQHdlYjQzMTM2Lm1haWwuc3AxLnlhaG9vLmNvbT4=","referencesHeader":"PDEzMDg4NTg1NjQuOTE3OTMuWWFob29NYWlsQ2xhc3NpY0B3ZWI0MzE0NC5tYWlsLnNwMS55YWhvby5jb20+IDxqaWc5aWYrYmZycEBlR3JvdXBzLmNvbT4gPDEzMzE1NjQyODcuOTQ4MDUuWWFob29NYWlsTmVvQHdlYjQzMTM2Lm1haWwuc3AxLnlhaG9vLmNvbT4="},"prevInTopic":7637,"nextInTopic":7676,"prevInTime":7674,"nextInTime":7676,"topicId":7171,"numMessagesInTopic":6,"msgSnippet":"Hello Pranay, The way it works, heritrix requests the url, gets the 401, then requeues the url, noting that next time it should try with the credential. Next ","rawEmail":"Return-Path: &lt;nlevitt@...&gt;\r\nX-Sender: nlevitt@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 66728 invoked from network); 25 Apr 2012 01:33:21 -0000\r\nX-Received: from unknown (98.137.35.162)\n  by m11.grp.sp2.yahoo.com with QMQP; 25 Apr 2012 01:33:21 -0000\r\nX-Received: from unknown (HELO mail.archive.org) (207.241.224.6)\n  by mta6.grp.sp2.yahoo.com with SMTP; 25 Apr 2012 01:33:21 -0000\r\nX-Received: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id 07FAC68410A2;\n\tTue, 24 Apr 2012 18:33:19 -0700 (PDT)\r\nX-Received: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id vcn1dy5ANtHg; Tue, 24 Apr 2012 18:33:15 -0700 (PDT)\r\nX-Received: from [208.70.27.155] (desktop-nlevitt.sf.archive.org [208.70.27.155])\n\tby mail.archive.org (Postfix) with ESMTPSA id 8713B6841098;\n\tTue, 24 Apr 2012 18:33:15 -0700 (PDT)\r\nMessage-ID: &lt;4F97545A.1040608@...&gt;\r\nDate: Tue, 24 Apr 2012 18:33:14 -0700\r\nUser-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:11.0) Gecko/20120329 Thunderbird/11.0.1\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: Pranay Pandey &lt;sspranay@...&gt;\r\nReferences: &lt;1308858564.91793.YahooMailClassic@...&gt; &lt;jig9if+bfrp@...&gt; &lt;1331564287.94805.YahooMailNeo@...&gt;\r\nIn-Reply-To: &lt;1331564287.94805.YahooMailNeo@...&gt;\r\nContent-Type: multipart/alternative;\n boundary=&quot;------------070902060500070703020004&quot;\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Noah Levitt &lt;nlevitt@...&gt;\r\nSubject: Re: [archive-crawler] Re: H3.0 config settings to crawl password\n protected pages.\r\nX-Yahoo-Group-Post: member; u=325624130; y=RqiHWYroZ3ibWRaZNxlLEtz65Hj394iPpnTGNC9r8pFoog\r\nX-Yahoo-Profile: nlevitt\r\n\r\n\r\n--------------070902060500070703020004\r\nContent-Type: text/plain; charset=UTF-8; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\n\r\nHello Pranay,\n\nThe way it works, heritrix requests the url, gets the 401, then requeues \nthe url, noting that next time it should try with the credential. Next \ntime around the url is crawled again with auth. The first time through, \non the 401, almost all the normal processing completes, short of logging \nto crawl.log. Full warc records are written. Normally this includes a \nrequest and a metadata record. So that&#39;s the only thing that&#39;s puzzling \nabout your scenario. There should also be 2 request records and 2 \nmetadata records, and the timestamps on the 401 and 200 should be \ndifferent.\n\nAs far as wayback goes, it&#39;s quite possible that it doesn&#39;t handle 401s \nwell. (Maybe the ideal behavior would be to replicate what happens on \nthe live web, that is, replay the 401, look for basic auth matching the \nrequest record of the 200 and only serve the content in that case.)\n\nNoah\n\nOn 03/12/2012 07:58 AM, Pranay Pandey wrote:\n&gt;\n&gt;\n&gt;\n&gt; Group,\n&gt;\n&gt; I am using 3.1.0 and I find it very strange to see just one response \n&gt; code (200) in crawl.log and two response codes (200 and 401) in form \n&gt; of two response records in the warc written.\n&gt; I am trying to crawl a password protected site with the config \n&gt; settings I had outlined in my older email below.\n&gt;\n&gt; My question:\n&gt; Are we ever supposed to get two &quot;response&quot; records in the WARC for the \n&gt; same object, fetched at the same time?\n&gt; While the first response gives 401, the second one has 200 OK.\n&gt;\n&gt; And while I see 200 OK written in both WARC and crawl.log, wayback \n&gt; displays the authentication failed page (401) for all the protected pages.\n&gt;\n&gt; These are the two responses I see in the WARC, in the order they were \n&gt; written.\n&gt;\n&gt; WARC/1.0^M\n&gt; WARC-Type: response^M\n&gt; WARC-Target-URI: http://www.xyz.com/index.html/^M\n&gt; WARC-Date: 2012-03-09T19:27:57Z^M\n&gt; WARC-Payload-Digest: sha1:XNMHLNSS4YF24HWXC52LDEETXXVHV47X^M\n&gt; WARC-IP-Address: 207.45.182.58^M\n&gt; WARC-Record-ID: &lt;urn:uuid:513f8d8f-edcc-42f8-ac07-136d2dcfe4a4&gt;^M\n&gt; Content-Type: application/http; msgtype=response^M\n&gt; Content-Length: 3403^M\n&gt; ^M\n&gt; HTTP/1.1 401 Authorization Required^M\n&gt; Date: Fri, 09 Mar 2012 19:27:56 GMT^M\n&gt; Server: Apache^M\n&gt; WWW-Authenticate: Basic realm=&quot;Netpreserve&quot;^M\n&gt; Accept-Ranges: bytes^M\n&gt; Connection: close^M\n&gt; Content-Type: text/html^M\n&gt;\n&gt; WARC/1.0^M\n&gt; WARC-Type: response^M\n&gt; WARC-Target-URI: http://www.xyz.com/index.html/^M\n&gt; WARC-Date: 2012-03-09T19:27:57Z^M\n&gt; WARC-Payload-Digest: sha1:FGAN7GIN5JNYCHGL6BCB3TDPKDCFUJER^M\n&gt; WARC-IP-Address: 207.45.182.58^M\n&gt; WARC-Record-ID: &lt;urn:uuid:f7f4761d-5c3b-4460-8ace-fed4e3477cd3&gt;^M\n&gt; Content-Type: application/http; msgtype=response^M\n&gt; Content-Length: 6052^M\n&gt; ^M\n&gt; HTTP/1.1 200 OK^M\n&gt; Date: Fri, 09 Mar 2012 19:27:56 GMT^M\n&gt; Server: Apache^M\n&gt; X-Powered-By: PHP/5.2.17^M\n&gt; Expires: Thu, 19 Nov 1981 08:52:00 GMT^M\n&gt; Cache-Control: no-store, no-cache, must-revalidate, post-check=0, \n&gt; pre-check=0^M\n&gt; Pragma: no-cache^M\n&gt; Set-Cookie: PHPSESSID=7289c28a8ac5ba1b87aead5f94bc5473; path=/^M\n&gt; Content-Length: 5687^M\n&gt; Connection: close^M\n&gt; Content-Type: text/html^M\n&gt;\n&gt; ------------------------------------------------------------------------\n&gt; *From:* Patrick &lt;lapaon@...&gt;\n&gt; *To:* archive-crawler@yahoogroups.com\n&gt; *Sent:* Monday, February 27, 2012 11:04 AM\n&gt; *Subject:* [archive-crawler] Re: H3.0 config settings to crawl \n&gt; password protected pages.\n&gt;\n&gt; I have got the same problem. Have you worked out the solution?\n&gt;\n&gt; --- In archive-crawler@yahoogroups.com \n&gt; &lt;mailto:archive-crawler%40yahoogroups.com&gt;, Pranay Pandey \n&gt; &lt;sspranay@...&gt; wrote:\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; OK, I took a shot at configuring the beans, it doesn&#39;t seem to be \n&gt; helping.\n&gt; &gt; The job gets build and run but doesn&#39;t pass the authentication stage.\n&gt; &gt; Any suggestion(s)?\n&gt; &gt;\n&gt; &gt; This is what I tried :\n&gt; &gt; ------------\n&gt; &gt; &lt;bean id=&quot;HttpAuthenticationCredential&quot; \n&gt; class=&quot;org.archive.modules.credential.HttpAuthenticationCredential&quot;&gt;\n&gt; &gt; Â Â Â &lt;property name=&quot;domain&quot; value=&quot;www.mysite.com&quot;/&gt;\n&gt; &gt; Â Â Â &lt;property name=&quot;login&quot; value=&quot;xxxxx&quot;/&gt;\n&gt; &gt; Â Â Â &lt;property name=&quot;password&quot; value=&quot;xxxxxx&quot;/&gt;\n&gt; &gt; &lt;/bean&gt;\n&gt; &gt;\n&gt; &gt; &lt;bean id=&quot;credentialStore&quot; \n&gt; class=&quot;org.archive.modules.credential.CredentialStore&quot;&gt;\n&gt; &gt; Â Â &lt;property name=&quot;credentials&quot;&gt;\n&gt; &gt; Â Â Â Â Â Â &lt;map&gt;\n&gt; &gt; Â Â Â Â Â Â Â Â Â Â &lt;entry key=&quot;credentials&quot; \n&gt; value-ref=&quot;HttpAuthenticationCredential&quot; /&gt;\n&gt; &gt; Â Â Â Â Â Â &lt;/map&gt;\n&gt; &gt; Â Â &lt;/property&gt;\n&gt; &gt; &lt;/bean&gt;\n&gt; &gt; --------------\n&gt; &gt; And inside fetchFTTP, I add the property &quot;credentialStore&quot; as below.\n&gt; &gt;\n&gt; &gt; Â &lt;bean id=&quot;fetchHttp&quot; class=&quot;org.archive.modules.fetcher.FetchHTTP&quot;&gt;\n&gt; &gt; Â Â &lt;property name=&quot;credentialStore&quot;&gt;\n&gt; &gt; &lt;ref bean=&quot;credentialStore&quot;/&gt;\n&gt; &gt; Â &lt;/property&gt;\n&gt; &gt;\n&gt; &gt; Thanks,\n&gt; &gt; Pranay\n&gt; &gt;\n&gt; &gt; --- On Thu, 6/16/11, Pranay Pandey &lt;sspranay@...&gt; wrote:\n&gt; &gt;\n&gt; &gt; From: Pranay Pandey &lt;sspranay@...&gt;\n&gt; &gt; Subject: [archive-crawler] H3.0 config settings to crawl password \n&gt; protected pages.\n&gt; &gt; To: &quot;archive-crawler@yahoogroups.com \n&gt; &lt;mailto:archive-crawler%40yahoogroups.com&gt;&quot; \n&gt; &lt;archive-crawler@yahoogroups.com \n&gt; &lt;mailto:archive-crawler%40yahoogroups.com&gt;&gt;\n&gt; &gt; Date: Thursday, June 16, 2011, 11:16 AM\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; Â\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; Â Hello,\n&gt; &gt;\n&gt; &gt; I have been looking around to get the related beans setting \n&gt; configuration to be able to crawl password protected sites/pages.\n&gt; &gt; Does anyone has it handy for H-3.0?\n&gt; &gt;\n&gt; &gt; Thanks!\n&gt; &gt; Pranay\n&gt; &gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; \n\n\r\n--------------070902060500070703020004\r\nContent-Type: text/html; charset=UTF-8\r\nContent-Transfer-Encoding: 8bit\r\n\r\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;meta content=&quot;text/html; charset=UTF-8&quot; http-equiv=&quot;Content-Type&quot;&gt;\n  &lt;/head&gt;\n  &lt;body bgcolor=&quot;#FFFFFF&quot; text=&quot;#000000&quot;&gt;\n    Hello Pranay,&lt;br&gt;\n    &lt;br&gt;\n    The way it works, heritrix requests the url, gets the 401, then\n    requeues the url, noting that next time it should try with the\n    credential. Next time around the url is crawled again with auth. The\n    first time through, on the 401, almost all the normal processing\n    completes, short of logging to crawl.log. Full warc records are\n    written. Normally this includes a request and a metadata record. So\n    that&#39;s the only thing that&#39;s puzzling about your scenario. There\n    should also be 2 request records and 2 metadata records, and the\n    timestamps on the 401 and 200 should be different. &lt;br&gt;\n    &lt;br&gt;\n    As far as wayback goes, it&#39;s quite possible that it doesn&#39;t handle\n    401s well. (Maybe the ideal behavior would be to replicate what\n    happens on the live web, that is, replay the 401, look for basic\n    auth matching the request record of the 200 and only serve the\n    content in that case.)&lt;br&gt;\n    &lt;br&gt;\n    Noah&lt;br&gt;\n    &lt;br&gt;\n    On 03/12/2012 07:58 AM, Pranay Pandey wrote:\n    &lt;blockquote\n      cite=&quot;mid:1331564287.94805.YahooMailNeo@...&quot;\n      type=&quot;cite&quot;&gt;\n      &lt;style type=&quot;text/css&quot;&gt;\n&lt;!--\n\n/* start of attachment style */\n       .ygrp-photo-title{\n         clear: both;\n         font-size: smaller;\n         height: 15px;\n         overflow: hidden;\n         text-align: center;\n         width: 75px;\n       }\n       div.ygrp-photo{\n         background-position: center;\n         background-repeat: no-repeat;\n         background-color: white;\n         border: 1px solid black;\n         height: 62px;\n         width: 62px;\n       }\n\n       div.photo-title \n         a,\n         div.photo-title a:active,\n         div.photo-title a:hover,\n         div.photo-title a:visited {\n           text-decoration: none; \n       }\n\n       div.attach-table div.attach-row {\n         clear: both;\n       }\n\n       div.attach-table div.attach-row div {\n         float: left;\n         /* margin: 2px;*/\n       }\n\n       p {\n         clear: both;\n         padding: 15px 0 3px 0;\n\t overflow: hidden;\n       }\n\n       div.ygrp-file {\n         width: 30px;\n         valign: middle;\n       }\n       div.attach-table div.attach-row div div a {\n         text-decoration: none;\n       }\n\n       div.attach-table div.attach-row div div span {\n         font-weight: normal;\n       }\n\n       div.ygrp-file-title {\n         font-weight: bold;\n       }\n /* end of attachment style */\n        --&gt;\n        &lt;/style&gt;\n      \n      &lt;div style=&quot;color:#000; background-color:#fff; font-family:times\n        new roman, new york, times, serif;font-size:12pt&quot;&gt;\n        &lt;div&gt;&lt;span&gt;&lt;br&gt;\n          &lt;/span&gt;&lt;/div&gt;\n        Group,&lt;br&gt;\n        &lt;br&gt;\n        I am using 3.1.0 and I find it very strange to see just one\n        response code (200) in crawl.log and two response codes (200 and\n        401) in form of two response records in the warc written.&lt;br&gt;\n        I am trying to crawl a password protected site with the config\n        settings I had outlined in my older email below.&lt;br&gt;\n        &lt;br&gt;\n        My question:&lt;br&gt;\n        Are we ever supposed to get two &quot;response&quot; records in the WARC\n        for the same object, fetched at the same time? &lt;br&gt;\n        While the first response gives 401, the second one has 200 OK.&lt;br&gt;\n        &lt;br&gt;\n        And while I see 200 OK written in both WARC and crawl.log,\n        wayback displays the authentication failed page (401) for all\n        the protected pages.&lt;br&gt;\n        &lt;br&gt;\n        These are the two responses I see in the WARC, in the order they\n        were written.&lt;br&gt;\n        &lt;br&gt;\n        WARC/1.0^M&lt;br&gt;\n        WARC-Type: response^M&lt;br&gt;\n        WARC-Target-URI: &lt;a class=&quot;moz-txt-link-freetext&quot; href=&quot;http://www.xyz.com/index.html/^M&quot;&gt;http://www.xyz.com/index.html/^M&lt;/a&gt;&lt;br&gt;\n        WARC-Date: 2012-03-09T19:27:57Z^M&lt;br&gt;\n        WARC-Payload-Digest: sha1:XNMHLNSS4YF24HWXC52LDEETXXVHV47X^M&lt;br&gt;\n        WARC-IP-Address: 207.45.182.58^M&lt;br&gt;\n        WARC-Record-ID:\n        &lt;urn:uuid:513f8d8f-edcc-42f8-ac07-136d2dcfe4a4&gt;^M&lt;br&gt;\n        Content-Type: application/http; msgtype=response^M&lt;br&gt;\n        Content-Length: 3403^M&lt;br&gt;\n        ^M&lt;br&gt;\n        HTTP/1.1 401 Authorization Required^M&lt;br&gt;\n        Date: Fri, 09 Mar 2012 19:27:56 GMT^M&lt;br&gt;\n        Server: Apache^M&lt;br&gt;\n        WWW-Authenticate: Basic realm=&quot;Netpreserve&quot;^M&lt;br&gt;\n        Accept-Ranges: bytes^M&lt;br&gt;\n        Connection: close^M&lt;br&gt;\n        Content-Type: text/html^M&lt;br&gt;\n        &lt;br&gt;\n        WARC/1.0^M&lt;br&gt;\n        WARC-Type: response^M&lt;br&gt;\n        WARC-Target-URI: &lt;a class=&quot;moz-txt-link-freetext&quot; href=&quot;http://www.xyz.com/index.html/^M&quot;&gt;http://www.xyz.com/index.html/^M&lt;/a&gt;&lt;br&gt;\n        WARC-Date: 2012-03-09T19:27:57Z^M&lt;br&gt;\n        WARC-Payload-Digest: sha1:FGAN7GIN5JNYCHGL6BCB3TDPKDCFUJER^M&lt;br&gt;\n        WARC-IP-Address: 207.45.182.58^M&lt;br&gt;\n        WARC-Record-ID:\n        &lt;urn:uuid:f7f4761d-5c3b-4460-8ace-fed4e3477cd3&gt;^M&lt;br&gt;\n        Content-Type: application/http; msgtype=response^M&lt;br&gt;\n        Content-Length: 6052^M&lt;br&gt;\n        ^M&lt;br&gt;\n        HTTP/1.1 200 OK^M&lt;br&gt;\n        Date: Fri, 09 Mar 2012 19:27:56 GMT^M&lt;br&gt;\n        Server: Apache^M&lt;br&gt;\n        X-Powered-By: PHP/5.2.17^M&lt;br&gt;\n        Expires: Thu, 19 Nov 1981 08:52:00 GMT^M&lt;br&gt;\n        Cache-Control: no-store, no-cache, must-revalidate,\n        post-check=0, pre-check=0^M&lt;br&gt;\n        Pragma: no-cache^M&lt;br&gt;\n        Set-Cookie: PHPSESSID=7289c28a8ac5ba1b87aead5f94bc5473; path=/^M&lt;br&gt;\n        Content-Length: 5687^M&lt;br&gt;\n        Connection: close^M&lt;br&gt;\n        Content-Type: text/html^M&lt;br&gt;\n        &lt;div&gt;&lt;br&gt;\n        &lt;/div&gt;\n        &lt;div style=&quot;font-family: times new roman, new york, times,\n          serif; font-size: 12pt;&quot;&gt;\n          &lt;div style=&quot;font-family: times new roman, new york, times,\n            serif; font-size: 12pt;&quot;&gt;\n            &lt;div dir=&quot;ltr&quot;&gt; &lt;font face=&quot;Arial&quot; size=&quot;2&quot;&gt;\n                &lt;hr size=&quot;1&quot;&gt; &lt;b&gt;&lt;span style=&quot;font-weight:bold;&quot;&gt;From:&lt;/span&gt;&lt;/b&gt;\n                Patrick &lt;a class=&quot;moz-txt-link-rfc2396E&quot; href=&quot;mailto:lapaon@...&quot;&gt;&lt;lapaon@...&gt;&lt;/a&gt;&lt;br&gt;\n                &lt;b&gt;&lt;span style=&quot;font-weight: bold;&quot;&gt;To:&lt;/span&gt;&lt;/b&gt;\n                &lt;a class=&quot;moz-txt-link-abbreviated&quot; href=&quot;mailto:archive-crawler@yahoogroups.com&quot;&gt;archive-crawler@yahoogroups.com&lt;/a&gt; &lt;br&gt;\n                &lt;b&gt;&lt;span style=&quot;font-weight: bold;&quot;&gt;Sent:&lt;/span&gt;&lt;/b&gt;\n                Monday, February 27, 2012 11:04 AM&lt;br&gt;\n                &lt;b&gt;&lt;span style=&quot;font-weight: bold;&quot;&gt;Subject:&lt;/span&gt;&lt;/b&gt;\n                [archive-crawler] Re: H3.0 config settings to crawl\n                password protected pages.&lt;br&gt;\n              &lt;/font&gt; &lt;/div&gt;\n            &lt;br&gt;\n            &lt;div id=&quot;yiv1371232199&quot;&gt;\n              &lt;div&gt;\n                &lt;span style=&quot;display:none;&quot;&gt; &lt;/span&gt;\n                &lt;div id=&quot;yiv1371232199ygrp-text&quot;&gt;\n                  &lt;div&gt;I have got the same problem. Have you worked out\n                    the solution?&lt;br&gt;\n                    &lt;br&gt;\n                    --- In &lt;a moz-do-not-send=&quot;true&quot; rel=&quot;nofollow&quot;\n                      ymailto=&quot;mailto:archive-crawler%40yahoogroups.com&quot;\n                      target=&quot;_blank&quot;\n                      href=&quot;mailto:archive-crawler%40yahoogroups.com&quot;&gt;archive-crawler@yahoogroups.com&lt;/a&gt;,\n                    Pranay Pandey &lt;a class=&quot;moz-txt-link-rfc2396E&quot; href=&quot;mailto:sspranay@...&quot;&gt;&lt;sspranay@...&gt;&lt;/a&gt; wrote:&lt;br&gt;\n                    &gt;&lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; OK, I took a shot at configuring the beans, it\n                    doesn&#39;t seem to be helping.&lt;br&gt;\n                    &gt; The job gets build and run but doesn&#39;t pass the\n                    authentication stage.&lt;br&gt;\n                    &gt; Any suggestion(s)?&lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; This is what I tried :&lt;br&gt;\n                    &gt; ------------&lt;br&gt;\n                    &gt; &lt;bean id=&quot;HttpAuthenticationCredential&quot;\n                    class=&quot;org.archive.modules.credential.HttpAuthenticationCredential&quot;&gt;&lt;br&gt;\n                    &gt; Â Â Â  &lt;property name=&quot;domain&quot;\n                    value=&quot;&lt;a class=&quot;moz-txt-link-abbreviated&quot; href=&quot;http://www.mysite.com&quot;&gt;www.mysite.com&lt;/a&gt;&quot;/&gt;&lt;br&gt;\n                    &gt; Â Â Â  &lt;property name=&quot;login&quot;\n                    value=&quot;xxxxx&quot;/&gt;&lt;br&gt;\n                    &gt; Â Â Â  &lt;property name=&quot;password&quot;\n                    value=&quot;xxxxxx&quot;/&gt;&lt;br&gt;\n                    &gt; &lt;/bean&gt;&lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; &lt;bean id=&quot;credentialStore&quot;\n                    class=&quot;org.archive.modules.credential.CredentialStore&quot;&gt;&lt;br&gt;\n                    &gt; Â Â  &lt;property name=&quot;credentials&quot;&gt;&lt;br&gt;\n                    &gt; Â Â Â Â Â Â  &lt;map&gt;&lt;br&gt;\n                    &gt; Â Â Â Â Â Â Â Â Â Â  &lt;entry\n                    key=&quot;credentials&quot;\n                    value-ref=&quot;HttpAuthenticationCredential&quot; /&gt;&lt;br&gt;\n                    &gt; Â Â Â Â Â Â  &lt;/map&gt;&lt;br&gt;\n                    &gt; Â Â  &lt;/property&gt;&lt;br&gt;\n                    &gt; &lt;/bean&gt;&lt;br&gt;\n                    &gt; --------------&lt;br&gt;\n                    &gt; And inside fetchFTTP, I add the property\n                    &quot;credentialStore&quot; as below.&lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; Â &lt;bean id=&quot;fetchHttp&quot;\n                    class=&quot;org.archive.modules.fetcher.FetchHTTP&quot;&gt;&lt;br&gt;\n                    &gt; Â Â  &lt;property name=&quot;credentialStore&quot;&gt;&lt;br&gt;\n                    &gt; &lt;ref bean=&quot;credentialStore&quot;/&gt;&lt;br&gt;\n                    &gt; Â &lt;/property&gt;&lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; Thanks,&lt;br&gt;\n                    &gt; Pranay&lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; --- On Thu, 6/16/11, Pranay Pandey\n                    &lt;a class=&quot;moz-txt-link-rfc2396E&quot; href=&quot;mailto:sspranay@...&quot;&gt;&lt;sspranay@...&gt;&lt;/a&gt; wrote:&lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; From: Pranay Pandey &lt;a class=&quot;moz-txt-link-rfc2396E&quot; href=&quot;mailto:sspranay@...&quot;&gt;&lt;sspranay@...&gt;&lt;/a&gt;&lt;br&gt;\n                    &gt; Subject: [archive-crawler] H3.0 config settings\n                    to crawl password protected pages.&lt;br&gt;\n                    &gt; To: &quot;&lt;a moz-do-not-send=&quot;true&quot; rel=&quot;nofollow&quot;\n                      ymailto=&quot;mailto:archive-crawler%40yahoogroups.com&quot;\n                      target=&quot;_blank&quot;\n                      href=&quot;mailto:archive-crawler%40yahoogroups.com&quot;&gt;archive-crawler@yahoogroups.com&lt;/a&gt;&quot;\n                    &lt;&lt;a moz-do-not-send=&quot;true&quot; rel=&quot;nofollow&quot;\n                      ymailto=&quot;mailto:archive-crawler%40yahoogroups.com&quot;\n                      target=&quot;_blank&quot;\n                      href=&quot;mailto:archive-crawler%40yahoogroups.com&quot;&gt;archive-crawler@yahoogroups.com&lt;/a&gt;&gt;&lt;br&gt;\n                    &gt; Date: Thursday, June 16, 2011, 11:16 AM&lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; Â &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; Â Hello,&lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; I have been looking around to get the related\n                    beans setting configuration to be able to crawl\n                    password protected sites/pages.&lt;br&gt;\n                    &gt; Does anyone has it handy for H-3.0? &lt;br&gt;\n                    &gt; &lt;br&gt;\n                    &gt; Thanks!&lt;br&gt;\n                    &gt; Pranay&lt;br&gt;\n                    &gt;&lt;br&gt;\n                    &lt;br&gt;\n                  &lt;/div&gt;\n                &lt;/div&gt;\n              &lt;/div&gt;\n            &lt;/div&gt;\n            &lt;br&gt;\n            &lt;br&gt;\n          &lt;/div&gt;\n        &lt;/div&gt;\n      &lt;/div&gt;\n      \n      &lt;div width=&quot;1&quot; style=&quot;color: white; clear: both;&quot;&gt;&lt;/div&gt;\n    &lt;/blockquote&gt;\n    &lt;br&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\r\n--------------070902060500070703020004--\r\n\n"}}