{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"xly_1tpMC9IgGI7-88y9SzYarlvA_vN0BdQEHWs26X05ZP49iO_bvODFsy49Gioauxqtniqfske1XQZnhku_6Ec16p9GU40","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] Re: BroadScope Crawl OOME","postDate":"1281472218","msgId":6665,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRDNjFCNkRBLjIwNjA0MDdAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGkzczhoMStoNW5wQGVHcm91cHMuY29tPg==","referencesHeader":"PGkzczhoMStoNW5wQGVHcm91cHMuY29tPg=="},"prevInTopic":6664,"nextInTopic":6666,"prevInTime":6664,"nextInTime":6666,"topicId":6661,"numMessagesInTopic":6,"msgSnippet":"GC occurs as needed, almost constantly, depending on VM settings. In busy crawls, I ve observed the used space swing hundreds of MB over the span of minutes.","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 67674 invoked from network); 10 Aug 2010 20:30:25 -0000\r\nX-Received: from unknown (66.196.94.107)\n  by m11.grp.re1.yahoo.com with QMQP; 10 Aug 2010 20:30:25 -0000\r\nX-Received: from unknown (HELO relay00.pair.com) (209.68.5.9)\n  by mta3.grp.re1.yahoo.com with SMTP; 10 Aug 2010 20:30:25 -0000\r\nX-Received: (qmail 39942 invoked from network); 10 Aug 2010 20:30:19 -0000\r\nX-Received: from 208.70.27.190 (HELO silverbook.local) (208.70.27.190)\n  by relay00.pair.com with SMTP; 10 Aug 2010 20:30:19 -0000\r\nX-pair-Authenticated: 208.70.27.190\r\nMessage-ID: &lt;4C61B6DA.2060407@...&gt;\r\nDate: Tue, 10 Aug 2010 13:30:18 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.6; en-US; rv:1.9.1.11) Gecko/20100711 Thunderbird/3.0.6\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: &quot;peter.hannon@...&quot; &lt;peter.hannon@...&gt;\r\nReferences: &lt;i3s8h1+h5np@...&gt;\r\nIn-Reply-To: &lt;i3s8h1+h5np@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Re: BroadScope Crawl OOME\r\nX-Yahoo-Group-Post: member; u=137285340; y=oGUMXI6NGfErjjUOJjjwiikQkaUnXl9DlDW0QL9srDU4\r\nX-Yahoo-Profile: gojomo\r\n\r\nGC occurs as needed, almost constantly, depending on VM settings.\n\nIn busy crawls, I&#39;ve observed the used space swing hundreds of MB over \nthe span of minutes. (The low point will be roughly the typical live \nobject set size, and usage will grow to near max before falling back on \na major collection. So the range from peak to trough will depend on what \nyour configured max is, rather than being a percentage.) Space once \nallotted to the heap is never given back -- so once the total heap size \nreaches max it stays there, even when much (or even most) of it is free \nfor reuse.\n\nIf the usage stays in a very small range -- a few tens of MB, near the \nfull size -- that&#39;s a warning sign. It&#39;s constantly trying to reclaim \nspace but never getting much headroom. More effort is being spent on GC \nthan might be possible with less-frequent, coarser bulk collection, and \nany small burst of memory needs might outpace the available space, \ngenerating an OOME.\n\nIf you&#39;re seeing 100MB-200MB+ between peak and valley, that&#39;s normal and \nprobably safe.\n\n- Gordon @ IA\n\n\nOn 8/10/10 12:15 PM, peter.hannon@... wrote:\n&gt; Gordon thanks for getting back to me.\n&gt; How often should these GCs occur? The crawl has been running for nearly 4 and a half hours and the memory on the Web UI is at:\n&gt;\n&gt;   Memory\n&gt; 562537 KB used\n&gt; 760256 KB current heap\n&gt; 760256 KB max heap\n&gt;\n&gt; and while I&#39;ve been checking periodically the memory used has not gone below 500MB and the current heap has been stuck at the max heap size of 760MB. When you say a signicant drop - how much are we talking 50%?\n&gt;\n&gt; Thanks again for your help.\n&gt; P\n&gt;\n&gt; --- In archive-crawler@yahoogroups.com, Gordon Mohr&lt;gojomo@...&gt;  wrote:\n&gt;&gt;\n&gt;&gt; It&#39;s normal behavior for heap usage to rise to near max, then drop\n&gt;&gt; significantly, as the VM goes through garbage-collection cycles.\n&gt;&gt;\n&gt;&gt; It&#39;s our goal for there to be no OOMEs no matter how large or\n&gt;&gt; long-running a crawl. (The crawl may be slower, as the on-disk data\n&gt;&gt; structures get larger and more seeks are required for normal URL\n&gt;&gt; handling, but as long as you have disk space, there should be forward\n&gt;&gt; progress without memory errors.) And, as of the version you&#39;re using\n&gt;&gt; (1.14.4), we believe we&#39;ve hit that goal except in some very rare and\n&gt;&gt; obscure edge cases. So I do suspect your OOMEs may have been due to some\n&gt;&gt; VM/GC/platform bug fixed since 1.5.0_06.\n&gt;&gt;\n&gt;&gt; If it recurs and the crawler manages to pause in reaction to the OOME,\n&gt;&gt; the &#39;jmap -histo [PID]&#39; output for the VM can often give a hint as to\n&gt;&gt; what unwanted object retention caused the problem. (Also, the OOME\n&gt;&gt; errors in later JVMs are sometimes more informative.)\n&gt;&gt;\n&gt;&gt; FYI, BroadScope is a very old implementation; we recommend using the\n&gt;&gt; DecidingScope, with rules adjusted to allow a broad crawl, if possible\n&gt;&gt; and as preparation for future versions (where BroadScope class goes\n&gt;&gt; away). But its use isn&#39;t implicated in the OOMEs, and if it&#39;s working\n&gt;&gt; for you there&#39;s no urgent reason to change.\n&gt;&gt;\n&gt;&gt; - Gordon @ IA\n&gt;&gt;\n&gt;&gt; On 8/10/10 10:09 AM, peter.hannon@... wrote:\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; To update, I upgraded to Java 1.6.0_21, and I&#39;ve currently got a crawl running over 2 hours with 201696 documents downloaded, so more than double the previous amount I was able to download before getting an OOME. It&#39;s still running so I&#39;ll continue to monitor it to see how long it goes.\n&gt;&gt;&gt;\n&gt;&gt;&gt; On the web UI under memory it says:\n&gt;&gt;&gt; Memory\n&gt;&gt;&gt; 553999 KB used\n&gt;&gt;&gt; 760256 KB current heap\n&gt;&gt;&gt; 760256 KB max heap\n&gt;&gt;&gt;\n&gt;&gt;&gt; The current heap value reached the max heap value within about a half hour or 70000 documents downloaded as it had done previously (with Java 1.5.0_06-b05), but the used number continuously varies between about 500000 KB and 720000, I guess it goes down as objects are garbage collected. Is this the expected behaviour? I&#39;m wondering now if it was just a Java version issue or there is also a configuration issue in the order.xml I posted previously.\n&gt;&gt;&gt; Thanks,\n&gt;&gt;&gt; Peter.\n&gt;&gt;&gt;\n&gt;&gt;&gt; --- In archive-crawler@yahoogroups.com, &quot;peter.hannon@&quot;&lt;peter.hannon@&gt;   wrote:\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Hi there, I&#39;m a heritrix newbie, so I apologise if this is a stupid\n&gt;&gt;&gt;&gt; question. I&#39;m running heritrix v1.14.4 on a Debian box with 1 GB of RAM.\n&gt;&gt;&gt;&gt; It&#39;s a virtual machine running on a Intel Xeon E5420 @ 2.50GHz. The JVM\n&gt;&gt;&gt;&gt; heap is set to 768 MB, and the Java version is: 1.5.0_06-b05\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; It&#39;s a broad scope crawl with no crawl end parameters set (so it should\n&gt;&gt;&gt;&gt; run continuously). I know it should eventually exhaust the memory but\n&gt;&gt;&gt;&gt; currently it&#39;s downloading about 77000 documents after about 45 minutes\n&gt;&gt;&gt;&gt; and pausing itself, the current heap having reached the max heap size of\n&gt;&gt;&gt;&gt; 780416 KB. The alert shows an exception:\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; java.lang.OutOfMemoryError: Java heap space\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; There are 2 customised extract processors, TextCatProcessor and\n&gt;&gt;&gt;&gt; BowProcessor, I have tried crawls without both to eliminate a memory\n&gt;&gt;&gt;&gt; leak in either of them, and in fact the crawls seems to end with OOME\n&gt;&gt;&gt;&gt; even sooner in that case.\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; I&#39;ve attached my order.xml, I&#39;m think that I&#39;ve got something\n&gt;&gt;&gt;&gt; misconfigured, any thoughts/suggestions would be appreciated, again I\n&gt;&gt;&gt;&gt; apologise if it&#39;s something extremely obvious - I&#39;ve inherited this\n&gt;&gt;&gt;&gt; config from someone else and I&#39;m trying to get it working myself.\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Here&#39;s the order.xml\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;crawl-order\n&gt;&gt;&gt;&gt; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\n&gt;&gt;&gt;&gt; xsi:noNamespaceSchemaLocation=&quot;heritrix_settings.xsd&quot;&gt;\n&gt;&gt;&gt;&gt;      &lt;meta&gt;\n&gt;&gt;&gt;&gt;        &lt;name&gt;SQL_job_name&lt;/name&gt;\n&gt;&gt;&gt;&gt;        &lt;description&gt;Default Profile&lt;/description&gt;\n&gt;&gt;&gt;&gt;        &lt;operator&gt;Admin&lt;/operator&gt;\n&gt;&gt;&gt;&gt;        &lt;organization&gt;TCD&lt;/organization&gt;\n&gt;&gt;&gt;&gt;        &lt;audience&gt;&lt;/audience&gt;\n&gt;&gt;&gt;&gt;        &lt;date&gt;20100810001552&lt;/date&gt;\n&gt;&gt;&gt;&gt;      &lt;/meta&gt;\n&gt;&gt;&gt;&gt;      &lt;controller&gt;\n&gt;&gt;&gt;&gt;        &lt;string name=&quot;settings-directory&quot;&gt;settings&lt;/string&gt;\n&gt;&gt;&gt;&gt;        &lt;string name=&quot;disk-path&quot;&gt;&lt;/string&gt;\n&gt;&gt;&gt;&gt;        &lt;string name=&quot;logs-path&quot;&gt;logs&lt;/string&gt;\n&gt;&gt;&gt;&gt;        &lt;string name=&quot;checkpoints-path&quot;&gt;checkpoints&lt;/string&gt;\n&gt;&gt;&gt;&gt;        &lt;string name=&quot;state-path&quot;&gt;state&lt;/string&gt;\n&gt;&gt;&gt;&gt;        &lt;string name=&quot;scratch-path&quot;&gt;scratch&lt;/string&gt;\n&gt;&gt;&gt;&gt;        &lt;long name=&quot;max-bytes-download&quot;&gt;0&lt;/long&gt;\n&gt;&gt;&gt;&gt;        &lt;long name=&quot;max-document-download&quot;&gt;0&lt;/long&gt;\n&gt;&gt;&gt;&gt;        &lt;long name=&quot;max-time-sec&quot;&gt;0&lt;/long&gt;\n&gt;&gt;&gt;&gt;        &lt;integer name=&quot;max-toe-threads&quot;&gt;50&lt;/integer&gt;\n&gt;&gt;&gt;&gt;        &lt;integer name=&quot;recorder-out-buffer-bytes&quot;&gt;4096&lt;/integer&gt;\n&gt;&gt;&gt;&gt;        &lt;integer name=&quot;recorder-in-buffer-bytes&quot;&gt;65536&lt;/integer&gt;\n&gt;&gt;&gt;&gt;        &lt;integer name=&quot;bdb-cache-percent&quot;&gt;0&lt;/integer&gt;\n&gt;&gt;&gt;&gt;        &lt;newObject name=&quot;scope&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.scope.BroadScope&quot;&gt;\n&gt;&gt;&gt;&gt;          &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;          &lt;string name=&quot;seedsfile&quot;&gt;seeds.txt&lt;/string&gt;\n&gt;&gt;&gt;&gt;          &lt;integer name=&quot;max-link-hops&quot;&gt;25&lt;/integer&gt;\n&gt;&gt;&gt;&gt;          &lt;integer name=&quot;max-trans-hops&quot;&gt;5&lt;/integer&gt;\n&gt;&gt;&gt;&gt;          &lt;newObject name=&quot;exclude-filter&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.filter.OrFilter&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;if-matches-return&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;            &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;&gt;              &lt;newObject name=&quot;removeNonTextPages&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.filter.URIRegExpFilter&quot;&gt;\n&gt;&gt;&gt;&gt;                &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;                &lt;boolean name=&quot;if-match-return&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;                &lt;string\n&gt;&gt;&gt;&gt; name=&quot;regexp&quot;&gt;.*(?i)&#92;.(a|ai|aif|aifc|aiff|asc|bcpio|bin|bz2|c|cdf|cgi|cg&#92;\n&gt;&gt;&gt;&gt; m|class|cpio|cpp?|cpt|csh|css|cxx|dcr|dif|dir|djv|djvu|dll|dmg|dms|dtd|d&#92;\n&gt;&gt;&gt;&gt; v|dvi|dxr|eps|etx|exe|ez|gram|grxml|gtar|h|hdf|hqx|ice|ics|ief|ifb|iges|&#92;\n&gt;&gt;&gt;&gt; igs|iso|jnlp|jp2|js|kar|lha|lzh|m3u|mac|man|mathml|me|mesh|mif|ms|msh|mx&#92;\n&gt;&gt;&gt;&gt; u|nc|o|oda|ogg|pbm|pct|pdb|pgm|pgn|pl|pnm|pnt|pntg|ppm|py|qt|qti|qtif|ra&#92;\n&gt;&gt;&gt;&gt; |ram|ras|rdf|rgb|rm|roff|rpm|rtx|s|sgm|sgml|sh|shar|silo|sit|skd|skm|skp&#92;\n&gt;&gt;&gt;&gt; |skt|smi|smil|snd|so|spl|src|srpm|sv4cpio|sv4crc|swf|t|tar|tcl|tex|texi|&#92;\n&gt;&gt;&gt;&gt; texinfo|tgz|tr|tsv|ustar|vcd|vrml|vxml|wav|wbmp|wbxml|wml|wmlc|wmls|wmls&#92;\n&gt;&gt;&gt;&gt; c|wrl|xbm|xht|xpm|xsl|xslt|xwd|xyz|z|zip)$&lt;/string&gt;\n&gt;&gt;&gt;&gt;              &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;              &lt;newObject name=&quot;pathdepth&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.filter.PathDepthFilter&quot;&gt;\n&gt;&gt;&gt;&gt;                &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;                &lt;integer name=&quot;max-path-depth&quot;&gt;20&lt;/integer&gt;\n&gt;&gt;&gt;&gt;                &lt;boolean name=&quot;path-less-or-equal-return&quot;&gt;false&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;              &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;              &lt;newObject name=&quot;pathologicalpath&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.filter.PathologicalPathFilter&quot;&gt;\n&gt;&gt;&gt;&gt;                &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;                &lt;integer name=&quot;repetitions&quot;&gt;3&lt;/integer&gt;\n&gt;&gt;&gt;&gt;              &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;            &lt;/map&gt;\n&gt;&gt;&gt;&gt;          &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;        &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;        &lt;map name=&quot;http-headers&quot;&gt;\n&gt;&gt;&gt;&gt;          &lt;string name=&quot;user-agent&quot;&gt;Mozilla/5.0 (compatible; heritrix/1.14.4\n&gt;&gt;&gt;&gt; +http://www.tcd.ie)&lt;/string&gt;\n&gt;&gt;&gt;&gt;          &lt;string name=&quot;from&quot;&gt;phannon@&lt;/string&gt;\n&gt;&gt;&gt;&gt;        &lt;/map&gt;\n&gt;&gt;&gt;&gt;        &lt;newObject name=&quot;robots-honoring-policy&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.datamodel.RobotsHonoringPolicy&quot;&gt;\n&gt;&gt;&gt;&gt;          &lt;string name=&quot;type&quot;&gt;classic&lt;/string&gt;\n&gt;&gt;&gt;&gt;          &lt;boolean name=&quot;masquerade&quot;&gt;false&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;          &lt;text name=&quot;custom-robots&quot;&gt;&lt;/text&gt;\n&gt;&gt;&gt;&gt;          &lt;stringList name=&quot;user-agents&quot;&gt;\n&gt;&gt;&gt;&gt;          &lt;/stringList&gt;\n&gt;&gt;&gt;&gt;        &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;        &lt;newObject name=&quot;frontier&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.frontier.BdbFrontier&quot;&gt;\n&gt;&gt;&gt;&gt;          &lt;float name=&quot;delay-factor&quot;&gt;5.0&lt;/float&gt;\n&gt;&gt;&gt;&gt;          &lt;integer name=&quot;max-delay-ms&quot;&gt;5000&lt;/integer&gt;\n&gt;&gt;&gt;&gt;          &lt;integer name=&quot;min-delay-ms&quot;&gt;500&lt;/integer&gt;\n&gt;&gt;&gt;&gt;          &lt;integer name=&quot;max-retries&quot;&gt;30&lt;/integer&gt;\n&gt;&gt;&gt;&gt;          &lt;long name=&quot;retry-delay-seconds&quot;&gt;900&lt;/long&gt;\n&gt;&gt;&gt;&gt;          &lt;integer name=&quot;preference-embed-hops&quot;&gt;1&lt;/integer&gt;\n&gt;&gt;&gt;&gt;          &lt;integer name=&quot;total-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt;&gt;&gt;&gt;          &lt;integer name=&quot;max-per-host-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt;&gt;&gt;&gt;          &lt;string name=&quot;force-queue-assignment&quot;&gt;&lt;/string&gt;\n&gt;&gt;&gt;&gt;          &lt;boolean name=&quot;pause-at-finish&quot;&gt;false&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;          &lt;boolean name=&quot;hold-queues&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;          &lt;integer name=&quot;balance-replenish-amount&quot;&gt;3000&lt;/integer&gt;\n&gt;&gt;&gt;&gt;          &lt;long name=&quot;queue-total-budget&quot;&gt;-1&lt;/long&gt;\n&gt;&gt;&gt;&gt;          &lt;string\n&gt;&gt;&gt;&gt; name=&quot;cost-policy&quot;&gt;org.archive.crawler.frontier.ZeroCostAssignmentPolicy&#92;\n&gt;&gt;&gt;&gt; &lt;/string&gt;\n&gt;&gt;&gt;&gt;        &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;        &lt;map name=&quot;uri-canonicalization-rules&quot;&gt;\n&gt;&gt;&gt;&gt;          &lt;newObject name=&quot;Lowercase&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.url.canonicalize.LowercaseRule&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;          &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;          &lt;newObject name=&quot;Userinfo&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.url.canonicalize.StripUserinfoRule&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;          &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;          &lt;newObject name=&quot;WWW[0-9]*&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.url.canonicalize.StripWWWNRule&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;          &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;          &lt;newObject name=&quot;SessionIDs&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.url.canonicalize.StripSessionIDs&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;          &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;          &lt;newObject name=&quot;SessionCFIDs&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.url.canonicalize.StripSessionCFIDs&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;          &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;          &lt;newObject name=&quot;QueryStrPrefix&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.url.canonicalize.FixupQueryStr&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;          &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;        &lt;/map&gt;\n&gt;&gt;&gt;&gt;        &lt;map name=&quot;pre-fetch-processors&quot;&gt;\n&gt;&gt;&gt;&gt;          &lt;newObject name=&quot;Preselector&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.prefetch.Preselector&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;            &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;/map&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;recheck-scope&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;block-all&quot;&gt;false&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;            &lt;string name=&quot;block-by-regexp&quot;&gt;&lt;/string&gt;\n&gt;&gt;&gt;&gt;          &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;          &lt;newObject name=&quot;Preprocessor&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.prefetch.PreconditionEnforcer&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;            &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;/map&gt;\n&gt;&gt;&gt;&gt;            &lt;integer name=&quot;ip-validity-duration-seconds&quot;&gt;21600&lt;/integer&gt;\n&gt;&gt;&gt;&gt;            &lt;integer name=&quot;robot-validity-duration-seconds&quot;&gt;86400&lt;/integer&gt;\n&gt;&gt;&gt;&gt;          &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;        &lt;/map&gt;\n&gt;&gt;&gt;&gt;        &lt;map name=&quot;fetch-processors&quot;&gt;\n&gt;&gt;&gt;&gt;          &lt;newObject name=&quot;DNS&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.fetcher.FetchDNS&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;            &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;/map&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;accept-non-dns-resolves&quot;&gt;false&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;          &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;          &lt;newObject name=&quot;HTTP&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.fetcher.FetchHTTP&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;            &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;/map&gt;\n&gt;&gt;&gt;&gt;            &lt;map name=&quot;midfetch-filters&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;/map&gt;\n&gt;&gt;&gt;&gt;            &lt;integer name=&quot;timeout-seconds&quot;&gt;1200&lt;/integer&gt;\n&gt;&gt;&gt;&gt;            &lt;integer name=&quot;sotimeout-ms&quot;&gt;20000&lt;/integer&gt;\n&gt;&gt;&gt;&gt;            &lt;long name=&quot;max-length-bytes&quot;&gt;0&lt;/long&gt;\n&gt;&gt;&gt;&gt;            &lt;string name=&quot;load-cookies-from-file&quot;&gt;&lt;/string&gt;\n&gt;&gt;&gt;&gt;            &lt;string name=&quot;save-cookies-to-file&quot;&gt;&lt;/string&gt;\n&gt;&gt;&gt;&gt;            &lt;string name=&quot;trust-level&quot;&gt;open&lt;/string&gt;\n&gt;&gt;&gt;&gt;            &lt;stringList name=&quot;accept-headers&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;/stringList&gt;\n&gt;&gt;&gt;&gt;            &lt;string name=&quot;http-proxy-host&quot;&gt;134.226.32.57&lt;/string&gt;\n&gt;&gt;&gt;&gt;            &lt;string name=&quot;http-proxy-port&quot;&gt;8080&lt;/string&gt;\n&gt;&gt;&gt;&gt;            &lt;string name=&quot;default-encoding&quot;&gt;ISO-8859-1&lt;/string&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;send-connection-close&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;send-referer&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;send-range&quot;&gt;false&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;          &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;        &lt;/map&gt;\n&gt;&gt;&gt;&gt;        &lt;map name=&quot;extract-processors&quot;&gt;\n&gt;&gt;&gt;&gt;          &lt;newObject name=&quot;TextCatProcessor&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.metacombine.languagemodule.TextCatProcessor&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;            &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;/map&gt;\n&gt;&gt;&gt;&gt;          &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;          &lt;newObject name=&quot;BowProcessor&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.metacombine.crawlmodule.BowProcessor&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;            &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;/map&gt;\n&gt;&gt;&gt;&gt;          &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;          &lt;newObject name=&quot;ExtractorHTTP&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.extractor.ExtractorHTTP&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;            &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;/map&gt;\n&gt;&gt;&gt;&gt;          &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;          &lt;newObject name=&quot;ExtractorHTML&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.extractor.ExtractorHTML&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;            &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;/map&gt;\n&gt;&gt;&gt;&gt;          &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;          &lt;newObject name=&quot;ExtractorCSS&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.extractor.ExtractorCSS&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;            &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;/map&gt;\n&gt;&gt;&gt;&gt;          &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;          &lt;newObject name=&quot;ExtractorJS&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.extractor.ExtractorJS&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;            &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;/map&gt;\n&gt;&gt;&gt;&gt;          &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;          &lt;newObject name=&quot;ExtractorSWF&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.extractor.ExtractorSWF&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;            &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;/map&gt;\n&gt;&gt;&gt;&gt;          &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;        &lt;/map&gt;\n&gt;&gt;&gt;&gt;        &lt;map name=&quot;write-processors&quot;&gt;\n&gt;&gt;&gt;&gt;          &lt;newObject name=&quot;Archiver&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.writer.ARCWriterProcessor&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;            &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;/map&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;compress&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;            &lt;string name=&quot;prefix&quot;&gt;IAH&lt;/string&gt;\n&gt;&gt;&gt;&gt;            &lt;string name=&quot;suffix&quot;&gt;${HOSTNAME_ADMINPORT}&lt;/string&gt;\n&gt;&gt;&gt;&gt;            &lt;integer name=&quot;max-size-bytes&quot;&gt;70000000&lt;/integer&gt;\n&gt;&gt;&gt;&gt;            &lt;stringList name=&quot;path&quot;&gt;\n&gt;&gt;&gt;&gt;              &lt;string&gt;arcs&lt;/string&gt;\n&gt;&gt;&gt;&gt;            &lt;/stringList&gt;\n&gt;&gt;&gt;&gt;            &lt;integer name=&quot;pool-max-active&quot;&gt;5&lt;/integer&gt;\n&gt;&gt;&gt;&gt;            &lt;integer name=&quot;pool-max-wait&quot;&gt;300000&lt;/integer&gt;\n&gt;&gt;&gt;&gt;            &lt;long name=&quot;total-bytes-to-write&quot;&gt;0&lt;/long&gt;\n&gt;&gt;&gt;&gt;          &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;        &lt;/map&gt;\n&gt;&gt;&gt;&gt;        &lt;map name=&quot;post-processors&quot;&gt;\n&gt;&gt;&gt;&gt;          &lt;newObject name=&quot;Updater&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.postprocessor.CrawlStateUpdater&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;            &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;/map&gt;\n&gt;&gt;&gt;&gt;          &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;          &lt;newObject name=&quot;LinksScoper&quot;\n&gt;&gt;&gt;&gt;                class=&quot;org.archive.crawler.postprocessor.LinksScoper&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;            &lt;map name=&quot;filters&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;/map&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;seed-redirects-new-seed&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;override-logger&quot;&gt;false&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;            &lt;map name=&quot;scope-rejected-url-filters&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;/map&gt;\n&gt;&gt;&gt;&gt;          &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;          &lt;newObject name=&quot;Scheduler&quot;\n&gt;&gt;&gt;&gt;                class=&quot;org.archive.crawler.postprocessor.FrontierScheduler&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;          &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;        &lt;/map&gt;\n&gt;&gt;&gt;&gt;        &lt;map name=&quot;loggers&quot;&gt;\n&gt;&gt;&gt;&gt;          &lt;newObject name=&quot;crawl-statistics&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.admin.StatisticsTracker&quot;&gt;\n&gt;&gt;&gt;&gt;            &lt;integer name=&quot;interval-seconds&quot;&gt;20&lt;/integer&gt;\n&gt;&gt;&gt;&gt;          &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;        &lt;/map&gt;\n&gt;&gt;&gt;&gt;        &lt;string name=&quot;recover-path&quot;&gt;&lt;/string&gt;\n&gt;&gt;&gt;&gt;        &lt;boolean name=&quot;recover-retain-failures&quot;&gt;false&lt;/boolean&gt;\n&gt;&gt;&gt;&gt;        &lt;newObject name=&quot;credential-store&quot;\n&gt;&gt;&gt;&gt; class=&quot;org.archive.crawler.datamodel.CredentialStore&quot;&gt;\n&gt;&gt;&gt;&gt;          &lt;map name=&quot;credentials&quot;&gt;\n&gt;&gt;&gt;&gt;          &lt;/map&gt;\n&gt;&gt;&gt;&gt;        &lt;/newObject&gt;\n&gt;&gt;&gt;&gt;      &lt;/controller&gt;\n&gt;&gt;&gt;&gt; &lt;/crawl-order&gt;\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; ------------------------------------\n&gt;&gt;&gt;\n&gt;&gt;&gt; Yahoo! Groups Links\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------\n&gt;\n&gt; Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n\n"}}