{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":500983475,"authorName":"david_pane1","from":"&quot;david_pane1&quot; &lt;dpane@...&gt;","profile":"david_pane1","replyTo":"LIST","senderId":"i0bzAEmF15PyigaAmoEzZ6KzrvtWDnwhCFLmZ7TllU4bqPzWRs3PcWgrIXM6roVUyMMKZ2K9bUrr_BUkscfd_kQV5Ecqx1I","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: questions before we restart the crawl","postDate":"1327937228","msgId":7585,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGpnNmNzYytsNDBkQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDRGMjMzN0Q2LjMwMzA1QGdtYWlsLmNvbT4="},"prevInTopic":7582,"nextInTopic":7586,"prevInTime":7584,"nextInTime":7586,"topicId":7527,"numMessagesInTopic":27,"msgSnippet":"Kenji, I didn t change any of the values in WARCWriterProcessor.  It is the default. ","rawEmail":"Return-Path: &lt;dpane@...&gt;\r\nX-Sender: dpane@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 8278 invoked from network); 30 Jan 2012 15:27:12 -0000\r\nX-Received: from unknown (98.137.35.160)\n  by m7.grp.sp2.yahoo.com with QMQP; 30 Jan 2012 15:27:12 -0000\r\nX-Received: from unknown (HELO ng16-ip2.bullet.mail.bf1.yahoo.com) (98.139.165.138)\n  by mta4.grp.sp2.yahoo.com with SMTP; 30 Jan 2012 15:27:11 -0000\r\nX-Received: from [98.139.164.123] by ng16.bullet.mail.bf1.yahoo.com with NNFMP; 30 Jan 2012 15:27:11 -0000\r\nX-Received: from [69.147.65.150] by tg4.bullet.mail.bf1.yahoo.com with NNFMP; 30 Jan 2012 15:27:10 -0000\r\nX-Received: from [98.137.34.73] by t7.bullet.mail.sp1.yahoo.com with NNFMP; 30 Jan 2012 15:27:10 -0000\r\nDate: Mon, 30 Jan 2012 15:27:08 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;jg6csc+l40d@...&gt;\r\nIn-Reply-To: &lt;4F2337D6.30305@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;david_pane1&quot; &lt;dpane@...&gt;\r\nSubject: Re: questions before we restart the crawl\r\nX-Yahoo-Group-Post: member; u=500983475; y=iUtY_GZIgDgQq4G1zOi9JBXMYsny5vpSSLLk3o3bwRdTfdwXNaoldQ\r\nX-Yahoo-Profile: david_pane1\r\n\r\nKenji,\n\nI didn&#39;t change any of the values in WARCWriterProcessor.  It is th=\r\ne default.\n\n &lt;bean id=3D&quot;warcWriter&quot; class=3D&quot;org.archive.modules.writer.WA=\r\nRCWriterProcessor&quot;&gt;\n  &lt;!-- &lt;property name=3D&quot;compress&quot; value=3D&quot;true&quot; /&gt; --=\r\n&gt;\n  &lt;!-- &lt;property name=3D&quot;prefix&quot; value=3D&quot;IAH&quot; /&gt; --&gt;\n  &lt;!-- &lt;property na=\r\nme=3D&quot;suffix&quot; value=3D&quot;${HOSTNAME}&quot; /&gt; --&gt;\n  &lt;!-- &lt;property name=3D&quot;maxFile=\r\nSizeBytes&quot; value=3D&quot;1000000000&quot; /&gt; --&gt;\n  &lt;!-- &lt;property name=3D&quot;poolMaxActi=\r\nve&quot; value=3D&quot;1&quot; /&gt; --&gt;\n  &lt;!-- &lt;property name=3D&quot;MaxWaitForIdleMs&quot; value=3D&quot;=\r\n500&quot; /&gt; --&gt;\n  &lt;!-- &lt;property name=3D&quot;skipIdenticalDigests&quot; value=3D&quot;false&quot; =\r\n/&gt; --&gt;\n  &lt;!-- &lt;property name=3D&quot;maxTotalBytesToWrite&quot; value=3D&quot;0&quot; /&gt; --&gt;\n  =\r\n&lt;!-- &lt;property name=3D&quot;directory&quot; value=3D&quot;${launchId}&quot; /&gt; --&gt;\n  &lt;!-- &lt;prop=\r\nerty name=3D&quot;storePaths&quot;&gt;\n        &lt;list&gt;\n         &lt;value&gt;warcs&lt;/value&gt;\n    =\r\n    &lt;/list&gt;\n       &lt;/property&gt; --&gt;\n  &lt;!-- &lt;property name=3D&quot;writeRequests&quot; =\r\nvalue=3D&quot;true&quot; /&gt; --&gt;\n  &lt;!-- &lt;property name=3D&quot;writeMetadata&quot; value=3D&quot;true=\r\n&quot; /&gt; --&gt;\n  &lt;!-- &lt;property name=3D&quot;writeRevisitForIdenticalDigests&quot; value=3D=\r\n&quot;true&quot; /&gt; --&gt;\n  &lt;!-- &lt;property name=3D&quot;writeRevisitForNotModified&quot; value=3D=\r\n&quot;true&quot; /&gt; --&gt;\n &lt;/bean&gt;\n\n--David\n\n--- In archive-crawler@yahoogroups.com, Ke=\r\nnji Nagahashi &lt;knagahashi@...&gt; wrote:\n&gt;\n&gt; David,\n&gt; \n&gt; It is fairly common H=\r\n3 goes 2x~3x faster at the beginning, where URI/s \n&gt; figure includes lots o=\r\nf DNS queries, many queues are ready, state \n&gt; database is smaller, etc. I =\r\noften see my crawlers running at &gt;200URI/s, \n&gt; too. (Also URI/s shown on th=\r\ne web UI is not really reliable.)\n&gt; \n&gt; It is difficult to tell how many que=\r\nues are enough to keep all threads \n&gt; busy, as there are many factors affec=\r\nting crawl speed. Assuming 0.5 sec \n&gt; processing time per URI and 100% conc=\r\nurrency, 1200 thread could do 2400 \n&gt; URI/s. On the other hand, assuming co=\r\nnstant crawl delay of 3sec, 4000 \n&gt; active queues can only emit 1333 URI/s.=\r\n In this case, active queue size \n&gt; becomes the limiting factor. If process=\r\ning time per URI becomes 1 sec, \n&gt; then processing time becomes a bottlenec=\r\nk. Some queues get snoozed much \n&gt; longer than 3 sec and it makes URI emit =\r\nrate lower. I tried drawing a \n&gt; active-queue to crawl-speed graph, but wha=\r\nt I can say is that there is a \n&gt; strong correlation between them (roughly,=\r\n 5000 queues -&gt; 40URI/s, 8000 \n&gt; queue -&gt; 70URI/s ; variance is really big)=\r\n.\n&gt; \n&gt; Looking at your thread and frontier report, I noticed:\n&gt; \n&gt; - 994 qu=\r\neues are &quot;ready&quot;\n&gt; - 911 threads are in warcWriter\n&gt; \n&gt; that is, you have e=\r\nnough active queues to keep threads busy, but threads \n&gt; are spending too m=\r\nuch time on writing WARCs to process URIs on time. \n&gt; WarcWriter is the bot=\r\ntleneck in this case, probably because of small \n&gt; number of concurrent wri=\r\nters? What is your warcWriter.poolMaxActive?\n&gt; \n&gt; --Kenji\n&gt; \n&gt; (1/27/12 7:3=\r\n2 AM), david_pane1 wrote:\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; Kenji,\n&gt; &gt;\n&gt; &gt; You understood correct=\r\nly 25M pages/day for 5 machines. Right now, with\n&gt; &gt; three instances runnin=\r\ng, we are seeing around 17M pages per day. This\n&gt; &gt; makes me think that we =\r\nmay be saturating our network throughput.\n&gt; &gt;\n&gt; &gt; But, we have seen, at the=\r\n beginning of the crawl, 250-300 URIs/second\n&gt; &gt; (an average of 52M pages/d=\r\nay over the first 3 days of the crawl. Once we\n&gt; &gt; get past the first few d=\r\nays, the crawl slows. During mid crawl, we found\n&gt; &gt; that stopping the craw=\r\nl and restarting it improves the throughput but\n&gt; &gt; never back to 50M pages=\r\n/day.\n&gt; &gt;\n&gt; &gt; How many queues do you need active per thread? Wouldn&#39;t Herit=\r\nrix\n&gt; &gt; activate more queues if there are enough threads to handle them? We=\r\n\n&gt; &gt; certainly have a lot of queues.\n&gt; &gt;\n&gt; &gt; As an example, on one instance=\r\n we are seeing a rate of 93.25 URIs/sec\n&gt; &gt; average.\n&gt; &gt;\n&gt; &gt; Load:\n&gt; &gt; 1176=\r\n active of 1176 threads; 3,456.5 congestion ration 13688365 deepest\n&gt; &gt; que=\r\nue; 62 average depth\n&gt; &gt;\n&gt; &gt; Threads:\n&gt; &gt; 1176 threads: 1176 ABOUT_TO_BEGIN=\r\n_PROCESSOR; 911 warcWriter, 262\n&gt; &gt; fetchHttp, 2 candidates, 1 extractorHtm=\r\nl\n&gt; &gt;\n&gt; &gt; Frontier:\n&gt; &gt;\n&gt; &gt; RUN 12955728 URI queues: 4302 active (1200 in-p=\r\nrocess; 994 ready; 2108\n&gt; &gt; snoozed); 11429799 inactive; 0 ineligible; 0 re=\r\ntired; 1521627 exhausted.\n&gt; &gt;\n&gt; &gt; --David\n&gt; &gt;\n&gt; &gt; --- In archive-crawler@ya=\r\nhoogroups.com\n&gt; &gt; &lt;mailto:archive-crawler%40yahoogroups.com&gt;, Kenji Nagahas=\r\nhi\n&gt; &gt; &lt;knagahashi@&gt; wrote:\n&gt; &gt;  &gt;\n&gt; &gt;  &gt; David,\n&gt; &gt;  &gt;\n&gt; &gt;  &gt; I understood=\r\n &quot;25M + page/day&quot; was total for 5 machines, as you wrote\n&gt; &gt;  &gt; &quot;(these num=\r\nbers are totals of all 5 instances combined)&quot;. Did you mean\n&gt; &gt;  &gt; 25M+ pag=\r\ne/day/instance? If so, my &quot;100 threads&quot; comment is pointless.\n&gt; &gt;  &gt; Please=\r\n disregard it.\n&gt; &gt;  &gt;\n&gt; &gt;  &gt; I&#39;m running broad crawl that captures everythi=\r\nng linked: images, script,\n&gt; &gt;  &gt; CSS, PDF, Excel, ... even mpeg4 videos. O=\r\nur Heritrix 3 runs on 8GB\n&gt; &gt;  &gt; memory + 4 core virtual machine (KVM), wit=\r\nh 100 threads. it goes\n&gt; &gt;  &gt; ~60URI/s on average (per instance). Probably =\r\nwe could go as high as 150\n&gt; &gt;  &gt; threads to get higher crawl speed, but it=\r\n comes with higher risk of\n&gt; &gt;  &gt; dying of OutOfMemoryError, empirically. C=\r\nrawl speed is also limited by\n&gt; &gt;  &gt; lower disk I/O performance of VMs. 100=\r\n seems to be a good number for us.\n&gt; &gt;  &gt;\n&gt; &gt;  &gt; Yes, increasing threads br=\r\nings significant increase in crawl speed, to\n&gt; &gt;  &gt; certain extent. If you =\r\ndon&#39;t have enough &quot;active queues,&quot; threads are\n&gt; &gt;  &gt; just wasted. There ar=\r\ne other bottleneck, too, and it can change over\n&gt; &gt; time.\n&gt; &gt;  &gt;\n&gt; &gt;  &gt; At =\r\nleast we&#39;re getting sustained 60URI/s level of speed with 100\n&gt; &gt;  &gt; thread=\r\ns. With 1,200 threads and enough active queues, you should be\n&gt; &gt;  &gt; gettin=\r\ng crawl speed much much higher than that (I&#39;ve never been able to\n&gt; &gt;  &gt; ru=\r\nn my crawler with 1200 threads, though!)\n&gt; &gt;  &gt;\n&gt; &gt;  &gt; --Kenji\n&gt; &gt;  &gt;\n&gt; &gt;  =\r\n&gt; (1/26/12 10:31 AM), david_pane1 wrote:\n&gt; &gt;  &gt; &gt; Kenji,\n&gt; &gt;  &gt; &gt;\n&gt; &gt;  &gt; &gt; =\r\nAre you saying that you can get 25M pages per day on 100 threads and 1\n&gt; &gt; =\r\n &gt; &gt; instance or 25M URIs/day? Do you capture all images, pdfs, and\n&gt; &gt;  &gt; =\r\n&gt; supporting page documents or are you just capturing html pages?\n&gt; &gt;  &gt; &gt;\n=\r\n&gt; &gt;  &gt; &gt; My test crawls before running our large crawl showed significant\n&gt;=\r\n &gt;  &gt; &gt; increase in the number of pages captured when we increased the\n&gt; &gt; =\r\nnumber of\n&gt; &gt;  &gt; &gt; threads.\n&gt; &gt;  &gt; &gt;\n&gt; &gt;  &gt; &gt; --David\n&gt; &gt;  &gt; &gt;\n&gt; &gt;  &gt; &gt; ---=\r\n In archive-crawler@yahoogroups.com\n&gt; &gt; &lt;mailto:archive-crawler%40yahoogrou=\r\nps.com&gt;\n&gt; &gt;  &gt; &gt; &lt;mailto:archive-crawler%40yahoogroups.com&gt;, Kenji Nagahash=\r\ni\n&gt; &gt;  &gt; &gt; &lt;knagahashi@&gt; wrote:\n&gt; &gt;  &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; Hi,\n&gt; &gt;  &gt; &gt; &gt;\n&gt; &gt;  &gt;=\r\n &gt; &gt; May be a bit off-topic, but 25M/day with 5 machine is average\n&gt; &gt; 58/s=\r\n per\n&gt; &gt;  &gt; &gt; &gt; machine. Since I know Heritrix-3 can crawl at this speed wi=\r\nth\n&gt; &gt; just 100\n&gt; &gt;  &gt; &gt; &gt; ToeThreads, I wonder if most of your 1200 ToeThr=\r\neads are idle.\n&gt; &gt;  &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; While why you don&#39;t get much higher sp=\r\need with 1200 threads is a big\n&gt; &gt;  &gt; &gt; &gt; question, it may make sense to cu=\r\nt down the number of ToeThreads if\n&gt; &gt;  &gt; &gt; &gt; you&#39;re okay with current craw=\r\nl speed. Less threads will make H3 less\n&gt; &gt;  &gt; &gt; &gt; susceptible to memory pr=\r\noblems... Just a thought.\n&gt; &gt;  &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; --Kenji\n&gt; &gt;  &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt;=\r\n &gt; (1/20/12 9:54 PM), David Pane wrote:\n&gt; &gt;  &gt; &gt; &gt; &gt; Gordon,\n&gt; &gt;  &gt; &gt; &gt; &gt;\n&gt;=\r\n &gt;  &gt; &gt; &gt; &gt; Thank you for your response. And I am sorry for the\n&gt; &gt; overwhe=\r\nlming amount\n&gt; &gt;  &gt; &gt; &gt; &gt; of information...I think I am a little overwhelme=\r\nd.... and\n&gt; &gt; feeling the\n&gt; &gt;  &gt; &gt; &gt; &gt; pressure.\n&gt; &gt;  &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; =\r\n1) Our Bloom filter configuration:\n&gt; &gt;  &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &lt;bean id=3D&quot;ur=\r\niUniqFilter&quot;\n&gt; &gt;  &gt; &gt; &gt; &gt; class=3D&quot;org.archive.crawler.util.BloomUriUniqFil=\r\nter&quot;&gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &lt;property name=3D&quot;bloomFilter&quot;&gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &lt;bean class=\r\n=3D&quot;org.archive.util.BloomFilter64bit&quot;&gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &lt;constructor-arg value=\r\n=3D&quot;400000000&quot;/&gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &lt;constructor-arg value=3D&quot;30&quot;/&gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; =\r\n&lt;/bean&gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &lt;/property&gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &lt;/bean&gt;\n&gt; &gt;  &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt;=\r\n &gt; &gt; 2) We are writing the crawl data to a NAS configured with RAID 6.\n&gt; &gt; =\r\n &gt; &gt; We did\n&gt; &gt;  &gt; &gt; &gt; &gt; see some problems with disk errors on the NAS earl=\r\nier in the crawl\n&gt; &gt;  &gt; &gt; (late\n&gt; &gt;  &gt; &gt; &gt; &gt; Dec ). I recently found this o=\r\nut. We were/are running in a degraded\n&gt; &gt;  &gt; &gt; &gt; &gt; raid state - a few of th=\r\ne disks have been replaced and the RAID is\n&gt; &gt;  &gt; &gt; being\n&gt; &gt;  &gt; &gt; &gt; &gt; rebu=\r\nilt. We didn&#39;t see any block device errors in the logs on\n&gt; &gt; the NAS\n&gt; &gt;  =\r\n&gt; &gt; &gt; &gt; so the write failures we saw are probably not related to the\n&gt; &gt;  &gt;=\r\n &gt; rebuild. We\n&gt; &gt;  &gt; &gt; &gt; &gt; did see some network hiccups (no outright failu=\r\nres) in the logs.\n&gt; &gt;  &gt; &gt; &gt; &gt; So, this may be the culprit for some of the\n=\r\n&gt; &gt;  &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; 3) Yes, we have been cross-feeding URIs.\n&gt; &gt;  &gt; &gt;=\r\n &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; --David\n&gt; &gt;  &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; On 1/21/12 12:22 AM, Go=\r\nrdon Mohr wrote:\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; You&#39;ve provided an overwhelming amount of i=\r\nnformation and we\n&gt; &gt; may be\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; dealing with multiple issues, s=\r\nome of which have roots going back\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; earlier than the diagnost=\r\nic data we now have available.\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; A few key poin=\r\nts of emphasis:\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; - we&#39;ve not run crawls with 1=\r\n200 threads before, or on hardware\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; similar to yours, so our =\r\nexperience is only vaguely suggestive\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; - it&#39;s =\r\nnot the lower thread counts that are the real source of\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; conc=\r\nern; you can even adjust the number of threads mid-crawl.\n&gt; &gt; It&#39;s\n&gt; &gt;  &gt; &gt;=\r\n &gt; &gt; &gt; that the error that killed the threads almost certainly left\n&gt; &gt; a q=\r\nueue\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; in a &#39;phantom&#39; state where no progress would be made cr=\r\nawling its\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; URIs, each time it happened, on each resume leadi=\r\nng to the\n&gt; &gt;  &gt; &gt; current state.\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; - without h=\r\naving understood and fixed whatever software or system\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; probl=\r\nems caused the earliest/most-foundational errors in your\n&gt; &gt; crawl,\n&gt; &gt;  &gt; =\r\n&gt; &gt; &gt; &gt; it&#39;s impossible to say how likely they are to recur.\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;=\r\n\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; With that in mind, I&#39;ll try to provide quick answers to you=\r\nr\n&gt; &gt; other\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; questions...\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; On 1/=\r\n20/12 4:20 PM, David Pane wrote:\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; We have co=\r\nllected about 550 million pages along with the\n&gt; &gt; images and\n&gt; &gt;  &gt; &gt; &gt; &gt; =\r\n&gt;&gt; supporting documents on our 5 instance crawl that was started\n&gt; &gt;  &gt; &gt; D=\r\nec. 23rd.\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; Although we are please with the amount of data we=\r\n captured to\n&gt; &gt;  &gt; &gt; date, we\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; are very concerned about the=\r\n state of the Heritrix instances. If\n&gt; &gt;  &gt; &gt; fact,\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; we aren=\r\n&#39;t very confident that the instances will last until the\n&gt; &gt;  &gt; &gt; end of\n&gt; =\r\n&gt;  &gt; &gt; &gt; &gt; &gt;&gt; February. We are now running on a total of over 500 less thre=\r\nads\n&gt; &gt;  &gt; &gt; than\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; the configured 1200 threads/instance.\n&gt; &gt;=\r\n  &gt; &gt; &gt; &gt; &gt;&gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; 0 - not running right now.\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; 1 -=\r\n running on 1198 ( 2 less)\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; 2 - running on 931 (269 less)\n&gt; =\r\n&gt;  &gt; &gt; &gt; &gt; &gt;&gt; 3 - running on 987 (213 less)\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; 4 - running on =\r\n1170 (30 less)\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; Since we are seriously consi=\r\ndering throwing away this past\n&gt; &gt;  &gt; &gt; month&#39;s work\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; and st=\r\narting over, we would like to pick your brain on some\n&gt; &gt;  &gt; &gt; strategies\n&gt;=\r\n &gt;  &gt; &gt; &gt; &gt; &gt;&gt; that will help us avoid getting into this situation again.\n&gt;=\r\n &gt; We were\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; hoping to be done crawling by the end of Februar=\r\ny so this\n&gt; &gt;  &gt; &gt; restart will\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; put us behind schedule.\n&gt; &gt;=\r\n  &gt; &gt; &gt; &gt; &gt;&gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; 1) Can we continue from here but with &quot;clean&quot; =\r\nHeritrix\n&gt; &gt; instances?\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; Is there a way that=\r\n we can continue from the this point\n&gt; &gt; forward, but\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; start=\r\n with Heritrix instances that will not be corrupt due\n&gt; &gt; to sever\n&gt; &gt;  &gt; &gt;=\r\n &gt; &gt; &gt;&gt; error? (e.g. using the\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt;\n&gt; &gt; https://webarchive.jira.=\r\ncom/wiki/display/Heritrix/Crawl+Recovery\n&gt; &gt; &lt;https://webarchive.jira.com/w=\r\niki/display/Heritrix/Crawl+Recovery&gt;\n&gt; &gt;  &gt; &gt; &lt;https://webarchive.jira.com/=\r\nwiki/display/Heritrix/Crawl+Recovery\n&gt; &gt; &lt;https://webarchive.jira.com/wiki/=\r\ndisplay/Heritrix/Crawl+Recovery&gt;&gt;\n&gt; &gt;  &gt; &gt; &gt; &gt;\n&gt; &gt; &lt;https://webarchive.jira=\r\n.com/wiki/display/Heritrix/Crawl+Recovery\n&gt; &gt; &lt;https://webarchive.jira.com/=\r\nwiki/display/Heritrix/Crawl+Recovery&gt;\n&gt; &gt;  &gt; &gt; &lt;https://webarchive.jira.com=\r\n/wiki/display/Heritrix/Crawl+Recovery\n&gt; &gt; &lt;https://webarchive.jira.com/wiki=\r\n/display/Heritrix/Crawl+Recovery&gt;&gt;&gt; ) If\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; so, would you reco=\r\nmmend doing this? You mentioned that this\n&gt; &gt; could be\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; time=\r\n consuming. Each of our instances has downloaded around 170M\n&gt; &gt;  &gt; &gt; URIs,=\r\n\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; they have over 700M queued URIs, what is your time estimat=\r\ne for\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; something this large?\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt;=\r\n We are willing to sacrifice a few days to get our crawler to\n&gt; &gt; a clean\n&gt;=\r\n &gt;  &gt; &gt; &gt; &gt; &gt;&gt; state again so we can crawl for another 30 days at the pace =\r\nwe\n&gt; &gt;  &gt; &gt; have been\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; crawling.\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt;=\r\n &gt; You can do a big &#39;frontier-recover&#39; log replay to avoid\n&gt; &gt;  &gt; &gt; recrawl=\r\ning the\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; same URIs, and approximate the earlier queue state.\n=\r\n&gt; &gt; Splitting/filters\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; the logs manually beforehand as allude=\r\nd to in the wiki page\n&gt; &gt; can speed\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; this process somewhat...=\r\n but given the size of all your\n&gt; &gt; log-segments\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; that log gr=\r\nooming beforehand is itself likely to be a lengthy\n&gt; &gt;  &gt; &gt; process.\n&gt; &gt;  &gt;=\r\n &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; I don&#39;t think we&#39;ve ever done it with logs of 170M =\r\ncrawled / 870M\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; discovered before, nor on any hardware compar=\r\nable to yours.\n&gt; &gt; So it&#39;s\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; impossible to project its duratio=\r\nn in your environment. It&#39;s\n&gt; &gt;  &gt; &gt; taken 2-3\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; days for us o=\r\nn smaller crawls, slower hardware.\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; An added c=\r\nomplication is that this older frontier-recover-log\n&gt; &gt; replay\n&gt; &gt;  &gt; &gt; &gt; &gt;=\r\n &gt; technique happens in its own thread separate from the\n&gt; &gt; checkpointing\n=\r\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; process, so it is not, itself, accurately checkpointed durin=\r\ng the\n&gt; &gt;  &gt; &gt; long\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; reload process.\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; =\r\n&gt; &gt; &gt; At nearly 1B discovered URIs per node, even if you are using the\n&gt; &gt; =\r\n &gt; &gt; &gt; &gt; &gt; alternate BloomUriUniqFilter, if you are using it at its\n&gt; &gt; def=\r\nault size\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; (~500MB) it will now be heavily saturated and thus=\r\n returning many\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; false-positives causing truly unique URIs to=\r\n be rejected as\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; duplicates. (If you&#39;re using a significantly=\r\n larger filter,\n&gt; &gt; you may\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; not yet be at a high false-posit=\r\nive rate: you&#39;d have to do\n&gt; &gt; the bloom\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; filter math. If you=\r\n&#39;re still using BdbUriUniqFilter, you&#39;re\n&gt; &gt; way way\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; past th=\r\ne point where its disk seeks have usually made it too\n&gt; &gt; slow for\n&gt; &gt;  &gt; &gt;=\r\n &gt; &gt; &gt; our purposes.)\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; 2) What can be done to=\r\n avoid corrupting the Heritrix instances?\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; -=\r\n What kind of strategies might we take to keep the crawl error\n&gt; &gt;  &gt; &gt; fre=\r\ne?\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; - Do you think the SEVER errors that we =\r\nhave seen are\n&gt; &gt;  &gt; &gt; deterministic or\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; random (e.g., trigg=\r\nered by occasional flaky network conditions,\n&gt; &gt;  &gt; &gt; disks,\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;=\r\n&gt; race conditions, or whatever)?\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; Hard to say.=\r\n The main thing I could suggest is watch very\n&gt; &gt; closely and\n&gt; &gt;  &gt; &gt; &gt; &gt; =\r\n&gt; when a SEVERE error occurs, prioritize diagnosing and\n&gt; &gt; resolving the\n&gt;=\r\n &gt;  &gt; &gt; &gt; &gt; &gt; cause while the info is fresh.\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt;=\r\n - Do you believe that we can reliably backup to the previous\n&gt; &gt;  &gt; &gt; chec=\r\nkpoint\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; if we watch the logs and stop as soon as we see the =\r\nfirst SEVER\n&gt; &gt;  &gt; &gt; error?\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; If we do this, do you speculate=\r\n that the same SEVER will occur\n&gt; &gt;  &gt; &gt; again?\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt;=\r\n &gt; Resuming from the latest checkpoint before an error believed to\n&gt; &gt;  &gt; &gt;=\r\n &gt; &gt; &gt; corrupt the on-disk state will be the best strategy.\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n=\r\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; If we never figure out the real cause, but run the same\n&gt; &gt; =\r\nsoftware on\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; the same machine, yes, I expect the same problem=\r\n will recur!\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; - Is there any reason why a Her=\r\nitrix instance that is run while\n&gt; &gt;  &gt; &gt; binded\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; to one ip =\r\naddress can&#39;t be resumed binded to a different ip\n&gt; &gt; address?\n&gt; &gt;  &gt; &gt; &gt; &gt;=\r\n &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; Only the web UI to my knowledge binds to a chosen address=\r\n,\n&gt; &gt; and it is\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; common to have it bind to all. I don&#39;t expec=\r\nt the outbound\n&gt; &gt; requests\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; would be hurt by a machine chang=\r\ning its IP address while the\n&gt; &gt;  &gt; &gt; crawl was\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; running, but=\r\n I would run a test to be sure if that was an\n&gt; &gt; important,\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;=\r\n expected transition.\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; 3) Should we configure=\r\n the crawler with more instances and\n&gt; &gt; switch\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; between the=\r\nm?\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; We have seen that we can run a single in=\r\nstance to 100M pages +\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; supporting images and documents. Per=\r\nhaps this means that we need\n&gt; &gt;  &gt; &gt; 10 or\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; more instances =\r\ninstead of 5. That raises the possibility of\n&gt; &gt;  &gt; &gt; running 2\n&gt; &gt;  &gt; &gt; &gt; =\r\n&gt; &gt;&gt; instances per machine. If we could run 2, or even 4,\n&gt; &gt; instances on =\r\na\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; single machine, they would each run half as long.\n&gt; &gt;  &gt; =\r\n&gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; I don&#39;t think the problems as reported are specifica=\r\nlly due\n&gt; &gt; to one\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; node&#39;s progress growing beyond a certain =\r\nsize, but it might\n&gt; &gt; be the\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; case that giant instances are =\r\nmore likely to suffer from, and\n&gt; &gt; harder\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; to recover from, =\r\nsingle glitches (eg a single disk error). On the\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; other hand,=\r\n many instances introduce more redundant overhead\n&gt; &gt; costs\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; =\r\n(certain data structures, cross-feeding URIs if you&#39;re doing\n&gt; &gt;  &gt; &gt; that,=\r\n etc.).\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; - Can you suggest a way to start/sto=\r\np instances from a script so\n&gt; &gt;  &gt; &gt; we can\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; change between=\r\n instances automatically?\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; Not a mode I&#39;ve tho=\r\nught much about.\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; - Have you seen frequent st=\r\narting / stopping of instances\n&gt; &gt; introduce\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; instability?\n&gt;=\r\n &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; No... but it might make you notice latent issu=\r\nes sooner.\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; 4) Crawl slows but restarting see=\r\nms to improve the speed again.\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; We noticed t=\r\nhat the all of our instances would initially run at\n&gt; &gt;  &gt; &gt; a fast\n&gt; &gt;  &gt; =\r\n&gt; &gt; &gt; &gt;&gt; pace. We would collect an average of 25M + pages/day for 2-3\n&gt; &gt;  =\r\n&gt; &gt; days and\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; then the crawl would slow down to 10M pages/da=\r\ny over the next\n&gt; &gt;  &gt; &gt; few days.\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; (these numbers are total=\r\ns of all 5 instances combined). When we\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; restarted the insta=\r\nnces, the average pages would improve back to\n&gt; &gt;  &gt; &gt; 25M +\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;=\r\n&gt; pages/day. The total crawled numbers (TiB) also reflected the\n&gt; &gt;  &gt; &gt; sl=\r\now down.\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; - Is this something that others ha=\r\nve experienced as well?\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; I don&#39;t recall hearin=\r\ng other reports of speed boosts after\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; checkpoint-resumes but=\r\n others may have more experience.\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; 5) We are =\r\ncapturing tweets from twitter, harvesting the urls and\n&gt; &gt;  &gt; &gt; want to\n&gt; &gt;=\r\n  &gt; &gt; &gt; &gt; &gt;&gt; crawl those urls within 1 day of receiving the tweet. Can you\n=\r\n&gt; &gt;  &gt; &gt; recommend\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; a strategy for doing this with the 5 ins=\r\ntances we are running?\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; - Do we need to run =\r\na separate crawler dedicated to this? If so,\n&gt; &gt;  &gt; &gt; can you\n&gt; &gt;  &gt; &gt; &gt; &gt; =\r\n&gt;&gt; suggest a way to crawl out from the tweeted urls but when we get\n&gt; &gt;  &gt; =\r\n&gt; &gt; &gt; &gt;&gt; additional urls from the tweets, quickly change focus to\n&gt; &gt; these=\r\n urls\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; instead of the ones branching out. When adding urls a=\r\ns seeds,\n&gt; &gt;  &gt; &gt; can you\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; set a high priority to crawl thos=\r\ne before the discovered urls?\n&gt; &gt;  &gt; &gt; Do you\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; recommend may=\r\nbe setting up a specific crawl for these urls and\n&gt; &gt;  &gt; &gt; then only\n&gt; &gt;  &gt;=\r\n &gt; &gt; &gt; &gt;&gt; crawl a few hopes from the seeds - injecting the urls from the\n&gt; =\r\n&gt;  &gt; &gt; tweets as\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; seeds?\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; Dedic=\r\nating a special script or crawler to URIs that come from\n&gt; &gt; such a\n&gt; &gt;  &gt; =\r\n&gt; &gt; &gt; &gt; constrained source (Twitter feeds), or that need to be\n&gt; &gt; crawled =\r\nin a\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; special timeframe, or according to other special limits=\r\n\n&gt; &gt; (fewer hops),\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; could make sense.\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt;=\r\n &gt; &gt; &gt; It would take some customization of the queueing-policy or\n&gt; &gt;  &gt; &gt; =\r\n&gt; &gt; &gt; &#39;precedence&#39; features of Heritrix to allow URIs added\n&gt; &gt; mid-crawl t=\r\no be\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; prioritized above those already discovered and queued. =\r\nThe most\n&gt; &gt;  &gt; &gt; simple\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; possible customization might be a U=\r\nriPrecedencePolicy that\n&gt; &gt; takes all\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; zero-hop URIs (which a=\r\nll seeds and most direct-fed URIs would\n&gt; &gt; be) and\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; gives th=\r\nem a higher precedence (lower precedence number) than all\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; ot=\r\nher URIs.\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; 6) I think the answer is no for th=\r\nis question, but I will ask it\n&gt; &gt;  &gt; &gt; anyway.\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; If you have=\r\n a Heritrix instance that is configured for 1200\n&gt; &gt;  &gt; &gt; threads on\n&gt; &gt;  &gt;=\r\n &gt; &gt; &gt; &gt;&gt; one machine, can you recover from a checkpoint from that\n&gt; &gt; 1200=\r\n thread\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; configuration on a different machine with an Heritr=\r\nix instance\n&gt; &gt;  &gt; &gt; that is\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;&gt; configured for less threads (e=\r\n.g. the default 25 threads)?\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; Yes - there&#39;s no=\r\n need to keep the thread count the same after a\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; resume. None=\r\n of the checkpoint structures (or usual disk\n&gt; &gt; structures)\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;=\r\n are based on the number of worker threads (&#39;ToeThreads&#39;)... as\n&gt; &gt;  &gt; &gt; &gt; =\r\n&gt; &gt; mentioned above you can even vary the number of threads in a\n&gt; &gt; runnin=\r\ng\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; crawl.\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt; &gt; - Gordon\n&gt; &gt;  &gt; &gt; &gt; &gt;=\r\n &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt; &gt;\n&gt; &gt;  &gt; &gt;\n&gt; &gt;  &gt; &gt;\n&gt; &gt;  &gt;\n&gt; &gt;\n&gt; &gt;\n&gt;\n=\r\n\n\n\n"}}