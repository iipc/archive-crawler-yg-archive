{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"S4mSqIn3qHt9KJHJyCNI37Ui-cUF30cDGS0jjgADnEMbulwyG4zaU3nJpY5rLJbifIc1teA1z8Z59-VTbg8XxhH_DUp0gLc","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Heritrix does not obey robots.txt rules on particular site","postDate":"1302746915","msgId":7106,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDREQTY1NzIzLjgwNDAxMDdAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDREQTYyOENDLjYwNzAzMDRAYXJjaGl2ZS5vcmc+","referencesHeader":"PEJBTkxrVGlrWj1LWmRGdWg3Y3VYLWJuTXdleXpfdmhZZlBnQG1haWwuZ21haWwuY29tPiA8NERBNjI4Q0MuNjA3MDMwNEBhcmNoaXZlLm9yZz4="},"prevInTopic":7104,"nextInTopic":7122,"prevInTime":7105,"nextInTime":7107,"topicId":7100,"numMessagesInTopic":4,"msgSnippet":"However, note that with respect to the original formulation of the Allow directive, the example site really does allow everything. See section 3.2.3 of: ","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 65524 invoked from network); 14 Apr 2011 02:08:37 -0000\r\nX-Received: from unknown (66.196.94.105)\n  by m13.grp.re1.yahoo.com with QMQP; 14 Apr 2011 02:08:37 -0000\r\nX-Received: from unknown (HELO relay03.pair.com) (209.68.5.17)\n  by mta1.grp.re1.yahoo.com with SMTP; 14 Apr 2011 02:08:37 -0000\r\nX-Received: (qmail 80285 invoked by uid 0); 14 Apr 2011 02:08:35 -0000\r\nX-Received: from 76.218.213.38 (HELO silverbook.local) (76.218.213.38)\n  by relay03.pair.com with SMTP; 14 Apr 2011 02:08:35 -0000\r\nX-pair-Authenticated: 76.218.213.38\r\nMessage-ID: &lt;4DA65723.8040107@...&gt;\r\nDate: Wed, 13 Apr 2011 19:08:35 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.6; en-US; rv:1.9.2.15) Gecko/20110303 Thunderbird/3.1.9\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: Noah Levitt &lt;nlevitt@...&gt;, =?UTF-8?B?QWRhbSBCcm9rZcWh?=\n &lt;adam.brokes@...&gt;\r\nReferences: &lt;BANLkTikZ=KZdFuh7cuX-bnMweyz_vhYfPg@...&gt; &lt;4DA628CC.6070304@...&gt;\r\nIn-Reply-To: &lt;4DA628CC.6070304@...&gt;\r\nContent-Type: text/plain; charset=UTF-8; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Heritrix does not obey robots.txt rules on\n particular site\r\nX-Yahoo-Group-Post: member; u=137285340; y=b4fLAsAWy6jhlXEiAhhTcHWkS-1YVPWsaRCSIaFYg3wg\r\nX-Yahoo-Profile: gojomo\r\n\r\nHowever, note that with respect to the original formulation of the \n&#39;Allow&#39; directive, the example site really does allow everything.\n\nSee section 3.2.3 of:\n\nhttp://www.robotstxt.org/norobots-rfc.txt\n\n&quot;To evaluate if access to a URL is allowed, a robot must attempt to \nmatch the paths in Allow and Disallow lines against the URL, in the \norder they occur in the record. The first match found is used.&quot;\n\nAlthough our code varies from that spec for certain rule orderings, in \nthis particular case, we&#39;re having the same effect.\n\nAlso, by any of the interpretations, a site never really needs an \n&quot;Allow: /&quot; directive. In the &quot;first match found&quot; interpretation, it \nsimply serves to disable all later rules of any type by matching all URL \npaths. (Just deleting the &quot;Allow: /&quot; and all later rules would have the \nsame effect, which probably isn&#39;t what&#39;s really wanted.) And with the \nGoogle/Bing interpretation, the &quot;Allow: /&quot; will be overruled by all \nother longer directives (since &#39;/&#39; is the shortest-possible path, and \n&#39;allow&#39; is already the default for no-other-matching-rules). It could \nalways be omitted with no change of behavior.\n\nStill, I think Heritrix should match the Google/Bing behavior, because \nthat&#39;s what webmasters generally come to expect, no matter what the \nwritten specs say, so we&#39;ll fix this. In the meantime, a tip to the \nwebmaster that their &quot;Allow: /&quot; rule only confuses Heritrix, and has no \neffects elsewhere, may provide some interim relief.\n\n- Gordon @ IA\n\nOn 4/13/11 3:50 PM, Noah Levitt wrote:\n&gt; Hello Adam,\n&gt;\n&gt; I think you&#39;re right, this is a bug. In heritrix, an Allow directive always overrides a Disallow. Quoting RobotsDirectives.java:\n&gt;\n&gt;       public boolean allows(String path) {\n&gt;           if(disallows.containsPrefixOf(path)) {\n&gt;               return allows.containsPrefixOf(path);\n&gt;           }\n&gt;           return true;\n&gt;       }\n&gt;\n&gt; However, https://secure.wikimedia.org/wikipedia/en/wiki/Robots_exclusion_standard says, &quot;While by standard implementation the first matching robots.txt pattern always wins, Google&#39;s implementation differs in that Allow patterns with equal or more characters in the directive path win over a matching Disallow pattern.[6] Bing uses the Allow or Disallow directive which is the most specific.[7]&quot;\n&gt;\n&gt; It seems logical that the most specific matching rule, Allow or Disallow, should be the one that applies.  Filedhttps://webarchive.jira.com/browse/HER-1880\n&gt;\n&gt; Noah\n&gt;\n&gt; On 2011-04-13 02:42 , Adam Brokeš wrote:\n&gt;&gt; Hi all,\n&gt;&gt;\n&gt;&gt; in our broad crawl I came across strange issue with robots.txt.\n&gt;&gt;\n&gt;&gt; The website http://www.jezise.cz is using robots.txt which contains:\n&gt;&gt;\n&gt;&gt; User-agent: *\n&gt;&gt; Allow: /\n&gt;&gt; Disallow: /bible21/\n&gt;&gt; Disallow: /downloads/\n&gt;&gt; Disallow: /stats/\n&gt;&gt; Sitemap: http://nasledovnici.jezise.net/sitemap.xml\n&gt;&gt; Sitemap: http://nasledovnici.jezise.net/ucebnice/sitemap.xml\n&gt;&gt;\n&gt;&gt; Even though the Heritrix is set to classic robot honouring policy, it\n&gt;&gt; crawls content inside the forbidden directories as can be seen from\n&gt;&gt; the log:\n&gt;&gt;\n&gt;&gt; 2011-04-13T09:15:52.303Z   200        663\n&gt;&gt; http://www.jezise.cz/stats/track.php?mode=js E http://www.jezise.cz/\n&gt;&gt; text/javascript #195 20110413091552265+37\n&gt;&gt; sha1:MBPGHNW6I7Z4GXREMWZVLPVVP27NYK6Q - - -\n&gt;&gt;\n&gt;&gt; I could not figure out why is this happening and how it can be solved.\n&gt;&gt; Is it possible that this is some bug?\n&gt;&gt;\n&gt;&gt; I am using Heritrix 1.15.5 on Linux and order.xml is in attachment.\n&gt;&gt;\n&gt;&gt; Thank you.\n&gt;&gt;\n&gt;&gt; Kind regards,\n&gt;&gt; Adam\n&gt;&gt; --\n&gt;&gt; Adam Brokeš\n&gt;&gt; http://www.brokes.net\n&gt;&gt; adam@...\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; ------------------------------------\n&gt;&gt;\n&gt;&gt; Yahoo! Groups Links\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;\n&gt;\n&gt; ------------------------------------\n&gt;\n&gt; Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n\n"}}