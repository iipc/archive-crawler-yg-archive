{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":163406187,"authorName":"kris@archive.org","from":"kris@...","profile":"kristsi25","replyTo":"LIST","senderId":"WWB3HsugQp6E5F5y1IWTUdsJNKn2-0u5pLZdkZBqjHyUMHYwZ7W01MJNpjk35FWxtIQuqjzotQ","spamInfo":{"isSpam":false,"reason":"0"},"subject":"RE: [archive-crawler] Advice needed on how to (properly) structure      new Heritrix modify and delete functionality","postDate":"1153151000","msgId":3064,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDM4OTQuMTMwLjIwOC4xNTIuODAuMTE1MzE1MTAwMC5zcXVpcnJlbEBtYWlsLmFyY2hpdmUub3JnPg=="},"prevInTopic":3063,"nextInTopic":3068,"prevInTime":3063,"nextInTime":3065,"topicId":3063,"numMessagesInTopic":32,"msgSnippet":"Hey Karl, That is a very ambitious project. It would be very interesting if you could share why you want this functionality. ... It occurs to me that it","rawEmail":"Return-Path: &lt;kris@...&gt;\r\nX-Sender: kris@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 77321 invoked from network); 17 Jul 2006 15:43:19 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m27.grp.scd.yahoo.com with QMQP; 17 Jul 2006 15:43:19 -0000\r\nReceived: from unknown (HELO mail.archive.org) (207.241.227.188)\n  by mta5.grp.scd.yahoo.com with SMTP; 17 Jul 2006 15:43:18 -0000\r\nReceived: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id 2BED214156CEB\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Mon, 17 Jul 2006 08:43:21 -0700 (PDT)\r\nReceived: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id 25417-01-43 for &lt;archive-crawler@yahoogroups.com&gt;;\n\tMon, 17 Jul 2006 08:43:20 -0700 (PDT)\r\nReceived: from mail.archive.org (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id 3D5C614156CEA\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Mon, 17 Jul 2006 08:43:20 -0700 (PDT)\r\nReceived: from 130.208.152.80\n        (SquirrelMail authenticated user kris)\n        by mail.archive.org with HTTP;\n        Mon, 17 Jul 2006 08:43:20 -0700 (PDT)\r\nMessage-ID: &lt;3894.130.208.152.80.1153151000.squirrel@...&gt;\r\nDate: Mon, 17 Jul 2006 08:43:20 -0700 (PDT)\r\nTo: archive-crawler@yahoogroups.com\r\nUser-Agent: SquirrelMail/1.4.6\r\nMIME-Version: 1.0\r\nContent-Type: text/plain;charset=iso-8859-1\r\nContent-Transfer-Encoding: 8bit\r\nX-Priority: 3 (Normal)\r\nImportance: Normal\r\nX-Virus-Scanned: Debian amavisd-new at archive.org\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: kris@...\r\nSubject: RE: [archive-crawler] Advice needed on how to (properly) structure \n     new Heritrix modify and delete functionality\r\nX-Yahoo-Group-Post: member; u=163406187; y=tYyF-kDAEXNk1bjaOvnpaUNG1L2AsSZX_wlxhyMjIpnsbwI6\r\nX-Yahoo-Profile: kristsi25\r\n\r\nHey Karl,\n\nThat is a very ambitious project. It would be very interesting if you\ncould share why you want this functionality.\n\n&gt; -----Original Message-----\n&gt; From: archive-crawler@yahoogroups.com\n&gt; [mailto:archive-crawler@yahoogroups.com] On Behalf Of Karl Wright\n&gt; Sent: 17. j�l� 2006 14:10\n&gt; To: archive-crawler@yahoogroups.com\n&gt; Subject: [archive-crawler] Advice needed on how to (properly)\n&gt; structure new Heritrix modify and delete functionality\n&gt;\n&gt; Hi folks,\n&gt;\n&gt; I&#39;m about to go deep on a project to add support for processing\n&gt; modifications and deletions for Heritrix, and I&#39;m looking for input as\n&gt; to how best to proceed on this.\n\nIt occurs to me that it _might_ be best to implement this is a separate\nprogram that is &quot;fed&quot; by Heritrix.\n\nI&#39;m unclear if you want this as a method of improving crawling or you\ndesire to synchronize some local database with what is one the web? If the\nlatter, then using a separate program that is fed Heritrix&#39;s snapshots\nwould be better. If the former then I&#39;d really like to hear what the goal\nis.\n\n&gt;\n&gt; The project basically will involve two stages\n&gt;\n&gt; First, I would be building into the Heritrix infrastructure the means\n&gt; of detecting changes to pages, and also detecting deletions of pages.\n\nThis is largely in place thanks to the AdaptiveRevisitFrontier (which is\nactually a bit of a misnomer since the adaptive part is handled in the\nprocessing chain) and the processor associated with it. Basically the\nARFrontier reissues URIs (with knowledge of their pasts) and the\nChangeEvaluator uses that past knowledge to determine changes (a sudden\n404 would then signal deletion).\n\nOne of the most difficult issue I ran into (and the one that ultimately\nconvinced me that the incremental crawl approach using adaptive tuning\ndoesn&#39;t work) was that detecting changes is bloody hard. At least if you\ncare to differentiate between changes in content and trivial changes in\nlayout (such as random images, irrelevant sections - stock ticker, clock\netc. - and so forth. I&#39;d love to hear your thoughts on that issue.\n\n&gt; These conditions would have to be signaled in some way to all Writers.\n\nURIs always pass through all processor unless their processing is\ninterrupted so once the determination has been made it is simply a matter\nof recording the meta-data in the CrawlURI and having the writers pick up\non that. You&#39;d clearly need your own writers but that was a given in any\ncase.\n\n&gt; Alternatively, since backwards compatibility might be a problem, it&#39;s\n&gt; potentially possible that a new kind of Writer-like module would need\n&gt; to be created. I was going to look at the adaptive frontier to see how\n&gt; exactly it handled changes, if indeed it does anything special at all.\n\nIt issues URIs, the URIs pass through the processing chain where stuff\nhappens and then they return to the frontier with updated state and are\nreinserted. The ARFrontier doesn&#39;t worry to much about &#39;change&#39; as such.\nIt relies on the fact that change can only occur when a URI is being\nprocessed. There are no external &#39;events&#39; that can trigger a change.\n\n&gt; As far as I know, though, there&#39;s no signaling pathway in Heritrix at\n&gt; all for handling deletions, so that would have to be added, hopefully\n&gt; in an approved manner.\n\nNot as such. The CrawlURIs provide a means of carrying information from\none processor to the next and (eventually) to the Frontier. Adding another\nlayer of communications doesn&#39;t seem necessary or wise.\n\n&gt; The second phase would involve marrying the BdbFrontier with the\n&gt; Adaptive frontier. The goal is to set the crawler up so that it\n&gt; dynamically and cost-effectively performs a synchronization over an\n&gt; extended time.\n\nMarrying the BdbFrontier and the ARFrontier isn&#39;t going to happen. You\ncould write something that encapsulated the functionality of both, but it\nwould be an entirely new beast. The BdbFrontier has been written with one\nobjective in mind, efficient snapshot crawling. The ARFrontier was built\naround the idea of incremental crawling, using adaptive strategies to\nreduce workload as you would only crawl URLs when they were likely to have\nchanged. As a result it compromises heavily on efficiency. They queuing\nstructure of the two are similar in concept but their implementations are\nworlds apart as the ARFrontier relies on queues with much richer state due\nto its more complicated crawling strategy.\n\n&gt; I looked at the\n&gt; BdbFrontier and discovered that there was actually not much going on\n&gt; in this module, per-se. In fact, I found that the frontier interface\n&gt; itself is not at all what I expected. Is there any design documents or\n&gt; anything you can throw my way that would help me understand how the\n&gt; BdbFrontier works, and what I might need to do to accomplish my goal?\n\nThe Developers manual has a section on this and is a good place to start\n(even if it is a little light on details). You may also want to give my\nmasters thesis a read (http://vefsofnun.bok.hi.is/upload/3/thesis.pdf). It\ndealt with the ARFrontier. It has a lot of non-relevant stuff and is\nsomewhat out of date but chapter 3.5 talks about Frontiers in general and\n6.2 talks about the ARFrontier.\n\nThe Frontier is the most complicated part of Heritrix. As far as I know,\nonly Gordon and I have attempted to write one of the beasts from scratch.\nThere are some arguments that the Frontier should no be a plug-able module\nat all and in fact the Frontier interface has been anything but stable. I\nsuggest starting by looking at the ARFrontier. Not because it is the\nbetter frontier, but because it has a much cleaner linage. The BdbFrontier\nis broken into several levels (AbstractFrontier extended by\nWorkQueueFrontier extended by the BdbFrontier). The ARFrontier is a\ncleaner implementations simply because it hasn&#39;t been rewritten and\ntweaked multiple times and as such should be easier to understand. Its\nseparation of logic in regards to the work queues is also much clearer\neven if it is less efficient.\n\n- Kris\n\n\n"}}