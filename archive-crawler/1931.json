{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"stack","from":"stack &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"mJncbWp4mtOf-cHrnNgTNl1a6hjIg8OkaXsRRpyyKU2M2TDmxfnMeSmmk2IgjNTGMKHEEKniYAQuElinjslugA","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] JMX importUri not causing more crawling","postDate":"1118288652","msgId":1931,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQyQTdCQjBDLjUwODA3MDRAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDlkMWU0NTI1MDUwNjA4MTgwMTE5NDBmNTY2QG1haWwuZ21haWwuY29tPg==","referencesHeader":"PDlkMWU0NTI1MDUwNjA4MTgwMTE5NDBmNTY2QG1haWwuZ21haWwuY29tPg=="},"prevInTopic":1930,"nextInTopic":1932,"prevInTime":1930,"nextInTime":1932,"topicId":1930,"numMessagesInTopic":7,"msgSnippet":"... And for sure the added URLs are in scope?  (You can enable logging of all rejected on the Postselector -- or if you re using a recent HEAD, on ","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 1107 invoked from network); 9 Jun 2005 03:45:46 -0000\r\nReceived: from unknown (66.218.66.218)\n  by m26.grp.scd.yahoo.com with QMQP; 9 Jun 2005 03:45:46 -0000\r\nReceived: from unknown (HELO dns.duboce.net) (63.203.238.114)\n  by mta3.grp.scd.yahoo.com with SMTP; 9 Jun 2005 03:45:45 -0000\r\nReceived: from [192.168.1.100] ([192.168.1.100])\n\t(authenticated)\n\tby dns-eth1.duboce.net (8.10.2/8.10.2) with ESMTP id j592h6A03388\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Wed, 8 Jun 2005 19:43:08 -0700\r\nMessage-ID: &lt;42A7BB0C.5080704@...&gt;\r\nDate: Wed, 08 Jun 2005 20:44:12 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; PPC Mac OS X Mach-O; en-US; rv:1.7.8) Gecko/20050511\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;9d1e452505060818011940f566@...&gt;\r\nIn-Reply-To: &lt;9d1e452505060818011940f566@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0\r\nFrom: stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] JMX importUri not causing more crawling\r\nX-Yahoo-Group-Post: member; u=168599281; y=iYNOPWKyXxyPyC0y6NPm7NOWljhOqi6hLhQNFYONc6HfX4mkYFwcH0Xm\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\nMatt Ittigson wrote:\n\n&gt; I&#39;m using the importURI JMX call to add sites to a running job.  I&#39;ve\n&gt; wrapped the cmdline-jmxclient in a perl script which depending on the\n&gt; level of activity, adds more URL&#39;s to the job.  The problem is, the\n&gt; threads don&#39;t seem to actually crawl the newly added URL&#39;s.  I&#39;m using\n&gt; the BdbFrontier and PathScrope.  I&#39;m limiting the host-based queue&#39;s\n&gt; to 200 URL&#39;s, and the Frontier queue&#39;s are all exhausted.  But I&#39;m\n&gt; setting the forceFetch to true and I&#39;d be very surprised if every\n&gt; single newly added URL would sort into an existing exhausted queue.\n\nAnd for sure the added URLs are in scope?  (You can enable logging of \nall rejected on the Postselector -- or if you&#39;re using a recent HEAD, on \nLinksScoper).\n\nWhat if you add URLs that have already been crawled (See the \ncrawl.log).   If  you add these w/ forceFetch, are they not being crawled?\n\nTry adding URLs as for-sure in-scope seeds.  Do these get crawled?\n\nLet me know.  This needs to be working for us in short order so if \nyou&#39;re having problems, I&#39;m interested.\n\nThanks for writing the list.\nSt.Ack\n\n&gt;\n&gt; Is there something I can do or someway to reconfigure the crawler so\n&gt; that I can add URL&#39;s to a running job and have them crawled?\n&gt;\n&gt; Thanks in advance.\n&gt;\n&gt; -matt\n&gt;\n&gt; ------------------------------------------------------------------------\n&gt; *Yahoo! Groups Links*\n&gt;\n&gt;     * To visit your group on the web, go to:\n&gt;       http://groups.yahoo.com/group/archive-crawler/\n&gt;        \n&gt;     * To unsubscribe from this group, send an email to:\n&gt;       archive-crawler-unsubscribe@yahoogroups.com\n&gt;       &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;        \n&gt;     * Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;.\n&gt;\n&gt;\n\n\n"}}