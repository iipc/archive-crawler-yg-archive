{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"NKcxcrvZuu1RDnyLRnYXC7LxQ5oow1vEaGv9nYFNKEgUCeTvG7et4ue1FYCeTHWvHzgN1jDbNEHKkZRnvJeHR23wFdKUK7U","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Re: Crawl rate decreasing with time?","postDate":"1311293311","msgId":7219,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRFMjhCRjdGLjEwMTAyMDZAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGowYWRlbys5ZmpoQGVHcm91cHMuY29tPg==","referencesHeader":"PGowYWRlbys5ZmpoQGVHcm91cHMuY29tPg=="},"prevInTopic":7217,"nextInTopic":7223,"prevInTime":7218,"nextInTime":7220,"topicId":7213,"numMessagesInTopic":9,"msgSnippet":"Looks like you re on a 4GB Mac with a 2GB heap, so there shouldn t be a swapping problem. 250 threads may be a lot for a 2GB heap. There are no firm rules, but","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 21942 invoked from network); 22 Jul 2011 00:08:33 -0000\r\nX-Received: from unknown (66.196.94.106)\n  by m11.grp.re1.yahoo.com with QMQP; 22 Jul 2011 00:08:33 -0000\r\nX-Received: from unknown (HELO relay03.pair.com) (209.68.5.17)\n  by mta2.grp.re1.yahoo.com with SMTP; 22 Jul 2011 00:08:32 -0000\r\nX-Received: (qmail 20531 invoked by uid 0); 22 Jul 2011 00:08:31 -0000\r\nX-Received: from 76.218.213.38 (HELO silverbook.local) (76.218.213.38)\n  by relay03.pair.com with SMTP; 22 Jul 2011 00:08:31 -0000\r\nX-pair-Authenticated: 76.218.213.38\r\nMessage-ID: &lt;4E28BF7F.1010206@...&gt;\r\nDate: Thu, 21 Jul 2011 17:08:31 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.6; en-US; rv:1.9.2.18) Gecko/20110616 Thunderbird/3.1.11\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;j0adeo+9fjh@...&gt;\r\nIn-Reply-To: &lt;j0adeo+9fjh@...&gt;\r\nContent-Type: text/plain; charset=windows-1252; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Re: Crawl rate decreasing with time?\r\nX-Yahoo-Group-Post: member; u=137285340; y=Lbj3geWuIx2My9fotKqQXNGBIIKBx3iFUDTii2mJYV1A\r\nX-Yahoo-Profile: gojomo\r\n\r\nLooks like you&#39;re on a 4GB Mac with a 2GB heap, so there shouldn&#39;t be a\nswapping problem.\n\n250 threads may be a lot for a 2GB heap. There are no firm rules, but a \nvery rough rule I&#39;ve used is to take the heap size, deduct the 60% used \nby default by the BerkeleyDB-JE-based structures, then divide the \nremaining value (800MB in your case) by ~5MB/thread to get a plausible \nthread count.\n\n*If* the problem is threads waiting for unresponsive hosts, then \nreducing soTimeout may help a little. The one-line reports on the \nreports page, or the longer &#39;threads report&#39;, may give a hint if this is \nthe block. But you can&#39;t make soTimeout too small, there are real delays \nfor busy networks/server for which you may not want to miss that URL \nentirely. It&#39;s a tradeoff you&#39;ll have to decide.\n\nCarefully watching the crawl and aggressively removing URLs from \nunwanted/unresponsive sites (eg by adding new scope limitations during \nthe crawl) may offer a better response to slowdowns due to unresponsive \nsites.\n\nIf threads spending their time on slow/big resources are an issue, \nreducing the timeout-seconds or maximum size to download settings could \nhelp a little. The threads report and crawl log might indicate if this \nis a contributing factor.\n\nAs a Mac I&#39;m guessing there&#39;s just a single hard drive. That&#39;s going to \ncap performance, with all queueing/lookups/scratch-files/content-writing \ncompeting for the single disk.\n\nWhen the tradeoffs associated with the Bloom option may be right for \nyour project is something you&#39;ll have to weigh.\n\n- Gordon\n\nOn 7/21/11 4:41 PM, helloitsmaxine wrote:\n&gt; I&#39;m referring to what it says on the Activity Monitor, though\n&gt; admittedly I&#39;m not sure what the relevance of it is. Here are\n&gt; screencaps of the console/Activity Monitor (2 panes):\n&gt; http://img39.imageshack.us/img39/2212/ss25h36m.jpg\n&gt; http://img29.imageshack.us/img29/9120/ss25h36mcpu.jpg\n&gt;\n&gt; The swap reported is 4.4gb at this point-about 25h into the\n&gt; crawl...is that a large enough amount to warrant scaling back on\n&gt; heap?\n&gt;\n&gt; The HTTP timeout-seconds value I have now is 1200 (that&#39;s 20\n&gt; mins...seems long?) and the sotimeout-ms is 20,000 (20s, I guess that\n&gt; makes sense). Would it help to reduce both or just the sotimeout? How\n&gt; much of a reduction would you suggest? Could I make it as low as 1\n&gt; second? Or is maybe 5-10 better?\n&gt;\n&gt; Currently it looks like URI&#39;s crawled is still under a million,\n&gt; though I would eventually like to grow it to the tens of\n&gt; millions--would looking into the BloomUriUniqFilter be worth it at\n&gt; this point?\n&gt;\n&gt; Thanks for your suggestions; I really appreciate it!\n&gt;\n&gt; --- In archive-crawler@yahoogroups.com, Gordon Mohr&lt;gojomo@...&gt;\n&gt; wrote:\n&gt;&gt;\n&gt;&gt; What do you mean by &quot;VM size&quot;? (What tool is reporting that\n&gt;&gt; number?)\n&gt;&gt;\n&gt;&gt; It would be very atypical for the heap size or JavaVM process\n&gt;&gt; address space to be 150 gigabytes.\n&gt;&gt;\n&gt;&gt; What is the hardware like? (RAM, CPU, disk count/speed)\n&gt;&gt;\n&gt;&gt; If all the threads are working on something, and the &#39;congestion\n&gt;&gt; ratio&#39; is high, then the problem is not that there&#39;s too little\n&gt;&gt; that&#39;s eligible to crawl politely.\n&gt;&gt;\n&gt;&gt; Some top possibilities:\n&gt;&gt;\n&gt;&gt; � Java process size has grown larger than RAM and excessive\n&gt;&gt; swapping is occurring. Due to Java&#39;s pattern of memory access, you\n&gt;&gt; essentially never want to be using swap. If &#39;top&#39; or &#39;vmstat&#39; show\n&gt;&gt; any swap being used, add RAM or scale back the heap so that it\n&gt;&gt; isn&#39;t.\n&gt;&gt;\n&gt;&gt; � most threads are making fetches against unresponsive sites, which\n&gt;&gt; can take a long time to timeout. Large crawls that hit giant\n&gt;&gt; link-lists to defunct/fake sites can experience this. More threads,\n&gt;&gt; shortening the FetchHTTP soTimeout, and manually pruning the bad\n&gt;&gt; URIs can help.\n&gt;&gt;\n&gt;&gt; � the crawl has grown so large that accesses to the\n&gt;&gt; data-structures which overflow to disk (notably the default\n&gt;&gt; &#39;already-seen&#39; BdbUriUniqFilter) are now dominating its time usage.\n&gt;&gt; On broader and larger crawls -- expected to grow to more than a few\n&gt;&gt; tens of millions of URIs -- you may want to consider the\n&gt;&gt; BloomUriUniqFilter, though it has other RAM costs and imprecision\n&gt;&gt; caveats.\n&gt;&gt;\n&gt;&gt; Hope this helps,\n&gt;&gt;\n&gt;&gt; - Gordon\n&gt;&gt;\n&gt;&gt; On 7/21/11 3:59 PM, helloitsmaxine wrote:\n&gt;&gt;&gt; Some other details I&#39;ve noticed are that according to the\n&gt;&gt;&gt; activity monitor, the VM size is about 150gb, and CPU usage\n&gt;&gt;&gt; during the crawl is typically very low, with over 95% idle.\n&gt;&gt;&gt;\n&gt;&gt;&gt; Is that weird? If there is so much CPU and VM available, would\n&gt;&gt;&gt; it just make sense to keep increasing memory allocation and #\n&gt;&gt;&gt; threads to keep crawl rates up? Anyone have experience with this\n&gt;&gt;&gt; sort of thing?\n&gt;&gt;&gt;\n&gt;&gt;&gt; --- In archive-crawler@yahoogroups.com,\n&gt;&gt;&gt; &quot;helloitsmaxine&quot;&lt;itsmaxine@&gt;   wrote:\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; On my crawls I&#39;ve noticed that they generally have been\n&gt;&gt;&gt;&gt; starting out at pretty good rates, ie. 1500kb/s, but then after\n&gt;&gt;&gt;&gt; a few hours, this goes down to 0-50kb/s and pretty much stays\n&gt;&gt;&gt;&gt; there.\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; After reading about some other people&#39;s same problems I tried a\n&gt;&gt;&gt;&gt; few tweaks: - increasing JVM memory to 1024 - increasing #\n&gt;&gt;&gt;&gt; threads from 50 to 100 - increasing in/out recording buffers\n&gt;&gt;&gt;&gt; However the problem still persists.\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Some information about my crawl is: - using Heritrix 1.4 - the\n&gt;&gt;&gt;&gt; max heap is being used (ie. current and max are the same) - the\n&gt;&gt;&gt;&gt; threads are all pretty much active (99-100 out of 100 active at\n&gt;&gt;&gt;&gt; a time) - very high congestion ratio, (ie. 7000) - so far it\n&gt;&gt;&gt;&gt; has crawled 674003 URI&#39;s in about 20h.\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Does anyone have insight into how I can prevent this problem?\n&gt;&gt;&gt;&gt; I&#39;ve read this:\n&gt;&gt;&gt;&gt; https://webarchive.jira.com/wiki/display/Heritrix/making+a+busy+crawl+go+faster\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;\n&gt;&gt;\n&gt;&gt;&gt;&gt;\nand a few other posts but am not sure what applies to my situation and\n&gt;&gt; what would be the best next steps to take. Or if there&#39;s any other\n&gt;&gt; information that might be helpful let me know!\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Thanks!\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; ------------------------------------\n&gt;&gt;&gt;\n&gt;&gt;&gt; Yahoo! Groups Links\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------\n&gt;\n&gt; Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n\n"}}