{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"9eykaPJpGwjcRC2ZrxOrVA3_zhM2Dwn7i5WnwoYIAc5R6hiDnA7z-OzViOcbeFduKk2zplk4ShlxqG77L-DxEuC_tTIWqvo","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] How can heritrix indicate web page got deleted from crawled website","postDate":"1250204755","msgId":5985,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRBODQ5QzUzLjEwMjAyMDhAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGg2MGd1dCttOTc0QGVHcm91cHMuY29tPg==","referencesHeader":"PGg2MGd1dCttOTc0QGVHcm91cHMuY29tPg=="},"prevInTopic":5980,"nextInTopic":0,"prevInTime":5984,"nextInTime":5986,"topicId":5980,"numMessagesInTopic":2,"msgSnippet":"... Generally, if you repeat a crawl with the same initial setup, but the site has changed so there are no links into the target page, Heritrix will not even","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 54219 invoked from network); 13 Aug 2009 23:07:09 -0000\r\nX-Received: from unknown (98.137.34.44)\n  by m5.grp.re1.yahoo.com with QMQP; 13 Aug 2009 23:07:09 -0000\r\nX-Received: from unknown (HELO relay01.pair.com) (209.68.5.15)\n  by mta1.grp.sp2.yahoo.com with SMTP; 13 Aug 2009 23:07:09 -0000\r\nX-Received: (qmail 64537 invoked from network); 13 Aug 2009 23:05:56 -0000\r\nX-Received: from 67.188.14.54 (HELO ?192.168.1.114?) (67.188.14.54)\n  by relay01.pair.com with SMTP; 13 Aug 2009 23:05:56 -0000\r\nX-pair-Authenticated: 67.188.14.54\r\nMessage-ID: &lt;4A849C53.1020208@...&gt;\r\nDate: Thu, 13 Aug 2009 16:05:55 -0700\r\nUser-Agent: Thunderbird 2.0.0.22 (Windows/20090605)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;h60gut+m974@...&gt;\r\nIn-Reply-To: &lt;h60gut+m974@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] How can heritrix indicate web page got deleted\n from crawled website\r\nX-Yahoo-Group-Post: member; u=137285340; y=Pziy3SoMip4l2iT53JHt44fQ3g1SkLqJ9eTSHnMBOKyB\r\nX-Yahoo-Profile: gojomo\r\n\r\ner.tarun9986 wrote:\n&gt; Hi all,\n&gt; \n&gt; I&#39;m quite new to this heritrix.\n&gt; Could u plz help me for specified problem?\n&gt; \n&gt; Consider, i have crawled one website and i got its web pages,\n&gt; if we take the case - crawled website removed one page(abc.html).\n&gt; After this, if i crawl this site again, then obviously removed page(abc.html) would not come by crawler, but my question is whether heritrix would somehow indicate us that this page(abc.html) was tried to fetch but it&#39;s been removed from website.\n&gt; \n&gt; Is it possible in heritrix, if yes then plz provide &quot;settings&quot; option to achieve this.\n\nGenerally, if you repeat a crawl with the same initial setup, but the \nsite has changed so there are no links into the target page, Heritrix \nwill not even try to fetch it.\n\nThus the transcripts of retrieved content on the second crawl express no \nopinion either way about whether the page exists or not; only that it \nwas not even attempted.\n\nYou could feed all URIs from the first crawl into the second crawl to \nforce them all to be reattempted. In such a case, if the page is gone, \nthe website will return an error -- usually but not always an HTTP &#39;404&#39; \nresponse code -- in response to the Heritrix fetch.\n\nWhether or not this is &#39;indicated&#39; depends on how you&#39;re viewing the \ndata. You&#39;ll see the error in the logs; the error page will be in the \nresponse transcripts ((W)ARC files, usually).\n\nHowever, if browsing the content (as for example in a &#39;Wayback&#39; \ninstallation run from the crawled content), usually 404s are elided from \nindexes or displayed results for index compactness. The only \n&#39;indication&#39; a page went away is indirect: there will be earlier dates, \nbut no later dates. An expert Wayback configurer/customizer could \ninclude 404s, and indicate them differently in date-results lists (for \nexample, with different color/rendering).\n\n- Gordon @ IA\n\n"}}