{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"Michael Stack","from":"Michael Stack &lt;stack@...&gt;","replyTo":"LIST","senderId":"pB5UwvBDd_gFvvhvr8qg0AjZoTfEo7ePmC1s2bmY5xyEajjmsMKPmw7XRllSR7Z3aJ2itaT2h4jBoLAvm_uEKxLzdufNc1_G","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Re: submit batch jobs","postDate":"1084298801","msgId":381,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQwQTExNjMxLjMwNjA2MDhAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGM3cjN1NCs4YWZzQGVHcm91cHMuY29tPg==","referencesHeader":"PGM3cjN1NCs4YWZzQGVHcm91cHMuY29tPg=="},"prevInTopic":380,"nextInTopic":386,"prevInTime":380,"nextInTime":382,"topicId":372,"numMessagesInTopic":10,"msgSnippet":"... Doing the latter sounds more manageable. See http://crawler.archive.org/articles/developer_manual.html#arcreader for a few notes on reading arcs. St.Ack ","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 60921 invoked from network); 11 May 2004 18:14:15 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m14.grp.scd.yahoo.com with QMQP; 11 May 2004 18:14:15 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (209.237.232.202)\n  by mta6.grp.scd.yahoo.com with SMTP; 11 May 2004 18:14:14 -0000\r\nReceived: (qmail 26866 invoked by uid 100); 11 May 2004 18:06:47 -0000\r\nReceived: from b116-dyn-60.archive.org (HELO archive.org) (stack@...@209.237.240.60)\n  by mail-dev.archive.org with SMTP; 11 May 2004 18:06:47 -0000\r\nMessage-ID: &lt;40A11631.3060608@...&gt;\r\nDate: Tue, 11 May 2004 11:06:41 -0700\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.5) Gecko/20031107 Debian/1.5-3\r\nX-Accept-Language: en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;c7r3u4+8afs@...&gt;\r\nIn-Reply-To: &lt;c7r3u4+8afs@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=0.5 required=6.0 tests=AWL,CLICK_BELOW autolearn=ham \n\tversion=2.63\r\nX-eGroups-Remote-IP: 209.237.232.202\r\nFrom: Michael Stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] Re: submit batch jobs\r\nX-Yahoo-Group-Post: member; u=168599281\r\n\r\npenguinoamante2 wrote:\n\n&gt;Yes you guys are right.  When I restart heritrix the pending jobs on\n&gt;disk get loaded into the crawler.\n&gt;\n&gt;Thanks for the tips.  \n&gt;\n&gt;I should be asking weather this is the feature to have or if there is\n&gt;a better way to do what I want to do.  \n&gt;\n&gt;I want to watch a list of customers sites to make sure that they\n&gt;continue to sell what they say they are currently selling, that their\n&gt;contact info is in the USA, and that they aren&#39;t doing anything illegal.\n&gt;\n&gt;It seems like launching a batch of jobs one for each customer would do\n&gt;the job. However heritrix could just crawl all the customer URIs in\n&gt;one job and then another program could split up the data from the ARC\n&gt;file into individual customers.\n&gt;  \n&gt;\n\nDoing the latter sounds more manageable.\n\nSee http://crawler.archive.org/articles/developer_manual.html#arcreader \nfor a few notes on reading arcs.\n\nSt.Ack\n\nP.S. Related, currently there is no means of stopping the crawler from \nthe command line.\n\n\n&gt;--- In archive-crawler@yahoogroups.com, &quot;Kristinn Sigurdsson&quot; \n&gt;\n&gt;&lt;kris@a...&gt; wrote:\n&gt;  \n&gt;\n&gt;&gt;Michael is correct. Jobs are only read from disk during program\n&gt;&gt;    \n&gt;&gt;\n&gt;startup. At\n&gt;  \n&gt;\n&gt;&gt;other times in memory chaching is used.\n&gt;&gt;\n&gt;&gt; \n&gt;&gt;\n&gt;&gt;A suitable workaround might by to create a page that accepts (via\n&gt;&gt;    \n&gt;&gt;\n&gt;GET) the\n&gt;  \n&gt;\n&gt;&gt;parameters needed to construct a new job (this might only be the\n&gt;&gt;    \n&gt;&gt;\n&gt;crawl order\n&gt;  \n&gt;\n&gt;&gt;xml file�s name) and creates the new job based on it.\n&gt;&gt;\n&gt;&gt; \n&gt;&gt;\n&gt;&gt;In fact if you go that route you could not write the XML to it&#39;s\n&gt;&gt;    \n&gt;&gt;\n&gt;intended\n&gt;  \n&gt;\n&gt;&gt;job directory. Instead you would save it somewhere else and create\n&gt;&gt;    \n&gt;&gt;\n&gt;the new\n&gt;  \n&gt;\n&gt;&gt;job BASED ON your order. This mirrors how jobs are generally created in\n&gt;&gt;Heritrix.\n&gt;&gt;\n&gt;&gt; \n&gt;&gt;\n&gt;&gt;I believe that ...webapps/admin/jobs/new.jsp would be a good\n&gt;&gt;    \n&gt;&gt;\n&gt;starting point\n&gt;  \n&gt;\n&gt;&gt;for someone intent on writing this add on :-)\n&gt;&gt;\n&gt;&gt; \n&gt;&gt;\n&gt;&gt;- Kris\n&gt;&gt;\n&gt;&gt; \n&gt;&gt;\n&gt;&gt; \n&gt;&gt;\n&gt;&gt;-----Original Message-----\n&gt;&gt;From: Michael Stack [mailto:stack@a...] \n&gt;&gt;Sent: 11. ma� 2004 16:57\n&gt;&gt;To: archive-crawler@yahoogroups.com\n&gt;&gt;Subject: Re: [archive-crawler] Re: submit batch jobs\n&gt;&gt;\n&gt;&gt; \n&gt;&gt;\n&gt;&gt;penguinoamante2 wrote:\n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;&gt;&gt;First try was not successful.  I create a directory called batchjob in\n&gt;&gt;&gt;the jobs directoy which contains three files: batchjob.job \n&gt;&gt;&gt;job-batchjob.xml and seeds-batchjob.txt.\n&gt;&gt;&gt;\n&gt;&gt;&gt;batchjob.job contains\n&gt;&gt;&gt;20040511155115186\n&gt;&gt;&gt;batchjob\n&gt;&gt;&gt;Pending\n&gt;&gt;&gt;false\n&gt;&gt;&gt;false\n&gt;&gt;&gt;2\n&gt;&gt;&gt;/opt/src/heritrix-0.6.0/jobs/batchjob/job-batchjob.xml\n&gt;&gt;&gt;\n&gt;&gt;&gt;job-batchjob.xml contains a ton of xml I think I got the important\n&gt;&gt;&gt;tags such as\n&gt;&gt;&gt;&lt;name&gt;batchjob&lt;/name&gt;\n&gt;&gt;&gt;&lt;string name=&quot;seedsfile&quot;&gt;seeds-batchjob.txt&lt;/string&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;seeds-batchjob has the right seeds.\n&gt;&gt;&gt;\n&gt;&gt;&gt;After doing this I would expect the job to at least show up as\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;Pending.  \n&gt;  \n&gt;\n&gt;&gt;&gt; \n&gt;&gt;&gt;\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;The code that reads the directory is only run on application startup it \n&gt;&gt;looks like.  Restart.  Does it work?\n&gt;&gt;\n&gt;&gt;Here is the pertinent code:\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;http://crawler.archive.org/xref-test/org/archive/crawler/admin/CrawlJobHand=\n&gt;l\n&gt;  \n&gt;\n&gt;&gt;er.html#211\n&gt;&gt;\n&gt;&gt;St.Ack\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;--- In archive-crawler@yahoogroups.com, Michael Stack &lt;stack@a...&gt;\n&gt;&gt;&gt;wrote:\n&gt;&gt;&gt; \n&gt;&gt;&gt;\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;penguinoamante2 wrote:\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;   \n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;        \n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;What are the best practices for submitting a batch of jobs.  I\n&gt;&gt;&gt;&gt;&gt;     \n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;          \n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;have a\n&gt;&gt;&gt; \n&gt;&gt;&gt;\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;list of fqdn&#39;s in a database and I want heritrix to consider each\n&gt;&gt;&gt;&gt;&gt;     \n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;          \n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;one\n&gt;&gt;&gt; \n&gt;&gt;&gt;\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;a seperate job.  The plan so far is to write a script to populate\n&gt;&gt;&gt;&gt;&gt;     \n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;          \n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;the\n&gt;&gt;&gt; \n&gt;&gt;&gt;\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;jobs directory with the right info.\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;Is this the right way to do it?\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;     \n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;          \n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;That sounds right.\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;Make sure the crawler is the &#39;Crawling state&#39; so that it&#39;ll just\n&gt;&gt;&gt;&gt;   \n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;        \n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;start \n&gt;&gt;&gt; \n&gt;&gt;&gt;\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;the next job soon as its finished the current job.\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;Yours,\n&gt;&gt;&gt;&gt;St.Ack\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;   \n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;        \n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;Thanks,\n&gt;&gt;&gt;&gt;&gt;Sunny\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;Yahoo! Groups Links\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;     \n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;          \n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;Yahoo! Groups Links\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; \n&gt;&gt;&gt;\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;Yahoo! Groups Sponsor\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;ADVERTISEMENT\n&gt;&gt; \n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;&lt;http://rd.yahoo.com/SIG=129q30o18/M=295196.4901138.6071305.3001176/D=group=\n&gt;s\n&gt;  \n&gt;\n&gt;/S=1705004924:HM/EXP=1084381409/A=2128215/R=0/SIG=10se96mf6/*http:/companio=\n&gt;n\n&gt;  \n&gt;\n&gt;&gt;.yahoo.com&gt; click here\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; \n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;&lt;http://us.adserver.yahoo.com/l?M=295196.4901138.6071305.3001176/D=groups/S=\n&gt;=\n&gt;  \n&gt;\n&gt;&gt;:HM/A=2128215/rand=708464738&gt; \n&gt;&gt;\n&gt;&gt; \n&gt;&gt;\n&gt;&gt;  _____  \n&gt;&gt;\n&gt;&gt;Yahoo! Groups Links\n&gt;&gt;\n&gt;&gt;*\tTo visit your group on the web, go to:\n&gt;&gt;http://groups.yahoo.com/group/archive-crawler/\n&gt;&gt;  \n&gt;&gt;*\tTo unsubscribe from this group, send an email to:\n&gt;&gt;archive-crawler-unsubscribe@yahoogroups.com\n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;&lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt; \n&gt;  \n&gt;\n&gt;&gt;  \n&gt;&gt;*\tYour use of Yahoo! Groups is subject to the Yahoo! Terms of Service\n&gt;&gt;&lt;http://docs.yahoo.com/info/terms/&gt; .\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; \n&gt;Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n&gt; \n&gt;\n&gt;  \n&gt;\n\n\n\n"}}