{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":165458231,"authorName":"Bjarne Andersen","from":"Bjarne Andersen &lt;bja@...&gt;","profile":"bjarne_dk2000","replyTo":"LIST","senderId":"G48YQTsH9mWiSSd_9HBq8kg0O1eUrffZLPumRMRBPDo-Ykc0D4-hfaSXPMA1Y7MqgFBNWixngw_FXjThgghWmnDZCWU5e6tNRV-dBOM6qJI","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Issue with the max-retries option under BdbFrontier","postDate":"1186396979","msgId":4490,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ2QjZGQjMzLjQwNDA5MDlAc3RhdHNiaWJsaW90ZWtldC5kaz4=","inReplyToHeader":"PDQ2OTIzMEQ5LjIwOTAwMDhAYXJjaGl2ZS5vcmc+","referencesHeader":"PGY2dDNrcytiZTduQGVHcm91cHMuY29tPiA8NDY5MjFFNEUuODA5MDAwNEBzdGF0c2JpYmxpb3Rla2V0LmRrPiA8NDY5MjMwRDkuMjA5MDAwOEBhcmNoaXZlLm9yZz4="},"prevInTopic":4473,"nextInTopic":0,"prevInTime":4489,"nextInTime":4491,"topicId":4419,"numMessagesInTopic":7,"msgSnippet":"OK - I agree - this is not a bug. The manual should though mention that the minimum setting for max-retries should be 3 best Bjarne ... -- Bjarne Andersen ","rawEmail":"Return-Path: &lt;bja@...&gt;\r\nX-Sender: bja@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 78077 invoked from network); 6 Aug 2007 10:43:06 -0000\r\nReceived: from unknown (66.218.66.70)\n  by m57.grp.scd.yahoo.com with QMQP; 6 Aug 2007 10:43:06 -0000\r\nReceived: from unknown (HELO luna.statsbiblioteket.dk) (130.225.24.87)\n  by mta12.grp.scd.yahoo.com with SMTP; 6 Aug 2007 10:43:04 -0000\r\nReceived: from [130.225.24.216] (pc975.sb.statsbiblioteket.dk [130.225.24.216])\n by luna.statsbiblioteket.dk\n (iPlanet Messaging Server 5.2 HotFix 1.16 (built May 14 2003))\n with ESMTP id &lt;0JMC006EELRN1D@...&gt; for\n archive-crawler@yahoogroups.com; Mon, 06 Aug 2007 12:43:00 +0200 (MEST)\r\nDate: Mon, 06 Aug 2007 12:42:59 +0200\r\nIn-reply-to: &lt;469230D9.2090008@...&gt;\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-id: &lt;46B6FB33.4040909@...&gt;\r\nOrganization: Statsbiblioteket\r\nMIME-version: 1.0\r\nContent-type: multipart/mixed; boundary=&quot;Boundary_(ID_ZChelhpYF1AUJTdjd33/LQ)&quot;\r\nX-Accept-Language: en-us, en\r\nUser-Agent: Mozilla Thunderbird 1.0 (X11/20041206)\r\nReferences: &lt;f6t3ks+be7n@...&gt; &lt;46921E4E.8090004@...&gt;\n &lt;469230D9.2090008@...&gt;\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: Bjarne Andersen &lt;bja@...&gt;\r\nSubject: Re: [archive-crawler] Issue with the max-retries option under\n BdbFrontier\r\nX-Yahoo-Group-Post: member; u=165458231; y=V66Kk19grTpsHtK9yOwhFMxe5vknSGzzQSNfk1f5M33Yv2tk_gLEnQ\r\nX-Yahoo-Profile: bjarne_dk2000\r\n\r\n\r\n--Boundary_(ID_ZChelhpYF1AUJTdjd33/LQ)\r\nContent-type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-transfer-encoding: 8BIT\r\n\r\nOK - I agree - this is not a bug. The manual should though mention that the minimum setting for max-retries should be 3\n\nbest\nBjarne\n\nIgor Ranitovic wrote:\n&gt; \n&gt; \n&gt; Notice in crawl.log that every seed has at least 3 retries (3t in\n&gt; annotations). Every time an URI is deferred, the count of retries goes\n&gt; up. Seed will be deferred at least twice because of missing\n&gt; prerequisites (dns and robots.txt). Later in the crawl you will have\n&gt; some other URIs being deferred because of prerequisites but that depends\n&gt; of your configuration of dns and robots.txt lookups.\n&gt; \n&gt; I would not consider this a bug but that is just me. If you have\n&gt; different opinion please let u know. BTW, I am not sure if it is easy to\n&gt; change prerequisite defers not to count against max retries count.\n&gt; \n&gt; Take care,\n&gt; i.\n&gt; \n&gt; Bjarne Andersen wrote:\n&gt;  &gt; I&#39;ve had that problem as well - it seems the crawler won&#39;t crawl with \n&gt; a setting for max-retries lower that 3. Could be a bug?\n&gt;  &gt;\n&gt;  &gt; best\n&gt;  &gt;\n&gt; \n&gt; \n\n-- \nBjarne Andersen\nFunktionsansvarlig - Digitale Ressourcer\n\nSTATSBIBLIOTEKET\nUniversitetsparken\n8000 ï¿½rhus C\nTlf. 89462165 - Mobil 25662353\nCVR/SE 10100682 - EAN 5798000791084\nhttp://statsbiblioteket.dk\n\r\n--Boundary_(ID_ZChelhpYF1AUJTdjd33/LQ)\r\nContent-type: text/x-vcard; charset=utf-8; name=bja.vcf\r\nContent-disposition: attachment; filename=bja.vcf\r\n\r\n[ Attachment content not displayed ]\r\n--Boundary_(ID_ZChelhpYF1AUJTdjd33/LQ)--\r\n\n"}}