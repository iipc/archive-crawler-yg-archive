{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr (Internet Archive)","from":"&quot;Gordon Mohr (Internet Archive)&quot; &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"SlFFUUEcHyV8DDw_xA_y-FKaD32RUgG9FRurBbvhlBfbSw77QDQhTW9QygLnHIjs-pfXBAJICW6y_gc9K7sY_q7zgCAy8YcDy9efLBJotBWRA2dsSKUdhBHfhxc","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] RFE: New queue assignment policy","postDate":"1108427395","msgId":1559,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQyMTE0MjgzLjgwMjA4MDNAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDIwMDUwMjE0MTQxNC41MDM0OS5jay1oZXJpdHJpeEBuZXdzY2x1Yi5kZT4=","referencesHeader":"PDIwMDUwMjE0MTQxNC41MDM0OS5jay1oZXJpdHJpeEBuZXdzY2x1Yi5kZT4="},"prevInTopic":1558,"nextInTopic":1566,"prevInTime":1558,"nextInTime":1560,"topicId":1545,"numMessagesInTopic":13,"msgSnippet":"Christian, Thanks for this contribution! This is a mode of frontier operation we d like to enable. It hasn t been a priority yet because most of our internal","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 11089 invoked from network); 15 Feb 2005 00:30:00 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m18.grp.scd.yahoo.com with QMQP; 15 Feb 2005 00:29:59 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (207.241.224.172)\n  by mta5.grp.scd.yahoo.com with SMTP; 15 Feb 2005 00:29:59 -0000\r\nReceived: (qmail 30312 invoked by uid 100); 15 Feb 2005 00:13:39 -0000\r\nReceived: from b116-dyn-239.archive.org (HELO ?207.241.238.239?) (gojomo@...@207.241.238.239)\n  by mail-dev.archive.org with SMTP; 15 Feb 2005 00:13:39 -0000\r\nMessage-ID: &lt;42114283.8020803@...&gt;\r\nDate: Mon, 14 Feb 2005 16:29:55 -0800\r\nUser-Agent: Mozilla Thunderbird 1.0 (X11/20041206)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;200502141414.50349.ck-heritrix@...&gt;\r\nIn-Reply-To: &lt;200502141414.50349.ck-heritrix@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=0.1 required=6.5 tests=AWL autolearn=no version=2.63\r\nX-eGroups-Remote-IP: 207.241.224.172\r\nFrom: &quot;Gordon Mohr (Internet Archive)&quot; &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] RFE: New queue assignment policy\r\nX-Yahoo-Group-Post: member; u=137285340\r\nX-Yahoo-Profile: gojomo\r\n\r\nChristian,\n\nThanks for this contribution! This is a mode of frontier operation we&#39;d like\nto enable.\n\nIt hasn&#39;t been a priority yet because most of our internal crawls need\nvery host-centric behavior, and thus host-centric queues.\n\nThere could be some gotchas with this approach, until other behaviors are\nalso updated.\n\nIn particular, certain errors, like connection-refused errors, are\ncurrently handled by &#39;snoozing&#39; the affected queue for a medium-length\nperiod (~15 minutes), leaving the problem URL at the top of the queue\nfor retry.\n\nWith host-based queues (hostname or IP), this makes sense: you don&#39;t need to\ntry any other URLs on the same host until it becomes responsive again; you\ndon&#39;t want transient connection problems to disturb your preferred within-the-\nhost order-of-visitation.\n\nWith composite queues, however, many other perfectly responsive hosts could\nbe stuck &quot;behind&quot; the one problem URL.\n\nA short-term workaround could be to reduce the number of retries, and the\nretry-delay, so that a problem URL doesn&#39;t hold up much else for too long.\n(Retries should be at least 3 because internally an URL coming up for fetch\nwhen the DNS and robots information isn&#39;t available counts as a try.)\n\nStill, however, a broken site with a lot of URLs in the shared queue could\nhold up your progress.\n\nAnother solution could be to note problem hosts and shunt URLs from them off\nto a holding/scheduling queue, or simply fast-fail such URLs (if that&#39;s acceptable\nfor a given broad crawl, because you&#39;re not aiming for precision and/or know\nyou&#39;ll be recrawling soon).\n\nWe are working on making the host-centric queues approach memory-efficient,\nmaking only a small number of &#39;active&#39; queues consume main memory, with\nan arbitrary number of &#39;inactive&#39; queues taking turns rotating into &#39;active&#39;\nmode. (Retaining host-centric queues should also improve alreadySeen\nperformance, by making most tests highly correlated with other recent\ntests, and thus in the BDB cache.)\n\nWe plan to complete this work in March, allowing arbitrarily-large\ncrawls to be run, if you provide sufficient disk space (and have sufficient\npatience, because at least initially the scaling will come at a cost in\nspeed).\n\n- Gordon @ IA\n\n\nChristian Kohlschuetter wrote:\n&gt; Hi,\n&gt; \n&gt; here&#39;s another feature which I would like to contribute.\n&gt; \n&gt; Currently, I am performing broad crawls using BroadScope/BdbFrontier. However, \n&gt; due to the number of host- or IP-keyed queues, an OutOfMemoryError occurs \n&gt; very quickly after starting the crawl. One reason for this is the RAM-based \n&gt; bookkeeping of subqueues -- the more queues, the more heap.\n&gt; \n&gt; I have evaded this by writing a BucketQueueAssignmentPolicy class, which \n&gt; produces a _fixed_ number of subqueues (&quot;buckets&quot;), not one per host or per \n&gt; IP. The queue key is computed by hashing the hostname (or the IP, if \n&gt; available) modulo N (a fixed number, such as 1000).\n&gt; \n&gt; This way, I was able to increase the number of fetched pages from ca. 400,000 \n&gt; to 1,000,000. For some other reason, I still get OOMEs, but I think that is \n&gt; caused by a different problem -- the number of queues did not grow over the \n&gt; specified limit.\n&gt; \n&gt; Furthermore, I have modified AbstractFrontier to be able to choose arbitrary \n&gt; queue assignment policies and replaced the current &quot;ip-politness&quot; option by a \n&gt; selectbox.\n&gt; \n&gt; The patch against CVS HEAD is attached.\n&gt; \n&gt; Greetings,\n&gt; \n&gt; \n&gt; ------------------------------------------------------------------------\n&gt; \n&gt; Index: AbstractFrontier.java\n&gt; ===================================================================\n&gt; RCS file: /cvsroot/archive-crawler/ArchiveOpenCrawler/src/java/org/archive/crawler/frontier/AbstractFrontier.java,v\n&gt; retrieving revision 1.25\n&gt; diff -u -r1.25 AbstractFrontier.java\n&gt; --- AbstractFrontier.java\t1 Feb 2005 18:05:42 -0000\t1.25\n&gt; +++ AbstractFrontier.java\t14 Feb 2005 12:57:29 -0000\n&gt; @@ -111,10 +111,13 @@\n&gt;      public final static String ATTR_MAX_RETRIES = &quot;max-retries&quot;;\n&gt;      protected final static Integer DEFAULT_MAX_RETRIES = new Integer(30);\n&gt;  \n&gt; -    /** whether to reassign URIs to IP-address based queues when IP known */\n&gt; -    public final static String ATTR_IP_POLITENESS = &quot;ip-politeness&quot;;\n&gt; -    // TODO: change default to true once well-tested\n&gt; -    protected final static Boolean DEFAULT_IP_POLITENESS = new Boolean(false); \n&gt; +    public final static String ATTR_QUEUE_ASSIGNMENT_POLICY = &quot;queue-assignment-policy&quot;;\n&gt; +    private final static String[] AVAILABLE_QUEUE_ASSIGNMENT_POLICIES = new String[] {\n&gt; +        HostnameQueueAssignmentPolicy.class.getName(),\n&gt; +        IPQueueAssignmentPolicy.class.getName(),\n&gt; +        BucketQueueAssignmentPolicy.class.getName()\n&gt; +    };\n&gt; +    private final static String DEFAULT_QUEUE_ASSIGNMENT_POLICY = AVAILABLE_QUEUE_ASSIGNMENT_POLICIES[0];\n&gt;  \n&gt;      /** queue assignment to force onto CrawlURIs; intended to be overridden */\n&gt;      public final static String ATTR_FORCE_QUEUE = &quot;force-queue-assignment&quot;;\n&gt; @@ -202,11 +205,9 @@\n&gt;              &quot;limitation.&quot;,\n&gt;              DEFAULT_MAX_HOST_BANDWIDTH_USAGE));\n&gt;          t.setExpertSetting(true);\n&gt; -        t = addElementToDefinition(new SimpleType(ATTR_IP_POLITENESS,\n&gt; -                &quot;Whether to assign URIs to IP-address based queues &quot;+\n&gt; -                &quot;when possible, to remain polite on a per-IP-address &quot;+\n&gt; -                &quot;basis.&quot;,\n&gt; -                DEFAULT_IP_POLITENESS));\n&gt; +        addElementToDefinition(new SimpleType(ATTR_QUEUE_ASSIGNMENT_POLICY,\n&gt; +            &quot;Defines how to assign URIs to queues.&quot;, DEFAULT_QUEUE_ASSIGNMENT_POLICY,\n&gt; +            AVAILABLE_QUEUE_ASSIGNMENT_POLICIES));\n&gt;          t.setExpertSetting(true);\n&gt;          t.setOverrideable(false);\n&gt;          t = addElementToDefinition(\n&gt; @@ -259,10 +260,16 @@\n&gt;              String logsPath = logsDisk.getAbsolutePath() + File.separatorChar;\n&gt;              this.recover = new RecoveryJournal(logsPath, LOGNAME_RECOVER);\n&gt;          }\n&gt; -        if(((Boolean)getUncheckedAttribute(null,ATTR_IP_POLITENESS)).booleanValue()) {\n&gt; -            queueAssignmentPolicy = new IPQueueAssignmentPolicy();\n&gt; -        } else {\n&gt; -            queueAssignmentPolicy = new HostnameQueueAssignmentPolicy();\n&gt; +        try {\n&gt; +            final Class qapClass = Class\n&gt; +                .forName((String) getUncheckedAttribute(null,\n&gt; +                    ATTR_QUEUE_ASSIGNMENT_POLICY));\n&gt; +\n&gt; +            queueAssignmentPolicy = (QueueAssignmentPolicy) qapClass\n&gt; +                .newInstance();\n&gt; +        } catch (Exception e) {\n&gt; +            logger.log(Level.SEVERE, &quot;Bad queue assignment policy class&quot;, e);\n&gt; +            throw new FatalConfigurationException(e.getMessage());\n&gt;          }\n&gt;      }\n&gt;      \n&gt; Index: BucketQueueAssignmentPolicy.java\n&gt; ===================================================================\n&gt; RCS file: BucketQueueAssignmentPolicy.java\n&gt; diff -N BucketQueueAssignmentPolicy.java\n&gt; --- /dev/null\t1 Jan 1970 00:00:00 -0000\n&gt; +++ BucketQueueAssignmentPolicy.java\t1 Jan 1970 00:00:00 -0000\n&gt; @@ -0,0 +1,30 @@\n&gt; +package org.archive.crawler.frontier;\n&gt; +\n&gt; +import org.archive.crawler.datamodel.CrawlHost;\n&gt; +import org.archive.crawler.datamodel.CrawlURI;\n&gt; +import org.archive.crawler.framework.CrawlController;\n&gt; +\n&gt; +/**\n&gt; +* Uses the target IPs as basis for queue-assignment,\n&gt; +* distributing them over a fixed number of sub-queues.\n&gt; +* \n&gt; +* @author Christian Kohlschuetter\n&gt; +*/\n&gt; +public class BucketQueueAssignmentPolicy extends HostnameQueueAssignmentPolicy {\n&gt; +   private static final int DEFAULT_QUEUES_NOIP = 1000;\n&gt; +   private static final int DEFAULT_QUEUES_HOSTS = 1000;\n&gt; +\n&gt; +   public String getClassKey(CrawlController controller, CrawlURI curi) {\n&gt; +       CrawlHost host = controller.getServerCache().getHostFor(curi);\n&gt; +       if(host == null) {\n&gt; +           return &quot;NO-HOST&quot;;\n&gt; +       } else if(host.getIP() == null) {\n&gt; +           return &quot;NO-IP-&quot;.concat(Integer.toString(Math.abs(host.getHostName()\n&gt; +               .hashCode())\n&gt; +               % DEFAULT_QUEUES_NOIP));\n&gt; +       } else {\n&gt; +           return Integer.toString(Math.abs(host.getIP().hashCode())\n&gt; +           % DEFAULT_QUEUES_HOSTS);\n&gt; +       }\n&gt; +   }\n&gt; +}\n\n\n"}}