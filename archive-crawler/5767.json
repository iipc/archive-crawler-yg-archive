{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"uVWQRU7m2qpFP5hp_GThNXBfuifh5KINOEHXw22pAUAIFGzzDOZFvNK_ClJjSy5RQPtVTkrf__rVb9E7lQozf2UirZsKOdA","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] more re: repeated crawl failures","postDate":"1239124695","msgId":5767,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ5REI4QUQ3LjgwNjAxMDlAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGdyZnNvMStsamwxQGVHcm91cHMuY29tPg==","referencesHeader":"PGdyZnNvMStsamwxQGVHcm91cHMuY29tPg=="},"prevInTopic":5766,"nextInTopic":0,"prevInTime":5766,"nextInTime":5768,"topicId":5766,"numMessagesInTopic":2,"msgSnippet":"Did you launch your all defaults crawl by starting from the bundled, never-edited default profile? Have you tried Sun s JDK? Is there anything in","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 61378 invoked from network); 7 Apr 2009 17:18:20 -0000\r\nX-Received: from unknown (98.137.34.44)\n  by 98.137.34.37 with QMQP; 7 Apr 2009 17:18:20 -0000\r\nX-Received: from unknown (HELO relay01.pair.com) (209.68.5.15)\n  by mta1.grp.sp2.yahoo.com with SMTP; 7 Apr 2009 17:18:19 -0000\r\nX-Received: (qmail 46375 invoked from network); 7 Apr 2009 17:18:14 -0000\r\nX-Received: from 70.137.147.22 (HELO ?10.0.13.7?) (70.137.147.22)\n  by relay01.pair.com with SMTP; 7 Apr 2009 17:18:14 -0000\r\nX-pair-Authenticated: 70.137.147.22\r\nMessage-ID: &lt;49DB8AD7.8060109@...&gt;\r\nDate: Tue, 07 Apr 2009 10:18:15 -0700\r\nUser-Agent: Thunderbird 2.0.0.21 (Windows/20090302)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;grfso1+ljl1@...&gt;\r\nIn-Reply-To: &lt;grfso1+ljl1@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] more re: repeated crawl failures\r\nX-Yahoo-Group-Post: member; u=137285340; y=plzpFPwvYnI02Bg4-Ip5okY-t2NGF4mivd_ZVThU1y5U\r\nX-Yahoo-Profile: gojomo\r\n\r\nDid you launch your &#39;all defaults&#39; crawl by starting from the bundled, \nnever-edited &#39;default&#39; profile?\n\nHave you tried Sun&#39;s JDK?\n\nIs there anything in heritrix_out.log, or any &#39;alerts&#39; in the web UI?\n\nIf checking those doesn&#39;t offer clues, you could forward your job&#39;s \norder.xml for outside confirmation that it still has the \ndefault/necessary basics.\n\n- Gordon @ IA\n\nbowser.richard wrote:\n&gt; Thanks so much everyone, for responding.  I&#39;m delighted to get such helpful feedback, especially concerning the preprocessor PreconditionEnforcer.  I must admit that I had totally failed to report that all this started when I did my initial crawls using all defaults (except the user-agent and from fields, which I set legally and appropriately.)  I just repeated this original all-default crawl (with seed http://www.cs.nmt.edu), and saw it run to completion in 52 ms.  It SEEMED an identical failure.\n&gt; \n&gt; Now I&#39;m not completely sure where to find what relevant data, but once again 0 sites were visited & 0 downloaded.  I started with the crawl-manifest and found a good list of all crawl activities.  The crawl.log was empty, the runtime-errors.log was empty, the local-errors log was empty, the uri-errors.log was empty, the progress-statics log showed 0 discovered, 0 queued, 0 downloaded, a doc/s of 0(0), a KB/s (ag) of 0(0), dl-failures = 0, busy-thread = 0, mem-use-KB = 14571, heap-size-KB = 23632, congestion = &#65533;, max-depth = -1, & avg-depth = 0.\n&gt; \n&gt; The file order.xml looked fine to me, seeds.txt said &quot;http:/www.cs.nmt.edu&quot;, host-report.txt was empty, mimetype-report.txt was empty, responsecode-report.txt was empty, seeds-report.txt was empty.   Crawl-report.txt showed the crawl finished in 52 ms., &quot;Total Seeds Crawled: 0&quot;, &quot;Total Seeds not Crawled: 0&quot;, &quot;Total Hosts Crawled: -1&quot;, &quot;Total Documents Crawled: 0&quot;, and all other statistics were 0.\n&gt; \n&gt; I am only a newbie here, but to me this says:  &quot;Something didn&#39;t work somewhere for some reason.&quot;  I was unable to find any other information of interest, and I&#39;m hoping for some clarification here.\n&gt; \n&gt; All my environment remains the same as before.  Thanks for any suggestions.\n&gt; \n&gt; -Rich B.\n&gt; \n&gt; \n&gt; \n&gt; ------------------------------------\n&gt; \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n"}}