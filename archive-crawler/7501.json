{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":500983475,"authorName":"David Pane","from":"David Pane &lt;dpane@...&gt;","profile":"david_pane1","replyTo":"LIST","senderId":"x1n3WnkqKo3oPgHXsQpXtbDrChftQprxUCD9bhYqTbjf-iJI4hOwHYQiPJJkkKlnCaPJ2hZl4H5xcHKp2YPi1QCXGV0","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: Crawler running with less than configured threads.","postDate":"1326129337","msgId":7501,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRGMEIyMEI5LjgwNTA0MDFAY3MuY211LmVkdT4=","inReplyToHeader":"PDRGMDlGNTQ4LjQwNDA3MDVAYXJjaGl2ZS5vcmc+","referencesHeader":"PDRGMDVFOUFELjkwMTA5MDNAY3MuY211LmVkdT4gPDRGMDZCQUZCLjgwMTA0MDJAYXJjaGl2ZS5vcmc+IDw0RjA3MjM5My4yMDYwNzAwQGNzLmNtdS5lZHU+IDw0RjA5RjU0OC40MDQwNzA1QGFyY2hpdmUub3JnPg=="},"prevInTopic":7500,"nextInTopic":7503,"prevInTime":7500,"nextInTime":7502,"topicId":7493,"numMessagesInTopic":14,"msgSnippet":"Gordon, The checkpoints appeared to be succeeding.  Is there any way of confirming that they are or are not recoverable checkpoints without stopping the crawl","rawEmail":"Return-Path: &lt;dpane@...&gt;\r\nX-Sender: dpane@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 78060 invoked from network); 9 Jan 2012 17:15:41 -0000\r\nX-Received: from unknown (98.137.35.161)\n  by m9.grp.sp2.yahoo.com with QMQP; 9 Jan 2012 17:15:41 -0000\r\nX-Received: from unknown (HELO smtp.andrew.cmu.edu) (128.2.11.95)\n  by mta5.grp.sp2.yahoo.com with SMTP; 9 Jan 2012 17:15:41 -0000\r\nX-Received: from [128.2.209.200] (SAVOY.LTI.CS.CMU.EDU [128.2.209.200])\n\t(user=dpane mech=PLAIN (0 bits))\n\tby smtp.andrew.cmu.edu (8.14.4/8.14.4) with ESMTP id q09HFbhm018430\n\t(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NOT);\n\tMon, 9 Jan 2012 12:15:37 -0500\r\nMessage-ID: &lt;4F0B20B9.8050401@...&gt;\r\nDate: Mon, 09 Jan 2012 12:15:37 -0500\r\nUser-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:8.0) Gecko/20111105 Thunderbird/8.0\r\nMIME-Version: 1.0\r\nTo: Gordon Mohr &lt;gojomo@...&gt;\r\nCc: archive-crawler@yahoogroups.com\r\nReferences: &lt;4F05E9AD.9010903@...&gt; &lt;4F06BAFB.8010402@...&gt; &lt;4F072393.2060700@...&gt; &lt;4F09F548.4040705@...&gt;\r\nIn-Reply-To: &lt;4F09F548.4040705@...&gt;\r\nContent-Type: text/plain; charset=windows-1252; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-PMX-Version: 5.5.9.388399, Antispam-Engine: 2.7.2.376379, Antispam-Data: 2011.5.19.222118\r\nX-SMTP-Spam-Clean: 8% (\n BODYTEXTP_SIZE_3000_LESS 0, BODY_SIZE_1000_LESS 0, BODY_SIZE_2000_LESS 0, BODY_SIZE_5000_LESS 0, BODY_SIZE_7000_LESS 0, BODY_SIZE_900_999 0, DATE_TZ_NEG_0500 0, NO_URI_FOUND 0, __BOUNCE_CHALLENGE_SUBJ 0, __BOUNCE_NDR_SUBJ_EXEMPT 0, __CT 0, __CTE 0, __CT_TEXT_PLAIN 0, __HAS_MSGID 0, __MIME_TEXT_ONLY 0, __MIME_VERSION 0, __MOZILLA_MSGID 0, __SANE_MSGID 0, __TO_MALFORMED_2 0, __USER_AGENT 0)\r\nX-SMTP-Spam-Score: 8%\r\nX-Scanned-By: MIMEDefang 2.60 on 128.2.11.95\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: David Pane &lt;dpane@...&gt;\r\nSubject: Re: Crawler running with less than configured threads.\r\nX-Yahoo-Group-Post: member; u=500983475; y=4DktM-X1JrgATfeEoQaOF2BqiwnmjgDUX14_mgB5FzZzQUzMY4ciOQ\r\nX-Yahoo-Profile: david_pane1\r\n\r\nGordon,\n\nThe checkpoints appeared to be succeeding.  Is there any way of \nconfirming that they are or are not recoverable checkpoints without \nstopping the crawl and attempting to recover?\n\nIf the crawler does crash or needs to be stopped and we cannot recover \nfrom the last checkpoint (or any recent checkpoint) what are our \noptions?  Do we have to start from an old checkpoint and recrawl all of \nthe previously collected pages and data after that old recoverable \ncheckpoint?\n\n--David\n\nOn 1/8/2012 2:58 PM, Gordon Mohr wrote:\n&gt; I don&#39;t know if future checkpoints after this point will succeed, or\n&gt; would be resumable even if they appeared to succeed; there&#39;s not enough\n&gt; info about what went wrong. Presumably whatever caused the topmost-URI\n&gt; deserialization to fail will remain as a problem unless the code or\n&gt; data-on-disk changes, so those queues might continue to be inert even\n&gt; with some heroic tampering with heap state or the on-disk data.\n\n"}}