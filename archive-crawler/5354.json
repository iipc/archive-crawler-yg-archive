{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":334763322,"authorName":"Christian Krumm","from":"Christian Krumm &lt;signore.chrissi@...&gt;","profile":"chuk_ol","replyTo":"LIST","senderId":"9oe6Z3b6hofaW_QqKvtbOHMULWPfBVKurpeBnOZjLg1Ea7KATubPFjvRMUyt_s0xK_6pLnlTGtpg4PfAcJqqKJ7whmPh-C6Pdq20gs24-ovzLVMIFBPc","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Newbie, Only download html pages in seeds","postDate":"1215803968","msgId":5354,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ4NzdCMjQwLjcwOTAyMDNAZ29vZ2xlbWFpbC5jb20+","inReplyToHeader":"PGc1N2ViZCt1MDU0QGVHcm91cHMuY29tPg==","referencesHeader":"PGc1N2ViZCt1MDU0QGVHcm91cHMuY29tPg=="},"prevInTopic":5353,"nextInTopic":5355,"prevInTime":5353,"nextInTime":5355,"topicId":5353,"numMessagesInTopic":6,"msgSnippet":"... Hi, I think you have to change the order of the deciderules. They are executed in order, so the last decision whould be used to make the whole decision for","rawEmail":"Return-Path: &lt;signore.chrissi@...&gt;\r\nX-Sender: signore.chrissi@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 82886 invoked from network); 11 Jul 2008 19:19:40 -0000\r\nX-Received: from unknown (66.218.67.97)\n  by m57.grp.scd.yahoo.com with QMQP; 11 Jul 2008 19:19:40 -0000\r\nX-Received: from unknown (HELO smtpmx11.uni-oldenburg.de) (134.106.87.111)\n  by mta18.grp.scd.yahoo.com with SMTP; 11 Jul 2008 19:19:40 -0000\r\nX-Received: from [192.168.2.27] (p57B6F328.dip.t-dialin.net [87.182.243.40])\n\t(authenticated bits=0)\n\tby smtpmx11.uni-oldenburg.de (8.13.1/8.13.1) with ESMTP id m6BJJaNp023783\n\t(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NO)\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Fri, 11 Jul 2008 21:19:38 +0200\r\nMessage-ID: &lt;4877B240.7090203@...&gt;\r\nDate: Fri, 11 Jul 2008 21:19:28 +0200\r\nUser-Agent: Thunderbird 2.0.0.14 (X11/20080502)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;g57ebd+u054@...&gt;\r\nIn-Reply-To: &lt;g57ebd+u054@...&gt;\r\nX-Enigmail-Version: 0.95.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Transfer-Encoding: 7bit\r\nX-PMX-Version: 5.4.0.320885, Antispam-Engine: 2.5.2.313940, Antispam-Data: 2008.7.11.185027\r\nX-PerlMx-Spam: Gauge=IIIIIII, Probability=7%, Report=&#39;BODY_SIZE_1500_1599 0, BODY_SIZE_5000_LESS 0, RDNS_DYNAMIC 0, RDNS_SUSP 0, RDNS_SUSP_SPECIFIC 0, __BOUNCE_CHALLENGE_SUBJ 0, __CP_MEDIA_BODY 0, __CT 0, __CTE 0, __CT_TEXT_PLAIN 0, __FRAUD_419_WEBMAIL 0, __FRAUD_419_WEBMAIL_FROM 0, __HAS_MSGID 0, __MIME_TEXT_ONLY 0, __MIME_VERSION 0, __SANE_MSGID 0, __USER_AGENT 0&#39;\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Christian Krumm &lt;signore.chrissi@...&gt;\r\nSubject: Re: [archive-crawler] Newbie, Only download html pages in seeds\r\nX-Yahoo-Group-Post: member; u=334763322; y=w60BI3eN6yKsirxbrkrFC1543UJzGhISsnhjTvroe4BXZw\r\nX-Yahoo-Profile: chuk_ol\r\n\r\nhaidong.pan schrieb:\n&gt; Hi\n&gt; \n&gt; I&#39;m trying to fetch html pages only defined in seeds using\n&gt; heritrix2.0. and don&#39;t want other pages linked in html pages be download.\n&gt; \n&gt; \n&gt; This is my settings:\n&gt; global \n&gt; root:controller:processors:LinksScoper:seed-redirects-new-seeds \n&gt; boolean \tfalse \n&gt; \n&gt; global \troot:controller:processors:Scheduler:decide-rules:rules \n&gt; list \torg.archive.modules.deciderules.DecideRule\n&gt; global \troot:controller:processors:Scheduler:decide-rules:rules:0 \n&gt; object \torg.archive.modules.deciderules.SeedAcceptDecideRule\n&gt; global \troot:controller:processors:Scheduler:decide-rules:rules:1 \n&gt; object \torg.archive.modules.deciderules.RejectDecideRule \n&gt; \n&gt; But it&#39;s not works.\n&gt; \n&gt; Can i have any help?\n&gt; \n&gt; Thanks\n&gt; \n&gt; \n\nHi,\n\nI think you have to change the order of the deciderules. They are\nexecuted in order, so the last decision whould be used to make the whole\ndecision for the CrawlURI. So actually you accept the seed and then\nrejects all URIs. So currently all CrawlURIs whould be rejected and none\nof them will be downloaded. You may use the profile-basic_seed_sites\ndistributed in heritrix2, which actually only fetches the seeds\n(including prerequisites like robots.txt) and then stops the crawl. If\nyou want to download HTML-Files only, you may add a decide-rule to\nFetchHTTPProcessor or to the writer you are using, so images or\nmultimedia-elements (audio, video, applets, etc.) whould be rejected.\n\nHope this helps\nChristian\n\n"}}