{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":160886731,"authorName":"Marco Baroni","from":"Marco Baroni &lt;baroni@...&gt;","profile":"kumaraja2000","replyTo":"LIST","senderId":"m4vOopQ4qXb_K963b4hXX8YfiCMRPa5omWGeDSS277Zduenn_QY68PEQkKAAaPZcWYCUciXkKfMGqaxM-bBTF6iNLQMcprsVrFajWQ","spamInfo":{"isSpam":false,"reason":"0"},"subject":"beginner&#39;s questions...","postDate":"1103463117","msgId":1286,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDVBQkU3ODM0LTUxQzItMTFEOS1COUJELTAwMzA2NUE3MDFDMkBzc2xtaXQudW5pYm8uaXQ+"},"prevInTopic":0,"nextInTopic":1287,"prevInTime":1285,"nextInTime":1287,"topicId":1286,"numMessagesInTopic":8,"msgSnippet":"Dear Archive Crawlers, My name is Marco Baroni, I am a linguist employed as a researcher at the University of Bologna. As a linguist, I have been interested in","rawEmail":"Return-Path: &lt;baroni@...&gt;\r\nX-Sender: baroni@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 60171 invoked from network); 19 Dec 2004 13:31:56 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m25.grp.scd.yahoo.com with QMQP; 19 Dec 2004 13:31:56 -0000\r\nReceived: from unknown (HELO vsmtp12.tin.it) (212.216.176.206)\n  by mta4.grp.scd.yahoo.com with SMTP; 19 Dec 2004 13:31:56 -0000\r\nReceived: from sslmit.unibo.it (82.55.243.79) by vsmtp12.tin.it (7.0.027)\n        id 41BF38910029E85B for archive-crawler@yahoogroups.com; Sun, 19 Dec 2004 14:31:56 +0100\r\nDate: Sun, 19 Dec 2004 14:31:57 +0100\r\nMime-Version: 1.0 (Apple Message framework v553)\r\nContent-Type: text/plain; charset=US-ASCII; format=flowed\r\nTo: archive-crawler@yahoogroups.com\r\nContent-Transfer-Encoding: 7bit\r\nMessage-Id: &lt;5ABE7834-51C2-11D9-B9BD-003065A701C2@...&gt;\r\nX-Mailer: Apple Mail (2.553)\r\nX-eGroups-Remote-IP: 212.216.176.206\r\nFrom: Marco Baroni &lt;baroni@...&gt;\r\nSubject: beginner&#39;s questions...\r\nX-Yahoo-Group-Post: member; u=160886731\r\nX-Yahoo-Profile: kumaraja2000\r\n\r\nDear Archive Crawlers,\n\nMy name is Marco Baroni, I am a linguist employed as a researcher at \nthe University of Bologna.\n\nAs a linguist, I have been interested in downloading large amounts of \ntext from the web for various forms of statistical analyses. However, \nuntil now I have been relying on simple home-made scripts to gather web \ndata. Now, as I should get some funds to buy a few dedicated servers, I \nwould like to get started with some more ambitious crawl, and heritrix \nlooks like the ideal choice.\n\nI realize that the questions I&#39;m about to ask are very basic, and \nprobably they are already answered somewhere, but I have not been able \nto find the relevant documentation by myself... perhaps somebody could \npoint me to it?\n\n1) I understand that there is a way to stop fetching documents that do \nnot match certain content-types with a filter. Is there a way to insert \nsuch a filter via the standard WUI?\n\n2) Similarly, is it possible to restrict the documents to be written to \nthe arc files to a certain maximum and minimum size?\n\n3) In order to extract pure text from the documents, I plan to write \nscripts that invoke arcdump to get file type and contents out of the \narcs, and then call appropriate tools such as pdftotex. Actually, for \nnow I would be quite happy just extracting text from the html files. \nBefore I re-invent the wheel, is there already some tool/module to do \nthis?\n\n4) Am I right in thinking that heritrix will not download the same url \ntwice (within the same crawling job)?\n\nThanks in advance for your advice!\n\nRegards,\n\nMarco\n\n\n---\nMarco Baroni\nUniversity of Bologna\nhttp://sslmit.unibo.it/~baroni\n\n\n"}}