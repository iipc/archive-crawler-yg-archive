{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":164438524,"authorName":"Lars Clausen","from":"Lars Clausen &lt;lc@...&gt;","profile":"lrclause","replyTo":"LIST","senderId":"BDx7GM4OLuNjHn7NiccEDOE67IANYbs1N8PnroPF1bWeUFudTnVZGsDIc_voCAcTGOqc-TZwOTWR4R3etPcx0RTx3EOpbQnkcNq0qg","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Determining a sites Page depth?","postDate":"1090481197","msgId":700,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDEwOTA0ODExOTcuMTkzNS4xNTAuY2FtZWxAcGM3NzAuc2Iuc3RhdHNiaWJsaW90ZWtldC5kaz4=","inReplyToHeader":"PGNkbHYzZStiOTExQGVHcm91cHMuY29tPg==","referencesHeader":"PGNkbHYzZStiOTExQGVHcm91cHMuY29tPg=="},"prevInTopic":698,"nextInTopic":0,"prevInTime":699,"nextInTime":701,"topicId":688,"numMessagesInTopic":4,"msgSnippet":"... I m not sure that Heritrix is strictly breadth-first, is it? Depth-first uses a lot less memory in general.  And if it s not breadth-first, then you can","rawEmail":"Return-Path: &lt;lc@...&gt;\r\nX-Sender: lc@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 42244 invoked from network); 22 Jul 2004 07:27:31 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m25.grp.scd.yahoo.com with QMQP; 22 Jul 2004 07:27:31 -0000\r\nReceived: from unknown (HELO luna.statsbiblioteket.dk) (130.225.24.87)\n  by mta4.grp.scd.yahoo.com with SMTP; 22 Jul 2004 07:27:31 -0000\r\nReceived: from pc770.sb.statsbiblioteket.dk\n (pc770.sb.statsbiblioteket.dk [130.225.24.181]) by luna.statsbiblioteket.dk\n (iPlanet Messaging Server 5.2 HotFix 1.16 (built May 14 2003))\n with ESMTP id &lt;0I180058ISODH9@...&gt; for\n archive-crawler@yahoogroups.com; Thu, 22 Jul 2004 09:26:37 +0200 (MEST)\r\nDate: Thu, 22 Jul 2004 09:26:37 +0200\r\nIn-reply-to: &lt;cdlv3e+b911@...&gt;\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-id: &lt;1090481197.1935.150.camel@...&gt;\r\nOrganization: Statsbiblioteket\r\nMIME-version: 1.0\r\nX-Mailer: Ximian Evolution 1.4.5 (1.4.5-1)\r\nContent-type: text/plain\r\nContent-transfer-encoding: 7BIT\r\nReferences: &lt;cdlv3e+b911@...&gt;\r\nX-eGroups-Remote-IP: 130.225.24.87\r\nFrom: Lars Clausen &lt;lc@...&gt;\r\nSubject: Re: [archive-crawler] Determining a sites Page depth?\r\nX-Yahoo-Group-Post: member; u=164438524\r\nX-Yahoo-Profile: lrclause\r\n\r\nOn Wed, 2004-07-21 at 16:37, Ahnu Nahki wrote:\n&gt; I want to find out the distance from a home page, to another page on\n&gt; the site, how many links away is that page from the start of the site.\n&gt; We have an application that requires the page depth of a site. We used\n&gt; to determine it using an old crawler we have. We&#39;d like to use\n&gt; heritrix to do the same thing, but I dont know what in the API I use\n&gt; to determine how far a page is from the starting page. Some one had\n&gt; mentioned hopsfilter class, but I really dont understand it or have\n&gt; any proper documentation to go by. Any help would be greatly appreciated.\n\nI&#39;m not sure that Heritrix is strictly breadth-first, is it? \nDepth-first uses a lot less memory in general.  And if it&#39;s not\nbreadth-first, then you can only find the actual distance from the home\npage when you have the whole thing downloaded by looking at the actual\ngraph of links.\n\n-Lars\n\n\n"}}