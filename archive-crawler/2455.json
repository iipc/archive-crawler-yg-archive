{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"stack","from":"stack &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"73WyrN6RlhUXCtRd8nnEr0M_iUgM1GwBPRT06fnvvqvGN86ssYVktWg5x5jGSMuoO9rHzI2NQYaoJh7KXSOiuw","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Heritrix - Getting involved","postDate":"1135199058","msgId":2455,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQzQTlDMzUyLjIwOTA0MDBAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDQzQTgxRDZCLjIwODAzMDBAbWFydGluaWVuLmRlPg==","referencesHeader":"PDQzQTgxRDZCLjIwODAzMDBAbWFydGluaWVuLmRlPg=="},"prevInTopic":2453,"nextInTopic":0,"prevInTime":2454,"nextInTime":2456,"topicId":2453,"numMessagesInTopic":2,"msgSnippet":"... Thanks for writing Martin. Here s some suggestions: + You could write/improve current extractors/parsers, for example: ++ An FTP or SMB extractor (We have","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 29621 invoked from network); 21 Dec 2005 21:04:28 -0000\r\nReceived: from unknown (66.218.66.218)\n  by m35.grp.scd.yahoo.com with QMQP; 21 Dec 2005 21:04:28 -0000\r\nReceived: from unknown (HELO dns.duboce.net) (63.203.238.114)\n  by mta3.grp.scd.yahoo.com with SMTP; 21 Dec 2005 21:04:28 -0000\r\nReceived: from [192.168.1.105] ([192.168.1.105])\n\t(authenticated)\n\tby dns-eth1.duboce.net (8.10.2/8.10.2) with ESMTP id jBLJwgN17021;\n\tWed, 21 Dec 2005 11:58:42 -0800\r\nMessage-ID: &lt;43A9C352.2090400@...&gt;\r\nDate: Wed, 21 Dec 2005 13:04:18 -0800\r\nUser-Agent: Thunderbird 1.5 (Macintosh/20051025)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;43A81D6B.2080300@...&gt;\r\nIn-Reply-To: &lt;43A81D6B.2080300@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 2:12:4:0\r\nFrom: stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] Heritrix - Getting involved\r\nX-Yahoo-Group-Post: member; u=168599281; y=JWt6ziVX0sl9Epet7DO_HrRL7-SlU5kj1Nyi4Eob5Gs9MHPK6UOJi2OU\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\nMartin Richtarsky wrote:\n&gt; Hello,\n&gt; \n&gt; I&#39;m a student of Computer Science at a German university. I&#39;m looking\n&gt; for a challenging topic for my diploma thesis. As I&#39;ve been working on\n&gt; crawling/searching in the past (FTP and SMB) I would like to put my\n&gt; knowledge in this area to use.\n&gt; \n&gt; So I&#39;ve taken a look at the Heritrix crawler and would like to get\n&gt; involved in this project. Perhaps it&#39;s possible to work on an relatively\n&gt; isolated sub-project? The wiki has some TODOs/future directions. I think\n&gt; I could be of help in areas where some research and testing is required\n&gt; (which approach to choose, etc.). The time frame for my thesis is six\n&gt; months.\n\nThanks for writing Martin.\n\nHere&#39;s some suggestions:\n\n+ You could write/improve current extractors/parsers, for example:\n++ An FTP or SMB extractor (We have neither).\n++ You could compare and contrast parsing libraries: e.g. \ncompare/contrast all opensource HTTP parsers would be an interesting \nassignment that would benefit the general community, not just Heritrix \n(Might not be enough meat on this project to keep you going for 6 months).\n+ You could use Heritrix crawling particular domains: Tune Heritrix to \ncrawl blogs or the semantic web.  Would necessitate writing custom parsers.\n+ Avoiding duplicate sites, documents or near-duplicate documents.\n+ How to avoid crawlng junk/traps (See \nhttp://crawler.archive.org/cgi-bin/wiki.pl?TrapDetectionIdeas and \nhttp://crawler.archive.org/cgi-bin/wiki.pl?ChaffControl).\n\nWe can come up with others or hang more detail on the list above.  Just \nask (You can write off-list if you&#39;d like).  Also, take a look at \ncurrent list of &#39;RFEs&#39;: \nhttp://sourceforge.net/tracker/?group_id=73833&atid=539102.  Might \nsuggest a topic.\n\nFYI, currently Nicolas Baly is working on the problems crawling \nstreaming media as part of a thesis he&#39;s doing finishing up his computer \nscience degree at epfl.ch. You might write him to get a reference as to \nhow supportive and nurturing the Heritrix community can be of students \n(smile).  In the past, Kristinn Sigurdsson wrote his thesis on &#39;Adaptive \nRevisiting with Heritrix&#39; (See end of FAQ for link).\n\nYours,\nSt.Ack\n\n\n&gt; \n&gt; Any suggestions on how I could help?\n&gt; \n&gt; \n&gt; Martin\n&gt; -- \n&gt; http://www.martinien.de/\n&gt; ICQ: 124394797\n&gt; \n&gt; ------------------------------------------------------------------------\n&gt; YAHOO! GROUPS LINKS\n&gt; \n&gt;     *  Visit your group &quot;archive-crawler\n&gt;       &lt;http://groups.yahoo.com/group/archive-crawler&gt;&quot; on the web.\n&gt;        \n&gt;     *  To unsubscribe from this group, send an email to:\n&gt;        archive-crawler-unsubscribe@yahoogroups.com\n&gt;       &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;        \n&gt;     *  Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;. \n&gt; \n&gt; \n&gt; ------------------------------------------------------------------------\n&gt; \n\n\n"}}