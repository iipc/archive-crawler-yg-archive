{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137477665,"authorName":"Igor Ranitovic","from":"Igor Ranitovic &lt;igor@...&gt;","profile":"iranitovic","replyTo":"LIST","senderId":"4SW38QLy_KU3Lje8a_fvV3RMeGJ0EGqx0Iug2wk4Ccj8_OJHP-yLdQd__1GpcBc_nC-QF4WV5Dnc57Qi2Y4uppgJPIWIBCQN","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Overview of WUI proposal","postDate":"1062519787","msgId":149,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PFBpbmUuTE5YLjQuMzMuMDMwOTAyMDg1NzI5MC41NjUwLTEwMDAwMEBob21lc2VydmVyLmFyY2hpdmUub3JnPg=="},"prevInTopic":0,"nextInTopic":150,"prevInTime":148,"nextInTime":150,"topicId":149,"numMessagesInTopic":2,"msgSnippet":"This is an overview of Heritrix Web-based administration interface. I am still working on Real use-cases with screenshots and Actor/System interaction. As for","rawEmail":"Return-Path: &lt;igor@...&gt;\r\nX-Sender: igor@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 93906 invoked from network); 2 Sep 2003 16:23:19 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m15.grp.scd.yahoo.com with QMQP; 2 Sep 2003 16:23:19 -0000\r\nReceived: from unknown (HELO homeserver.archive.org) (209.237.233.202)\n  by mta5.grp.scd.yahoo.com with SMTP; 2 Sep 2003 16:23:19 -0000\r\nReceived: from localhost (igor@localhost)\n\tby homeserver.archive.org (8.11.6/8.11.6) with ESMTP id h82GN8A13729\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Tue, 2 Sep 2003 09:23:08 -0700\r\nX-Authentication-Warning: homeserver.archive.org: igor owned process doing -bs\r\nDate: Tue, 2 Sep 2003 09:23:07 -0700 (PDT)\r\nTo: &lt;archive-crawler@yahoogroups.com&gt;\r\nSubject: Overview of WUI proposal\r\nMessage-ID: &lt;Pine.LNX.4.33.0309020857290.5650-100000@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: TEXT/PLAIN; charset=US-ASCII\r\nFrom: Igor Ranitovic &lt;igor@...&gt;\r\nX-Yahoo-Group-Post: member; u=137477665\r\nX-Yahoo-Profile: iranitovic\r\n\r\nThis is an overview of Heritrix Web-based administration interface.\nI am still working on Real use-cases with screenshots and Actor/System \ninteraction. As for now there are two simplified use-cases in this \noverview.\n\n\nInternet Archive Open Source Crawler Web User Interface Proposal\n\n1.Introduction\n\nInternet Archive&#39;s Open Source Crawler (a.k.a Heritrix) Web user interface \nshould be an application that will provide administrative and monitoring \ninterface to the crawler.\n\n1.1\tAdministrative and Monitoring Overview\n\nAdministrative part of the interface should consist of three different \n&#39;panels&#39;, one control and two configuration panels. The control panel \nshould consist of start, stop, pause, checkpoint, resume, and terminate \noptions. First configuration panel should be the crawl configuration panel \nwhere the crawl is a web collection that will be harvest.  Second \nconfiguration panel should be the crawler&#39;s configuration panel where the \ncrawler is a group of Heritrix configurable modules.\nMonitoring part of the interface should consist of Heritrix reports such \nas progress and data captured, errors, and crawler status reports.\nThis interface should also provide some basic authentication mechanism.\n\n1.2 Use-case Scenarios \n\nSimple use-case scenario:\n1)\tThe operator starts the crawler on command-line without any \nparameters. The operator is prompt with URL to the interface.\n2)\tThe operator visits the interface via a Web browser. The operator \nis redirected to &#39;welcome&#39; page and no status message is display. \n3)\tThe operator selects &#39;start new crawl&#39; option. The operator is \nredirected to the crawl panel and default crawl values are automatically \nfilled-in.\n4)\tThe operator configures the crawl parameters (seeds, filters, \netc.)\n5)\tThe operator selects &quot;start crawler&quot; options. The operator is \nredirected to &#39;welcome&#39; page and status message &quot;crawler started&quot; is \ndisplayed.\n6)\tThe operator selects monitoring panel option to observe\ncrawl reports. Status message &quot;crawl in progress&quot; is displayed.\n7)\tThe operator terminates the crawl when done via &quot;terminate&quot; \noption.\n\nBasic use-case scenario:\n\tThe operator performs simple use-case scenario but exits the \ninterface before the crawl is done. The operator returns to the interface \nto check crawl status and decided to add more seeds, and filters.\n7-1)\tThe operator exits the interface by closing the Web browser.\n\n8)\tThe operator revisits the interface via the Web Browser. The \noperator is redirected to &#39;welcome&#39; page and status message &quot;crawl in \nprogress&quot; is displayed.\n9)\tThe operator selects monitoring panel to check crawl \nreports. The operation is redirected to monitoring panel and status \nmessage &quot;crawl in progress&quot; is displayed.\n10)\t The operator selects &#39;crawl panel&#39; option. The operator is \nredirected to the crawl panel and current crawl configuration is \nfilled-in.\n11)\t The operator adds seeds and filters, and selects &#39;update crawl \nconfiguration&#39; options. The operator is prompted with confirm window.\n13)\t The operator is redirected to &#39;welcome&#39; page and status message \n&quot;crawl in progress&quot; is displayed.\n14)\t The operator terminates the crawl when done via &quot;terminate&quot; \noption.\n\n2. Administrative Panels\n\n2.1 Control Panel\n\nThe control panel should provide start, stop, checkpoint, pause, resume, \nand terminate options. The operator should be able to use these options at \nall times.\n\t\nStart - starts the crawler.\n\t\nStop - stops the crawler. When crawler is stopped with this option it can \nbe resumed from last checkpoint.\n\nPause (optional?)- stops crawling but not the crawler. This option will \npause (put to sleep) crawler&#39;s workers. Similar effect can be achieved by \ncheckpoint followed by stop options therefore pause option may be \nredundant. \n\t\nResume - resumes stopped/paused crawler. Stopped crawl is resumed from \nlast known checkpoint. Paused crawl is resumed by waking up paused \nworkers. \n\t\nCheckpoint - it writes current crawler&#39;s state to a disk.\n\t\nTerminate - it shutdowns the server and all crawl activities.\n\t\n\t \n\n2.2 Crawler Configuration Panel \n \nThe crawler configuration panel should consist of Heritrix configurable \nmodules. Heritrix current modules are:\n-   selector\n-   scheduler\n-   store\n-   preprocessor\n-   DNS fetcher\n-   HTTP fetcher\n-   HTTP extractor\n-   HTML extractor\n-   MSDOC extractor\n-   SWF extractor\n-   PDF extractor\n-   archiver\nDefault mode of the interface should hide this configuration panel. The \npanel should be available in &#39;advance&#39; mode. In this mode the operator \nshould be able to add, change or reconfigure any of these modules. The \noperator should also be able to load any pre-existing XML \nconfiguration file in both modes.\n\n2.3 Crawl Configuration Panel\n\nThe crawl configuration panel should provide options to the operator to \nconfigure individual crawls. Heritrix current crawl options are:\n-\tcrawl name\n-\tcomments\n-\tseeds\n-\tUser-Agent (HTTP Header)\n-\tFrom (HTTP Header)\n-\tmax-link-depth (limits)\n-\tmax-toe-threads (limits)\n-\toutput file format (archiving)\n-\toutput file prefix (archiving)\n-\toutput file max size (archiving)\n-\tstatistics update interval (logging)\n-\tfilters\n-\tdisk path to resources\n-\tdisk output path\nCrawl options may apply to different modules therefore the interface \nshould provide mechanism that will allow the operator to associate these \noptions with modules that enforce them. For simplicity sake Heritrix \ndefault crawl configuration mode should hide this abstraction from the \noperator. The operator should be able to configure this abstraction in \nadvance mode.  The operator should be able to change or configure any of \nthese options at all times. Most changes to a running crawler should \nrequire stopping (possible pausing) and restarting from last checkpoint.\nSome useful changes that might not need stopping/pausing of the crawl \nshould be:\n  - inject new seeds\n  - add new negative-filters (e.g block a complainers&#39; site)\n  - add an operator comment to some &quot;crawl journal&quot; of sorts\n\n3. Monitoring and Progress Reports \n\nThe monitoring part of the interface should provide the operator with \ncrawler&#39;s reports on progress and captured data, status, and \nerrors. \nAll statistics will be updated on demand by the operator or by \n&#39;auto-refresh&#39; option.\n\n3.1 Progress and Captured Data Report\n\nProgress and captured data report should provide the following statistics:\n-\tNumber and rate of URLs processed\n-\tNumber and rate of unique URLs processed\n-\tNumber of discover URLs\n-\tNumber and rate of crawled hosts\n-\tNumber and rate of each HTTP response code\n-\tNumber and rate of types of documents\n-     List of URLs in &#39;frontier&#39; (limited to X number of URLs)\n\n3.2 Crawler&#39;s Status Report\n\nCrawler status report should provide the following statistics:\n-\tOverall bandwidth usages\n-\tOverall disk usages\n-\tOverall memory usages\n-\tNumber of total workers (toe threads)\n-\tNumber of total active workers (toe threads)\n\n3.3 Error Report\n\nError report should provide the following statistics:\n-\tNetwork errors\n-\tDNS errors\n-\tInternal Heritrix errors\n-\tRejected URLs (malformed, robots.txt excluded, restricted)\n-\tRestricted hosts (robots.txt excluded, restricted)\n\n4. Authentication Panel\n\nThe interface authentication should be a HTTP &quot;Basic&quot; or &quot;Digest&quot; \nauthentication. Only a single username/password is necessary for the \nforeseeable future.\nThis one username/password pair could be specified on the command-line. \nAll traffic of the interface should be logged.\n\n5. Implementation\nHeritrix crawler should primarily be administered through the web \ninterface, served from an embedded web server. Jetty web server is primary \nchoice since it is small and embeddable web server with efficient support \nfor Java Servlets and JSP. Java Servlets and JSP technology should be \nprimary choice for the implementation of the interface. This is well-known \nand flexible technology that is suitable for development of Web-based \napplications.\n\n(Still working on basic page layouts/screenshots)\n  \n6. Future Work\nProvide a support for multiple simultaneous individual crawls via the same \nweb interface. Provide quality-assurance &#39;toolkit&#39; (Wayback machine and \ncrawl comparison tools.) Provide per module configurations screen.\n\nPlease send me your comments and suggestions.\n\nTake care.\ni.\n\n\n\n"}}