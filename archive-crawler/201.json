{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"Michael Stack","from":"Michael Stack &lt;stack@...&gt;","replyTo":"LIST","senderId":"OItlTvKatmcFiXoOrgK_SsqrSb279llyxemoIC296A4oew4PMlrXTuBrdEM4xJRHpKZeV3VmNeF2yzasdzt11iZy7JvQ0fov","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Checkpointing","postDate":"1071180896","msgId":201,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDNGRDhFQzYwLjcwNTAwMDlAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDNGRDhDN0VCLjUwOTAyMDBAYXJjaGl2ZS5vcmc+","referencesHeader":"PDNGQkJGNjUzLjkwNjAxMDdAYXJjaGl2ZS5vcmc+IDwxMDcxMTAxMDAzLjEwOTA0LjkxLmNhbWVsQGIxMTYtZHluLTM3LmFyY2hpdmUub3JnPiA8M0ZEOEM3RUIuNTA5MDIwMEBhcmNoaXZlLm9yZz4="},"prevInTopic":200,"nextInTopic":202,"prevInTime":200,"nextInTime":202,"topicId":178,"numMessagesInTopic":7,"msgSnippet":"Is there definition of term checkpoint anywhere?  A description of how it currently works? See also inline below. ... Would be grand if we could minimize the","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 99304 invoked from network); 11 Dec 2003 22:20:42 -0000\r\nReceived: from unknown (66.218.66.218)\n  by m13.grp.scd.yahoo.com with QMQP; 11 Dec 2003 22:20:42 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (209.237.232.202)\n  by mta3.grp.scd.yahoo.com with SMTP; 11 Dec 2003 22:20:38 -0000\r\nReceived: (qmail 15715 invoked by uid 100); 11 Dec 2003 22:19:52 -0000\r\nReceived: from b116-dyn-60.archive.org (HELO archive.org) (stack@...@209.237.240.60)\n  by mail-dev.archive.org with SMTP; 11 Dec 2003 22:19:52 -0000\r\nMessage-ID: &lt;3FD8EC60.7050009@...&gt;\r\nDate: Thu, 11 Dec 2003 14:14:56 -0800\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.5) Gecko/20031007\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nSubject: Re: [archive-crawler] Checkpointing\r\nReferences: &lt;3FBBF653.9060107@...&gt; &lt;1071101003.10904.91.camel@...&gt; &lt;3FD8C7EB.5090200@...&gt;\r\nIn-Reply-To: &lt;3FD8C7EB.5090200@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-Status: No, hits=-4.8 required=6.0\n\ttests=AWL,BAYES_10,EMAIL_ATTRIBUTION,IN_REP_TO,QUOTED_EMAIL_TEXT,\n\t      REFERENCES,REPLY_WITH_QUOTES,TONER,USER_AGENT_MOZILLA_UA\n\tversion=2.55\r\nX-Spam-Level: \r\nX-Spam-Checker-Version: SpamAssassin 2.55 (1.174.2.19-2003-05-19-exp)\r\nX-eGroups-Remote-IP: 209.237.232.202\r\nFrom: Michael Stack &lt;stack@...&gt;\r\nX-Yahoo-Group-Post: member; u=168599281\r\n\r\nIs there definition of term checkpoint anywhere?  A description of how \nit currently works?\n\nSee also inline below.\n\nGordon Mohr wrote:\n\n&gt;John Erik Halse wrote:\n&gt;  \n&gt;\n&gt;&gt;When thinking of different approaches for doing checkpoints I came up\n&gt;&gt;with a some questions that should be answered before we try to design\n&gt;&gt;it.\n&gt;&gt;\n&gt;&gt;* How often are we supposed to do a checkpoint (aka how costly is a\n&gt;&gt;checkpoint allowed to be).\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;For recovery from major crawl problems, the checkpoint resolution is\n&gt;how much time/work will be lost when the crawl restarts. We&#39;d like\n&gt;to be able to do checkpoints every few hours on most focused crawls.\n&gt;We might want as infrequent as once per day on broad crawls.\n&gt;  \n&gt;\n&gt;&gt;If the checkpoints are very expensive, we could do a combination of\n&gt;&gt;checkpoint and recovery log. The recovery log should then be reset at\n&gt;&gt;every checkpoint.\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;  \n&gt;\n&gt;&gt;* Is it ok to pause the crawler for a checkpoint? It might take some\n&gt;&gt;time to wait for all the threads to finish. Is this acceptable?\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;Some disruption/pause to full crawler throughput is inevitable.\n&gt;\n&gt;An approach that has been recommended is to divide up the processing\n&gt;of a CrawlURI into a first phase (including the potentially lengthy\n&gt;network fetch), which has no persistent effect on the checkpointed\n&gt;state (of the Frontier or other modules), and then a second phase,\n&gt;which if started must be completed before a checkpoint occurs.\n&gt;\n&gt;So the problem of waiting for all the threads to finish becomes in\n&gt;fact just waiting for them to finish their critical second phases,\n&gt;which are more likely to be guaranteed to finish in a bounded\n&gt;amount of time. Also, progress can continue on first phase network\n&gt;download activity -- indeed new URIs can even be begun during a\n&gt;checkpoint, they just can&#39;t proceed to the second phase processing.\n&gt;\n&gt;In our design, this might entail making some subset of the Processors\n&gt;after the fetchers, including the ARCWriter and others with lasting\n&gt;effect on in-memory structures and running statistics, into the critical\n&gt;second phase\n&gt;\n&gt;  \n&gt;\nWould be grand if we could minimize the number (or type) of \nobjects/processors that need to serialize.\n\n&gt;&gt;* Is checkpointing just for recovering from crashes?\n&gt;&gt;If not:\n&gt;&gt;  - Should it be possible to manipulate queues in a suspended state? For\n&gt;&gt;example adding or removing URIs in the pending queue.\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;Yes -- though perhaps this is just the same capability as we would want\n&gt;for any paused crawl. (That is, the operator might not directly edit\n&gt;state on disk, but rather (1) load checkpoint without restarting active\n&gt;crawl; then (2) use other admin options to edit standing queues.)\n&gt;\n&gt;  \n&gt;\n&gt;&gt;  - Should it be possible to change implementation of modules between\n&gt;&gt;suspend and resume? For example fixing bugs.\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;Definitely.\n&gt;\n&gt;  \n&gt;\nWe&#39;d need to play w/ class-loaders to implement such a &quot;hot-deploy&quot; \nfeature so they&#39;d check disk on a period or when kicked for new class \ninstances. \n\n&gt;&gt;  - Should it be possible to alter the configuration in suspended state\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;Yes -- though again this may just be the same capability as would\n&gt;be wanted for any paused crawl, whether it has been completely\n&gt;checkpointed or not.\n&gt;\n&gt;  \n&gt;\n&gt;&gt;* Is it ok to insert a checkpoint mark in the working files or should\n&gt;&gt;everything be copied to a safe location to make sure that a crash would\n&gt;&gt;not corrupt files?\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;To be determined; I think some files which change in arbitrary ways\n&gt;between checkpoints would need to be duplicated in full. A &quot;safe location&quot;\n&gt;might just be another filename in the same working directory.\n&gt;\n&gt;  \n&gt;\n&gt;&gt;If we add the possibility to run a multiple machine crawl; Should the\n&gt;&gt;checkpoint span all the crawler instances or should the checkpoint be\n&gt;&gt;local to a single instance?\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;It must span all instances to the extent required to prevent any URIs\n&gt;from falling through the cracks or major discrepancies in expected\n&gt;behavior between the original run and a subsequent resume-from-checkpoint.\n&gt;\n&gt;For example, if cooperating crawler A sends a URI to B for crawling, then\n&gt;makes checkpoint 0001, while B makes checkpoint 0001, then receives\n&gt;the URI, there would be a problem upon resuming both from their respective\n&gt;checkpoints 0001: A would think the URI was already handled, while B will\n&gt;not have received it.\n&gt;\n&gt;  \n&gt;\nYeah.  Checkpointing would have to span the cluster.  Sounds like it&#39;d \nbe nice if the checkpointing was transactional (&quot;Are you ready to \ncheckpoint?&quot;, &quot;Ok, commit&quot;).\n\nSt.Ack\n\n&gt;- Gordon\n&gt;\n&gt;\n&gt;To unsubscribe from this group, send an email to:\n&gt;archive-crawler-unsubscribe@yahoogroups.com\n&gt;\n&gt; \n&gt;\n&gt;Your use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/ \n&gt;\n&gt;\n&gt;  \n&gt;\n\n\n\n"}}