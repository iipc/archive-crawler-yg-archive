{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":191387937,"authorName":"pandae667","from":"&quot;pandae667&quot; &lt;aaron667@...&gt;","profile":"pandae667","replyTo":"LIST","senderId":"Nt7jvhMbYo_JBalctPF6qySF4HQU1bKorwIOLtym2991CJKD64UpId5ot1doIlUjEg9rirmBhWf3OpSatfdfNqcqfyDN","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: DecidingScope and SURTs","postDate":"1175277955","msgId":3994,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGV1amppMytudjU3QGVHcm91cHMuY29tPg==","inReplyToHeader":"PDk3Mzg1OEMyQURGRjVDNEY5OTQxNTc4NEY5MzkxQzA2MDE4NTEzQUNAZ2xnZXhjaGFuZ2UwNC5nbGdyb3VwLmNvbT4="},"prevInTopic":3993,"nextInTopic":0,"prevInTime":3993,"nextInTime":3995,"topicId":3988,"numMessagesInTopic":5,"msgSnippet":"Hi Tom Emerson, heritrix does allready provide everything you need to filter the stuff based upon content-type. The right place to do such things is as a ","rawEmail":"Return-Path: &lt;aaron667@...&gt;\r\nX-Sender: aaron667@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 90148 invoked from network); 30 Mar 2007 18:06:07 -0000\r\nReceived: from unknown (66.218.66.68)\n  by m26.grp.scd.yahoo.com with QMQP; 30 Mar 2007 18:06:07 -0000\r\nReceived: from unknown (HELO n19c.bullet.scd.yahoo.com) (66.218.67.207)\n  by mta11.grp.scd.yahoo.com with SMTP; 30 Mar 2007 18:06:07 -0000\r\nReceived: from [66.218.69.1] by n19.bullet.scd.yahoo.com with NNFMP; 30 Mar 2007 18:05:56 -0000\r\nReceived: from [66.218.66.88] by t1.bullet.scd.yahoo.com with NNFMP; 30 Mar 2007 18:05:56 -0000\r\nDate: Fri, 30 Mar 2007 18:05:55 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;eujji3+nv57@...&gt;\r\nIn-Reply-To: &lt;973858C2ADFF5C4F99415784F9391C06018513AC@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;pandae667&quot; &lt;aaron667@...&gt;\r\nSubject: Re: DecidingScope and SURTs\r\nX-Yahoo-Group-Post: member; u=191387937; y=3Mijlf1J08DnTo0WOaBCGRNpjO0nMlPbO4aWtf9JhgxMVQal\r\nX-Yahoo-Profile: pandae667\r\n\r\nHi Tom Emerson,\n\nheritrix does allready provide everything you need to filt=\r\ner the stuff\nbased upon content-type. The right place to do such things is =\r\nas a\nmidfetch-abort rule. A (deprecated) filter to do this job is included\n=\r\nin heritrix, a DecideRule to accomplish this tasks\n(ContentTypeMatchesRegEx=\r\npDecideRule) awaits inclusion and should be\npresent in forthcoming heritrix=\r\n-1.12.1.\nI provided it as [HER-1106] over at JIRA. (\nhttp://webteam.archive=\r\n.org/jira/browse/HER-1106 )\n\nRegards\n  Olaf Freyer\n\n--- In archive-crawler@=\r\nyahoogroups.com, &quot;Tom Emerson&quot; &lt;TEmerson@...&gt;\nwrote:\n&gt;\n&gt; Mike and Gordon,\n&gt;=\r\n  \n&gt; Thanks for the very helpful responses: I appreciate it. This all\nworke=\r\nd, for the most part :-)\n&gt;  \n&gt; After configuring things as Mike suggests, t=\r\nhe crawled stopped\nimmediately. The problem was that the first seed,\n&gt;  \n&gt; =\r\nhttp://foo.glgdev.com/\n&gt;  \n&gt; gets rejected because it doesn&#39;t end in .html!=\r\n I added a rule after\nthe rejectNonHtml that accepts URLs ending with &#39;/&#39;..=\r\n. not ideal, but\nit got me off the ground so I could test other things. I t=\r\nhink what I\nreally want to do is use the contributed decide rule that looks=\r\n at\ncontent-type instead of relying on the path.\n&gt;  \n&gt; Gordon: you&#39;re right=\r\n, of course, about the use of the suffix and the\npossibility of missing con=\r\ntent that is valid (i.e., foo.aspx, foo.php,\netc.). For the purposes of the=\r\n crawl at hand, since this is an\ninternal site, I have more control over th=\r\ne suffixes I&#39;m going to see\nand can filter appropriately. But in the genera=\r\nl case relying on\nextension to *include* files is problematical.\n&gt;  \n&gt; Than=\r\nks again for your help, as always.\n&gt;  \n&gt;     -tree\n&gt;  \n&gt; \n&gt; \n&gt;  \n&gt; This e-m=\r\nail message, and any attachments, is intended only for the\nuse of the indiv=\r\nidual or entity identified in the alias address of\nthis message and may con=\r\ntain information that is confidential,\nprivileged and subject to legal rest=\r\nrictions and penalties regarding\nits unauthorized disclosure and use. Any u=\r\nnauthorized review, copying,\ndisclosure, use or distribution is strictly pr=\r\nohibited. If you have\nreceived this e-mail message in error, please notify =\r\nthe sender\nimmediately by reply e-mail and delete this message, and any\natt=\r\nachments, from your system. Thank you. \n&gt; \n&gt; ______________________________=\r\n__\n&gt; \n&gt; \n&gt; From: archive-crawler@yahoogroups.com\n[mailto:archive-crawler@ya=\r\nhoogroups.com] On Behalf Of Michael Magin\n&gt; Sent: Thursday, March 29, 2007 =\r\n4:57 PM\n&gt; To: archive-crawler@yahoogroups.com\n&gt; Subject: Re: [archive-crawl=\r\ner] DecidingScope and SURTs\n&gt; \n&gt; \n&gt; \n&gt; Tom Emerson wrote:\n&gt; \n&gt; &gt; How should=\r\n I go about figuring out what I&#39;m doing wrong. The order of \n&gt; &gt; decide rul=\r\nes is:\n&gt; &gt; \n&gt; &gt; rejectByDefault\n&gt; &gt; acceptIfSurtPrefixed\n&gt; &gt; rejectIfTooMan=\r\nyHops\n&gt; &gt; acceptIfTranscluded\n&gt; &gt; rejectIfPathological\n&gt; &gt; rejectIfTooManyP=\r\nathSegs\n&gt; &gt; acceptHtmlOnly &lt;--- MatchesRegExpDecideRule with regexp .*(?i)&#92;=\r\n.html?\n&gt; &gt; acceptIfPrerequisite\n&gt; &gt; \n&gt; &gt; Not only do I seem to be getting n=\r\non-HTML files (which I thought\nwould \n&gt; &gt; be filtered with the regexp decid=\r\ne rule) but I&#39;m getting stuff\noutside \n&gt; &gt; my SURTs.\n&gt; &gt; \n&gt; &gt; Should the ac=\r\nceptIfSurtPrefixed be moved below the others? Perhaps \n&gt; &gt; acceptIfTransclu=\r\nded is overriding the setting?\n&gt; \n&gt; These rules are tested in order -- if y=\r\nou really want to be certain you \n&gt; don&#39;t go beyond the SURT scope at all, =\r\ndon&#39;t have any other ACCEPT\nrules \n&gt; after the acceptIfSurtPrefixed (except=\r\n the acceptIfPrerequisite --\nwhich \n&gt; makes sure that the crawler will be a=\r\nble to get DNS and robots.txt \n&gt; prereqs.) Specifically, acceptIfTransclude=\r\nd is probably allowing a \n&gt; number of off-site images/redirects/etc to be f=\r\netched, even though they \n&gt; are outside of the exact SURT scope.\n&gt; \n&gt; Also,=\r\n if you want HTML _ONLY_, you probably want to change that rule to \n&gt; a rul=\r\ne that REJECTs if NotMatchesRegExpDecideRule with regexp \n&gt; .*(?i)&#92;.html? T=\r\nhe rule you have will merely accept anything matching \n&gt; that, it won&#39;t cha=\r\nnge the ACCEPT/REJECT result for things that do\nnot match.\n&gt; \n&gt; So, I think=\r\n you might be looking for something like:\n&gt; rejectByDefault\n&gt; acceptIfSurtP=\r\nrefixed\n&gt; rejectIfTooManyHops\n&gt; rejectIfPathological\n&gt; rejectIfTooManyPathS=\r\negs\n&gt; rejectNonHTML &lt;--- NotMatchesRegExpDecideRule with regexp .*(?i)&#92;.htm=\r\nl?\n&gt; acceptIfPrerequisite\n&gt; \n&gt; Mike\n&gt;\n\n\n\n"}}