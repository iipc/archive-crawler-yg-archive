{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"MA_V_HJoEXiBSukc9IChFb4kVA9Cx1sf1TbZtkVFiJoH1wedeEJQ3eccQ5zl1PHfjICty4Uorn5LBJ_bxNJcJDNpzcwg8bg","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] Heritrix 3 : How to enable the Javascript engine in DOM building","postDate":"1318275051","msgId":7344,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRFOTM0N0VCLjQwOTAzMDFAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGo2dDJvcyttYzBiQGVHcm91cHMuY29tPg==","referencesHeader":"PGo2dDJvcyttYzBiQGVHcm91cHMuY29tPg=="},"prevInTopic":7343,"nextInTopic":7346,"prevInTime":7343,"nextInTime":7345,"topicId":7343,"numMessagesInTopic":3,"msgSnippet":"... The Javascript support currently in H3 is only: • scanning Javascript resources (and  areas) for likely URIs using crude regex-based heuristics","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 78651 invoked from network); 10 Oct 2011 19:30:55 -0000\r\nX-Received: from unknown (98.137.34.45)\n  by m15.grp.sp2.yahoo.com with QMQP; 10 Oct 2011 19:30:55 -0000\r\nX-Received: from unknown (HELO relay03.pair.com) (209.68.5.17)\n  by mta2.grp.sp2.yahoo.com with SMTP; 10 Oct 2011 19:30:55 -0000\r\nX-Received: (qmail 18768 invoked by uid 0); 10 Oct 2011 19:30:52 -0000\r\nX-Received: from 76.218.213.38 (HELO silverbook.local) (76.218.213.38)\n  by relay03.pair.com with SMTP; 10 Oct 2011 19:30:52 -0000\r\nX-pair-Authenticated: 76.218.213.38\r\nMessage-ID: &lt;4E9347EB.4090301@...&gt;\r\nDate: Mon, 10 Oct 2011 12:30:51 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:6.0.2) Gecko/20110902 Thunderbird/6.0.2\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;j6t2os+mc0b@...&gt;\r\nIn-Reply-To: &lt;j6t2os+mc0b@...&gt;\r\nContent-Type: text/plain; charset=windows-1252; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Heritrix 3 : How to enable the Javascript engine\n in DOM building\r\nX-Yahoo-Group-Post: member; u=137285340; y=vO-H8jqkJQn9dUvGNLOCnba67iaFLwNJUFBshWL2f0aF\r\nX-Yahoo-Profile: gojomo\r\n\r\nOn 10/9/11 2:13 PM, paul.ihde wrote:\n&gt; Hi,\n&gt;\n&gt; I understood that Heritrix 3 has Javascript support. As such I&#39;m\n&gt; wondering if it&#39;s possible (and anyone actually has experience with\n&gt; that) to crawl the pages with javascript enabled?\n&gt;\n&gt; By Javascript support I mean : behaving like a browser with\n&gt; decent/standard javascript capabilities. As such all the pages that\n&gt; are crawled would be first (before the HTML link extraction) loaded\n&gt; in a Webkit like environment and then once the javascript code is\n&gt; loaded and finished running =&gt;  the DOM is builded. Once this is done\n&gt; the HTML extractor kicks in and continues the crawl.\n&gt;\n&gt; I know that Heritrix 3 has support for extracting URL&#39;s from JS code\n&gt; and I understood how that works. But that doesn&#39;t help to much if an\n&gt; AJAX request has to be done/finished for the DOM to be complete.\n\nThe &#39;Javascript support&#39; currently in H3 is only:\n\n� scanning Javascript resources (and &lt;SCRIPT&gt; areas) for likely URIs \nusing crude regex-based heuristics\n\n� the ability to use Javascript as a scripting language to implement \nProcessors/DecideRules or run operator scripts in the control console\n\nThere&#39;s not yet the ability to simulate a real browser DOM, and things \nlike AJAX requests to new URIs as a result of executed Javascript.\n\nThere are two main ways that could eventually be achieved:\n\n� embed a mock browser into the crawling process, using something like \nthe java HtmlUnit library -- which is apparently good enough that it can \ntest pages using major Javascript AJAX libraries and pages created by \nGoogle&#39;s GWT toolkit\n\n� use an actual browser that&#39;s been configured to visit and exercise \npages based on external triggers. Again, the tools from the testing \nworld have led the way here, and some crawls at the Internet Archive go \nthrough an automated QA process that as a side-effect fills gaps left by \nthe limited javascript support in Heritrix.\n\nIn both cases, a major choice to be made is how the many fetches \nrequired to complete the entire DOM/loaded-page/AJAX-modified-page \nshould be handled with respect to the traditional [fetch-1-URI, \ndiscover-many-URIs, enqueue, repeat] loop. Some of the possible \nalternatives there include:\n\n� let the component (HtmlUnit or external browser) do all its own \nfetching; decide separately whether those fetches are independently \narchived (they wouldn&#39;t all go through all queuing/Processing steps)\n\n� stall the browser-simulation while waiting for followup fetches \n(inline &lt;SCRIPT SRC=&gt;, AJAX) to go through the normal queue-fetch loop, \nthough perhaps at high priority)\n\n� have both the crawler and the extracting-browser go through a caching \nproxy that allows each to be somewhat less complex, within some \ntime-window, about whether the URIs they need have already been \nrecently/redundantly fetched by the other component.\n\nEach of these choices could have different effects on whether the same \nURIs are redundantly fetched/stored many times, whether the archived \nresource set is identical to what was used to discover URIs, and whether \nthe archived/used set of URIs really matches the tight associations a \nreal human-driven browser would have seen.\n\nSome projects at the Archive are working on this, but there&#39;s not yet \nany target dates/releases where a solution will become a standard \n&#39;out-of-the-box&#39; part of Heritrix.\n\n- Gordon\n\n"}}