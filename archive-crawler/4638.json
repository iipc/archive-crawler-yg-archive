{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":194872127,"authorName":"hinoglu","from":"&quot;hinoglu&quot; &lt;hinoglu@...&gt;","profile":"hinoglu","replyTo":"LIST","senderId":"RUn9rYKDxJVn9nmY7ur79JpnSlcAocBEOonHiGpck1YkLzrP8qe4i7VGdCRqs2-d4995uy7Ut2HvYOYwRkLF7WrOiHs","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: java.lang.OutOfMemoryError: GC overhead limit exceeded","postDate":"1193692318","msgId":4638,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZnNWlhdSs5ODI3QGVHcm91cHMuY29tPg==","inReplyToHeader":"PDQ3MjYzQjEzLjkwNDA1MDRAYXJjaGl2ZS5vcmc+"},"prevInTopic":4636,"nextInTopic":4640,"prevInTime":4637,"nextInTime":4639,"topicId":4629,"numMessagesInTopic":9,"msgSnippet":"hi, sorry i had some more details in the previous mail, but 65k mail limit rip them off. ... i m using version 1.12.1 on tomcat-6.0.14, jdk-1.6.0_2, running on","rawEmail":"Return-Path: &lt;hinoglu@...&gt;\r\nX-Sender: hinoglu@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 56601 invoked from network); 29 Oct 2007 21:11:58 -0000\r\nX-Received: from unknown (66.218.67.95)\n  by m46.grp.scd.yahoo.com with QMQP; 29 Oct 2007 21:11:58 -0000\r\nX-Received: from unknown (HELO n47c.bullet.mail.sp1.yahoo.com) (66.163.168.181)\n  by mta16.grp.scd.yahoo.com with SMTP; 29 Oct 2007 21:11:58 -0000\r\nX-Received: from [216.252.122.217] by n47.bullet.mail.sp1.yahoo.com with NNFMP; 29 Oct 2007 21:11:58 -0000\r\nX-Received: from [66.218.69.1] by t2.bullet.sp1.yahoo.com with NNFMP; 29 Oct 2007 21:11:58 -0000\r\nX-Received: from [66.218.66.84] by t1.bullet.scd.yahoo.com with NNFMP; 29 Oct 2007 21:11:58 -0000\r\nDate: Mon, 29 Oct 2007 21:11:58 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;fg5iau+9827@...&gt;\r\nIn-Reply-To: &lt;47263B13.9040504@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;hinoglu&quot; &lt;hinoglu@...&gt;\r\nSubject: Re: java.lang.OutOfMemoryError: GC overhead limit exceeded\r\nX-Yahoo-Group-Post: member; u=194872127; y=rA6X0dbz1mD4Fc9Jou_7vHUpL2JwIej-DfqgA8wPn6ngqA\r\nX-Yahoo-Profile: hinoglu\r\n\r\nhi, sorry i had some more details in the previous mail, \nbut 65k mail limit=\r\n rip them off. \n\n--- In archive-crawler@yahoogroups.com, Gordon Mohr &lt;gojom=\r\no@...&gt; wrote:\n&gt;\n&gt; What version of Heritrix are you using? 1.12.1 has fixes =\r\nthat would be \n\ni&#39;m using version 1.12.1 on tomcat-6.0.14, jdk-1.6.0_2, run=\r\nning on\nlinux 2.6.18 with 2 gbs of ram.\n\n&gt; \n&gt; Also remember that every craw=\r\nl creates its own BerkeleyDB-JE \n&gt; environment, and each such environment t=\r\nries to limit its cache by \n&gt; default to using 60% of the total heap. So, i=\r\nf you leave this\ndefault in \n&gt; place, and launch 2 simultaneous crawls, the=\r\nir environments will\nseek to \n&gt; limit themselves to 120% of the heap -- alm=\r\nost guaranteed to cause \n&gt; problems unless the crawls wrap up very quickly.=\r\n\n\nhm i&#39;ve got most of the settings untouched, should&#39;ve read the\ninstructio=\r\nns better :( i&#39;ll try again by setting the bdb heap around \n20-25%, but aga=\r\nin it seems that: if i have 5-6 instances at the same\ntime(since i have aro=\r\nund 20 sites to crawl), then i&#39;ll probably have\nsome troubles. so, what wou=\r\nld be the optimum setting for this value?\n\n&gt; \n&gt; The size and number of &#39;set=\r\ntings&#39;-related instances in your &#39;jmap \n&gt; -histo&#39; output caught my eye. Are=\r\n you making extensive use of\nper-domain \n&gt; overrides?\n\ni&#39;m not sure if i go=\r\nt it right, so let me explain my crawling process. \ni have around 20 wap an=\r\nd web sites to crawl, and for the process i\n have created 5 profiles with d=\r\nifferent user-agent and cookie\nsettings. according to the periodsi, crawlin=\r\ng processes are\n automatically started with a script that uses the jmx comm=\r\nandline\n client.  \n\ndata per site is around 50mb&#39;s at most, consisting of \n=\r\nthousands of tiny files and urls.\n\nwhen the crawling process is ended, the =\r\nsame script destroys the \ninstance related with the process using the destr=\r\noy command via jmx\nclient.\nif i get it right, yes it seems i&#39;m making exten=\r\nsive use of per-domain\noverrides.. any suggestions about a better solution =\r\nfor this scenario?\n\n\n\n"}}