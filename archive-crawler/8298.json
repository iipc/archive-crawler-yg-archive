{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":546562328,"authorName":"bobbyledingo","from":"&quot;bobbyledingo&quot; &lt;pierz@...&gt;","profile":"bobbyledingo","replyTo":"LIST","senderId":"bW-sVVQbvkmH4gaMT6_tEMhoXjEl8ZuotmVlc09OzkckqJQldlVFM4o2yquZjH-MEKs3rUC2Qg_zBQIhhU3GhijMCrAIPBnauK0jFQ","spamInfo":{"isSpam":false,"reason":"3"},"subject":"Re: Url ordering/prerequisite : fetch the root url first","postDate":"1376073015","msgId":8298,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGt1M2Nmbitxb3I0QGVHcm91cHMuY29tPg==","inReplyToHeader":"PDUwQkU5QjU1LjYwMTA2MDhAYXJjaGl2ZS5vcmc+"},"prevInTopic":7865,"nextInTopic":0,"prevInTime":8297,"nextInTime":8299,"topicId":7864,"numMessagesInTopic":3,"msgSnippet":"Hello, It worked with ExtractorHttp + inferRoot parameter but didn t like the solution because it needed to fetch /a/b/c.html to infer root / So I try with a","rawEmail":"Return-Path: &lt;pierz@...&gt;\r\nX-Sender: pierz@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 47392 invoked by uid 102); 9 Aug 2013 18:30:17 -0000\r\nX-Received: from unknown (HELO mtaq6.grp.bf1.yahoo.com) (10.193.84.37)\n  by m5.grp.bf1.yahoo.com with SMTP; 9 Aug 2013 18:30:17 -0000\r\nX-Received: (qmail 30154 invoked from network); 9 Aug 2013 18:30:17 -0000\r\nX-Received: from unknown (HELO ng8-vm10.bullet.mail.gq1.yahoo.com) (98.136.219.101)\n  by mtaq6.grp.bf1.yahoo.com with SMTP; 9 Aug 2013 18:30:17 -0000\r\nX-Received: from [216.39.60.220] by ng8.bullet.mail.gq1.yahoo.com with NNFMP; 09 Aug 2013 18:30:17 -0000\r\nX-Received: from [10.193.94.106] by tg12.bullet.mail.gq1.yahoo.com with NNFMP; 09 Aug 2013 18:30:16 -0000\r\nDate: Fri, 09 Aug 2013 18:30:15 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;ku3cfn+qor4@...&gt;\r\nIn-Reply-To: &lt;50BE9B55.6010608@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 2:3:4:0:0\r\nFrom: &quot;bobbyledingo&quot; &lt;pierz@...&gt;\r\nSubject: Re: Url ordering/prerequisite : fetch the root url first\r\nX-Yahoo-Group-Post: member; u=546562328; y=q1pfkN-Wx2zL-jY_cugOJ10zRibXfhagwlMW4tkrRhOjxIYUjRoNLlq2xd7zYwI\r\nX-Yahoo-Profile: bobbyledingo\r\n\r\nHello,\n\nIt worked with ExtractorHttp + inferRoot parameter but didn&#39;t like =\r\nthe solution because it needed to fetch /a/b/c.html to infer root /\n\nSo I t=\r\nry with a custom extractor triggered on robots.txt fetch, but it didn&#39;t wor=\r\nked. Looking at the log, the ImpliedURIExtractor.extract() is called but I =\r\nsee nothing in the scope.log/crawl.log\n\nthe code : http://pastebin.com/CBpM=\r\n7qYd\n\n\nI also try with a more complex solution, using a precondition class,=\r\n like PreconditionEnforcer (where it handles robots.txt and dns resolve). B=\r\nut It doesn&#39;t works too, it mark the root url -50 in the crawl.log and stop=\r\n the crawl...\n\nthe code : http://pastebin.com/farRCFVL\n\n\n\n\n\n--- In archive-=\r\ncrawler@yahoogroups.com, Gordon Mohr &lt;gojomo@...&gt; wrote:\n&gt;\n&gt; On 12/3/12 4:2=\r\n6 AM, bobbyledingo wrote:\n&gt; &gt; Hi,\n&gt; &gt;\n&gt; &gt; Each time heritrix extract the ou=\r\ntlinks of a document, if it discover\n&gt; &gt; a link like http://www.domain.com/=\r\na/b/c.html I would like to create\n&gt; &gt; some dependency/prerequisite like for=\r\ncing heritrix to always fetch\n&gt; &gt; the root url (eg http://www.domain.com/) =\r\nbefore the found url (if it\n&gt; &gt; has not been crawled previously).\n&gt; &gt;\n&gt; &gt; S=\r\no my goal is to always crawl the root url (http://www.domain.com)\n&gt; &gt; for a=\r\nll new website I discover, before fetching any deeper urls.\n&gt; &gt;\n&gt; &gt; I think=\r\n the way to increase/decrease priority is by using\n&gt; &gt; UriPrecedencePolicy,=\r\n but I don&#39;t know how and when to insert/schedule\n&gt; &gt; the &quot;fetch that root =\r\nurl&quot; prerequisite...\n&gt; \n&gt; You won&#39;t need to use the &#39;precedence policy&#39; fac=\r\nility, unless you need \n&gt; to do fine-grained prioritization, with many tier=\r\ns.\n&gt; \n&gt; There is an existing option to automatically infer that the root pa=\r\nge of \n&gt; every discovered URI should also sent to the frontier for crawling=\r\n. It&#39;s \n&gt; the &#39;inferRootPage&#39; parameter (default false) on the &#39;ExtractorHT=\r\nTP&#39; \n&gt; component. If &#39;true&#39;, every URI crawled will be presumed to have an =\r\n\n&gt; implied outlink to the root URI of the same domain. So, the root URI \n&gt; =\r\nwill be presented to the frontier along with an other outlinks on the \n&gt; pa=\r\nge, and enqueued if novel.\n&gt; \n&gt; Unfortunately this only acts when the trigg=\r\nering HTTP URI is fetched \n&gt; (and thus the ExtractorHTTP component is run, =\r\nalong with the other \n&gt; extractors, on some response). And, this &#39;inferred&#39;=\r\n root URI is given a \n&gt; discovery hop-type of &#39;I&#39; -- this mixes it with oth=\r\ner inline-like items, \n&gt; so it will be crawled *before* other navigational =\r\noutlinks (&quot;A HREF&quot; - \n&gt; hop-type &#39;L&#39;) on the same page, but mixed in with (=\r\nand perhaps after) \n&gt; other transitive outlinks (&quot;IMG SRC&quot;, &quot;FRAME SRC&quot;, et=\r\nc).\n&gt; \n&gt; Perhaps this is good enough - the root page will be fetched very e=\r\narly \n&gt; among a site&#39;s pages, but not necessarily &#39;first&#39;.\n&gt; \n&gt; If that isn=\r\n&#39;t enough, you&#39;ll have to write some custom code. I think the \n&gt; best appro=\r\nach would be to write something like the ExtractorHTTP, or \n&gt; ImpliedURIExt=\r\nractor, but triggering off an earlier step. You wouldn&#39;t \n&gt; have to write t=\r\nhis new behavior in a compiled Java class; using the \n&gt; ScriptedProcessor, =\r\nyou could supply a javascript/groovy/beanshell script \n&gt; as text, inside yo=\r\nur crawl configuration\n&gt; \n&gt; I would suggest this script look for the domain=\r\n&#39;s /robots.txt URI fetch. \n&gt; (That&#39;s always triggered, via an explicit prer=\r\nequisite mechanism, before \n&gt; any other URIs from a domain are fetched.) Wh=\r\nen it sees such a fetch, it \n&gt; could add the root page as an inferred outli=\r\nnk, just like ExtractorHTTP \n&gt; does. But, it would also give it an addition=\r\nal marking to promote it \n&gt; ahead of other URIs already on the same domain =\r\nqueue. Using \n&gt; CrawlURI.setSchedulingDirective(SchedulingConstants.HIGH) o=\r\nn that \n&gt; outlink CrawlURI would probably do the trick.\n&gt; \n&gt; - Gordon\n&gt;\n\n\n\n"}}