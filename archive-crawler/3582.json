{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"3u5MhW47WxdPE53px-FIqm0h_tf-OiL7dQXFH9G_MvWK01ffx82MqrqJLkJO5f_0SQjqDcBjJDz_8qfmdzCHRpSy0eSqV38","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] How to stop filtering of already seen URIs based on previous fetch status code?","postDate":"1165611083","msgId":3582,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ1NzlEMDRCLjEwMTA0QGFyY2hpdmUub3JnPg==","inReplyToHeader":"PGVsY2JyaytmN2g2QGVHcm91cHMuY29tPg==","referencesHeader":"PGVsY2JyaytmN2g2QGVHcm91cHMuY29tPg=="},"prevInTopic":3581,"nextInTopic":3588,"prevInTime":3581,"nextInTime":3583,"topicId":3580,"numMessagesInTopic":5,"msgSnippet":"... As Stack notes, this should work. The force-fetch flag means to ignore the already-included status. However, it doesn t ignore scoping -- are you sure","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 17775 invoked from network); 8 Dec 2006 20:51:27 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m40.grp.scd.yahoo.com with QMQP; 8 Dec 2006 20:51:27 -0000\r\nReceived: from unknown (HELO relay00.pair.com) (209.68.5.9)\n  by mta5.grp.scd.yahoo.com with SMTP; 8 Dec 2006 20:51:27 -0000\r\nReceived: (qmail 80132 invoked from network); 8 Dec 2006 20:51:19 -0000\r\nReceived: from 207.241.238.245 (HELO ?10.11.12.108?) (207.241.238.245)\n  by relay00.pair.com with SMTP; 8 Dec 2006 20:51:19 -0000\r\nX-pair-Authenticated: 207.241.238.245\r\nMessage-ID: &lt;4579D04B.10104@...&gt;\r\nDate: Fri, 08 Dec 2006 12:51:23 -0800\r\nUser-Agent: Thunderbird 1.5.0.8 (Windows/20061025)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;elcbrk+f7h6@...&gt;\r\nIn-Reply-To: &lt;elcbrk+f7h6@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] How to stop filtering of already seen URIs\n based on previous fetch status code?\r\nX-Yahoo-Group-Post: member; u=137285340; y=2Y1x9yvwNAJQ2qPM8wazDwHj4HuBuxvU72HN7fa8y1-m\r\nX-Yahoo-Profile: gojomo\r\n\r\nastar_t wrote:\n&gt; Hi, I&#39;m running a crawl where initially some URIs were rejected by a \n&gt; DecideRule that was added by mistake.  So the URIs show up in the \n&gt; crawl.log as having a -5000 fetch code.  However, I have realized that \n&gt; I would actually like to crawl a subset of these URIs that have already \n&gt; been rejected.  \n&gt; \n&gt; So I tried to import the URIs back into the frontier with force fetch \n&gt; via JMX cmdline but they are not being fetched.  I&#39;m assuming this is \n&gt; because they are &quot;already seen&quot; URIs so the BdbUriUniqFilter is \n&gt; ignoring them.\n&gt; \n&gt; Is there a way I can force Heritrx to retry a fetch of the URIs that \n&gt; previously had a -5000 code ?\n\nAs Stack notes, this should work. The &#39;force-fetch&#39; flag means to ignore \nthe already-included status. However, it doesn&#39;t ignore scoping -- are \nyou sure the URIs, as added, would be ruled in-scope?\n\n(Are they appearing anywhere after your force-fetch add -- in the \nfrontier report, in the crawl.log, etc.?)\n\n- Gordon @ IA\n\n"}}