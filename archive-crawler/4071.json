{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"tcGy0ytKnrl_zVcMZb5hESw9fYO3aTujL6V8XL2ocHPkIJQqqlVuJJqUoc7q4I3yQ8Apimrlr_5g8-io1N1HVodYJGT8aM0","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] user agent","postDate":"1176145539","msgId":4071,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ2MUE4RTgzLjcwMjAzMDRAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDVhMWMzNGFhMDcwNDA5MTEyMmc1NjFhMGM0MnA1OWM4Zjg1YjhmMTVhNTAzQG1haWwuZ21haWwuY29tPg==","referencesHeader":"PDVhMWMzNGFhMDcwNDA5MDg0MXM0M2QzNDhjN2o5NmUzYzMxMjI1NjE5NWRiQG1haWwuZ21haWwuY29tPgkgPDQ2MUE3MzQxLjIwMzA1MDhAYXJjaGl2ZS5vcmc+IDw0NjFBODE2OS45MDYwMDAwQGFyY2hpdmUub3JnPiA8NWExYzM0YWEwNzA0MDkxMTIyZzU2MWEwYzQycDU5YzhmODViOGYxNWE1MDNAbWFpbC5nbWFpbC5jb20+"},"prevInTopic":4070,"nextInTopic":0,"prevInTime":4070,"nextInTime":4072,"topicId":4066,"numMessagesInTopic":6,"msgSnippet":"... The original 1994 robots.txt is silent on what should happen if more than one robots.txt record (set of rules) matches a robot s User-Agent (via the","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 76970 invoked from network); 9 Apr 2007 19:05:54 -0000\r\nReceived: from unknown (66.218.67.33)\n  by m28.grp.scd.yahoo.com with QMQP; 9 Apr 2007 19:05:54 -0000\r\nReceived: from unknown (HELO mail.archive.org) (207.241.233.246)\n  by mta7.grp.scd.yahoo.com with SMTP; 9 Apr 2007 19:05:54 -0000\r\nReceived: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id 4AE4D141C6E69\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Mon,  9 Apr 2007 12:03:12 -0700 (PDT)\r\nReceived: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id 02391-09-39 for &lt;archive-crawler@yahoogroups.com&gt;;\n\tMon, 9 Apr 2007 12:03:11 -0700 (PDT)\r\nReceived: from [192.168.1.203] (c-76-102-230-209.hsd1.ca.comcast.net [76.102.230.209])\n\tby mail.archive.org (Postfix) with ESMTP id D68D9141C6D0D\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Mon,  9 Apr 2007 12:03:11 -0700 (PDT)\r\nMessage-ID: &lt;461A8E83.7020304@...&gt;\r\nDate: Mon, 09 Apr 2007 12:05:39 -0700\r\nUser-Agent: Thunderbird 1.5.0.10 (X11/20070306)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;5a1c34aa0704090841s43d348c7j96e3c312256195db@...&gt;\t &lt;461A7341.2030508@...&gt; &lt;461A8169.9060000@...&gt; &lt;5a1c34aa0704091122g561a0c42p59c8f85b8f15a503@...&gt;\r\nIn-Reply-To: &lt;5a1c34aa0704091122g561a0c42p59c8f85b8f15a503@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Virus-Scanned: Debian amavisd-new at archive.org\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] user agent\r\nX-Yahoo-Group-Post: member; u=137285340; y=I3XbWJIsQQSG8O3D1SKfuuAbrfpyvC58cMr6spH5KS0r\r\nX-Yahoo-Profile: gojomo\r\n\r\nAndrea Goethals wrote:\n&gt; Thanks for the clarifications. As a future enhancement maybe we should\n&gt; iterate through the list of user agents from the robots.txt file and look\n&gt; for the best match instead of the first match.\n\nThe original 1994 robots.txt is silent on what should happen if more \nthan one robots.txt &#39;record&#39; (set of rules) matches a robot&#39;s User-Agent \n(via the substring-testing). However, the 1996 draft\n(&lt;http://www.robotstxt.org/wc/norobots-rfc.html&gt;) states:\n\n&quot;The robot must obey the first record in /robots.txt that contains a \nUser-Agent line whose value contains the name token of the robot as a \nsubstring.&quot;\n\nSo defining any other kind of &quot;best&quot; match other than &quot;first&quot; (such as \n&quot;longest substring&quot;) could clash with current practice relying on the \n1996 draft.\n\n- Gordon @ IA\n\n&gt; thanks,\n&gt; Andrea\n&gt; \n&gt; On 4/9/07, Michael Stack &lt;stack@...&gt; wrote:\n&gt;&gt;\n&gt;&gt;   On a re-reading of code -- prompted by a kick from our Igor -- Heritrix\n&gt;&gt; is doing as you first suppose in your message below: If &#39;bot1&#39; is the\n&gt;&gt; User-agent and in Heritrix, the User-agent string is &#39;Mozilla/5.0\n&gt;&gt; (compatible; bot1 +http://myUrl)&#39;, then Heritrix will read the\n&gt;&gt; subsequent allows/disallows as referring to it.\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; http://crawler.archive.org/xref/org/archive/crawler/datamodel/Robotstxt.html#38 \n&gt;&gt;\n&gt;&gt; is where we parse the robots.txt.\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; http://crawler.archive.org/xref/org/archive/crawler/datamodel/RobotsExclusionPolicy.html#147 \n&gt;&gt;\n&gt;&gt; &lt;\n&gt;&gt; http://crawler.archive.org/xref/org/archive/crawler/datamodel/RobotsExclusionPolicy.html#147,&gt; \n&gt;&gt;\n&gt;&gt;\n&gt;&gt; on line 166 is where we look into the Heritrix user-agent for any\n&gt;&gt; instance of what is specified on a User-agent line in robots.txt.\n&gt;&gt;\n&gt;&gt; Sorry for any confusion.\n&gt;&gt;\n&gt;&gt; St.Ack\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; Michael Stack wrote:\n&gt;&gt; &gt;\n&gt;&gt; &gt; Looks like Heritrix is doing exact matches of string that follows\n&gt;&gt; &gt; &#39;User-agent: &#39; in robots.txt. See\n&gt;&gt; &gt;\n&gt;&gt; http://crawler.archive.org/xref/org/archive/crawler/datamodel/Robotstxt.html#38 \n&gt;&gt;\n&gt;&gt; &gt; &lt;\n&gt;&gt; http://crawler.archive.org/xref/org/archive/crawler/datamodel/Robotstxt.html#38&gt; \n&gt;&gt;\n&gt;&gt;\n&gt;&gt; &gt;\n&gt;&gt; &gt; for where we do the parse and then here,\n&gt;&gt; &gt;\n&gt;&gt; http://crawler.archive.org/xref/org/archive/crawler/datamodel/RobotsExclusionPolicy.html#147, \n&gt;&gt;\n&gt;&gt; &gt; &lt;\n&gt;&gt; http://crawler.archive.org/xref/org/archive/crawler/datamodel/RobotsExclusionPolicy.html#147,&gt; \n&gt;&gt;\n&gt;&gt;\n&gt;&gt; &gt;\n&gt;&gt; &gt; for the check of whats disallowed.\n&gt;&gt; &gt;\n&gt;&gt; &gt; St.Ack\n&gt;&gt; &gt;\n&gt;&gt; &gt; Andrea Goethals wrote:\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt; Hello,\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt; Does heritrix do any &quot;liberal-reading&quot; of robots.txt files when\n&gt;&gt; &gt; &gt; determining if a user agent specified in it is referring to it or \n&gt;&gt; does\n&gt;&gt; &gt; &gt; it take the user agent we configure for it as is?\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt; For example, if a robots.txt file says\n&gt;&gt; &gt; &gt; User-agent: bot1\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt; and we configure our user agent as:\n&gt;&gt; &gt; &gt; Mozilla/5.0 (compatible; bot1 +http://myUrl)\n&gt;&gt; &gt; &gt; will the crawler interpret the bot1 user-agent specified in the file\n&gt;&gt; &gt; &gt; as referring to it?\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt; Or do we need to specify our user agent like:\n&gt;&gt; &gt; &gt; bot1 (+http://myUrl)\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt; thanks,\n&gt;&gt; &gt; &gt; Andrea\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt; &gt;\n&gt;&gt; &gt;\n&gt;&gt; &gt;\n&gt;&gt;\n&gt;&gt;  \n&gt;&gt;\n&gt; \n\n\n"}}