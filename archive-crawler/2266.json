{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":219074861,"authorName":"swamikrish2001","from":"&quot;swamikrish2001&quot; &lt;swamikrish2001@...&gt;","profile":"swamikrish2001","replyTo":"LIST","senderId":"h_FWzS9wfY1VENRk8sa7jSfanQDMEbPNMB851_8V3OzyV4sxr4S2Tt-miGmc7wGvE2AqLwHKgVR80aipw5TH-ZtvP9rL0-uQlX2JpB2WWTrteA","spamInfo":{"isSpam":false,"reason":"12"},"subject":"hi,the seed is not being crawled after dns/.txt file-please help","postDate":"1129900811","msgId":2266,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGRqYXB1YytjZW9qQGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":2275,"prevInTime":2265,"nextInTime":2267,"topicId":2266,"numMessagesInTopic":2,"msgSnippet":"Hi, I am extremely sorry for the inconvenience caused. I read the windows faq and I am still not able run the crawler and download the documents (trying for","rawEmail":"Return-Path: &lt;swamikrish2001@...&gt;\r\nX-Sender: swamikrish2001@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 37558 invoked from network); 21 Oct 2005 13:20:30 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m32.grp.scd.yahoo.com with QMQP; 21 Oct 2005 13:20:30 -0000\r\nReceived: from unknown (HELO n8a.bulk.scd.yahoo.com) (66.94.237.42)\n  by mta4.grp.scd.yahoo.com with SMTP; 21 Oct 2005 13:20:30 -0000\r\nComment: DomainKeys? See http://antispam.yahoo.com/domainkeys\r\nReceived: from [66.218.66.58] by n8.bulk.scd.yahoo.com with NNFMP; 21 Oct 2005 13:20:13 -0000\r\nReceived: from [66.218.66.71] by mailer7.bulk.scd.yahoo.com with NNFMP; 21 Oct 2005 13:20:13 -0000\r\nDate: Fri, 21 Oct 2005 13:20:11 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;djapuc+ceoj@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: &quot;swamikrish2001&quot; &lt;swamikrish2001@...&gt;\r\nSubject: hi,the seed is not being crawled after dns/.txt file-please help\r\nX-Yahoo-Group-Post: member; u=219074861; y=v6Se7G8PqML8hyaqiRfb-A3IVB_Ogv1z8M51CSlqAGuogiZkgTSRK7I\r\nX-Yahoo-Profile: swamikrish2001\r\n\r\nHi,\nI am extremely sorry for the inconvenience caused.\nI read the windows f=\r\naq and I am still not able run the crawler and \ndownload the documents (try=\r\ning for the past 2 days)and I would really \nappreciate  help on this regard=\r\n.\nWhen I set up the job with the user agent and url,even for open sites \nsu=\r\nch wikepedia or slshdot the crwler downloads a single dns/txt file \nand sto=\r\nps crawling.\nI dont know where I had gone wrong:\n\n1)i am using internet exp=\r\nlorer,is there any specific settings for \nthis ?,if so where should I chang=\r\ne ?\n\n2)The computer I am using goes through a proxy,i have set the proxy \ns=\r\netting in Heritrix settings,but still not able crawl and download.\n\n3)When =\r\ngoing to an external site my connection in the internal network \nasks for a=\r\n url and password,for the first time when opening the \nbrowser.Will this be=\r\n the problem?but when I see the log files,i get the \nmessage the crawler ha=\r\ns visited the page and from the page only got the \ntxt file.So where else w=\r\nould be the problem?or have I got the whole \nconcept wrong!\n\n4)For an earli=\r\ner mail on this regard I was asked to check the faq \nfile,but I had configu=\r\nred the batch file properly and my batch file is \nas follows:\nset HERITRIX_=\r\nHOME=3DD:/heritrix\n\nset CLASSPATH=3D%HERITRIX_HOME%/heritrix-1.4.0.jar;%\nHE=\r\nRITRIX_HOME%/lib/ant-1.6.2.jar;%HERITRIX_HOME%/lib/commons-cli-\n1.0.jar;%HE=\r\nRITRIX_HOME%/lib/commons-codec-1.3.jar;%\nHERITRIX_HOME%/lib/commons-collect=\r\nions-3.1.jar;%\nHERITRIX_HOME%/lib/commons-httpclient-3.0-beta1.jar;%\nHERITR=\r\nIX_HOME%/lib/commons-logging-1.0.4.jar;%\nHERITRIX_HOME%/lib/commons-net-1.1=\r\n.0.jar;%HERITRIX_HOME%/lib/commons-\npool-1.2.jar;%HERITRIX_HOME%/lib/concur=\r\nrent-1.3.2.jar;%\nHERITRIX_HOME%/lib/dnsjava-1.6.2.jar;%HERITRIX_HOME%/lib/d=\r\nsi-unimi-it-\n0.9.1.jar;%HERITRIX_HOME%/lib/itext-1.2.0.jar;%\nHERITRIX_HOME%=\r\n/lib/jasper-compiler-tomcat-4.1.30.jar;%\nHERITRIX_HOME%/lib/jasper-runtime-=\r\ntomcat-4.1.30.jar;%\nHERITRIX_HOME%/lib/javaswf-CVS-SNAPSHOT-1.jar;%HERITRIX=\r\n_HOME%/lib/je-\n1.7.1-12115_11552-2.jar;%HERITRIX_HOME%/lib/jetty-4.2.23.jar=\r\n;%\nHERITRIX_HOME%/lib/jmxri-1.2.1.jar;%HERITRIX_HOME%/lib/jmxtools-\n1.2.1.j=\r\nar;%HERITRIX_HOME%/lib/junit-3.8.1.jar;%HERITRIX_HOME%/lib/poi-\n2.0-RC1-200=\r\n31102.jar;%HERITRIX_HOME%/lib/poi-scratchpad-2.0-RC1-\n20031102.jar;%HERITRI=\r\nX_HOME%/lib/servlet-tomcat-4.1.30.jar\n\n\njava -Dheritrix.home=3DD:/heritrix =\r\n-Djava.ext.dirs=3DD:/heritrix/lib -\nXmx256m org.archive.crawler.Heritrix\n\n\n=\r\n\nhave made any mistake in the batch file configuration??\n\n5)When I run the =\r\nbatch file I get some warnings,are these the reasons \nbehing the crawler no=\r\nt working?\nthe messages on cmd.exe are as follows:\n\n3:04:08.561 EVENT  Star=\r\nting Jetty/4.2.23\n3:04:08.952 WARN!! Delete existing temp dir C:&#92;DOCUME~1&#92;1=\r\n27924&#92;LOCALS~1\n&#92;Temp&#92;\nty__8080__ for WebApplicationContext\n[/,jar:file:/D:/=\r\nheritrix/webapps/admin.wa\n]\n3:04:09.296 EVENT  Started WebApplicationContex=\r\nt[/,Heritrix Console]\n3:04:09.967 EVENT  Started SocketListener on 0.0.0.0:=\r\n8080\n3:04:09.967 EVENT  Started org.mortbay.jetty.Server@de6f34\n0/21/2005 1=\r\n3:04:11 +0000 WARNING \norg.archive.crawler.settings.CrawlSettingsSA\nndler$S=\r\nimpleElementHandler endElement Unknown attribute &#39;10.237.3.28&#39; \nin &#39;fil\nD:/=\r\nheritrix/conf/profiles/krish/order.xml&#39;, line: 129, column: 45\n0/21/2005 13=\r\n:04:11 +0000 WARNING \norg.archive.crawler.settings.CrawlSettingsSA\nndler$Si=\r\nmpleElementHandler endElement Unknown attribute &#39;6050&#39; \nin &#39;file:/D:/h\ntrix=\r\n/conf/profiles/krish/order.xml&#39;, line: 130, column: 38\n0/21/2005 13:04:12 +=\r\n0000 WARNING \norg.archive.crawler.settings.CrawlSettingsSA\nndler handleValu=\r\neError This field must contain a valid URL leading to \nthe web\ne of the per=\r\nson or organization responsible for this crawl.\nAttribute: &#39;http-headers:us=\r\ner-agent&#39;\nValue:     &#39;Mozilla/5.0 (compatible; heritrix/@VERSION@ \n+www.wik=\r\nepedia.org)&#39;\nFile:      &#39;file:/D:/heritrix/jobs/default1-\n20051020121523526=\r\n/order.xml&#39;, lin\n58, column: 105\neritrix version: 1.4.0\n\nIs there anything =\r\nI have to do with this?\n\n\n5)I tried running heritrix for navigating html fi=\r\nles created by me.\nThe link of the file was  http://localhost:8080/first.ht=\r\nml\n\nThe crawl job came as finished but nothing downloaded!!\n\nThe crawl log =\r\nis as follows:\n\n2005-10-21T05:28:38.706Z     1         46 dns:localhost P \n=\r\nhttp://localhost:8080/first.html text/dns #001 20051021052838691+0 - -\n2005=\r\n-10-21T05:28:41.128Z   404          0 \nhttp://localhost:8080/robots.txt P h=\r\nttp://localhost:8080/first.html \ntext/html #031 20051021052841113+0 3I42H3S=\r\n6NNFQ2MSVX7XZKYAYSCX5QBYJ -\n2005-10-21T05:28:43.144Z   404          0 \nhttp=\r\n://localhost:8080/first.html - - text/html #031 20051021052843128+0 \n3I42H3=\r\nS6NNFQ2MSVX7XZKYAYSCX5QBYJ \n\nHow did the robots.txt come in my page??\n\n\n6)I=\r\ns there any other setting I have to set or enable to make the \napplication =\r\nwork?\n\n\nIs the problem with regard to windows or browser or network and \nco=\r\nnnection?\n\n\nPlease help me on resolving the problem.\n-Krishna\n\n\n\n\n\n\n\n\n"}}