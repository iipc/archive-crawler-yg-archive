{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"stack","from":"stack &lt;stack@...&gt;","replyTo":"LIST","senderId":"MDYDcb9z_tUgj4zVIfW20V3Bghpa9iIAm1E1Gm5W1SCtkpBH2yG5cSjmkQvvaQygKLxlhillFpLWpoLPH6sFHg","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Redirections OK but not extracting actual pages","postDate":"1098285499","msgId":1100,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQxNzY4MUJCLjMwMjA1MDFAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDIwMDQxMDIwMTY1Mi41ODQ2NC5uaWtsYXMudmFyZ2Vuc3RlbkBqYWpqYS5jb20+","referencesHeader":"PGNsNXQ3bCtmcmhiQGVHcm91cHMuY29tPiA8MjAwNDEwMjAxNjUyLjU4NDY0Lm5pa2xhcy52YXJnZW5zdGVuQGphamphLmNvbT4="},"prevInTopic":1099,"nextInTopic":1102,"prevInTime":1099,"nextInTime":1101,"topicId":1097,"numMessagesInTopic":11,"msgSnippet":"... Thanks Niklas for jumping in. The heritrix.jar needs to be found before any of the supporting jars because it overlays classes from the httpclient jar. ","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 75973 invoked from network); 20 Oct 2004 15:16:40 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m24.grp.scd.yahoo.com with QMQP; 20 Oct 2004 15:16:40 -0000\r\nReceived: from unknown (HELO dns.duboce.net) (63.203.238.114)\n  by mta2.grp.scd.yahoo.com with SMTP; 20 Oct 2004 15:16:40 -0000\r\nReceived: from archive.org ([192.168.1.105])\n\t(authenticated)\n\tby dns-eth1.duboce.net (8.10.2/8.10.2) with ESMTP id i9KEX3B30774\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Wed, 20 Oct 2004 07:33:03 -0700\r\nMessage-ID: &lt;417681BB.3020501@...&gt;\r\nDate: Wed, 20 Oct 2004 08:18:19 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; PPC Mac OS X Mach-O; en-US; rv:1.7b) Gecko/20040421\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;cl5t7l+frhb@...&gt; &lt;200410201652.58464.niklas.vargensten@...&gt;\r\nIn-Reply-To: &lt;200410201652.58464.niklas.vargensten@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Remote-IP: 63.203.238.114\r\nFrom: stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] Redirections OK but not extracting actual pages\r\nX-Yahoo-Group-Post: member; u=168599281\r\n\r\nNiklas Vargensten wrote:\n\n&gt;Hey, I had the same problem a while back. No data, except for DNS. \n&gt;In my case it seemed to depend on my putting some additional .jar files in the \n&gt;heritrix directory, and as the heritrix startup script includes all jars with \n&gt;($HERITRIX_HOME)/*.jar in addition to ($HERITRIX_HOME)/lib/*.jar when \n&gt;running, it got \n&gt;confused, somehow (probably because my jar files contained some libs used by \n&gt;heritrix). \n&gt;It seemed really strange, but I tried everything, and \n&gt;the problem was not solved until I moved my jar files to another directory. I \n&gt;can&#39;t really tell if that was really it, but heritrix has worked perfect \n&gt;since then, anyway.\n&gt;\n&gt;This was just a wildcard, but if this is the case for you too, the startup \n&gt;script would really be in need of a re-write...\n&gt;/ Niklas\n&gt;  \n&gt;\nThanks Niklas for jumping in.\n\nThe heritrix.jar needs to be found before any of the supporting jars \nbecause it overlays classes from the httpclient jar. \n\nLooking back though the list, others have reported a problem similar to \nJim&#39;s fixed by rejiggling the classpath:\n\nhttp://groups.yahoo.com/group/archive-crawler/message/772\n\nWe have yet to do a windows start script.  Technically its an \nunsupported platform but it seems like experience has it that it \ngenerally works for people.  If anyone wants to donate a windows start \nscript, I can add it in.\n\nThanks,\nSt.Ack\n\n&gt;On Wednesday 20 October 2004 16.37, jkilleen74 wrote:\n&gt;  \n&gt;\n&gt;&gt;I&#39;m running Heritrix 1.0.4 on a PC (Windows XP); I&#39;m having a problem\n&gt;&gt;where any crawl jobs seem to start fine - retrieve the DNS and\n&gt;&gt;robots.txt as appropriate, redirect as appropriate etc. But once they\n&gt;&gt;hit an actual page e.g. somewebsite/index.html, the crawl comes to an\n&gt;&gt;end. It&#39;s as if the page contained no data or links, yet I know this\n&gt;&gt;is not the case (I can browse to it through IE perfectly normally.)\n&gt;&gt;In my crawl.log, I see something like the following e.g.:\n&gt;&gt;\n&gt;&gt;20041020142929438     1         62 dns:www.st-andrews.ac.uk P\n&gt;&gt;http://www.st-andrews.ac.uk/study.shtml text/dns #000 0 - -\n&gt;&gt;\n&gt;&gt;20041020142930190   404          0 http://www.st-\n&gt;&gt;andrews.ac.uk/robots.txt P http://www.st-andrews.ac.uk/study.shtml\n&gt;&gt;text/html #000 251 - -\n&gt;&gt;\n&gt;&gt;20041020142931601   200          0 http://www.st-\n&gt;&gt;andrews.ac.uk/study.shtml - - text/html #000 142 - 3t\n&gt;&gt;\n&gt;&gt;Note the figures in the second column, for amount of data downloaded.\n&gt;&gt;For the front page (study.shtml), it seems to have downloaded zero\n&gt;&gt;data. Yet the crawl completes without any obvious errors or alerts -\n&gt;&gt;it seems to have found this front page, then decided that not only\n&gt;&gt;are there no links to follow, but not even any data to retrieve. The\n&gt;&gt;same pattern is seen whether I respect or ignore robots.txt, for any\n&gt;&gt;number of sites I&#39;ve tried to examine so far. I&#39;m not applying any\n&gt;&gt;unusual filters, just a standard crawl.\n&gt;&gt;\n&gt;&gt;I&#39;m running this behind a firewall, so am using the Proxy server\n&gt;&gt;patch proved a while back, which seems to be working (without it, any\n&gt;&gt;crawl job just stalled on the very first step.)\n&gt;&gt;\n&gt;&gt;I&#39;m probably missing something obvious, but any suggestions\n&gt;&gt;appreciated!\n&gt;&gt;\n&gt;&gt;Jim K\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;Yahoo! Groups Links\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;\n&gt;\n&gt; \n&gt;Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n&gt; \n&gt;\n&gt;\n&gt;\n&gt;  \n&gt;\n\n\n"}}