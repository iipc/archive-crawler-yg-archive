{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"gYdXZDLbqwB6Jmy0Mvi-xts7LGN0k-0sAgixWJtLuxyzkTxbi5KxH4NlgcA1WbRjoRSCOizx9IPev4IeI-cHyrZYKs_KYFc","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] Can I split seeds for a HashCrawlMapper crawl?","postDate":"1250110036","msgId":5975,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRBODMyQTU0LjUwOTAzMDVAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGg1djBuMitlcXRyQGVHcm91cHMuY29tPg==","referencesHeader":"PGg1djBuMitlcXRyQGVHcm91cHMuY29tPg=="},"prevInTopic":5971,"nextInTopic":5976,"prevInTime":5974,"nextInTime":5976,"topicId":5971,"numMessagesInTopic":8,"msgSnippet":"It would be useful if (for example) HashCrawlMapper had a main() that let it be used outside the crawler to pre-split lists... however the way it s currently","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 45756 invoked from network); 12 Aug 2009 20:47:17 -0000\r\nX-Received: from unknown (69.147.108.202)\n  by m5.grp.sp2.yahoo.com with QMQP; 12 Aug 2009 20:47:17 -0000\r\nX-Received: from unknown (HELO relay01.pair.com) (209.68.5.15)\n  by mta3.grp.re1.yahoo.com with SMTP; 12 Aug 2009 20:47:17 -0000\r\nX-Received: (qmail 91934 invoked from network); 12 Aug 2009 20:47:16 -0000\r\nX-Received: from 70.137.152.95 (HELO ?10.0.13.17?) (70.137.152.95)\n  by relay01.pair.com with SMTP; 12 Aug 2009 20:47:16 -0000\r\nX-pair-Authenticated: 70.137.152.95\r\nMessage-ID: &lt;4A832A54.5090305@...&gt;\r\nDate: Wed, 12 Aug 2009 13:47:16 -0700\r\nUser-Agent: Thunderbird 2.0.0.22 (Windows/20090605)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;h5v0n2+eqtr@...&gt;\r\nIn-Reply-To: &lt;h5v0n2+eqtr@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Can I split seeds for a HashCrawlMapper crawl?\r\nX-Yahoo-Group-Post: member; u=137285340; y=Kvka57T8Sjdysogj_oHfYMS8RHsbglji7XRs99U_k-Ss\r\nX-Yahoo-Profile: gojomo\r\n\r\nIt would be useful if (for example) HashCrawlMapper had a main() that \nlet it be used outside the crawler to pre-split lists... however the way \nit&#39;s currently dependent on the frontier&#39;s configured queue-key policy \nwould require some extra complication on how such a hypothetical utility \nwas invoked.\n\nA roundabout way to achieve the same effect might be to set up a dummy \ncrawler whose first HashCrawlMapper does &#39;check-uri&#39; but also has a \nerroneous &#39;local-name&#39;. Feed it all 20MM URLs -- and every one will land \nin one of the diversion logs, because none will be bucketed to the bad \n&#39;local-name&#39;. This dummy crawl wouldn&#39;t need any other things (like \nseed-based scopes) that might be choking on a large seed list.\n\nNote that if each of the 12 crawlers only is initialized with a small \nportion of the seed list, when they discover deep URIs on hosts assigned \nto other nodes they might mistakenly rule them out-of-scope, though in \npractice this might not be an issue for well-connected sites.\n\n- Gordon @ IA\n\njoehung302 wrote:\n&gt; I&#39;m using Heritrix 1.14.3.\n&gt; \n&gt; Let&#39;s say I have \n&gt; 1. one big seed list consisting of 1MM seeds. \n&gt; 2. 2 crawler instances to implement HashCrawlMapper. \n&gt; 3. The crawl scope is domain + 1 (implemented through OnDomainDecideRule with &quot;seeds-as-surt-prefixes&quot;==true and &quot;also-check-via&quot;==true). \n&gt; \n&gt; Can I split the seeds using the same HashCrawlMapper rule so that each crawler would only get seeds that are within its scope? Would there be any difference if I use the same 1MM seeds for both crawlers?\n&gt; \n&gt; \n&gt; The reason why I want to do this is, I have 20MM seeds among 12 crawlers. I&#39;ve tested with one instance handling 20MM seeds and it doesn&#39;t seem to work. If I can split the seeds so that each cralwer starts with URLs that belong to themselves it should make the crawl process easier....\n&gt; \n&gt; Thanks,\n&gt; -Joe\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; ------------------------------------\n&gt; \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n"}}