{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":264138474,"authorName":"Kenji Nagahashi","from":"Kenji Nagahashi &lt;knagahashi@...&gt;","profile":"kenznag","replyTo":"LIST","senderId":"g8bgy2HmiR1aHVq9BiYNX5AsHWkfrvDxkObqZln5X-0_MpRsZ41u-VQlssJFrNGT9o1rBCJ95ArucQ9Vwf35EWZR-ggS7KeATmk4aeA","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Recovering a crawler [1 Attachment]","postDate":"1348788724","msgId":7803,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDUwNjRFMUY0LjUwMzA0MDJAZ21haWwuY29tPg==","inReplyToHeader":"PDc0Qzk3RTdERjVBNzc4NEQ5OTcyMTdGRjc1RDEyMTY2MEZDMUQ5NTdAdzJrMy1ic3BleDE+","referencesHeader":"PDc0Qzk3RTdERjVBNzc4NEQ5OTcyMTdGRjc1RDEyMTY2MEZDMUQ3NDhAdzJrMy1ic3BleDE+IDw1MDYzMkRDNS43MDUwNzAwQGFyY2hpdmUub3JnPiA8NzRDOTdFN0RGNUE3Nzg0RDk5NzIxN0ZGNzVEMTIxNjYwRkMxRDk1N0B3MmszLWJzcGV4MT4="},"prevInTopic":7800,"nextInTopic":7804,"prevInTime":7802,"nextInTime":7804,"topicId":7795,"numMessagesInTopic":5,"msgSnippet":"Hi, I believe I ve seen this before. BDB-JE (DB lib embedded inside Heritrix) is doing some bookkeeping/repair work (I don t know what) as part of opening","rawEmail":"Return-Path: &lt;knagahashi@...&gt;\r\nX-Sender: knagahashi@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 13652 invoked from network); 27 Sep 2012 23:32:07 -0000\r\nX-Received: from unknown (98.137.35.161)\n  by m4.grp.sp2.yahoo.com with QMQP; 27 Sep 2012 23:32:07 -0000\r\nX-Received: from unknown (HELO mail-pb0-f48.google.com) (209.85.160.48)\n  by mta5.grp.sp2.yahoo.com with SMTP; 27 Sep 2012 23:32:07 -0000\r\nX-Received: by mail-pb0-f48.google.com with SMTP id wy7so3165869pbc.21\n        for &lt;archive-crawler@yahoogroups.com&gt;; Thu, 27 Sep 2012 16:32:07 -0700 (PDT)\r\nX-Received: by 10.66.73.166 with SMTP id m6mr13130638pav.1.1348788727126;\n        Thu, 27 Sep 2012 16:32:07 -0700 (PDT)\r\nReturn-Path: &lt;knagahashi@...&gt;\r\nX-Received: from kenji-mbp.local (adsl-71-135-164-129.dsl.pltn13.pacbell.net. [71.135.164.129])\n        by mx.google.com with ESMTPS id te6sm4543367pbc.29.2012.09.27.16.32.05\n        (version=TLSv1/SSLv3 cipher=OTHER);\n        Thu, 27 Sep 2012 16:32:06 -0700 (PDT)\r\nMessage-ID: &lt;5064E1F4.5030402@...&gt;\r\nDate: Thu, 27 Sep 2012 16:32:04 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:15.0) Gecko/20120907 Thunderbird/15.0.1\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;74C97E7DF5A7784D997217FF75D121660FC1D748@w2k3-bspex1&gt; &lt;50632DC5.7050700@...&gt; &lt;74C97E7DF5A7784D997217FF75D121660FC1D957@w2k3-bspex1&gt;\r\nIn-Reply-To: &lt;74C97E7DF5A7784D997217FF75D121660FC1D957@w2k3-bspex1&gt;\r\nContent-Type: text/plain; charset=windows-1252; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Kenji Nagahashi &lt;knagahashi@...&gt;\r\nSubject: Re: [archive-crawler] Recovering a crawler [1 Attachment]\r\nX-Yahoo-Group-Post: member; u=264138474; y=JLWJ-IRm28kNCBZarTaB40dgtss0S2IpJA_y1CN5bnHv9Q\r\nX-Yahoo-Profile: kenznag\r\n\r\nHi,\n\nI believe I&#39;ve seen this before.\n\nBDB-JE (DB lib embedded inside Heritrix) is doing some \nbookkeeping/repair work (I don&#39;t know what) as part of opening database, \ninside crawl job initialization. UI thread is blocked by synchronization \nuntil initialization finishes. this database work often took very very \nlong time to finish.\n\nif you&#39;re okay with time-consuming recovery-log approach, you can avoid \nthis problem by deleting all files in &quot;state&quot; directory before building \ncrawl job.\n\n--Kenji\n\n(9/27/12 2:45 AM), Coram, Roger wrote:\n&gt; [Attachment(s) &lt;#TopText&gt; from Coram, Roger included below]\n&gt;\n&gt; Hi Gordon,\n&gt; The recovery-log approach is the one we&#39;ve used in the past\n&gt; (build-&gt;launch paused-&gt;copy log-&gt;unpause when complete). However, in\n&gt; this case we&#39;re not even getting as far as copying the file to the\n&gt; &#39;action&#39; directory. The heritrix_out.log show the following, then\n&gt; nothing more:\n&gt;\n&gt; 2012-09-27 08:25:40.880 INFO thread-11\n&gt; org.archive.crawler.framework.CrawlJob.launch() Job launched\n&gt; 2012-09-27 08:25:42.387 INFO thread-12\n&gt; org.archive.spring.PathSharingContext.initLaunchId() launch id\n&gt; 20120927082542\n&gt; 2012-09-27 08:25:42.591 INFO thread-12\n&gt; org.springframework.context.support.DefaultLifecycleProcessor$LifecycleG\n&gt; roup.start() Starting beans in phase 0\n&gt;\n&gt; The JVM is definitely busy and an &#39;lsof&#39; implies that it&#39;s accessing the\n&gt; contents of the &#39;state&#39; directory; the frontier.recover.gz isn&#39;t being\n&gt; written to.\n&gt;\n&gt; I&#39;ve attached a section from jstack - am I right in inferring that the\n&gt; BLOCKED thread is the web-UI?\n&gt;\n&gt; Many thanks,\n&gt; Roger\n&gt;\n&gt; -----Original Message-----\n&gt; From: Gordon Mohr [mailto:gojomo@... &lt;mailto:gojomo%40archive.org&gt;]\n&gt; Sent: 26 September 2012 17:31\n&gt; To: archive-crawler@yahoogroups.com\n&gt; &lt;mailto:archive-crawler%40yahoogroups.com&gt;\n&gt; Cc: Coram, Roger\n&gt; Subject: Re: [archive-crawler] Recovering a crawler\n&gt;\n&gt; A recovery using the H3 checkpointing mechanism, if such a checkpoint is\n&gt; available, should be very quick (almost instant).\n&gt;\n&gt; Using the recovery log approach will take much longer -- on the order of\n&gt; days to replay weeks&#39; worth of prior crawling is not surprising.\n&gt;\n&gt; Note that in H3, to use the recovery-log approach, you&#39;d normally drop\n&gt; the &quot;.recover.gz&quot; log into the &#39;action&#39; directory and do a &#39;paused&#39;\n&gt; launch of the crawl, only unpausing the crawl once there&#39;s evidence of\n&gt; some number of URIs appearing in the frontier queues. (That can take a\n&gt; while, because first there&#39;s one pass of the entire .recover log to\n&gt; discover already-visited URIs, then a 2nd pass to add URis.)\n&gt;\n&gt; I don&#39;t think that any part of this should block the UI, so there may be\n&gt; something else wrong. One way to confirm progress would be to check that\n&gt; the machine is CPU/IO busy and that repeated Java thread dumps (via the\n&gt; &#39;jstack&#39; utility or sending a SIGQUIT and viewing the heritrix_out log)\n&gt; show stacks suggesting intended activity. (This might also reveal if\n&gt; there&#39;s a good reason for the unresponsive web UI.) I also believe the\n&gt; new launch&#39;s &#39;.recovery.gz&#39; file would be growing during an in-progress\n&gt; recovery.\n&gt;\n&gt; If for some reason the recovery is hung, the heritrix_out.log or thread\n&gt; dumps might indicate why with an error or suspicious thread stack.\n&gt;\n&gt; - Gordon\n&gt;\n&gt; On 9/26/12 2:19 AM, Coram, Roger wrote:\n&gt;  &gt;\n&gt;  &gt;\n&gt;  &gt; Hi,\n&gt;  &gt;\n&gt;  &gt; One of our crawlers had to be restarted several weeks into a crawl\n&gt;  &gt; (H3.1.1). After a successful build and clicking &#39;Launch&#39; the crawler\n&gt;  &gt; and its web-UI have been completely unresponsive (the last job.log\n&gt;  &gt; entry was &quot;INFO Job launched&quot; nearly 48 hours ago). The &#39;state&#39;\n&gt;  &gt; directory for this particular crawler (using the\n&gt;  &gt; PersistStoreProcessor) is more than 3TB in size.\n&gt;  &gt;\n&gt;  &gt; My question: how long can a recovery typically take? We&#39;ve had to\n&gt;  &gt; recover crawlers before but it&#39;s never taken quite this long before.\n&gt;  &gt; Is there some way to figure out what it&#39;s doing?\n&gt;  &gt;\n&gt;  &gt; Thanks.\n&gt;  &gt;\n&gt;  &gt; Roger G. Coram\n&gt;  &gt;\n&gt;  &gt; Web Archiving Engineer\n&gt;  &gt;\n&gt;  &gt; The British Library\n&gt;  &gt;\n&gt;  &gt; T: +44 (0)1937 546607\n&gt;  &gt;\n&gt;  &gt; F: +44 (0)1937 546872\n&gt;  &gt;\n&gt;  &gt; E: roger.coram@... &lt;mailto:roger.coram%40bl.uk&gt;\n&gt; &lt;mailto:roger.coram@... &lt;mailto:roger.coram%40bl.uk&gt;&gt;\n&gt;  &gt;\n&gt;  &gt;\n&gt;  &gt;\n&gt;  &gt;\n&gt;\n&gt; \n\n\n"}}