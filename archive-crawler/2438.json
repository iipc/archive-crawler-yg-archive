{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137477665,"authorName":"Igor Ranitovic","from":"Igor Ranitovic &lt;igor@...&gt;","profile":"iranitovic","replyTo":"LIST","senderId":"H1RIBxy-5KoNiiE0ffsNyNdguX98dNwD7-hWlt5Q2l_SpBZKfBOAKsF5gYF1xmv2qUPeOlQB_CANVeVQIqRvJaRKs3BgN4AE","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] questions on split crawl","postDate":"1134691314","msgId":2438,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQzQTIwM0YyLjYwMDA5QGFyY2hpdmUub3JnPg==","inReplyToHeader":"PGRuc284aStkMmNyQGVHcm91cHMuY29tPg==","referencesHeader":"PGRuc284aStkMmNyQGVHcm91cHMuY29tPg=="},"prevInTopic":2437,"nextInTopic":0,"prevInTime":2437,"nextInTime":2439,"topicId":2437,"numMessagesInTopic":2,"msgSnippet":"You can use jmx command line tool to feed a running crawler with new urls or seeds. Take a look at importUris option. See more at:","rawEmail":"Return-Path: &lt;igor@...&gt;\r\nX-Sender: igor@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 11199 invoked from network); 16 Dec 2005 00:07:22 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m24.grp.scd.yahoo.com with QMQP; 16 Dec 2005 00:07:22 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (207.241.224.171)\n  by mta5.grp.scd.yahoo.com with SMTP; 16 Dec 2005 00:07:22 -0000\r\nReceived: (qmail 12982 invoked by uid 100); 16 Dec 2005 00:03:06 -0000\r\nReceived: from adsl-71-130-102-78.dsl.pltn13.pacbell.net (HELO ?192.168.1.5?) (igor@...@71.130.102.78)\n  by mail-dev.archive.org with SMTP; 16 Dec 2005 00:03:06 -0000\r\nMessage-ID: &lt;43A203F2.60009@...&gt;\r\nDate: Thu, 15 Dec 2005 16:01:54 -0800\r\nUser-Agent: Mozilla Thunderbird 1.0.6 (Windows/20050716)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;dnso8i+d2cr@...&gt;\r\nIn-Reply-To: &lt;dnso8i+d2cr@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=-94.6 required=7.0 tests=AWL,USER_IN_WHITELIST \n\tautolearn=no version=2.63\r\nX-eGroups-Msg-Info: 2:12:4:0\r\nFrom: Igor Ranitovic &lt;igor@...&gt;\r\nSubject: Re: [archive-crawler] questions on split crawl\r\nX-Yahoo-Group-Post: member; u=137477665; y=rOoDE1iA47p3yIpP6WiFG8b9N3HX28cRhHOytQo1rHkshYzgPQ\r\nX-Yahoo-Profile: iranitovic\r\n\r\nYou can use jmx command line tool to feed a running crawler with new urls or seeds.\nTake a look at importUris option.\n\nSee more at: http://crawler.archive.org/cmdline-jmxclient/\n\nExample:\njava -jar cmdline-jmxclient-0.10.5.jar controlRole:passwd crawling-host:8849 \norg.archive.crawler:name=20051012104832156,type=CrawlJob importUris=A-to-B.divert,recoveryJournal,false\n\nwhere A-to-B.divert is a list of URLs that crawl A discovered and crawl B needs to crawl.\n\nAll this cross feeding can be done programmatically with a bit of scripting.\ni.\n\njoehung302 wrote:\n&gt; Hi,\n&gt; \n&gt; I&#39;ve read the thread about split crawl \n&gt; http://groups.yahoo.com/group/archive-crawler/message/2141. and have \n&gt; a few questions on it. \n&gt; \n&gt; Let&#39;s say I start with 2 machines, each one has its own category. \n&gt; For simplicity, let&#39;s say machine A deals with *.com and machine B \n&gt; deals with non *.com. And they use the same seed list.\n&gt; \n&gt; After a while machine A generate a list of URLs that contains non \n&gt; *.com links. Now, how do I add that list to machine B? I know one \n&gt; way to add them is to (1) pause B (2) add the list to B&#39;s seed list \n&gt; (3) restart B. But if I keep doing this, eventually the seed list \n&gt; will grow to big and I cannot use GUI to modify it. So let&#39;s say I \n&gt; bypass GUI and modify the seeds.txt manually. Would that be a \n&gt; problem?\n&gt; \n&gt; Or is there a better way to handle this?\n&gt; \n&gt; Thanks,\n&gt; \n&gt; -joe\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt;  \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n&gt;  \n&gt; \n&gt; \n\n\n"}}