{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":465980601,"authorName":"Zach Bailey","from":"Zach Bailey &lt;zach.bailey@...&gt;","replyTo":"LIST","senderId":"cKC8bB2uVGB6drIYjou1NSrs-UyesbHtELeGd58mgGnnhEhTUVwUMVZlAi8Vqr6cIK17dJfAy_eJC7_GCTa71a7seiP-ZntSMQ2FaVM","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Storing Crawl Results in Alternate (non-FS) Store","postDate":"1284502101","msgId":6726,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEFBTkxrVGk9aGt2SjlRVlM5Y1FHWEV6ejZCRllRMFdQNmV2PXhfNkhKelc3TEBtYWlsLmdtYWlsLmNvbT4=","inReplyToHeader":"PDRDOEZEQUEyLjEwNDA0MDdAYXJjaGl2ZS5vcmc+","referencesHeader":"PEFBTkxrVGk9YWJnRktrTE1FLXlPZWpYYzFFT2hWWmlKQUw5bzExb01IVzZWNEBtYWlsLmdtYWlsLmNvbT4JPDRDOEZEQUEyLjEwNDA0MDdAYXJjaGl2ZS5vcmc+"},"prevInTopic":6724,"nextInTopic":6727,"prevInTime":6725,"nextInTime":6727,"topicId":6723,"numMessagesInTopic":6,"msgSnippet":"Thanks a lot for your answers, Gordon. I am absolutely planning on contributing this back for others to build on and use, once I figure out how to make it","rawEmail":"Return-Path: &lt;zach.bailey@...&gt;\r\nX-Sender: zach.bailey@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 86323 invoked from network); 14 Sep 2010 22:08:22 -0000\r\nX-Received: from unknown (66.196.94.106)\n  by m10.grp.re1.yahoo.com with QMQP; 14 Sep 2010 22:08:22 -0000\r\nX-Received: from unknown (HELO mail-ww0-f47.google.com) (74.125.82.47)\n  by mta2.grp.re1.yahoo.com with SMTP; 14 Sep 2010 22:08:22 -0000\r\nX-Received: by wwb31 with SMTP id 31so7952490wwb.16\n        for &lt;archive-crawler@yahoogroups.com&gt;; Tue, 14 Sep 2010 15:08:21 -0700 (PDT)\r\nMIME-Version: 1.0\r\nX-Received: by 10.216.12.139 with SMTP id 11mr472129wez.63.1284502101453; Tue,\n 14 Sep 2010 15:08:21 -0700 (PDT)\r\nX-Received: by 10.216.47.7 with HTTP; Tue, 14 Sep 2010 15:08:21 -0700 (PDT)\r\nIn-Reply-To: &lt;4C8FDAA2.1040407@...&gt;\r\nReferences: &lt;AANLkTi=abgFKkLME-yOejXc1EOhVZiJAL9o11oMHW6V4@...&gt;\n\t&lt;4C8FDAA2.1040407@...&gt;\r\nDate: Tue, 14 Sep 2010 18:08:21 -0400\r\nMessage-ID: &lt;AANLkTi=hkvJ9QVS9cQGXEzz6BFYQ0WP6ev=x_6HJzW7L@...&gt;\r\nTo: Gordon Mohr &lt;gojomo@...&gt;\r\nCc: archive-crawler@yahoogroups.com\r\nContent-Type: multipart/alternative; boundary=0016364c7ad7786c6904903f73d5\r\nFrom: Zach Bailey &lt;zach.bailey@...&gt;\r\nSubject: Re: [archive-crawler] Storing Crawl Results in Alternate (non-FS) Store\r\nX-Yahoo-Group-Post: member; u=465980601\r\n\r\n\r\n--0016364c7ad7786c6904903f73d5\r\nContent-Type: text/plain; charset=ISO-8859-1\r\n\r\nThanks a lot for your answers, Gordon.\n\nI am absolutely planning on contributing this back for others to build on\nand use, once I figure out how to make it generic enough to be useful to\nothers. More than likely I will put it up on my public github account.\n\nA follow-up question - am I correct in assuming my implementation of\nProcessor#shouldProcess should be pretty much identical to the one in\nWriterPoolProcessor?\n\nAlso, what is the best way to get at the raw page content separate from the\nheaders (just the content, not the entire response)? Am I correct in\nthinking that this is what I would be provided when calling\ncrawlURI.getRecorder().getRecordedInput().getContentReplayInputStream() ?\n\nThanks,\n-Zach\n\nOn Tue, Sep 14, 2010 at 4:27 PM, Gordon Mohr &lt;gojomo@...&gt; wrote:\n\n&gt; Great questions! I know there&#39;s other interest in such writer alternatives,\n&gt; so I hope you can make whatever you come up with available to other users,\n&gt; or donate it for possible inclusion in the official H3 distribution!\n&gt;\n&gt; There also has been previous work to create an HBaseWriter for Heritrix; it\n&gt; might already work in H3, or require only a little updating. I haven&#39;t yet\n&gt; tried it myself. See:\n&gt;\n&gt; http://code.google.com/p/hbase-writer/\n&gt;\n&gt; On to your questions, interspersed below:\n&gt;\n&gt;\n&gt; On 9/14/10 12:39 PM, Zach Bailey wrote:\n&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; Hi all,\n&gt;&gt;\n&gt;&gt; I wanted to run some questions by you and maybe get some pointers from\n&gt;&gt; the architects of heritrix hoping I could save a little time before\n&gt;&gt; attempting this.\n&gt;&gt;\n&gt;&gt; What I am hoping to do is develop a custom writer to store the results\n&gt;&gt; of my crawls in a distributed database, something like Riak, Cassandra,\n&gt;&gt; or HBase for the Heritrix 3.0 code base.\n&gt;&gt;\n&gt;&gt; I am very comfortable writing Java code and am very familiar with\n&gt;&gt; building applications using the Spring Framework so I&#39;m thinking this\n&gt;&gt; should be a relatively easy task to get a proof of concept/prototype\n&gt;&gt; working.\n&gt;&gt;\n&gt;&gt; Looking through the code I had some questions:\n&gt;&gt;\n&gt;&gt; 1.) It looks like I will wire in my custom code inside the\n&gt;&gt; DispositionChain, essentially replacing where the warcWriter bean is\n&gt;&gt; referenced.\n&gt;&gt;\n&gt;\n&gt; Yes; you could also have both in place for testing. (I&#39;ve often run with\n&gt; both our ARCWriterProcessor and WARCWriterProcessor while debugging things.)\n&gt; One common gotcha when installing your own Processors, as edits to our model\n&gt; CXML, is that if you follow the pattern there you need to both declare the\n&gt; bean with a name, then add the bean by name to the chain&#39;s ordered list. So:\n&gt; two edits, a short distance from each other, to have the intended effect.\n&gt;\n&gt;\n&gt;  2.) Looking at the WARCWriterProcessor it appears it uses a pooled\n&gt;&gt; approach. I&#39;m guessing this is for performance reasons. Assuming I&#39;m\n&gt;&gt; using a driver which already implements connection pooling, are there\n&gt;&gt; any other considerations I should think about while implementing my own\n&gt;&gt; Writer?\n&gt;&gt;\n&gt;\n&gt; The existing pooling was motivated by the belief that having more than one\n&gt; active open file at a time could increase throughput. That&#39;s definitely the\n&gt; case if the files are on independent disks; I&#39;m not as sure it helps to have\n&gt; more than one file open on the same disk. This has undergone some recent\n&gt; simplification (eliminating the dependency on Apache commons-pool) in TRUNK\n&gt; that will appear in 3.0.1, and is likely to change more in the next month as\n&gt; some other novel policies for grouping related site captures to different\n&gt; WARCs are added.\n&gt;\n&gt; So I&#39;d say: keep an eye on TRUNK for ideas but don&#39;t assume anything in the\n&gt; existing WARCWriterProcessor approach is optimal or locked-in-place.\n&gt;\n&gt; I would think writing to a remote distributed store might offer nice\n&gt; throughput benefits by essentially fanning the IO out over many more disks,\n&gt; whether you were writing WARCs into (eg) HDFS or individual\n&gt; records/content-bodies into (eg) HBase.\n&gt;\n&gt; The least-straightforward part of the current Writer is the special-case\n&gt; handling of deduced duplicates, from headers or content-hashes, to change\n&gt; how (or whether) individual records are written. There might be an\n&gt; opportunity to factor that decisionmaking out of WARCWriterProcessor to be\n&gt; shared with other non-file or even non-WARC writers.\n&gt;\n&gt;\n&gt;  3.) Once I get my custom code developed, I assume all I need to do to\n&gt;&gt; make it available to heritrix is to jar it up and just drop it in\n&gt;&gt; $HERITRIX_HOME/lib - anything else I need to be aware of there?\n&gt;&gt;\n&gt;\n&gt; That should be all. Then, as I&#39;m sure you know, you just name the classes\n&gt; in your crawl-configuration CXML (Spring XML) bean-declarations.\n&gt;\n&gt; Hope this helps and let me know any other questions!\n&gt;\n&gt; - Gordon @ IA\n&gt;\n\r\n--0016364c7ad7786c6904903f73d5\r\nContent-Type: text/html; charset=ISO-8859-1\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nThanks a lot for your answers, Gordon.&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I am absolutely p=\r\nlanning on contributing this back for others to build on and use, once I fi=\r\ngure out how to make it generic enough to be useful to others. More than li=\r\nkely I will put it up on my public github account.&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;di=\r\nv&gt;A follow-up question - am I correct in assuming my implementation of Proc=\r\nessor#shouldProcess should be pretty much identical to the one in WriterPoo=\r\nlProcessor?&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Also, what is the best way to get at t=\r\nhe raw page content separate from the headers (just the content, not the en=\r\ntire response)? Am I correct in thinking that this is what I would be provi=\r\nded when calling crawlURI.getRecorder().getRecordedInput().getContentReplay=\r\nInputStream() ?&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Thanks,&lt;/div&gt;&lt;div&gt;-Zach&lt;/div&gt;&lt;div=\r\n&gt;&lt;br&gt;&lt;div class=3D&quot;gmail_quote&quot;&gt;On Tue, Sep 14, 2010 at 4:27 PM, Gordon Moh=\r\nr &lt;span dir=3D&quot;ltr&quot;&gt;&lt;&lt;a href=3D&quot;mailto:gojomo@...&quot;&gt;gojomo@archiv=\r\ne.org&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt;\n&lt;blockquote class=3D&quot;gmail_quote&quot; style=3D&quot;=\r\nmargin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex;&quot;&gt;Great quest=\r\nions! I know there&#39;s other interest in such writer alternatives, so I h=\r\nope you can make whatever you come up with available to other users, or don=\r\nate it for possible inclusion in the official H3 distribution!&lt;br&gt;\n\n&lt;br&gt;\nTh=\r\nere also has been previous work to create an HBaseWriter for Heritrix; it m=\r\night already work in H3, or require only a little updating. I haven&#39;t y=\r\net tried it myself. See:&lt;br&gt;\n&lt;br&gt;\n&lt;a href=3D&quot;http://code.google.com/p/hbase=\r\n-writer/&quot; target=3D&quot;_blank&quot;&gt;http://code.google.com/p/hbase-writer/&lt;/a&gt;&lt;br&gt;\n=\r\n&lt;br&gt;\nOn to your questions, interspersed below:&lt;div class=3D&quot;im&quot;&gt;&lt;br&gt;\n&lt;br&gt;\nO=\r\nn 9/14/10 12:39 PM, Zach Bailey wrote:&lt;br&gt;\n&lt;blockquote class=3D&quot;gmail_quote=\r\n&quot; style=3D&quot;margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex&quot;&gt;\n=\r\n&lt;br&gt;\n&lt;br&gt;\nHi all,&lt;br&gt;\n&lt;br&gt;\nI wanted to run some questions by you and maybe =\r\nget some pointers from&lt;br&gt;\nthe architects of heritrix hoping I could save a=\r\n little time before&lt;br&gt;\nattempting this.&lt;br&gt;\n&lt;br&gt;\nWhat I am hoping to do is=\r\n develop a custom writer to store the results&lt;br&gt;\nof my crawls in a distrib=\r\nuted database, something like Riak, Cassandra,&lt;br&gt;\nor HBase for the Heritri=\r\nx 3.0 code base.&lt;br&gt;\n&lt;br&gt;\nI am very comfortable writing Java code and am ve=\r\nry familiar with&lt;br&gt;\nbuilding applications using the Spring Framework so I&=\r\n#39;m thinking this&lt;br&gt;\nshould be a relatively easy task to get a proof of =\r\nconcept/prototype&lt;br&gt;\nworking.&lt;br&gt;\n&lt;br&gt;\nLooking through the code I had some=\r\n questions:&lt;br&gt;\n&lt;br&gt;\n1.) It looks like I will wire in my custom code inside=\r\n the&lt;br&gt;\nDispositionChain, essentially replacing where the warcWriter bean =\r\nis&lt;br&gt;\nreferenced.&lt;br&gt;\n&lt;/blockquote&gt;\n&lt;br&gt;&lt;/div&gt;\nYes; you could also have bo=\r\nth in place for testing. (I&#39;ve often run with both our ARCWriterProcess=\r\nor and WARCWriterProcessor while debugging things.) One common gotcha when =\r\ninstalling your own Processors, as edits to our model CXML, is that if you =\r\nfollow the pattern there you need to both declare the bean with a name, the=\r\nn add the bean by name to the chain&#39;s ordered list. So: two edits, a sh=\r\nort distance from each other, to have the intended effect.&lt;div class=3D&quot;im&quot;=\r\n&gt;\n&lt;br&gt;\n&lt;br&gt;\n&lt;blockquote class=3D&quot;gmail_quote&quot; style=3D&quot;margin:0 0 0 .8ex;bo=\r\nrder-left:1px #ccc solid;padding-left:1ex&quot;&gt;\n2.) Looking at the WARCWriterPr=\r\nocessor it appears it uses a pooled&lt;br&gt;\napproach. I&#39;m guessing this is =\r\nfor performance reasons. Assuming I&#39;m&lt;br&gt;\nusing a driver which already =\r\nimplements connection pooling, are there&lt;br&gt;\nany other considerations I sho=\r\nuld think about while implementing my own&lt;br&gt;\nWriter?&lt;br&gt;\n&lt;/blockquote&gt;\n&lt;br=\r\n&gt;&lt;/div&gt;\nThe existing pooling was motivated by the belief that having more t=\r\nhan one active open file at a time could increase throughput. That&#39;s de=\r\nfinitely the case if the files are on independent disks; I&#39;m not as sur=\r\ne it helps to have more than one file open on the same disk. This has under=\r\ngone some recent simplification (eliminating the dependency on Apache commo=\r\nns-pool) in TRUNK that will appear in 3.0.1, and is likely to change more i=\r\nn the next month as some other novel policies for grouping related site cap=\r\ntures to different WARCs are added.&lt;br&gt;\n\n&lt;br&gt;\nSo I&#39;d say: keep an eye o=\r\nn TRUNK for ideas but don&#39;t assume anything in the existing WARCWriterP=\r\nrocessor approach is optimal or locked-in-place.&lt;br&gt;\n&lt;br&gt;\nI would think wri=\r\nting to a remote distributed store might offer nice throughput benefits by =\r\nessentially fanning the IO out over many more disks, whether you were writi=\r\nng WARCs into (eg) HDFS or individual records/content-bodies into (eg) HBas=\r\ne.&lt;br&gt;\n\n&lt;br&gt;\nThe least-straightforward part of the current Writer is the sp=\r\necial-case handling of deduced duplicates, from headers or content-hashes, =\r\nto change how (or whether) individual records are written. There might be a=\r\nn opportunity to factor that decisionmaking out of WARCWriterProcessor to b=\r\ne shared with other non-file or even non-WARC writers.&lt;div class=3D&quot;im&quot;&gt;\n&lt;b=\r\nr&gt;\n&lt;br&gt;\n&lt;blockquote class=3D&quot;gmail_quote&quot; style=3D&quot;margin:0 0 0 .8ex;border=\r\n-left:1px #ccc solid;padding-left:1ex&quot;&gt;\n3.) Once I get my custom code devel=\r\noped, I assume all I need to do to&lt;br&gt;\nmake it available to heritrix is to =\r\njar it up and just drop it in&lt;br&gt;\n$HERITRIX_HOME/lib - anything else I need=\r\n to be aware of there?&lt;br&gt;\n&lt;/blockquote&gt;\n&lt;br&gt;&lt;/div&gt;\nThat should be all. The=\r\nn, as I&#39;m sure you know, you just name the classes in your crawl-config=\r\nuration CXML (Spring XML) bean-declarations.&lt;br&gt;\n&lt;br&gt;\nHope this helps and l=\r\net me know any other questions!&lt;br&gt;\n&lt;br&gt;\n- Gordon @ IA&lt;br&gt;\n&lt;/blockquote&gt;&lt;/d=\r\niv&gt;&lt;br&gt;&lt;/div&gt;\n\r\n--0016364c7ad7786c6904903f73d5--\r\n\n"}}