{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":163406187,"authorName":"Kristinn Sigurdsson","from":"&quot;Kristinn Sigurdsson&quot; &lt;kris@...&gt;","profile":"kristsi25","replyTo":"LIST","senderId":"MnK3PqhHXa_zt13pTUosmXg1VcP1SadMLsyrMF9I_y8Kn07Btm4df8eYTuBeDQi6lU3UCz7qs1Jd4mK1ErEysg8DqWAPPlzF03psaf9VGQ","spamInfo":{"isSpam":false,"reason":"0"},"subject":"RE: [archive-crawler] Re: Inserting information to MYSQL during crawl","postDate":"1086619432","msgId":515,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEQ5NTgxMTBCMjczQ0Q1MTFBQ0MxMDBCMEQwNzlBQTRFMDE5NjBDQTNAbG9raS5ib2suaGkuaXM+","inReplyToHeader":"PEQ5NTgxMTBCMjczQ0Q1MTFBQ0MxMDBCMEQwNzlBQTRFMDI2NUVFQTZAbG9raS5ib2suaGkuaXM+"},"prevInTopic":514,"nextInTopic":518,"prevInTime":514,"nextInTime":516,"topicId":507,"numMessagesInTopic":19,"msgSnippet":"I should add as a side not to all of this that even if you write your own DB insertion processor you can still have the crawler write ARC files. Heritrix is","rawEmail":"Return-Path: &lt;kris@...&gt;\r\nX-Sender: kris@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 2833 invoked from network); 7 Jun 2004 14:43:48 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m21.grp.scd.yahoo.com with QMQP; 7 Jun 2004 14:43:48 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (209.237.232.202)\n  by mta6.grp.scd.yahoo.com with SMTP; 7 Jun 2004 14:43:48 -0000\r\nReceived: (qmail 22331 invoked by uid 100); 7 Jun 2004 14:36:17 -0000\r\nReceived: from forritun-4.bok.hi.is (HELO forritun4) (130.208.152.83)\n  by mail-dev.archive.org with SMTP; 7 Jun 2004 14:36:17 -0000\r\nTo: &lt;archive-crawler@yahoogroups.com&gt;\r\nDate: Mon, 7 Jun 2004 14:43:52 -0000\r\nMessage-ID: &lt;D958110B273CD511ACC100B0D079AA4E01960CA3@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: text/plain;\n\tcharset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Priority: 3 (Normal)\r\nX-MSMail-Priority: Normal\r\nX-Mailer: Microsoft Outlook, Build 10.0.4510\r\nIn-Reply-To: &lt;D958110B273CD511ACC100B0D079AA4E0265EEA6@...&gt;\r\nImportance: Normal\r\nX-MimeOLE: Produced By Microsoft MimeOLE V6.00.2800.1409\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=0.5 required=6.0 tests=AWL autolearn=ham version=2.63\r\nX-eGroups-Remote-IP: 209.237.232.202\r\nFrom: &quot;Kristinn Sigurdsson&quot; &lt;kris@...&gt;\r\nSubject: RE: [archive-crawler] Re: Inserting information to MYSQL during crawl\r\nX-Yahoo-Group-Post: member; u=163406187\r\nX-Yahoo-Profile: kristsi25\r\n\r\nI should add as a side not to all of this that even if you write your own D=\r\nB\n\ninsertion processor you can still have the crawler write ARC files. Heri=\r\ntrix\n\nis not limited to one writer/indexer processor but can in fact have a=\r\ns many \nas you wish. So in case you want to keep the ARCs around but still =\r\nwrite\ndata \nstraight to the DB you can. Don=92t know why you would want to =\r\ndo that but I \nfelt that it was worth pointing out.\n\nRegards,\nKristinn Sigu=\r\nr=F0sson\nNational Library of Iceland\n\n-----Original Message-----\nFrom: Ahnu=\r\n Nahki [mailto:ahnunahki@...] \nSent: 7. j=FAn=ED 2004 14:35\nT=\r\no: archive-crawler@yahoogroups.com\nSubject: [archive-crawler] Re: Inserting=\r\n information to MYSQL during crawl\n\n&gt;--- In archive-crawler@yahoogroups.com=\r\n, Andy Boyko &lt;aboy@l...&gt; wrote:\n&gt;&gt; Ahnu Nahki wrote:\n&gt;&gt; &gt; Instead of writin=\r\ng to an arc file, Id like to create a method that\n&gt;&gt; &gt; takes the URI info, =\r\nContent, headers, ect into a MYSQL database. Does\n&gt;&gt; &gt; anyone have any sugg=\r\nestion on how to do this , where I should look to\n&gt;&gt; &gt; place my methods?\n&gt;&gt;=\r\n \n&gt;&gt; Are you interested in that specifically to get away from ARC, or more =\r\n\n&gt;&gt; simply because you&#39;re interested in being able to issue queries on the =\r\n\n&gt;&gt; crawl results in interesting/relational ways?  I ask because we&#39;re \n&gt;&gt; =\r\nlooking into a slightly different approach - rather than building the \n&gt;&gt; d=\r\natabase logic into Heritrix, treating the DB import as a \n&gt;&gt; post-processin=\r\ng step on the crawl output (ARC files & logs) once the \n&gt;&gt; crawl is complet=\r\ne.  I believe Tom Emerson has also talked about \n&gt;&gt; populating a DB from AR=\r\nC files in future versions of his libarc library.\n&gt;&gt; \n&gt;&gt; By keeping the con=\r\ntent in ARCs, you get the ability to leverage the \n&gt;&gt; growing number of too=\r\nls for dealing with the format coming from this \n&gt;&gt; community, and if the p=\r\nost-processing approach can work for you, code \n&gt;&gt; for populating a DB may =\r\nbe forthcoming from a couple of sources in the \n&gt;&gt; near future.\n&gt;&gt; \n&gt;&gt; Can =\r\nyou describe in more detail what you&#39;re envisioning with your \n&gt;&gt; planned D=\r\nB crawl storage?\n&gt;&gt; \n&gt;&gt; Regards,\n&gt;&gt; Andy Boyko    aboy@l...     Library of =\r\nCongress\n&gt;\n&gt;We had considered that aswell initially as a quick way of impor=\r\nting\n&gt;the data into the db. Going the arc route after a crawl. But we have =\r\na\n&gt;search engine we run that is powered by\n&gt;lucene(http://jakarta.apache.or=\r\ng/lucene/docs/index.html). We have our\n&gt;own crawler which has done all it c=\r\nan and is not nearly as powerful as\n&gt;heritrix. So we want to incorporate he=\r\nritrix into out environment\n&gt;quickly. We make all our indexes off of conten=\r\nt stored in the db, and\n&gt;it makes alot of sense for us to just have the cra=\r\nwler populate the db\n&gt;at runtime than have some post crawl method were we d=\r\no it. \n&gt;\n\n\n"}}