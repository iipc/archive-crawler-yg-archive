{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":501493342,"authorName":"paul.ihde","from":"&quot;paul.ihde&quot; &lt;paul.ihde@...&gt;","profile":"paul.ihde","replyTo":"LIST","senderId":"IE5v8paCmC78rqvzk77DLaN-tNQ3fUd_39cc0XYhUjfM7gIEOG8RIfeo2eqX-TuOzVurMuKyJJ3XjpAL40Sb9mwMXgHpTA_M","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Setting crawl max depth per seed (H3)","postDate":"1328689608","msgId":7612,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGpndGJrOCsyY2ZvQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDRGMzE3RURELjUwMDAwMDVAYXJjaGl2ZS5vcmc+"},"prevInTopic":7611,"nextInTopic":7613,"prevInTime":7611,"nextInTime":7613,"topicId":7607,"numMessagesInTopic":4,"msgSnippet":"Hi Gordon, Thanks a lot for the hint. I have researched a little bit in the last and I realized that I don t know how to actually do what you are suggesting","rawEmail":"Return-Path: &lt;paul.ihde@...&gt;\r\nX-Sender: paul.ihde@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 27776 invoked from network); 8 Feb 2012 08:26:50 -0000\r\nX-Received: from unknown (98.137.35.160)\n  by m16.grp.sp2.yahoo.com with QMQP; 8 Feb 2012 08:26:50 -0000\r\nX-Received: from unknown (HELO ng1-ip1.bullet.mail.ne1.yahoo.com) (98.138.215.55)\n  by mta4.grp.sp2.yahoo.com with SMTP; 8 Feb 2012 08:26:49 -0000\r\nX-Received: from [98.138.217.179] by ng1.bullet.mail.ne1.yahoo.com with NNFMP; 08 Feb 2012 08:26:49 -0000\r\nX-Received: from [69.147.65.149] by tg4.bullet.mail.ne1.yahoo.com with NNFMP; 08 Feb 2012 08:26:49 -0000\r\nX-Received: from [98.137.34.32] by t9.bullet.mail.sp1.yahoo.com with NNFMP; 08 Feb 2012 08:26:49 -0000\r\nDate: Wed, 08 Feb 2012 08:26:48 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;jgtbk8+2cfo@...&gt;\r\nIn-Reply-To: &lt;4F317EDD.5000005@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;paul.ihde&quot; &lt;paul.ihde@...&gt;\r\nSubject: Re: Setting crawl max depth per seed (H3)\r\nX-Yahoo-Group-Post: member; u=501493342; y=-0MwfN-vi-u2CCpCC51znsoNo8aes1tdZHEmLLmhBdE1T_sg\r\nX-Yahoo-Profile: paul.ihde\r\n\r\nHi Gordon,\n\n\nThanks a lot for the hint.\n\nI have researched a little bit in =\r\nthe last and I realized that I don&#39;t know how to actually do what you are s=\r\nuggesting (even if I understand it).\n\nBasically I fail to write the XML tha=\r\nt would :\n1). configure the seed as to carry forward the &quot;source tag&quot;\n2). c=\r\nonfigure the DecideRule that checks/limits the length of the &#39;hops-path&#39;\n\nC=\r\nould you please give a short XML example with 2 seeds and 2 decide rules th=\r\nat limit the hops-path based on the source tag (set to carry forward to ori=\r\nginal seed). \nI believe that other people who use the mailing list would al=\r\nso benefit from such an example (hoping that I&#39;m not the only newbie around=\r\n :))\n\nCheers\nPaul.\n\n\n--- In archive-crawler@yahoogroups.com, Gordon Mohr &lt;g=\r\nojomo@...&gt; wrote:\n&gt;\n&gt; There&#39;s no built-in facility for this.\n&gt; \n&gt; A quick-a=\r\nnd-dirty approach to writing a custom DecideRule might look at \n&gt; the &#39;sour=\r\nce-tag&#39; (which can be set to carry forward the original seed) \n&gt; and then, =\r\ndepending on that, apply different limits to the length of the \n&gt; &#39;hops-pat=\r\nh&#39; string.\n&gt; \n&gt; But, since the crawler is only evaluating the paths it happ=\r\nened to \n&gt; follow, rather than *all* paths or *all shortest paths*, there w=\r\nill be \n&gt; situations where this is unlikely to do exactly what you want.\n&gt; =\r\n\n&gt; Consider two seed URIs, A and B.\n&gt; \n&gt; Let&#39;s say you want to crawl from A=\r\n to a depth of 1, and from B to a \n&gt; depth of 5.\n&gt; \n&gt; The crawl starts. URI=\r\n A is fetched. An outlink from A goes to C, it&#39;s 1 \n&gt; hop away, C is enqueu=\r\ned and marked as having been discovered from &#39;A&#39; \n&gt; (as source-tag). C is t=\r\nhen fetched. All its outlinks are depth 2, and \n&gt; are all marked as discove=\r\nred via A, and thus over the depth-limit and \n&gt; ignored.\n&gt; \n&gt; URI B was als=\r\no fetched in parallel. It may also have an outlink to C. \n&gt; But if that out=\r\nlink loses the race to seen-yet testing with the one from \n&gt; A, only the on=\r\ne marked as coming from A is enqueued. If the outlink from \n&gt; B won the rac=\r\ne, 4 more hops from C would have been fetched. But it \n&gt; didn&#39;t, so they&#39;re=\r\n not (though they might be discovered without \n&gt; prejudice via other paths)=\r\n.\n&gt; \n&gt; - Gordon\n&gt; \n&gt; On 2/4/12 10:25 AM, paul.ihde wrote:\n&gt; &gt; Hi,\n&gt; &gt;\n&gt; &gt; T=\r\nhe documentation on setting the max depth of crawl has only examples on how=\r\n to set the max crawl depth on the whole &quot;seed list&quot; level. I would like to=\r\n know if it&#39;s (and how) possible to set the crawl depth per individual seed=\r\n. I know that this could be achieved by having one crawl job for every seed=\r\n, but this would be quite cumbersome. So I suppose there is some mechanism =\r\nin Heritrix 3 to set the max depth level per seed.\n&gt; &gt;\n&gt; &gt; A. What I know (=\r\nand understand) : setting a max depth level on all the seeds\n&gt; &gt; As such if=\r\n my seed list is :\n&gt; &gt; * www.domain1.com\n&gt; &gt; * www.domain2.com\n&gt; &gt; * www.do=\r\nmain3.com\n&gt; &gt;\n&gt; &gt; and I set the :\n&gt; &gt;      &lt;bean class=3D&quot;org.archive.modul=\r\nes.deciderules.TooManyHopsDecideRule&quot;&gt;\n&gt; &gt;       &lt;property name=3D&quot;maxHops&quot;=\r\n value=3D&quot;3&quot; /&gt;\n&gt; &gt;      &lt;/bean&gt;\n&gt; &gt;\n&gt; &gt; then basically it will limit the c=\r\nrawl depth level to all the seed to the same level :\n&gt; &gt; * www.domain1.com =\r\n(max depth =3D 3)\n&gt; &gt; * www.domain2.com (max depth =3D3)\n&gt; &gt; * www.domain3.=\r\ncom (max depth =3D 3)\n&gt; &gt;\n&gt; &gt; B. What I would like to do (but I don&#39;t know =\r\nhow) : setting a max depth level at seed level\n&gt; &gt; As such if my seed list =\r\nis :\n&gt; &gt; * www.domain1.com\n&gt; &gt; * www.domain2.com\n&gt; &gt; * www.domain3.com\n&gt; &gt;\n=\r\n&gt; &gt; and, I set the crawl depth on each seed, I would like to get :\n&gt; &gt; * ww=\r\nw.domain1.com (max depth =3D 1)\n&gt; &gt; * www.domain2.com (max depth =3D7)\n&gt; &gt; =\r\n* www.domain3.com (max depth =3D 3)\n&gt; &gt;\n&gt; &gt; Thanks\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; ----=\r\n--------------------------------\n&gt; &gt;\n&gt; &gt; Yahoo! Groups Links\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt;\n=\r\n\n\n\n"}}