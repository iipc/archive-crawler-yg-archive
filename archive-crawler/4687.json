{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"7ahoyWevvbc6vLap2YTX9aYwloOI_JH9I1FgfxJ2_9Fj68t9pO2K8bLG5bGT3OKpCJ2Vy0RitUVK-DPvar1emyksFbzO260","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Re: [HER-1103] feature request: implement skipHttpHeader/readHttpHeader for WARC","postDate":"1195079608","msgId":4687,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ3M0I3N0I4LjcwNDAxQGFyY2hpdmUub3JnPg==","inReplyToHeader":"PGZoZmwxYStkODFtQGVHcm91cHMuY29tPg==","referencesHeader":"PGZoZmwxYStkODFtQGVHcm91cHMuY29tPg=="},"prevInTopic":4684,"nextInTopic":0,"prevInTime":4686,"nextInTime":4688,"topicId":4677,"numMessagesInTopic":5,"msgSnippet":"... Yes, this is definitely a locking bottleneck. Also, because the Java synchronization isn t fair/fifo, I believe I ve seen ToeThreads being overtaken here,","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 16592 invoked from network); 14 Nov 2007 22:33:27 -0000\r\nX-Received: from unknown (66.218.67.97)\n  by m53.grp.scd.yahoo.com with QMQP; 14 Nov 2007 22:33:27 -0000\r\nX-Received: from unknown (HELO relay02.pair.com) (209.68.5.16)\n  by mta18.grp.scd.yahoo.com with SMTP; 14 Nov 2007 22:33:27 -0000\r\nX-Received: (qmail 91859 invoked from network); 14 Nov 2007 22:33:26 -0000\r\nX-Received: from unknown (HELO ?192.168.1.30?) (unknown)\n  by unknown with SMTP; 14 Nov 2007 22:33:26 -0000\r\nX-pair-Authenticated: 76.102.230.209\r\nMessage-ID: &lt;473B77B8.70401@...&gt;\r\nDate: Wed, 14 Nov 2007 14:33:28 -0800\r\nUser-Agent: Thunderbird 2.0.0.6 (Windows/20070728)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;fhfl1a+d81m@...&gt;\r\nIn-Reply-To: &lt;fhfl1a+d81m@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Re: [HER-1103] feature request: implement skipHttpHeader/readHttpHeader\n for WARC\r\nX-Yahoo-Group-Post: member; u=137285340; y=5PdxaQMWdSiWZmgQaSY3oNgDytqhprYY355mqDrNUNDQ\r\nX-Yahoo-Profile: gojomo\r\n\r\npandae667 wrote:\n&gt; The benefit I would like to see by the manager thread approach is\n&gt; seeing fewer threads being locked in:\n&gt; \n&gt;    ToeThread #195\n&gt; [ToeThread #195: http://www.someurl.com/somepage.html\n&gt;  CrawlURI http://www.someurl.com/somepage.html LLL\n&gt; http://www.someurl.com/somepageother.html 0 attempts\n&gt;     in processor: Scheduler\n&gt;     ACTIVE for 5s346ms\n&gt;     step: ABOUT_TO_BEGIN_PROCESSOR for 2s190ms\n&gt;    \n&gt; org.archive.crawler.postprocessor.FrontierScheduler.innerProcess(FrontierScheduler.java:76)\n&gt;     org.archive.crawler.framework.Processor.process(Processor.java:112)\n&gt;    \n&gt; org.archive.crawler.framework.ToeThread.processCrawlUri(ToeThread.java:302)\n&gt;     org.archive.crawler.framework.ToeThread.run(ToeThread.java:151)\n&gt; \n&gt; I have 200 ToeThreads starting their crawl with about 200000 seeds. At\n&gt; some point in the crawl more and more threads lock at this position\n&gt; (up to 20-25%) and it seems the code is quite suboptimal.\n\nYes, this is definitely a locking bottleneck. Also, because the Java \nsynchronization isn&#39;t fair/fifo, I believe I&#39;ve seen ToeThreads being \novertaken here, while other threads progress through multiple times.\n\n&gt; If I recall things correct from my mind right now (I don&#39;t have access\n&gt; to the code right now) that line of code is a global lock. Hitting\n&gt; this point an URI starts to canonicalize all its retrieved OutLinks\n&gt; and checks if they are in-scope. Afterwards all those links are put\n&gt; into the correct queues. All this canonicalization and in-scope\n&gt; testing is done/triggered by the Frontier. I were wondering if it\n&gt; wouldn&#39;t be a better approach to do the canonicalization and in-scope\n&gt; testing before locking all the other threads that want to do the exact\n&gt; same thing (which I think can be done without touching any frontier\n&gt; internals). Only when an URI starts to enqueue its OutCandidates it\n&gt; might/should be required to lock out the other threads.\n\nThis is largely correct, though scope-testing occurs outside of the lock \nin a previous processor. Canonicalization occurs inside the lock, \nthough, and could be moved out. (Though, since canonicalization usually \nrequires no IO, I would only expect a slight improvement from this \nparallelization, and only on multicore machines.)\n\nThere&#39;s certainly room for improvement here.\n\n&gt; I might be wrong with my presumptions as I know and understand some of\n&gt; Heritrixs internals - but for sure not yet all of them. My hope is/was\n&gt; that this manager thread approach might overcome this problem and\n&gt; speed up crawling.\n\nYou presumptions seem right, and it&#39;s also my hope the manager-thread \napproach will help here, though it&#39;s not the main reason for the change.\n\nI don&#39;t yet have enough experience with the change to see such benefits, \nand it may require additional refactoring before any tangible \nimprovement is seen. (In particular, the already-included testing which \nalso occurs inside that lock may also benefit from being decoupled from \nthe worker threads and the frontier with buffer queues and its own \nmanager thread.)\n\nStill, if we achieve greater throughput and lower contention with the \n2.0 approach, our first choice would be help people move to the later \ncode, rather than retrofit the approach to 1.x.\n\n- Gordon @ IA\n\n\n"}}