{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"gSNiXfZlw2yAaUtGS0mMaQBRBQF9Iu5hPAFb-gmkTJRBODxrzM2-qOGvm8p1qArAfBbKPvzkWqmhpiCUtMZvHg_90xrb2eg","spamInfo":{"isSpam":false,"reason":"2"},"subject":"Re: [archive-crawler] crawl troubles","postDate":"1239227444","msgId":5769,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ5REQxQzM0LjgwNzA3MDhAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGdyaTI0ZSt0Y21yQGVHcm91cHMuY29tPg==","referencesHeader":"PGdyaTI0ZSt0Y21yQGVHcm91cHMuY29tPg=="},"prevInTopic":5768,"nextInTopic":5770,"prevInTime":5768,"nextInTime":5770,"topicId":5768,"numMessagesInTopic":3,"msgSnippet":"Richard - Please reply to previous messages so all traffic on this topic lands in the same thread. I don t see any problems with your order.xml. The only way","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 29546 invoked from network); 8 Apr 2009 21:51:13 -0000\r\nX-Received: from unknown (98.137.34.46)\n  by m3.grp.sp2.yahoo.com with QMQP; 8 Apr 2009 21:51:13 -0000\r\nX-Received: from unknown (HELO relay03.pair.com) (209.68.5.17)\n  by mta3.grp.sp2.yahoo.com with SMTP; 8 Apr 2009 21:51:13 -0000\r\nX-Received: (qmail 22487 invoked from network); 8 Apr 2009 21:50:41 -0000\r\nX-Received: from 70.137.147.22 (HELO ?10.0.13.7?) (70.137.147.22)\n  by relay03.pair.com with SMTP; 8 Apr 2009 21:50:41 -0000\r\nX-pair-Authenticated: 70.137.147.22\r\nMessage-ID: &lt;49DD1C34.8070708@...&gt;\r\nDate: Wed, 08 Apr 2009 14:50:44 -0700\r\nUser-Agent: Thunderbird 2.0.0.21 (Windows/20090302)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;gri24e+tcmr@...&gt;\r\nIn-Reply-To: &lt;gri24e+tcmr@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 2:2:2:0:1\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] crawl troubles\r\nX-Yahoo-Group-Post: member; u=137285340; y=d2kfDEWHPjxxNjynl_YBhZ5EKtrWCfPQpNC_Wi5suD9M\r\nX-Yahoo-Profile: gojomo\r\n\r\nRichard -\n\nPlease &#39;reply&#39; to previous messages so all traffic on this topic lands \nin the same thread.\n\nI don&#39;t see any problems with your order.xml. The only way I can get a \nresult similar to yours is if I launch a crawl with no seed URLs at all.\n\nIs there anything in the job&#39;s &#39;progress-statistics.log&#39;?\n\nIt shouldn&#39;t be that hard to switch to Sun&#39;s Java... there is lots of \ninfo online about how to do it. Usually it just involves enabling the \nright repository, doing an appropriate &#39;apt-get&#39; (for a package like \n&#39;sun-java6-jdk&#39;), then setting that Java to be the default using &#39;sudo \nupdate-java-alternatives&#39;. See here for more info:\n\nhttps://help.ubuntu.com/community/Java\n\n32/64 bit should be irrelevant -- Sun Java is available for both. \nNetBeans is also irrelevant and unneeded.\n\n- Gordon @ IA\n\nbowser.richard wrote:\n&gt; Hi Gordon\n&gt; \n&gt; Yes, I launched my &#39;all defaults&#39; crawl by starting from the bundled,\n&gt; never-edited &#39;default&#39; profile.  This has always been my result in trying to use Heritrix.  No I have never tried Sun&#39;s JDK, although I&#39;d like to.  The fact is I&#39;m too new to Ubuntu to know how to clean my system from OpenJDK 64-bit VM and go with Sun&#39;s 32-bit JDK.\n&gt; \n&gt; I could wipe my whole system and start over with 64-bit Ubuntu, but while that install works for me, the 32-bit Ubuntu install just dies in the water.  I started trying to use Sun&#39;s JDK and could not manage it with Ubuntu.  I also need Sun&#39;s NetBeans 6.5 IDE, and only finally managed to get it running.\n&gt; \n&gt; I wiped all previous crawl info, and did a fresh restart.  This time I did not specify {$HOSTNAME}.  I started another &#39;all defaults&quot; crawl, specifying this: \n&gt; \n&gt; Meta data\n&gt; Description:\t\tX_Perry_Mental\n&gt; Crawl Operator:\t\tAdmin\n&gt; Crawl Organization:\tcs.nmt.edu\n&gt; Crawl Job Recipient: \tbowser@...\n&gt; crawl-order\t\tHeritrix crawl order.\n&gt; max-bytes-download:\t0\n&gt; max-document-download:\t1000\n&gt; max-time-sec:\t\t3600\n&gt; max-toe-threads:\t50\n&gt; scope\t\t\tDecidingScope.\n&gt; enabled:\t\tTrue\n&gt; decide-rules\t\tDecideRuleSequence.\n&gt; rules\t\t\tThis is a list of DecideRules to be applied in sequence.\n&gt;   rejectByDefault\tRejectDecideRule: always gives REJECT decision. \n&gt;   acceptIfSurtPrefixed\tSurtPrefixedDecideRule.\n&gt;     decision:\t\tAccept\n&gt;     surts-source-file:\t(blank)\n&gt;     seeds-as-surt-prefixes: True\n&gt; rejectIfTooManyHops\tTooManyHopsDecideRule.\n&gt;   max-hops:\t\t20\n&gt; acceptIfTranscluded\tTransclusionDecideRule.\n&gt;   max-trans-hops:\t3\n&gt;   max-speculative-hops:\t1\n&gt; rejectIfPathological\tPathologicalPathDecideRule.\n&gt;   max-repetitions:\t2\n&gt; rejectIfTooManyPathSegs\tTooManyPathSegmentsDecideRule.\n&gt;   max-path-depth:\t20\n&gt; acceptIfPrerequisite\tPrerequisiteAcceptDecideRule.\n&gt; http-headers\t\tHTTP headers.\n&gt;   user-agent:\t\t(compatible; heritrix/1.14.3 +http://www.cs.nmt.edu/bowserdog.xml)\n&gt;   from:\t\t\tmailto:bowser.richard@...\n&gt; \n&gt; -ALL ELSE WAS UNALTERED -\n&gt; \n&gt; There were no alerts in any of my attempted crawls, just immediate completion at about 52 ms with zero results.\n&gt; \n&gt; At this pont, I submitted the job and then had one pending job.  Then I started it.  Here are the results:\n&gt; \n&gt; Admin Console\n&gt; \t   \t\n&gt; Status as of Apr. 8, 2009 11:20:21 GMT    Alerts: no alerts\n&gt; Crawling Jobs  \tPreparing job: Clueless_Lewis\n&gt; 0 jobs pending, 0 completed   \t0 URIs in 0s (0/sec)\n&gt; \t  \n&gt;   Crawler Status: CRAWLING JOBS | Hold\n&gt; Memory\n&gt; 17954 KB used\n&gt; 26924 KB current heap\n&gt; 253440 KB max heap\n&gt; Jobs\n&gt; None available\n&gt; 0 pending, 1 completed\n&gt; Alerts: 0 (0 new) \n&gt; \n&gt; At this point, I shut down the Heritrix software to ensure complete reporting.\n&gt; \n&gt; Here is my heritrix_out.log:\n&gt; Wed Apr  8 04:31:58 MDT 2009 Starting heritrix\n&gt; Linux Rough-Writer 2.6.27-11-server #1 SMP Wed Apr 1 21:34:13 UTC 2009 x86_64 GNU/Linux\n&gt; java version &quot;1.6.0_0&quot;\n&gt; IcedTea6 1.3.1 (6b12-0ubuntu6.4) Runtime Environment (build 1.6.0_0-b12)\n&gt; OpenJDK 64-Bit Server VM (build 1.6.0_0-b12, mixed mode)\n&gt; JAVA_OPTS= -Xmx256m\n&gt; time(seconds)        unlimited\n&gt; file(blocks)         unlimited\n&gt; data(kbytes)         unlimited\n&gt; stack(kbytes)        8192\n&gt; coredump(blocks)     0\n&gt; memory(kbytes)       unlimited\n&gt; locked memory(kbytes) 32\n&gt; process              7677\n&gt; nofiles              1024\n&gt; vmemory(kbytes)      unlimited\n&gt; locks                unlimited\n&gt; 10:32:01.488 EVENT  Starting Jetty/4.2.23\n&gt; 10:32:02.158 EVENT  Started WebApplicationContext[/,Heritrix Console]\n&gt; 10:32:02.376 EVENT  Started SocketListener on 127.0.0.1:8080\n&gt; 10:32:02.376 EVENT  Started org.mortbay.jetty.Server@8f0c85e\n&gt; 04/08/2009 10:32:03 +0000 INFO org.archive.crawler.Heritrix postRegister org.archive.crawler:guiport=8080,host=Rough-Writer,jmxport=8849,name=Heritrix,type=CrawlService registered to MBeanServerId=Rough-Writer_1239186719268, SpecificationVersion=1.4, ImplementationVersion=1.6.0_0-b12, SpecificationVendor=Sun Microsystems\n&gt; Heritrix version: 1.14.3\n&gt; 127.0.0.1 - - [08/Apr/2009:10:32:41 +0000] &quot;GET / HTTP/1.1&quot; 302 0 \n&gt; 127.0.0.1 - - [08/Apr/2009:10:32:41 +0000] &quot;GET /index.jsp HTTP/1.1&quot; 302 0 \n&gt; 127.0.0.1 - - [08/Apr/2009:10:32:41 +0000] &quot;GET /login.jsp;jsessionid=5ccbl6n0rafba HTTP/1.1&quot; 200 2743 \n&gt; 127.0.0.1 - - [08/Apr/2009:10:32:44 +0000] &quot;GET /favicon.ico HTTP/1.1&quot; 404 1214 \n&gt; 127.0.0.1 - Rufus [08/Apr/2009:10:32:55 +0000] &quot;POST /j_security_check HTTP/1.1&quot; 302 0 \n&gt; 127.0.0.1 - Rufus [08/Apr/2009:10:32:55 +0000] &quot;GET /index.jsp HTTP/1.1&quot; 200 8457 \n&gt; 127.0.0.1 - Rufus [08/Apr/2009:10:32:58 +0000] &quot;GET /jobs.jsp HTTP/1.1&quot; 200 7286 \n&gt; 127.0.0.1 - Rufus [08/Apr/2009:10:33:00 +0000] &quot;GET /jobs/new.jsp HTTP/1.1&quot; 200 9076 \n&gt; 127.0.0.1 - Rufus [08/Apr/2009:10:33:54 +0000] &quot;POST /jobs/new.jsp HTTP/1.1&quot; 302 19 \n&gt; 127.0.0.1 - Rufus [08/Apr/2009:10:33:55 +0000] &quot;GET /jobs/modules.jsp?job=20090408103354968 HTTP/1.1&quot; 200 52599 \n&gt; 127.0.0.1 - Rufus [08/Apr/2009:10:33:59 +0000] &quot;POST /jobs/modules.jsp HTTP/1.1&quot; 302 39 \n&gt; 127.0.0.1 - Rufus [08/Apr/2009:10:33:59 +0000] &quot;GET /jobs/configure.jsp?job=20090408103354968 HTTP/1.1&quot; 200 150920 \n&gt; 127.0.0.1 - Rufus [08/Apr/2009:11:16:32 +0000] &quot;GET /jobs.jsp?message=Job%20created HTTP/1.1&quot; 200 8599 \n&gt; 127.0.0.1 - Rufus [08/Apr/2009:11:16:32 +0000] &quot;POST /jobs/configure.jsp HTTP/1.1&quot; 302 1073 \n&gt; 127.0.0.1 - Rufus [08/Apr/2009:11:19:36 +0000] &quot;GET /index.jsp HTTP/1.1&quot; 200 8457 \n&gt; 127.0.0.1 - Rufus [08/Apr/2009:11:20:21 +0000] &quot;GET /console/action.jsp?action=start HTTP/1.1&quot; 302 8 \n&gt; 127.0.0.1 - Rufus [08/Apr/2009:11:20:21 +0000] &quot;GET /index.jsp HTTP/1.1&quot; 200 11011 \n&gt; 04/08/2009 11:20:23 +0000 INFO org.archive.crawler.admin.CrawlJob postRegister org.archive.crawler:host=Rough-Writer,jmxport=8849,mother=Heritrix,name=Clueless_Lewis-20090408103354968,type=CrawlService.Job registered to MBeanServerId=Rough-Writer_1239186719268, SpecificationVersion=1.4, ImplementationVersion=1.6.0_0-b12, SpecificationVendor=Sun Microsystems\n&gt; 04/08/2009 11:20:31 +0000 INFO org.archive.crawler.admin.CrawlJob postDeregister org.archive.crawler:host=Rough-Writer,jmxport=8849,mother=Heritrix,name=Clueless_Lewis-20090408103354968,type=CrawlService.Job unregistered from MBeanServerId=Rough-Writer_1239186719268, SpecificationVersion=1.4, ImplementationVersion=1.6.0_0-b12, SpecificationVendor=Sun Microsystems\n&gt; 127.0.0.1 - - [08/Apr/2009:11:21:56 +0000] &quot;GET / HTTP/1.1&quot; 302 0 \n&gt; 127.0.0.1 - Rufus [08/Apr/2009:11:21:56 +0000] &quot;GET /index.jsp HTTP/1.1&quot; 200 8537 \n&gt; 127.0.0.1 - Rufus [08/Apr/2009:11:23:23 +0000] &quot;GET /console/shutdown.jsp HTTP/1.1&quot; 200 7942 \n&gt; 127.0.0.1 - Rufus [08/Apr/2009:11:23:57 +0000] &quot;POST /console/shutdown.jsp HTTP/1.1&quot; 200 7277 \n&gt; 04/08/2009 11:23:57 +0000 INFO org.archive.crawler.Heritrix postDeregister org.archive.crawler:guiport=8080,host=Rough-Writer,jmxport=8849,name=Heritrix,type=CrawlService unregistered from MBeanServerId=Rough-Writer_1239186719268, SpecificationVersion=1.4, ImplementationVersion=1.6.0_0-b12, SpecificationVendor=Sun Microsystems\n&gt; 11:23:57.699 EVENT  Stopping Acceptor ServerSocket[addr=/127.0.0.1,port=0,localport=8080]\n&gt; 11:23:57.700 EVENT  Stopped SocketListener on 127.0.0.1:8080\n&gt; 11:23:57.701 EVENT  Stopped WebApplicationContext[/,Heritrix Console]\n&gt; 11:23:57.702 EVENT  Stopped org.mortbay.http.NCSARequestLog@79f7abae\n&gt; 11:23:57.702 EVENT  Stopped org.mortbay.jetty.Server@8f0c85e\n&gt; \n&gt; As I see it, it reports NO PROBLEMS WHATSOEVER.\n&gt; \n&gt; Here is my order.xml:\n&gt; &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;crawl-order xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;heritrix_settings.xsd&quot;&gt;\n&gt;   &lt;meta&gt;\n&gt;     &lt;name&gt;Clueless_Lewis&lt;/name&gt;\n&gt;     &lt;description&gt;X_Perry_Mental&lt;/description&gt;\n&gt;     &lt;operator&gt;Admin&lt;/operator&gt;\n&gt;     &lt;organization&gt;cs.nmt.edu&lt;/organization&gt;\n&gt;     &lt;audience&gt;bowser@...&lt;/audience&gt;\n&gt;     &lt;date&gt;20090408111632&lt;/date&gt;\n&gt;   &lt;/meta&gt;\n&gt;   &lt;controller&gt;\n&gt;     &lt;string name=&quot;settings-directory&quot;&gt;settings&lt;/string&gt;\n&gt;     &lt;string name=&quot;disk-path&quot;/&gt;\n&gt;     &lt;string name=&quot;logs-path&quot;&gt;logs&lt;/string&gt;\n&gt;     &lt;string name=&quot;checkpoints-path&quot;&gt;checkpoints&lt;/string&gt;\n&gt;     &lt;string name=&quot;state-path&quot;&gt;state&lt;/string&gt;\n&gt;     &lt;string name=&quot;scratch-path&quot;&gt;scratch&lt;/string&gt;\n&gt;     &lt;long name=&quot;max-bytes-download&quot;&gt;0&lt;/long&gt;\n&gt;     &lt;long name=&quot;max-document-download&quot;&gt;1000&lt;/long&gt;\n&gt;     &lt;long name=&quot;max-time-sec&quot;&gt;3600&lt;/long&gt;\n&gt;     &lt;integer name=&quot;max-toe-threads&quot;&gt;50&lt;/integer&gt;\n&gt;     &lt;integer name=&quot;recorder-out-buffer-bytes&quot;&gt;4096&lt;/integer&gt;\n&gt;     &lt;integer name=&quot;recorder-in-buffer-bytes&quot;&gt;65536&lt;/integer&gt;\n&gt;     &lt;integer name=&quot;bdb-cache-percent&quot;&gt;0&lt;/integer&gt;\n&gt;     &lt;newObject name=&quot;scope&quot; class=&quot;org.archive.crawler.deciderules.DecidingScope&quot;&gt;\n&gt;       &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;string name=&quot;seedsfile&quot;&gt;seeds.txt&lt;/string&gt;\n&gt;       &lt;boolean name=&quot;reread-seeds-on-config&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;newObject name=&quot;decide-rules&quot; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;         &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;newObject name=&quot;rejectByDefault&quot; class=&quot;org.archive.crawler.deciderules.RejectDecideRule&quot;&gt;\n&gt;           &lt;/newObject&gt;\n&gt;           &lt;newObject name=&quot;acceptIfSurtPrefixed&quot; class=&quot;org.archive.crawler.deciderules.SurtPrefixedDecideRule&quot;&gt;\n&gt;             &lt;string name=&quot;decision&quot;&gt;ACCEPT&lt;/string&gt;\n&gt;             &lt;string name=&quot;surts-source-file&quot;/&gt;\n&gt;             &lt;boolean name=&quot;seeds-as-surt-prefixes&quot;&gt;true&lt;/boolean&gt;\n&gt;             &lt;string name=&quot;surts-dump-file&quot;/&gt;\n&gt;             &lt;boolean name=&quot;also-check-via&quot;&gt;false&lt;/boolean&gt;\n&gt;             &lt;boolean name=&quot;rebuild-on-reconfig&quot;&gt;true&lt;/boolean&gt;\n&gt;           &lt;/newObject&gt;\n&gt;           &lt;newObject name=&quot;rejectIfTooManyHops&quot; class=&quot;org.archive.crawler.deciderules.TooManyHopsDecideRule&quot;&gt;\n&gt;             &lt;integer name=&quot;max-hops&quot;&gt;20&lt;/integer&gt;\n&gt;           &lt;/newObject&gt;\n&gt;           &lt;newObject name=&quot;acceptIfTranscluded&quot; class=&quot;org.archive.crawler.deciderules.TransclusionDecideRule&quot;&gt;\n&gt;             &lt;integer name=&quot;max-trans-hops&quot;&gt;3&lt;/integer&gt;\n&gt;             &lt;integer name=&quot;max-speculative-hops&quot;&gt;1&lt;/integer&gt;\n&gt;           &lt;/newObject&gt;\n&gt;           &lt;newObject name=&quot;rejectIfPathological&quot; class=&quot;org.archive.crawler.deciderules.PathologicalPathDecideRule&quot;&gt;\n&gt;             &lt;integer name=&quot;max-repetitions&quot;&gt;2&lt;/integer&gt;\n&gt;           &lt;/newObject&gt;\n&gt;           &lt;newObject name=&quot;rejectIfTooManyPathSegs&quot; class=&quot;org.archive.crawler.deciderules.TooManyPathSegmentsDecideRule&quot;&gt;\n&gt;             &lt;integer name=&quot;max-path-depth&quot;&gt;20&lt;/integer&gt;\n&gt;           &lt;/newObject&gt;\n&gt;           &lt;newObject name=&quot;acceptIfPrerequisite&quot; class=&quot;org.archive.crawler.deciderules.PrerequisiteAcceptDecideRule&quot;&gt;\n&gt;           &lt;/newObject&gt;\n&gt;         &lt;/map&gt;\n&gt;       &lt;/newObject&gt;\n&gt;     &lt;/newObject&gt;\n&gt;     &lt;map name=&quot;http-headers&quot;&gt;\n&gt;       &lt;string name=&quot;user-agent&quot;&gt;Mozilla/5.0 (compatible; heritrix/1.14.3 +http://www.cs.nmt.edu/bowserdog.xml)&lt;/string&gt;\n&gt;       &lt;string name=&quot;from&quot;&gt;mailto:bowser.richard@...&lt;/string&gt;\n&gt;     &lt;/map&gt;\n&gt;     &lt;newObject name=&quot;robots-honoring-policy&quot; class=&quot;org.archive.crawler.datamodel.RobotsHonoringPolicy&quot;&gt;\n&gt;       &lt;string name=&quot;type&quot;&gt;classic&lt;/string&gt;\n&gt;       &lt;boolean name=&quot;masquerade&quot;&gt;false&lt;/boolean&gt;\n&gt;       &lt;text name=&quot;custom-robots&quot;/&gt;\n&gt;       &lt;stringList name=&quot;user-agents&quot;&gt;\n&gt;       &lt;/stringList&gt;\n&gt;     &lt;/newObject&gt;\n&gt;     &lt;newObject name=&quot;frontier&quot; class=&quot;org.archive.crawler.frontier.BdbFrontier&quot;&gt;\n&gt;       &lt;float name=&quot;delay-factor&quot;&gt;4.0&lt;/float&gt;\n&gt;       &lt;integer name=&quot;max-delay-ms&quot;&gt;20000&lt;/integer&gt;\n&gt;       &lt;integer name=&quot;min-delay-ms&quot;&gt;2000&lt;/integer&gt;\n&gt;       &lt;integer name=&quot;respect-crawl-delay-up-to-secs&quot;&gt;300&lt;/integer&gt;\n&gt;       &lt;integer name=&quot;max-retries&quot;&gt;30&lt;/integer&gt;\n&gt;       &lt;long name=&quot;retry-delay-seconds&quot;&gt;900&lt;/long&gt;\n&gt;       &lt;integer name=&quot;preference-embed-hops&quot;&gt;1&lt;/integer&gt;\n&gt;       &lt;integer name=&quot;total-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt;       &lt;integer name=&quot;max-per-host-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt;       &lt;string name=&quot;queue-assignment-policy&quot;&gt;org.archive.crawler.frontier.HostnameQueueAssignmentPolicy&lt;/string&gt;\n&gt;       &lt;string name=&quot;force-queue-assignment&quot;/&gt;\n&gt;       &lt;boolean name=&quot;pause-at-start&quot;&gt;false&lt;/boolean&gt;\n&gt;       &lt;boolean name=&quot;pause-at-finish&quot;&gt;false&lt;/boolean&gt;\n&gt;       &lt;boolean name=&quot;source-tag-seeds&quot;&gt;false&lt;/boolean&gt;\n&gt;       &lt;boolean name=&quot;recovery-log-enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;boolean name=&quot;hold-queues&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;integer name=&quot;balance-replenish-amount&quot;&gt;3000&lt;/integer&gt;\n&gt;       &lt;integer name=&quot;error-penalty-amount&quot;&gt;100&lt;/integer&gt;\n&gt;       &lt;long name=&quot;queue-total-budget&quot;&gt;-1&lt;/long&gt;\n&gt;       &lt;string name=&quot;cost-policy&quot;&gt;org.archive.crawler.frontier.ZeroCostAssignmentPolicy&lt;/string&gt;\n&gt;       &lt;long name=&quot;snooze-deactivate-ms&quot;&gt;300000&lt;/long&gt;\n&gt;       &lt;integer name=&quot;target-ready-backlog&quot;&gt;50&lt;/integer&gt;\n&gt;       &lt;string name=&quot;uri-included-structure&quot;&gt;org.archive.crawler.util.BdbUriUniqFilter&lt;/string&gt;\n&gt;       &lt;boolean name=&quot;dump-pending-at-close&quot;&gt;false&lt;/boolean&gt;\n&gt;     &lt;/newObject&gt;\n&gt;     &lt;map name=&quot;uri-canonicalization-rules&quot;&gt;\n&gt;       &lt;newObject name=&quot;Lowercase&quot; class=&quot;org.archive.crawler.url.canonicalize.LowercaseRule&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;Userinfo&quot; class=&quot;org.archive.crawler.url.canonicalize.StripUserinfoRule&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;WWW[0-9]*&quot; class=&quot;org.archive.crawler.url.canonicalize.StripWWWNRule&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;SessionIDs&quot; class=&quot;org.archive.crawler.url.canonicalize.StripSessionIDs&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;SessionCFIDs&quot; class=&quot;org.archive.crawler.url.canonicalize.StripSessionCFIDs&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;QueryStrPrefix&quot; class=&quot;org.archive.crawler.url.canonicalize.FixupQueryStr&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;/newObject&gt;\n&gt;     &lt;/map&gt;\n&gt;     &lt;map name=&quot;pre-fetch-processors&quot;&gt;\n&gt;       &lt;newObject name=&quot;Preselector&quot; class=&quot;org.archive.crawler.prefetch.Preselector&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;Preselector#decide-rules&quot; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;         &lt;boolean name=&quot;override-logger&quot;&gt;false&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;recheck-scope&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;block-all&quot;&gt;false&lt;/boolean&gt;\n&gt;         &lt;string name=&quot;block-by-regexp&quot;/&gt;\n&gt;         &lt;string name=&quot;allow-by-regexp&quot;/&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;Preprocessor&quot; class=&quot;org.archive.crawler.prefetch.PreconditionEnforcer&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;Preprocessor#decide-rules&quot; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;         &lt;integer name=&quot;ip-validity-duration-seconds&quot;&gt;21600&lt;/integer&gt;\n&gt;         &lt;integer name=&quot;robot-validity-duration-seconds&quot;&gt;86400&lt;/integer&gt;\n&gt;         &lt;boolean name=&quot;calculate-robots-only&quot;&gt;false&lt;/boolean&gt;\n&gt;       &lt;/newObject&gt;\n&gt;     &lt;/map&gt;\n&gt;     &lt;map name=&quot;fetch-processors&quot;&gt;\n&gt;       &lt;newObject name=&quot;DNS&quot; class=&quot;org.archive.crawler.fetcher.FetchDNS&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;DNS#decide-rules&quot; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;         &lt;boolean name=&quot;accept-non-dns-resolves&quot;&gt;false&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;digest-content&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;string name=&quot;digest-algorithm&quot;&gt;sha1&lt;/string&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;HTTP&quot; class=&quot;org.archive.crawler.fetcher.FetchHTTP&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;HTTP#decide-rules&quot; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;         &lt;newObject name=&quot;midfetch-decide-rules&quot; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;         &lt;integer name=&quot;timeout-seconds&quot;&gt;1200&lt;/integer&gt;\n&gt;         &lt;integer name=&quot;sotimeout-ms&quot;&gt;20000&lt;/integer&gt;\n&gt;         &lt;integer name=&quot;fetch-bandwidth&quot;&gt;0&lt;/integer&gt;\n&gt;         &lt;long name=&quot;max-length-bytes&quot;&gt;0&lt;/long&gt;\n&gt;         &lt;boolean name=&quot;ignore-cookies&quot;&gt;false&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;use-bdb-for-cookies&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;string name=&quot;load-cookies-from-file&quot;/&gt;\n&gt;         &lt;string name=&quot;save-cookies-to-file&quot;/&gt;\n&gt;         &lt;string name=&quot;trust-level&quot;&gt;open&lt;/string&gt;\n&gt;         &lt;stringList name=&quot;accept-headers&quot;&gt;\n&gt;         &lt;/stringList&gt;\n&gt;         &lt;string name=&quot;http-proxy-host&quot;/&gt;\n&gt;         &lt;string name=&quot;http-proxy-port&quot;/&gt;\n&gt;         &lt;string name=&quot;default-encoding&quot;&gt;ISO-8859-1&lt;/string&gt;\n&gt;         &lt;boolean name=&quot;digest-content&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;string name=&quot;digest-algorithm&quot;&gt;sha1&lt;/string&gt;\n&gt;         &lt;boolean name=&quot;send-if-modified-since&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;send-if-none-match&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;send-connection-close&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;send-referer&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;send-range&quot;&gt;false&lt;/boolean&gt;\n&gt;         &lt;string name=&quot;http-bind-address&quot;/&gt;\n&gt;       &lt;/newObject&gt;\n&gt;     &lt;/map&gt;\n&gt;     &lt;map name=&quot;extract-processors&quot;&gt;\n&gt;       &lt;newObject name=&quot;ExtractorHTTP&quot; class=&quot;org.archive.crawler.extractor.ExtractorHTTP&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;ExtractorHTTP#decide-rules&quot; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;ExtractorHTML&quot; class=&quot;org.archive.crawler.extractor.ExtractorHTML&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;ExtractorHTML#decide-rules&quot; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;         &lt;boolean name=&quot;extract-javascript&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;treat-frames-as-embed-links&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;ignore-form-action-urls&quot;&gt;false&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;extract-only-form-gets&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;extract-value-attributes&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;ignore-unexpected-html&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;ExtractorCSS&quot; class=&quot;org.archive.crawler.extractor.ExtractorCSS&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;ExtractorCSS#decide-rules&quot; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;ExtractorJS&quot; class=&quot;org.archive.crawler.extractor.ExtractorJS&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;ExtractorJS#decide-rules&quot; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;ExtractorSWF&quot; class=&quot;org.archive.crawler.extractor.ExtractorSWF&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;ExtractorSWF#decide-rules&quot; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;       &lt;/newObject&gt;\n&gt;     &lt;/map&gt;\n&gt;     &lt;map name=&quot;write-processors&quot;&gt;\n&gt;       &lt;newObject name=&quot;Archiver&quot; class=&quot;org.archive.crawler.writer.ARCWriterProcessor&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;Archiver#decide-rules&quot; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;         &lt;boolean name=&quot;compress&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;string name=&quot;prefix&quot;&gt;IAH&lt;/string&gt;\n&gt;         &lt;string name=&quot;suffix&quot;&gt;${HOSTNAME}&lt;/string&gt;\n&gt;         &lt;long name=&quot;max-size-bytes&quot;&gt;100000000&lt;/long&gt;\n&gt;         &lt;stringList name=&quot;path&quot;&gt;\n&gt;           &lt;string&gt;arcs&lt;/string&gt;\n&gt;         &lt;/stringList&gt;\n&gt;         &lt;integer name=&quot;pool-max-active&quot;&gt;5&lt;/integer&gt;\n&gt;         &lt;integer name=&quot;pool-max-wait&quot;&gt;300000&lt;/integer&gt;\n&gt;         &lt;long name=&quot;total-bytes-to-write&quot;&gt;0&lt;/long&gt;\n&gt;         &lt;boolean name=&quot;skip-identical-digests&quot;&gt;false&lt;/boolean&gt;\n&gt;       &lt;/newObject&gt;\n&gt;     &lt;/map&gt;\n&gt;     &lt;map name=&quot;post-processors&quot;&gt;\n&gt;       &lt;newObject name=&quot;Updater&quot; class=&quot;org.archive.crawler.postprocessor.CrawlStateUpdater&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;Updater#decide-rules&quot; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;LinksScoper&quot; class=&quot;org.archive.crawler.postprocessor.LinksScoper&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;LinksScoper#decide-rules&quot; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;         &lt;boolean name=&quot;override-logger&quot;&gt;false&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;seed-redirects-new-seed&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;integer name=&quot;preference-depth-hops&quot;&gt;-1&lt;/integer&gt;\n&gt;         &lt;newObject name=&quot;scope-rejected-url-rules&quot; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;Scheduler&quot; class=&quot;org.archive.crawler.postprocessor.FrontierScheduler&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;Scheduler#decide-rules&quot; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;       &lt;/newObject&gt;\n&gt;     &lt;/map&gt;\n&gt;     &lt;map name=&quot;loggers&quot;&gt;\n&gt;       &lt;newObject name=&quot;crawl-statistics&quot; class=&quot;org.archive.crawler.admin.StatisticsTracker&quot;&gt;\n&gt;         &lt;integer name=&quot;interval-seconds&quot;&gt;20&lt;/integer&gt;\n&gt;       &lt;/newObject&gt;\n&gt;     &lt;/map&gt;\n&gt;     &lt;string name=&quot;recover-path&quot;/&gt;\n&gt;     &lt;boolean name=&quot;checkpoint-copy-bdbje-logs&quot;&gt;true&lt;/boolean&gt;\n&gt;     &lt;boolean name=&quot;recover-retain-failures&quot;&gt;false&lt;/boolean&gt;\n&gt;     &lt;boolean name=&quot;recover-scope-includes&quot;&gt;true&lt;/boolean&gt;\n&gt;     &lt;boolean name=&quot;recover-scope-enqueues&quot;&gt;true&lt;/boolean&gt;\n&gt;     &lt;newObject name=&quot;credential-store&quot; class=&quot;org.archive.crawler.datamodel.CredentialStore&quot;&gt;\n&gt;       &lt;map name=&quot;credentials&quot;&gt;\n&gt;       &lt;/map&gt;\n&gt;     &lt;/newObject&gt;\n&gt;   &lt;/controller&gt;\n&gt; &lt;/crawl-order&gt;\n&gt; \n&gt; Again, I can see no problems here.  Can you offer any advice?\n&gt; \n&gt; \n&gt; \n&gt; ------------------------------------\n&gt; \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n"}}