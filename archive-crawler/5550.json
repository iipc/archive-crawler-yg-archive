{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":112974261,"authorName":"Mathew Nik Foscarini","from":"Mathew Nik Foscarini &lt;nfoscarini@...&gt;","profile":"nfoscarini","replyTo":"LIST","senderId":"q97to0ejtGeUOlM-mH1jgOiE7MVa3ZAfvUeKpGy4QsHs6oNZvOFERb3shDtu8KeG6N9ceys77UklTaow5tZiyLTTHmaS0skRiYf56lWx3AgdWA","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Re: Limit the number of downloaded documents per seed","postDate":"1224811484","msgId":5550,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDc4OTA2MC43MDMwMS5xbUB3ZWI1NDYwMy5tYWlsLnJlMi55YWhvby5jb20+"},"prevInTopic":5546,"nextInTopic":0,"prevInTime":5549,"nextInTime":5551,"topicId":5532,"numMessagesInTopic":4,"msgSnippet":"Thanks Gordon, It worked perfectly for last nights crawl. All seeds reported 300 documents fetched :) ... From: Gordon Mohr  To:","rawEmail":"Return-Path: &lt;nfoscarini@...&gt;\r\nX-Sender: nfoscarini@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 39628 invoked from network); 24 Oct 2008 01:24:45 -0000\r\nX-Received: from unknown (66.218.67.97)\n  by m48.grp.scd.yahoo.com with QMQP; 24 Oct 2008 01:24:45 -0000\r\nX-Received: from unknown (HELO web54603.mail.re2.yahoo.com) (206.190.49.173)\n  by mta18.grp.scd.yahoo.com with SMTP; 24 Oct 2008 01:24:45 -0000\r\nX-Received: (qmail 71245 invoked by uid 60001); 24 Oct 2008 01:24:44 -0000\r\nX-YMail-OSG: 7P6o9J0VM1mLg3YOiPdH5mOY8MZ_yQO.qVqloUG1CFOumbYHlhBK.UIodN_Nz2Hp9XEKT1rLgCAtYINKaRcZZ3aZ0COKuJRm07Z5Aj7MWDSMhniaqHN0AHgjK1mPraP7syeg.x_ggPBAuOQ_7C09SpehgG6tpL2oYzqBOZcUTX5e6pzBJpil5r3RSvg-\r\nX-Received: from [74.14.53.250] by web54603.mail.re2.yahoo.com via HTTP; Thu, 23 Oct 2008 18:24:44 PDT\r\nX-Mailer: YahooMailRC/1096.40 YahooMailWebService/0.7.247.3\r\nDate: Thu, 23 Oct 2008 18:24:44 -0700 (PDT)\r\nTo: archive-crawler@yahoogroups.com\r\nMIME-Version: 1.0\r\nContent-Type: multipart/alternative; boundary=&quot;0-26962112-1224811484=:70301&quot;\r\nMessage-ID: &lt;789060.70301.qm@...&gt;\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Mathew Nik Foscarini &lt;nfoscarini@...&gt;\r\nReply-To: Mathew Nik Foscarini &lt;nfoscarini@...&gt;\r\nSubject: Re: [archive-crawler] Re: Limit the number of downloaded documents per seed\r\nX-Yahoo-Group-Post: member; u=112974261; y=gE47SfHB2A3YZZGIVC2QB3xoPKR_Ar-gCcWV4sRsojE6uKKvGA\r\nX-Yahoo-Profile: nfoscarini\r\n\r\n\r\n--0-26962112-1224811484=:70301\r\nContent-Type: text/plain; charset=us-ascii\r\n\r\nThanks Gordon,\n\nIt worked perfectly for last nights crawl. All seeds reported 300 documents fetched :)\n\n\n\n----- Original Message ----\nFrom: Gordon Mohr &lt;gojomo@...&gt;\nTo: archive-crawler@yahoogroups.com\nSent: Thursday, October 23, 2008 7:59:20 PM\nSubject: Re: [archive-crawler] Re: Limit the number of downloaded documents per seed\n\n\nYes, I think QuotaEnforcer would work for your purpose, as long as the \n300 limit is something you want to apply per host, server, or frontier \n&#39;group&#39; (ie queue).\n\nQuotaEnforcer is a processor, and to use it insert it into the chain of \nprocessors before any fetchers, so that it has a chance to apply its \nprocessing-cancella tion before the URI is fetched. For example, you \ncould place it just after the Preselector.\n\n- Gordon @ IA\n\nnfoscarini wrote:\n&gt;&gt; Hi,\n&gt;&gt;\n&gt;&gt; I have a seed which has 671 domains listed. For each seed I limit\n&gt;&gt; scope of the crawl, but I want to limit it to no more then 300\n&gt;&gt; documents per seed.\n&gt;&gt;\n&gt;&gt; Is this possible?\n&gt;&gt;\n&gt; \n&gt; I was searching the source code, and I found something called\n&gt; &quot;QuotaEnforcer&quot; .\n&gt; \n&gt; Has this description\n&gt; \n&gt; &quot;A simple quota enforcer. If the host, server, or frontier group\n&gt; associated with the current CrawlURI is already over its quotas,\n&gt; blocks the current URI&#39;s processing with S_BLOCKED_BY_ QUOTA.&quot;\n&gt; \n&gt; That sounds like what I need, but I&#39;m not sure where to install this\n&gt; in the sheet?\n&gt; \n&gt; \n&gt; \n&gt; ------------ --------- --------- ------\n&gt; \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n    \n\n\n      \r\n--0-26962112-1224811484=:70301\r\nContent-Type: text/html; charset=us-ascii\r\n\r\n&lt;html&gt;&lt;head&gt;&lt;style type=&quot;text/css&quot;&gt;&lt;!-- DIV {margin:0px;} --&gt;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;div style=&quot;font-family:Courier New,courier,monaco,monospace,sans-serif;font-size:10pt&quot;&gt;&lt;div&gt;Thanks Gordon,&lt;br&gt;&lt;br&gt;It worked perfectly for last nights crawl. All seeds reported 300 documents fetched :)&lt;br&gt;&lt;/div&gt;&lt;div style=&quot;font-family: Courier New,courier,monaco,monospace,sans-serif; font-size: 10pt;&quot;&gt;&lt;br&gt;&lt;div style=&quot;border-left: 2px solid rgb(16, 16, 255); margin: 5px 0px 5px 5px; padding-left: 5px; font-family: times new roman,new york,times,serif; font-size: 12pt;&quot;&gt;----- Original Message ----&lt;br&gt;From: Gordon Mohr &lt;gojomo@...&gt;&lt;br&gt;To: archive-crawler@yahoogroups.com&lt;br&gt;Sent: Thursday, October 23, 2008 7:59:20 PM&lt;br&gt;Subject: Re: [archive-crawler] Re: Limit the number of downloaded documents per seed&lt;br&gt;&lt;br&gt;\n\n\n\n\n\n\n\n\n    &lt;div id=&quot;ygrp-text&quot;&gt;\n            &lt;p&gt;Yes, I think QuotaEnforcer would work for your purpose, as long as the &lt;br&gt;\n300 limit is something you want to apply per host, server, or frontier &lt;br&gt;\n&#39;group&#39; (ie queue).&lt;br&gt;\n&lt;br&gt;\nQuotaEnforcer is a processor, and to use it insert it into the chain of &lt;br&gt;\nprocessors before any fetchers, so that it has a chance to apply its &lt;br&gt;\nprocessing-cancella tion before the URI is fetched. For example, you &lt;br&gt;\ncould place it just after the Preselector.&lt;br&gt;\n&lt;br&gt;\n- Gordon @ IA&lt;br&gt;\n&lt;br&gt;\nnfoscarini wrote:&lt;br&gt;\n&gt;&gt; Hi,&lt;br&gt;\n&gt;&gt;&lt;br&gt;\n&gt;&gt; I have a seed which has 671 domains listed. For each seed I limit&lt;br&gt;\n&gt;&gt; scope of the crawl, but I want to limit it to no more then 300&lt;br&gt;\n&gt;&gt; documents per seed.&lt;br&gt;\n&gt;&gt;&lt;br&gt;\n&gt;&gt; Is this possible?&lt;br&gt;\n&gt;&gt;&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; I was searching the source code, and I found something called&lt;br&gt;\n&gt; &quot;QuotaEnforcer&quot; .&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; Has this description&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; &quot;A simple quota enforcer. If the host, server, or frontier group&lt;br&gt;\n&gt; associated with the current CrawlURI is already over its quotas,&lt;br&gt;\n&gt; blocks the current URI&#39;s processing with S_BLOCKED_BY_ QUOTA.&quot;&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; That sounds like what I need, but I&#39;m not sure where to install this&lt;br&gt;\n&gt; in the sheet?&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; &lt;br&gt;\n&gt; &lt;br&gt;\n&gt; ------------ --------- --------- ------&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; Yahoo! Groups Links&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; &lt;br&gt;\n&gt; &lt;br&gt;\n&lt;/p&gt;\n    &lt;/div&gt;  \n\n\n\t\n\t&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;br&gt;\n\n      &lt;/body&gt;&lt;/html&gt;\r\n--0-26962112-1224811484=:70301--\r\n\n"}}