{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":511156237,"authorName":"hatoum13","from":"&quot;hatoum13&quot; &lt;hatoum13@...&gt;","profile":"hatoum13","replyTo":"LIST","senderId":"ESebKFetHrSEwE1DNcFtyeLRhJPfWzCZkafv-kQ_J_Mt088YSTWKuoKgpTzRlAKp6FWbr_0ZiPSa9bF3xXwpE0IYJnkC","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: questions on how to setup Heritrix 3 on two machines","postDate":"1328081621","msgId":7598,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGpnYXBzbCtzdWY1QGVHcm91cHMuY29tPg==","inReplyToHeader":"PGo2djc0bis5aWUwQGVHcm91cHMuY29tPg=="},"prevInTopic":7342,"nextInTopic":7599,"prevInTime":7597,"nextInTime":7599,"topicId":7341,"numMessagesInTopic":9,"msgSnippet":"Hi, I m trying to install H3 on 2 different machines (in a local network) to crawl a large seeds file (more than 10 millions URL), I m faced to little problem,","rawEmail":"Return-Path: &lt;hatoum13@...&gt;\r\nX-Sender: hatoum13@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 76112 invoked from network); 1 Feb 2012 07:33:41 -0000\r\nX-Received: from unknown (98.137.34.46)\n  by m1.grp.sp2.yahoo.com with QMQP; 1 Feb 2012 07:33:41 -0000\r\nX-Received: from unknown (HELO ng10-ip1.bullet.mail.ne1.yahoo.com) (98.138.215.189)\n  by mta3.grp.sp2.yahoo.com with SMTP; 1 Feb 2012 07:33:41 -0000\r\nX-Received: from [98.138.217.180] by ng10.bullet.mail.ne1.yahoo.com with NNFMP; 01 Feb 2012 07:33:41 -0000\r\nX-Received: from [69.147.65.151] by tg5.bullet.mail.ne1.yahoo.com with NNFMP; 01 Feb 2012 07:33:41 -0000\r\nX-Received: from [98.137.34.51] by t5.bullet.mail.sp1.yahoo.com with NNFMP; 01 Feb 2012 07:33:41 -0000\r\nDate: Wed, 01 Feb 2012 07:33:41 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;jgapsl+suf5@...&gt;\r\nIn-Reply-To: &lt;j6v74n+9ie0@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;hatoum13&quot; &lt;hatoum13@...&gt;\r\nSubject: Re: questions on how to setup Heritrix 3 on two machines\r\nX-Yahoo-Group-Post: member; u=511156237; y=q--gQh1jRq57EbaJzNFLE00sBwVOqKhMVg7jx_1KHccH_VM\r\nX-Yahoo-Profile: hatoum13\r\n\r\nHi,\n\nI&#39;m trying to install H3 on 2 different machines (in a local network) =\r\nto crawl a large seeds file (more than 10 millions URL), I&#39;m faced to littl=\r\ne problem, how can I put the same seeds file for both instances?\n\nI tried t=\r\no make the file reachable from a web server but the Job can&#39;t be built beca=\r\nuse of an exception when it&#39;s creating the seed&#39;s bean.\n\nThanks\n\n--- In arc=\r\nhive-crawler@yahoogroups.com, &quot;david_pane1&quot; &lt;dpane@...&gt; wrote:\n&gt;\n&gt; With som=\r\ne effort, tips from Gordan and using the H1 to get an idea of the property =\r\nnames of the HashCrawlMapper, I was able to successfully configure and run =\r\na two machine test crawl.  I figured I would post this for others to refer =\r\nto in the future.  \n&gt; \n&gt; \n&gt; Using the default crawler-beans.cxml, I added t=\r\nhe following (in addition to the necessary user-agent and the seed list cha=\r\nnges )\n&gt; \n&gt; I defined the following in crawler-beans.cxml on machine 1:\n&gt;  =\r\n &lt;bean id=3D&quot;hashCrawlMapperProcessor&quot; class=3D&quot;org.archive.crawler.process=\r\nor.HashCrawlMapper&quot;&gt;\n&gt;  \t&lt;property name=3D&quot;localName&quot;      value=3D&quot;0&quot; /&gt;\n&gt;=\r\n \t&lt;property name=3D&quot;diversionDir&quot;   value=3D&quot;diversions&quot; /&gt;\n&gt; \t&lt;property na=\r\nme=3D&quot;checkUri&quot;       value=3D&quot;True&quot; /&gt;\n&gt; \t&lt;property name=3D&quot;checkOutlinks&quot;=\r\n  value=3D&quot;False&quot; /&gt;\n&gt; \t&lt;property name=3D&quot;rotationDigits&quot; value=3D&quot;10&quot; /&gt;\n&gt;=\r\n \t&lt;property name=3D&quot;crawlerCount&quot;   value=3D&quot;2&quot; /&gt;\n&gt;   &lt;/bean&gt;\n&gt; \n&gt; \n&gt; and =\r\nthis definition on machine #2 (only change was local-name value):\n&gt; \n&gt;   &lt;b=\r\nean id=3D&quot;hashCrawlMapperProcessor&quot; class=3D&quot;org.archive.crawler.processor.=\r\nHashCrawlMapper&quot;&gt;\n&gt;  \t&lt;property name=3D&quot;localName&quot;      value=3D&quot;1&quot; /&gt;\n&gt; \t&lt;=\r\nproperty name=3D&quot;diversionDir&quot;   value=3D&quot;diversions&quot; /&gt;\n&gt; \t&lt;property name=\r\n=3D&quot;checkUri&quot;       value=3D&quot;True&quot; /&gt;\n&gt; \t&lt;property name=3D&quot;checkOutlinks&quot;  =\r\nvalue=3D&quot;False&quot; /&gt;\n&gt; \t&lt;property name=3D&quot;rotationDigits&quot; value=3D&quot;10&quot; /&gt;\n&gt; \t=\r\n&lt;property name=3D&quot;crawlerCount&quot;   value=3D&quot;2&quot; /&gt;\n&gt;   &lt;/bean&gt;\n&gt; \n&gt; Then I ad=\r\nded in call to hashCrawlMapperProcessor in the candidateProcessors chain.\n&gt;=\r\n \n&gt;  &lt;!-- now, processors are assembled into ordered CandidateChain bean --=\r\n&gt;\n&gt;  &lt;bean id=3D&quot;candidateProcessors&quot; class=3D&quot;org.archive.modules.Candidat=\r\neChain&quot;&gt;\n&gt;   &lt;property name=3D&quot;processors&quot;&gt;\n&gt;    &lt;list&gt;\n&gt;     &lt;!-- apply sc=\r\noping rules to each individual candidate URI... --&gt;\n&gt;     &lt;ref bean=3D&quot;cand=\r\nidateScoper&quot;/&gt;\n&gt;     &lt;!-- check every URI discovered even before it is ever=\r\n enqueued --&gt;\n&gt;     &lt;ref bean=3D&quot;hashCrawlMapperProcessor&quot;/&gt;\n&gt; \n&gt;     &lt;!-- =\r\n...then prepare those ACCEPTed to be enqueued to frontier. --&gt;\n&gt;     &lt;ref b=\r\nean=3D&quot;preparer&quot;/&gt;\n&gt;    &lt;/list&gt;\n&gt;   &lt;/property&gt;\n&gt;  &lt;/bean&gt;\n&gt; \n&gt; and a call =\r\nto hashCrawlMapperProcessor in the FetchChain\n&gt; \n&gt;  &lt;!-- now, processors ar=\r\ne assembled into ordered FetchChain bean --&gt;\n&gt;  &lt;bean id=3D&quot;fetchProcessors=\r\n&quot; class=3D&quot;org.archive.modules.FetchChain&quot;&gt;\n&gt;   &lt;property name=3D&quot;processor=\r\ns&quot;&gt;\n&gt;    &lt;list&gt;\n&gt; \n&gt;     &lt;!-- re-check scope, if so enabled... --&gt;\n&gt;     &lt;r=\r\nef bean=3D&quot;preselector&quot;/&gt;\n&gt; \n&gt;     &lt;ref bean=3D&quot;hashCrawlMapperProcessor&quot;/&gt;=\r\n\n&gt; \n&gt; .\n&gt; .\n&gt; .\n&gt; \n&gt; \n&gt; \n&gt; --David\n&gt; \n&gt; --- In archive-crawler@yahoogroups.=\r\ncom, &quot;david_pane1&quot; &lt;dpane@&gt; wrote:\n&gt; &gt;\n&gt; &gt; I am new to using Heritrix 3 and=\r\n have only limited experience with H1.  I would like to setup H3 on two (ma=\r\nybe more in the future) machines for a distributed crawl.  I would also lik=\r\ne to apply the HashCrawlMapper to the processing chains so the URIs are sha=\r\nred between the two crawlers. \n&gt; &gt; \n&gt; &gt; Although there are discussions abou=\r\nt multiple machine crawls and the use of HashCrawlMapper, I could not find =\r\nspecifics on the setup of this (i.e even an example crawler-beans.cxml with=\r\n a default configuration).   I understand that both crawlers should have th=\r\ne same configuration.  However, how do you assign a crawler/node name to ea=\r\nch so that the HashCrawlMapper can assign URIs and each crawler understands=\r\n which ones to crawl.?\n&gt; &gt; \n&gt; &gt; Additionally, when attempting to define a n=\r\name bean for the HashCrawlMapper I am unclear on how to identify the availa=\r\nble property names and values.  (And this is true for any bean that is not =\r\nclearly defined as the default crawler-beans.cxml.)\n&gt; &gt; \n&gt; &gt; I understand t=\r\nhat the customization of the configuration for optimal performance may take=\r\n many iterations, but can anyone help me define the initial configuration o=\r\nf a two crawler/machine system which would work as a distributed crawl.\n&gt; &gt;=\r\n \n&gt; &gt; Thank you,\n&gt; &gt; \n&gt; &gt; -David\n&gt; &gt;\n&gt;\n\n\n\n"}}