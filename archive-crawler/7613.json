{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"CPtD0RQrQx5lRFkpwbrdSEwn-FTh9r79YHYs2OdBPFUA6g77nCNxHIE_v8YefKMQ3XjiB70oE56PfcUKuOx9bJCVj8ZMVuY","spamInfo":{"isSpam":false,"reason":"4"},"subject":"Re: [archive-crawler] Re: Setting crawl max depth per seed (H3)","postDate":"1328697372","msgId":7613,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRGMzI1MDFDLjUwMjAzMDZAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGpndGJrOCsyY2ZvQGVHcm91cHMuY29tPg==","referencesHeader":"PGpndGJrOCsyY2ZvQGVHcm91cHMuY29tPg=="},"prevInTopic":7612,"nextInTopic":0,"prevInTime":7612,"nextInTime":7614,"topicId":7607,"numMessagesInTopic":4,"msgSnippet":"It can t be done via only XML configuration; it requires writing a custom DecideRule, in Java or one of the other supported scripting languages for extending","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 15397 invoked from network); 8 Feb 2012 10:36:14 -0000\r\nX-Received: from unknown (98.137.35.160)\n  by m8.grp.sp2.yahoo.com with QMQP; 8 Feb 2012 10:36:14 -0000\r\nX-Received: from unknown (HELO relay00.pair.com) (209.68.5.9)\n  by mta4.grp.sp2.yahoo.com with SMTP; 8 Feb 2012 10:36:14 -0000\r\nX-Received: (qmail 59347 invoked by uid 0); 8 Feb 2012 10:36:13 -0000\r\nX-Received: from 50.0.190.15 (HELO silverbook.local) (50.0.190.15)\n  by relay00.pair.com with SMTP; 8 Feb 2012 10:36:13 -0000\r\nX-pair-Authenticated: 50.0.190.15\r\nMessage-ID: &lt;4F32501C.5020306@...&gt;\r\nDate: Wed, 08 Feb 2012 02:36:12 -0800\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.7; rv:9.0) Gecko/20111222 Thunderbird/9.0.1\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;jgtbk8+2cfo@...&gt;\r\nIn-Reply-To: &lt;jgtbk8+2cfo@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 2:4:8:0:1\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Re: Setting crawl max depth per seed (H3)\r\nX-Yahoo-Group-Post: member; u=137285340; y=v6XsZBs6UcciNBEn7JRd7Te_EWQ1Qpjsh8wXTbwxax4b\r\nX-Yahoo-Profile: gojomo\r\n\r\nIt can&#39;t be done via only XML configuration; it requires writing a \ncustom DecideRule, in Java or one of the other supported scripting \nlanguages for extending the crawler with new implementation classes.\n\nAnd even so, if following the &#39;quick-and-dirty&#39; approximation strategy I \ndescribed, it&#39;d suffer from the path-race limitation also mentioned. So \nit wouldn&#39;t really achieve the goal. For that reason I think it would be \nproblematic as a public example of a custom DecideRule.\n\n- Gordon\n\nOn 2/8/12 12:26 AM, paul.ihde wrote:\n&gt; Hi Gordon,\n&gt;\n&gt;\n&gt; Thanks a lot for the hint.\n&gt;\n&gt; I have researched a little bit in the last and I realized that I don&#39;t know how to actually do what you are suggesting (even if I understand it).\n&gt;\n&gt; Basically I fail to write the XML that would :\n&gt; 1). configure the seed as to carry forward the &quot;source tag&quot;\n&gt; 2). configure the DecideRule that checks/limits the length of the &#39;hops-path&#39;\n&gt;\n&gt; Could you please give a short XML example with 2 seeds and 2 decide rules that limit the hops-path based on the source tag (set to carry forward to original seed).\n&gt; I believe that other people who use the mailing list would also benefit from such an example (hoping that I&#39;m not the only newbie around :))\n&gt;\n&gt; Cheers\n&gt; Paul.\n&gt;\n&gt;\n&gt; --- In archive-crawler@yahoogroups.com, Gordon Mohr&lt;gojomo@...&gt;  wrote:\n&gt;&gt;\n&gt;&gt; There&#39;s no built-in facility for this.\n&gt;&gt;\n&gt;&gt; A quick-and-dirty approach to writing a custom DecideRule might look at\n&gt;&gt; the &#39;source-tag&#39; (which can be set to carry forward the original seed)\n&gt;&gt; and then, depending on that, apply different limits to the length of the\n&gt;&gt; &#39;hops-path&#39; string.\n&gt;&gt;\n&gt;&gt; But, since the crawler is only evaluating the paths it happened to\n&gt;&gt; follow, rather than *all* paths or *all shortest paths*, there will be\n&gt;&gt; situations where this is unlikely to do exactly what you want.\n&gt;&gt;\n&gt;&gt; Consider two seed URIs, A and B.\n&gt;&gt;\n&gt;&gt; Let&#39;s say you want to crawl from A to a depth of 1, and from B to a\n&gt;&gt; depth of 5.\n&gt;&gt;\n&gt;&gt; The crawl starts. URI A is fetched. An outlink from A goes to C, it&#39;s 1\n&gt;&gt; hop away, C is enqueued and marked as having been discovered from &#39;A&#39;\n&gt;&gt; (as source-tag). C is then fetched. All its outlinks are depth 2, and\n&gt;&gt; are all marked as discovered via A, and thus over the depth-limit and\n&gt;&gt; ignored.\n&gt;&gt;\n&gt;&gt; URI B was also fetched in parallel. It may also have an outlink to C.\n&gt;&gt; But if that outlink loses the race to seen-yet testing with the one from\n&gt;&gt; A, only the one marked as coming from A is enqueued. If the outlink from\n&gt;&gt; B won the race, 4 more hops from C would have been fetched. But it\n&gt;&gt; didn&#39;t, so they&#39;re not (though they might be discovered without\n&gt;&gt; prejudice via other paths).\n&gt;&gt;\n&gt;&gt; - Gordon\n&gt;&gt;\n&gt;&gt; On 2/4/12 10:25 AM, paul.ihde wrote:\n&gt;&gt;&gt; Hi,\n&gt;&gt;&gt;\n&gt;&gt;&gt; The documentation on setting the max depth of crawl has only examples on how to set the max crawl depth on the whole &quot;seed list&quot; level. I would like to know if it&#39;s (and how) possible to set the crawl depth per individual seed. I know that this could be achieved by having one crawl job for every seed, but this would be quite cumbersome. So I suppose there is some mechanism in Heritrix 3 to set the max depth level per seed.\n&gt;&gt;&gt;\n&gt;&gt;&gt; A. What I know (and understand) : setting a max depth level on all the seeds\n&gt;&gt;&gt; As such if my seed list is :\n&gt;&gt;&gt; * www.domain1.com\n&gt;&gt;&gt; * www.domain2.com\n&gt;&gt;&gt; * www.domain3.com\n&gt;&gt;&gt;\n&gt;&gt;&gt; and I set the :\n&gt;&gt;&gt;       &lt;bean class=&quot;org.archive.modules.deciderules.TooManyHopsDecideRule&quot;&gt;\n&gt;&gt;&gt;        &lt;property name=&quot;maxHops&quot; value=&quot;3&quot; /&gt;\n&gt;&gt;&gt;       &lt;/bean&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; then basically it will limit the crawl depth level to all the seed to the same level :\n&gt;&gt;&gt; * www.domain1.com (max depth = 3)\n&gt;&gt;&gt; * www.domain2.com (max depth =3)\n&gt;&gt;&gt; * www.domain3.com (max depth = 3)\n&gt;&gt;&gt;\n&gt;&gt;&gt; B. What I would like to do (but I don&#39;t know how) : setting a max depth level at seed level\n&gt;&gt;&gt; As such if my seed list is :\n&gt;&gt;&gt; * www.domain1.com\n&gt;&gt;&gt; * www.domain2.com\n&gt;&gt;&gt; * www.domain3.com\n&gt;&gt;&gt;\n&gt;&gt;&gt; and, I set the crawl depth on each seed, I would like to get :\n&gt;&gt;&gt; * www.domain1.com (max depth = 1)\n&gt;&gt;&gt; * www.domain2.com (max depth =7)\n&gt;&gt;&gt; * www.domain3.com (max depth = 3)\n&gt;&gt;&gt;\n&gt;&gt;&gt; Thanks\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; ------------------------------------\n&gt;&gt;&gt;\n&gt;&gt;&gt; Yahoo! Groups Links\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------\n&gt;\n&gt; Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n\n"}}