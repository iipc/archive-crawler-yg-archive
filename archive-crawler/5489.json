{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"1g32noY3KYm9TVYQZp-_V52rosaoKQH0ygGZeQ5WAcCz7smYbWkk1ULxUG2MCqW8kVlNT6o_ARQMOAnQgoYAIRmklDQar00","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] How to strip the seeds(blacklist) I don&#39;t want with set global.sheet","postDate":"1221834093","msgId":5489,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ4RDNCNTZELjIwMTAwQGFyY2hpdmUub3JnPg==","inReplyToHeader":"PGdhdmlwcytpYmgxQGVHcm91cHMuY29tPg==","referencesHeader":"PGdhdmlwcytpYmgxQGVHcm91cHMuY29tPg=="},"prevInTopic":5488,"nextInTopic":0,"prevInTime":5488,"nextInTime":5490,"topicId":5488,"numMessagesInTopic":2,"msgSnippet":"I don t quite understand. It sounds like you re saying: You have many seeds. Some should not be crawled. In which case: just delete those seeds. You shouldn t","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 1779 invoked from network); 19 Sep 2008 14:21:37 -0000\r\nX-Received: from unknown (66.218.67.96)\n  by m36.grp.scd.yahoo.com with QMQP; 19 Sep 2008 14:21:37 -0000\r\nX-Received: from unknown (HELO relay00.pair.com) (209.68.5.9)\n  by mta17.grp.scd.yahoo.com with SMTP; 19 Sep 2008 14:21:37 -0000\r\nX-Received: (qmail 2237 invoked from network); 19 Sep 2008 14:21:32 -0000\r\nX-Received: from unknown (HELO ?10.198.2.200?) (unknown)\n  by unknown with SMTP; 19 Sep 2008 14:21:32 -0000\r\nX-pair-Authenticated: 130.225.0.154\r\nMessage-ID: &lt;48D3B56D.20100@...&gt;\r\nDate: Fri, 19 Sep 2008 07:21:33 -0700\r\nUser-Agent: Thunderbird 2.0.0.16 (Windows/20080708)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;gavips+ibh1@...&gt;\r\nIn-Reply-To: &lt;gavips+ibh1@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] How to strip the seeds(blacklist) I don&#39;t want\n with set global.sheet\r\nX-Yahoo-Group-Post: member; u=137285340; y=g0Ie8fHGh8Gx13cMMTFcMd7lwpaHxnF7ADsEozeYfXW-\r\nX-Yahoo-Profile: gojomo\r\n\r\nI don&#39;t quite understand.\n\nIt sounds like you&#39;re saying: You have many seeds. Some should not be \ncrawled.\n\nIn which case: just delete those seeds. You shouldn&#39;t feed starting URLs \nto the crawler for sites you don&#39;t want crawled or added to the \nSURT-defined scope.\n\nWith the scope you describe, the crawler will generally stay on the seed \nsites, only wandering off to get URLs that appear necessary to have \nfully-rendered versions of the on-seed-site URLs.\n\nIf in fact you have two lists:\n  (1) seeds representing sites you want crawled\n  (2) other domains you don&#39;t want visited at all, not even just a \nlittle to get inline images/etc\n\n...then the NotOnDomainsDecideRule or NotSurtPrefixedDecideRule will \nhelp, but you need to be sure to configure it to take its source SURTs \nfrom your second list, in its own file -- NOT from your seeds.\n\nHope this helps,\n\n- Gordon @ IA\nhappyxinglele wrote:\n&gt; Hi, All\n&gt;   I have millions of seeds in my seedlist, and some domains or URLs \n&gt; are not expected to be crawled. How can I configure the global.sheet \n&gt; to reject all these domains.\n&gt;   I have tried NotOnDomainsDecideRule, but it seems not work.\n&gt;   My deciderules:\n&gt;&gt; root:scope:rules:0=object, \n&gt; org.archive.modules.deciderules.RejectDecideRule\n&gt;&gt; root:scope:rules:1=object, \n&gt; org.archive.modules.deciderules.surt.SurtPrefixedDecideRule\n&gt;&gt; root:scope:rules:2=object, \n&gt; org.archive.modules.deciderules.TooManyHopsDecideRule\n&gt;&gt; root:scope:rules:3=object, \n&gt; org.archive.modules.deciderules.TransclusionDecideRule\n&gt;&gt; root:scope:rules:4=object, \n&gt; org.archive.modules.deciderules.PathologicalPathDecideRule\n&gt;&gt; root:scope:rules:5=object, \n&gt; org.archive.modules.deciderules.TooManyPathSegmentsDecideRule\n&gt;&gt; root:scope:rules:6=object, \n&gt; org.archive.modules.deciderules.PrerequisiteAcceptDecideRule\n&gt;&gt; root:scope:rules:7=object, \n&gt; org.archive.modules.deciderules.surt.NotOnDomainsDecideRule\n&gt; \n&gt; Could anyone help me? Thanks a lot!\n&gt; \n&gt; \n&gt; ------------------------------------\n&gt; \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n"}}