{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"wrtiKlsgk3phvLZSDjeTIGwK4F2eTlMsr_pxHKHm0vzBHryry7tbCXQ-BHxvF_mZcWDCaMwRcR_-9jjSHwJ7UxWt1dJ4vJM","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Crawler running with less than configured threads.","postDate":"1326150558","msgId":7503,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRGMEI3MzlFLjIwOTA3MDVAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDRGMEIyMEI5LjgwNTA0MDFAY3MuY211LmVkdT4=","referencesHeader":"PDRGMDVFOUFELjkwMTA5MDNAY3MuY211LmVkdT4gPDRGMDZCQUZCLjgwMTA0MDJAYXJjaGl2ZS5vcmc+IDw0RjA3MjM5My4yMDYwNzAwQGNzLmNtdS5lZHU+IDw0RjA5RjU0OC40MDQwNzA1QGFyY2hpdmUub3JnPiA8NEYwQjIwQjkuODA1MDQwMUBjcy5jbXUuZWR1Pg=="},"prevInTopic":7501,"nextInTopic":7533,"prevInTime":7502,"nextInTime":7504,"topicId":7493,"numMessagesInTopic":14,"msgSnippet":"... Only trying them will reveal for sure. And even if they resume, it s likely the URIs/queues left in the phantom state by the thread crashes will remain","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 24608 invoked from network); 9 Jan 2012 23:09:19 -0000\r\nX-Received: from unknown (98.137.34.46)\n  by m7.grp.sp2.yahoo.com with QMQP; 9 Jan 2012 23:09:19 -0000\r\nX-Received: from unknown (HELO relay03.pair.com) (209.68.5.17)\n  by mta3.grp.sp2.yahoo.com with SMTP; 9 Jan 2012 23:09:19 -0000\r\nX-Received: (qmail 17077 invoked by uid 0); 9 Jan 2012 23:09:18 -0000\r\nX-Received: from 208.70.27.190 (HELO silverbook.local) (208.70.27.190)\n  by relay03.pair.com with SMTP; 9 Jan 2012 23:09:18 -0000\r\nX-pair-Authenticated: 208.70.27.190\r\nMessage-ID: &lt;4F0B739E.2090705@...&gt;\r\nDate: Mon, 09 Jan 2012 15:09:18 -0800\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.7; rv:8.0) Gecko/20111105 Thunderbird/8.0\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: David Pane &lt;dpane@...&gt;\r\nReferences: &lt;4F05E9AD.9010903@...&gt; &lt;4F06BAFB.8010402@...&gt; &lt;4F072393.2060700@...&gt; &lt;4F09F548.4040705@...&gt; &lt;4F0B20B9.8050401@...&gt;\r\nIn-Reply-To: &lt;4F0B20B9.8050401@...&gt;\r\nContent-Type: text/plain; charset=windows-1252; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: Crawler running with less than configured threads.\r\nX-Yahoo-Group-Post: member; u=137285340; y=GZAf4uxBGhYKmOCC_0uHh66wiMC9ZQ3h-yzklFlGYH_n\r\nX-Yahoo-Profile: gojomo\r\n\r\nOn 1/9/12 9:15 AM, David Pane wrote:\n&gt; Gordon,\n&gt;\n&gt; The checkpoints appeared to be succeeding. Is there any way of\n&gt; confirming that they are or are not recoverable checkpoints without\n&gt; stopping the crawl and attempting to recover?\n\nOnly trying them will reveal for sure. And even if they resume, it&#39;s \nlikely the URIs/queues left in the &#39;phantom&#39; state by the thread crashes \nwill remain unconsulted.\n\n&gt; If the crawler does crash or needs to be stopped and we cannot recover\n&gt; from the last checkpoint (or any recent checkpoint) what are our\n&gt; options? Do we have to start from an old checkpoint and recrawl all of\n&gt; the previously collected pages and data after that old recoverable\n&gt; checkpoint?\n\nResuming from a known-good checkpoint is best from the standpoint of \nperfectly picking up from that self-consistent point.\n\nThe older &#39;recovery log&#39; technique can approximate the crawl state at \nother points, at least with respect to URI discovery/completion. \nEssentially, from the &#39;frontier-recover&#39; log, this process first treats \nall previously-completed URIs as discovered (loads up the &#39;already-seen&#39; \nUriUniqFilter). Then, the process reconsiders all URIs discovered in the \nearlier run(s). Those that were completed get skipped (because of the \nfirst step), those that weren&#39;t are reenqueued in vaguely the same order \nas originally discovered.\n\nUnfortunately this process can take hours even in a moderately-sized \ncrawl. For yours it might take days (or weeks), and it&#39;s not itself \ncheckpointable (or optimized in other ways). It doesn&#39;t restore all \nrunning state for reporting purposes.\n\nIf you groom the logs a bit beforehand (for example not even bothering \nto include lines not needed in each step) you can save some of the work, \nspeeding the process.\n\nSome notes on this process that could get you started if you need to use \nthis approach:\n\nhttps://webarchive.jira.com/wiki/display/Heritrix/Crawl+Recovery\n\n- Gordon\n\n&gt; --David\n&gt;\n&gt; On 1/8/2012 2:58 PM, Gordon Mohr wrote:\n&gt;&gt; I don&#39;t know if future checkpoints after this point will succeed, or\n&gt;&gt; would be resumable even if they appeared to succeed; there&#39;s not enough\n&gt;&gt; info about what went wrong. Presumably whatever caused the topmost-URI\n&gt;&gt; deserialization to fail will remain as a problem unless the code or\n&gt;&gt; data-on-disk changes, so those queues might continue to be inert even\n&gt;&gt; with some heroic tampering with heap state or the on-disk data.\n\n"}}