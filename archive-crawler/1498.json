{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":6903103,"authorName":"Tom Emerson","from":"Tom Emerson &lt;Tree@...&gt;","profile":"tree02139","replyTo":"LIST","senderId":"JCms4lJOcMNwxOiIyEEKok3GyEbtvMnEcnyXHx-U8javFZ_WneEh885OHeyF_Lc9imTZF00luOweWLWsazFKxFrYa7ThLpM","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] continuous crawling proposal","postDate":"1107372651","msgId":1498,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDE2ODk3LjEwODU5LjEwMzQ4Ni4yMTg2NTRAdGlwaGFyZXMuYmFzaXN0ZWNoLm5ldD4=","inReplyToHeader":"PDQyMDEyNTM1LjUwNjAyQGFyY2hpdmUub3JnPg==","referencesHeader":"PFBpbmUuTE5YLjQuNTYuMDUwMjAxMDA1ODUxMC4xMzQ0OEBwaWtlc3BlYWsubWV0YWNhcnRhLmNvbT4JPDQyMDBCRTdBLjkwMzA1MDVAYXJjaGl2ZS5vcmc+CTxQaW5lLkxOWC40LjU2LjA1MDIwMjA4MzAyMzAuMjE1NTBAcGlrZXNwZWFrLm1ldGFjYXJ0YS5jb20+CTw0MjAxMjUzNS41MDYwMkBhcmNoaXZlLm9yZz4="},"prevInTopic":1496,"nextInTopic":1514,"prevInTime":1497,"nextInTime":1499,"topicId":1452,"numMessagesInTopic":24,"msgSnippet":"... Indeed, this and the WWW6 paper Broder coauthored are really the classic pieces on the problem. I have a paper by Sergei Brin and/or Larry Page on the","rawEmail":"Return-Path: &lt;Tree@...&gt;\r\nX-Sender: Tree@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 45306 invoked from network); 2 Feb 2005 19:31:44 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m24.grp.scd.yahoo.com with QMQP; 2 Feb 2005 19:31:44 -0000\r\nReceived: from unknown (HELO mail2.basistech.net) (199.88.205.1)\n  by mta6.grp.scd.yahoo.com with SMTP; 2 Feb 2005 19:31:44 -0000\r\nReceived: from tiphares.basistech.com ([10.1.3.65]) by mail2.basistech.net with Microsoft SMTPSVC(6.0.3790.211);\n\t Wed, 2 Feb 2005 14:30:51 -0500\r\nReceived: by tiphares.basistech.com (Postfix, from userid 5007)\n\tid 32FA93BA3AC; Wed,  2 Feb 2005 14:30:51 -0500 (EST)\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=us-ascii\r\nContent-Transfer-Encoding: 7bit\r\nMessage-ID: &lt;16897.10859.103486.218654@...&gt;\r\nDate: Wed, 2 Feb 2005 14:30:51 -0500\r\nTo: archive-crawler@yahoogroups.com\r\nIn-Reply-To: &lt;42012535.50602@...&gt;\r\nReferences: &lt;Pine.LNX.4.56.0502010058510.13448@...&gt;\n\t&lt;4200BE7A.9030505@...&gt;\n\t&lt;Pine.LNX.4.56.0502020830230.21550@...&gt;\n\t&lt;42012535.50602@...&gt;\r\nX-Mailer: VM 7.18 under Emacs 21.2.1\r\nReturn-Path: tree@...\r\nX-OriginalArrivalTime: 02 Feb 2005 19:30:51.0559 (UTC) FILETIME=[B48BB370:01C5095D]\r\nX-eGroups-Remote-IP: 199.88.205.1\r\nFrom: Tom Emerson &lt;Tree@...&gt;\r\nReply-To: tree@...\r\nSubject: Re: [archive-crawler] continuous crawling proposal\r\nX-Yahoo-Group-Post: member; u=6903103\r\nX-Yahoo-Profile: tree02139\r\n\r\nstack writes:\n&gt; On the resemblance of pages, there&#39;s been quite a bit written.  This \n&gt; seems to be the &#39;classic&#39;: \n&gt; http://citeseer.ist.psu.edu/broder97resemblance.html.\n\nIndeed, this and the WWW6 paper Broder coauthored are really the\n&quot;classic&quot; pieces on the problem. I have a paper by Sergei Brin and/or\nLarry Page on the method Google used to use (or may still be using, I\ndon&#39;t know).\n\nThe Broder shingling algorithm is relatively straight forward to\nimplement, but it requires that you remove markup and tokenize the\ninput. Stripping markup can be tricky, though for this task you can do\nso with extreme prejudice usually. Tokenization can be more difficult\nin some languages, like Chinese or Japanese where a straight\nimplementation of Broder&#39;s algorithm doesn&#39;t work well.\n\nAnother problem that many of these papers fail to address is how to\ndeal with encoding differences. For example, it is very common to see\nArabic documents encoded in Latin 1 using HTML character references\nfor the Arabic instead of encoding in CP1256 (or 8859-6 or UTF-8) and\nrepresenting the characters directly. In this case you either need to\nfirst normalize the encodings before generating the shingles (which\nhas its own complexity) or just punt. Japanese has two regularly used\nencodings. Russian has at least three... so the &quot;same&quot; document may\nappear in different encodings, and none of the methods will work\nwithout first normalizing.\n\nThere was a long thread on duplicate/similar document detection on the\nCorpora-L mailing list a month or two ago. While this was\nconcentrating on finding duplicates in linguistic corpora, most (if\nnot all) of the information there is applicable to this problem.\n\n    -tree\n\n-- \nTom Emerson                                          Basis Technology Corp.\nSoftware Architect                                 http://www.basistech.com\n  &quot;Beware the lollipop of mediocrity: lick it once and you suck forever&quot;\n\n"}}