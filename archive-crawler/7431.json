{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":325624130,"authorName":"Noah Levitt","from":"Noah Levitt &lt;nlevitt@...&gt;","profile":"nlevitt","replyTo":"LIST","senderId":"DhKOHpPUacBItbXpILGUgw6UoLOHbCD4f5VZcE-g-Ro-pqxTEOAOoOTTUA64pZ3wYS3FjEZcWtRHkXKajoNudLnWd1nRuCzB","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] DNS lookup for crawled links","postDate":"1323739623","msgId":7431,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRFRTZBOUU3LjMwMTAxMDlAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGpiZzQ0MCt0cmxoQGVHcm91cHMuY29tPg==","referencesHeader":"PGpiZzQ0MCt0cmxoQGVHcm91cHMuY29tPg=="},"prevInTopic":7419,"nextInTopic":0,"prevInTime":7430,"nextInTime":7432,"topicId":7419,"numMessagesInTopic":2,"msgSnippet":"Hello Markus, Dns failures do end up in crawl.log, with a -1 status. But it can take a long time because of the slow retry cycle. ","rawEmail":"Return-Path: &lt;nlevitt@...&gt;\r\nX-Sender: nlevitt@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 37338 invoked from network); 13 Dec 2011 01:27:04 -0000\r\nX-Received: from unknown (98.137.34.44)\n  by m9.grp.sp2.yahoo.com with QMQP; 13 Dec 2011 01:27:04 -0000\r\nX-Received: from unknown (HELO mail.archive.org) (207.241.224.6)\n  by mta1.grp.sp2.yahoo.com with SMTP; 13 Dec 2011 01:27:04 -0000\r\nX-Received: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id 39F6C6840151;\n\tMon, 12 Dec 2011 17:27:04 -0800 (PST)\r\nX-Received: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id fDzOceWGBI6D; Mon, 12 Dec 2011 17:27:03 -0800 (PST)\r\nX-Received: from [208.70.27.155] (desktop-nlevitt.sf.archive.org [208.70.27.155])\n\tby mail.archive.org (Postfix) with ESMTPSA id 5682C6840140;\n\tMon, 12 Dec 2011 17:27:03 -0800 (PST)\r\nMessage-ID: &lt;4EE6A9E7.3010109@...&gt;\r\nDate: Mon, 12 Dec 2011 17:27:03 -0800\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux x86_64; en-US; rv:1.9.2.23) Gecko/20110922 Thunderbird/3.1.15\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: mirschi74 &lt;markus.mirsberger@...&gt;\r\nReferences: &lt;jbg440+trlh@...&gt;\r\nIn-Reply-To: &lt;jbg440+trlh@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Noah Levitt &lt;nlevitt@...&gt;\r\nSubject: Re: [archive-crawler] DNS lookup for crawled links\r\nX-Yahoo-Group-Post: member; u=325624130; y=wlyaP4AgX6uuNa84LmxC8yBsAv6raxxIn5Qhq_FnACBm-w\r\nX-Yahoo-Profile: nlevitt\r\n\r\nHello Markus,\n\nDns failures do end up in crawl.log, with a -1 status. But it can take a \nlong time because of the slow retry cycle.\n\n&lt;!-- &lt;property name=&quot;retryDelaySeconds&quot; value=&quot;900&quot; /&gt; --&gt;\n&lt;!-- &lt;property name=&quot;maxRetries&quot; value=&quot;30&quot; /&gt; --&gt;\n\nBy default the url will be retried 30 times with at least 900 seconds \nbetween retries, so that will take at least 7 1/2 hours. You can adjust \nthose values for quick failure. For instance setting each of those \nvalues to 5 should get you results in less than 30 seconds. (It&#39;s \nimportant that maxRetries be at least 3 because dns lookup and \nrobots.txt fetch each account for one retry.)\n\nOf course if you circumvent slow retries, then your crawl could miss a \nsite if it&#39;s down for a few minutes, so you may want to wait the 7 1/2 \nhours instead.\n\nAnother option for quick feedback without otherwise affecting the \notherwise would be to add this line to logging.properties:\n\norg.archive.modules.fetcher.FetchDNS.level = FINE\n\nThen in heritrix_out.log you&#39;ll see output like this, for each attempt:\n\n2011-12-07 01:20:44.861 FINE thread-15 \norg.archive.modules.fetcher.FetchDNS.innerProcess() Failed find of \nrecordset for fdsajiopfdsafdsafdsa.com.\n\nThere will also be output for successful dns lookups.\n\nNoah\n\nOn 12/04/2011 07:37 AM, mirschi74 wrote:\n&gt; Hi,\n&gt;\n&gt; I want to crawl all url&#39;s of my seeds and get get dns lookup informations about all found external outlinks.\n&gt; I dont know why but I can only see successfully dns lookups in my logs or in the warcfile but I want to see those who failed.\n&gt; Maybe there is just a switch to turn that feature on/off but I cant find it.\n&gt; So how can I get the failed dns lookups for all outgoing external url&#39;s?\n&gt;\n&gt;\n&gt; Thanks in advance,\n&gt; Markus\n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------\n&gt;\n&gt; Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n\n\n"}}