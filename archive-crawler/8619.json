{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"vmq9ckWUGUmHNQLc3gy72HSWKy_P5CoBvXNvTbHp8yr9iPpyu76bahLysN4v-T8ma0GbsKXdLpi-XQNPWjmW8nktB25U-dk","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Re: Rejecting too many hops [1 Attachment]","postDate":"1411604510","msgId":8619,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDU0MjM2MDFFLjIwMzAxMDNAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGx2cmkwaysxaWdydmw1QFlhaG9vR3JvdXBzLmNvbT4=","referencesHeader":"PGx2Z2g4ZCtqNzBkcjZAWWFob29Hcm91cHMuY29tPgk8NTQxQ0JCMEYuNDA4MDMwM0BhcmNoaXZlLm9yZz4gPGx2b2U3OSsxZzVscjVmQFlhaG9vR3JvdXBzLmNvbT4JPDU0MjA4MEJCLjYwOTA3MDZAYXJjaGl2ZS5vcmc+IDxsdnJpMGsrMWlncnZsNUBZYWhvb0dyb3Vwcy5jb20+"},"prevInTopic":8618,"nextInTopic":0,"prevInTime":8618,"nextInTime":8620,"topicId":8611,"numMessagesInTopic":6,"msgSnippet":"If this is your actual order.xml, you re not properly identifying your crawling project and contact information via the user-agent setting. I don t see","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 12844 invoked by uid 102); 25 Sep 2014 00:21:53 -0000\r\nX-Received: from unknown (HELO mtaq2.grp.bf1.yahoo.com) (10.193.84.33)\n  by m13.grp.bf1.yahoo.com with SMTP; 25 Sep 2014 00:21:53 -0000\r\nX-Received: (qmail 8057 invoked from network); 25 Sep 2014 00:21:53 -0000\r\nX-Received: from unknown (HELO relay00.pair.com) (98.139.245.165)\n  by mtaq2.grp.bf1.yahoo.com with SMTP; 25 Sep 2014 00:21:53 -0000\r\nX-Received: (qmail 76227 invoked by uid 0); 25 Sep 2014 00:21:51 -0000\r\nX-Received: from 107.217.184.120 (HELO probook.local) (107.217.184.120)\n  by relay00.pair.com with SMTP; 25 Sep 2014 00:21:51 -0000\r\nX-pair-Authenticated: 107.217.184.120\r\nMessage-ID: &lt;5423601E.2030103@...&gt;\r\nDate: Wed, 24 Sep 2014 17:21:50 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:24.0) Gecko/20100101 Thunderbird/24.6.0\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;lvgh8d+j70dr6@...&gt;\t&lt;541CBB0F.4080303@...&gt; &lt;lvoe79+1g5lr5f@...&gt;\t&lt;542080BB.6090706@...&gt; &lt;lvri0k+1igrvl5@...&gt;\r\nIn-Reply-To: &lt;lvri0k+1igrvl5@...&gt;\r\nContent-Type: text/plain; charset=UTF-8; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nSubject: Re: [archive-crawler] Re: Rejecting too many hops [1 Attachment]\r\nX-Yahoo-Group-Post: member; u=137285340; y=Bim3cLkMFavlYOOKn6WzFnyvIG6bfnZYaR8VsRkOYs3v\r\nX-Yahoo-Profile: gojomo\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\n\r\nIf this is your actual order.xml, you&#39;re not properly identifying your \ncrawling project and contact information via the user-agent setting.\n\nI don&#39;t see anything obviously over-broad in your DecideRuleSequence... \nso perhaps you are inadvertently including more seeds (and thus more \nimplied acceptable hostnames) than you realize? (Maybe you&#39;re using some \nother advanced features -- settings overrides or other scripted feeds of \nraw URL lists into the crawler -- that result in URLs enqueued outside \nthe normal channels?)\n\nYou&#39;ll have to work backward from specific URLs in your logs that you \nare surprised to see crawled: what rule(s) gave an ACCEPT decision for \nthose URLs? Via what other immediate-predecessor URL were they found \n(the &#39;via&#39; field later in each crawl.log line)? What rule(s) ACCEPTed \nthat predecessor URL?\n\nThere&#39;s always a first URL in the logs, chronologically, that doesn&#39;t \nmatch your intent. Understand why it&#39;s included, and adjust the scope, \nand your problem may be solved for all later URLs. If not... there&#39;ll be \na new &#39;first discrepancy&#39; to understand and eliminate.\n\n- Gordon\n\nOn 9/23/14, 3:28 AM, kapiljadhav4@... [archive-crawler] wrote:\n&gt; [Attachment(s) &lt;#TopText&gt; from kapiljadhav4@... [archive-crawler]\n&gt; included below]\n&gt;\n&gt; As per your suggested approach I changed my order.xml file. but Still it\n&gt; crawls more hosts.\n&gt; I getting more data than expected.\n&gt; Have a look at my attached order.xml\n&gt;\n&gt;\n&gt; -Kapil\n&gt;\n&gt; \n\n"}}