{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"kZ6bLSi9-RGEg-eVtSxa7cY_5CSo9gCcnMH1LPIhhGX41PT4LRYogJvY-Jo1HG_J_zRldew-VopW1nJuC3qTUTTpmKaZE2g","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] Re: How can I create a complete graph in Heritrix?","postDate":"1330725108","msgId":7631,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRGNTE0MEY0LjkwMjAyMDNAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGppb3UwOStxY2J2QGVHcm91cHMuY29tPg==","referencesHeader":"PGppb3UwOStxY2J2QGVHcm91cHMuY29tPg=="},"prevInTopic":7630,"nextInTopic":0,"prevInTime":7630,"nextInTime":7632,"topicId":7623,"numMessagesInTopic":7,"msgSnippet":"That referenced message contains an old and not-very-efficient idea I wouldn t recommend unless you re already familiar enough with the codebase and","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 37695 invoked from network); 2 Mar 2012 21:51:56 -0000\r\nX-Received: from unknown (98.137.34.44)\n  by m10.grp.sp2.yahoo.com with QMQP; 2 Mar 2012 21:51:56 -0000\r\nX-Received: from unknown (HELO relay01.pair.com) (209.68.5.15)\n  by mta1.grp.sp2.yahoo.com with SMTP; 2 Mar 2012 21:51:56 -0000\r\nX-Received: (qmail 65857 invoked by uid 0); 2 Mar 2012 21:51:52 -0000\r\nX-Received: from 174.234.68.143 (HELO silverbook.local) (174.234.68.143)\n  by relay01.pair.com with SMTP; 2 Mar 2012 21:51:52 -0000\r\nX-pair-Authenticated: 174.234.68.143\r\nMessage-ID: &lt;4F5140F4.9020203@...&gt;\r\nDate: Fri, 02 Mar 2012 13:51:48 -0800\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.7; rv:10.0.2) Gecko/20120216 Thunderbird/10.0.2\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;jiou09+qcbv@...&gt;\r\nIn-Reply-To: &lt;jiou09+qcbv@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Re: How can I create a complete graph in Heritrix?\r\nX-Yahoo-Group-Post: member; u=137285340; y=Ragoz1sXIYnJ9u9WHYv7YhetwJPdxw4-IHGiZkuA1MSv\r\nX-Yahoo-Profile: gojomo\r\n\r\nThat referenced message contains an old and not-very-efficient idea I \nwouldn&#39;t recommend unless you&#39;re already familiar enough with the \ncodebase and architecture that the idea of rearranging the central &#39;URI \nuniquing&#39; functionality is natural to you.\n\nThe WARCWriterProcessor has settings that make the writing of  requests, \nmetadata, and revisit records optional... but we never thought to make \nwriting the HTTP response optional, because in our usual uses that&#39;s \nalways what&#39;s wanted. But, if you were just doing a crawl to get the \nlink metadata, you might want to write only the &#39;metadata&#39; records. \nThose include link data, but maybe not as much detail (full outlink text \nand element context) as you might want. The WARCWriterProcessor could be \nchanged to make writing responses optional lie with requests and \nmetadata, following the example of those settings/methods.\n\nBut, following Pranay&#39;s suggestion, the best current practice would \nprobably be to fist tune your crawl so it only fetches/stores \nlink-containing content. Then, post-crawl, use the WAT tool to get a \nricher set of outlink data from the bulk content. (The natural next \noptimization would be to make sure the during-crawl &#39;metadata&#39; record \ncreation was as good as the post-crawl WAT process.)\n\n- Gordon\n\nOn 3/1/12 2:42 PM, Elverton wrote:\n&gt; Hello Pranay,\n&gt;\n&gt; I tested the extractor here and it gave me exactly what I want in JSON format. Now, I&#39;m trying to read the JSON file (HTML Metadata).\n&gt; Thank you for your suggestion.\n&gt;\n&gt; I&#39;m close to get a complete graph. Perhaps, my great challenge will be space. Each warc files has about 1GB and it wrote 10 in a day.\n&gt; Is there a way to write only informations about HTML Metadata or other way to save space?\n&gt;\n&gt; Gordon, I read about a suggestion you gave to write in &quot;crawl.log&quot; (http://tech.groups.yahoo.com/group/archive-crawler/message/4099) all the fathers of a URL. In the suggestion, you said that the guy has to create his own BdbUniqFilter to say what to do with the URI. I downloaded the Heritrix-Open-Source but I got a bit confused about where I have to modify to get this. I parse the files and I got a interesting file &quot;/crawler/utils/BdbUriUniqFilter.java&quot;, but what I understood, this class create a hash of alreadyseen URIs but it doesn&#39;t tell anything to the URI (if it must be reject or not). Am I correct or I have to edit another file? Where can I find the &quot;critical point&quot; in which the information about the URI will be written in crawl.log?\n&gt;\n&gt; Thanks a lot the help people. When I get the graph I will &#39;post&#39; what I did to help people that have the same difficulty.\n&gt;\n&gt; Att.\n&gt; Elverton.\n&gt;\n&gt; --- In archive-crawler@yahoogroups.com, Pranay Pandey&lt;sspranay@...&gt;  wrote:\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; Hi Elverton,\n&gt;&gt;\n&gt;&gt; Not sure how useful, you may can explore the option of using the WAT utility that IA offers to pull some of the metadata relevant to your task.\n&gt;&gt;\n&gt;&gt; https://webarchive.jira.com/wiki/display/Iresearch/Web+Archive+Transformation+%28WAT%29+Specification%2C+Utilities%2C+and+Usage+Overview\n&gt;&gt;\n&gt;&gt; -Pranay\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; ________________________________\n&gt;&gt;   From: Elverton&lt;uelverton@...&gt;\n&gt;&gt; To: archive-crawler@yahoogroups.com\n&gt;&gt; Sent: Tuesday, February 28, 2012 6:17 PM\n&gt;&gt; Subject: [archive-crawler] Re: How can I create a complete graph in Heritrix?\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; ï¿½\n&gt;&gt; Hello everyone again.\n&gt;&gt;\n&gt;&gt; I&#39;m sorry to bother but I&#39;m out of ways. I read a lot of things about WARC in the group and there was a topic that has just what I want but it didn&#39;t get how to do it. The topic is (http://tech.groups.yahoo.com/group/archive-crawler/message/4099) but I don&#39;t know how to handle with them. So, my problems are:\n&gt;&gt;\n&gt;&gt; =&gt;  1: How can I handle with WARCFiles? What&#39;s the pattern? Where can I have more information about it?\n&gt;&gt;\n&gt;&gt; =&gt;  2: I perceive that ARCFiles, like below, has a pattern but I have to be sure about it. Is WARC-Target-URI the URI downloaded? I notice that http://www.cfpn.mar.mil.br/ has more links that we have in outlink. Is that correct or the others outlinks could be in others parts of the ARCFile?\n&gt;&gt;\n&gt;&gt; WARC/1.0\n&gt;&gt; WARC-Type: metadata\n&gt;&gt; WARC-Target-URI: http://www.cfpn.mar.mil.br/\n&gt;&gt; WARC-Date: 2012-02-28T18:15:47Z\n&gt;&gt; WARC-Concurrent-To:&lt;urn:uuid:8e0ee637-a052-440f-b454-83ecc1e5ab6c&gt;\n&gt;&gt; WARC-Record-ID:&lt;urn:uuid:fe9976f8-6550-432c-9b31-73bb3acaff48&gt;\n&gt;&gt; Content-Type: application/warc-fields\n&gt;&gt; Content-Length: 126\n&gt;&gt;\n&gt;&gt; fetchTimeMs: 79\n&gt;&gt; outlink: https://www.mar.mil.br/cfpn/ R Location:\n&gt;&gt; outlink: https://www.mar.mil.br/cfpn/ L a/@href\n&gt;&gt;\n&gt;&gt; Thanks again to everything.\n&gt;&gt;\n&gt;&gt; Att,\n&gt;&gt; Elverton.\n&gt;&gt;\n&gt;&gt; --- In archive-crawler@yahoogroups.com, &quot;Elverton&quot;&lt;uelverton@&gt;  wrote:\n&gt;&gt;&gt;\n&gt;&gt;&gt; Hi Travis,\n&gt;&gt;&gt;\n&gt;&gt;&gt; Thanks for the answer. I&#39;ll make this after the &quot;re-crawling&quot; because I disabled the WARCWriteProcessor in the first crawl.\n&gt;&gt;&gt; I&#39;ll return the results to this post when I finish the graph.\n&gt;&gt;&gt;\n&gt;&gt;&gt; Thanks again. :)\n&gt;&gt;&gt;\n&gt;&gt;&gt; Att.\n&gt;&gt;&gt; Elverton.\n&gt;&gt;&gt;\n&gt;&gt;&gt; --- In archive-crawler@yahoogroups.com, travis@ wrote:\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Elverton,\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Have you looked at the metadata in the warcs? Each record should list\n&gt;&gt;&gt;&gt; extracted links regardless of whether they were crawled due to scoping rules.\n&gt;&gt;&gt;&gt; Extract this set and intersect it with actual crawled uris to obtain a full\n&gt;&gt;&gt;&gt; graph within what was crawled. You may also consider that the extractor also\n&gt;&gt;&gt;&gt; has a [high] limit on the number of URIs it extracts.\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Travis\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; On Mon, February 27, 2012 11:45 am, Elverton wrote:\n&gt;&gt;&gt;&gt;&gt; Hello everybody,\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt; As I sent a email to Gordon this afternoon (below), I want to record and get\n&gt;&gt;&gt;&gt;&gt; suggestion how can I get more information about a URI before it get &#39;uniqued&#39;.\n&gt;&gt;&gt;&gt;&gt; As I read at &quot;Mohr-et-al-2004&#39;, the way to decide what to do with a URI is at\n&gt;&gt;&gt;&gt;&gt; Prefetch, more exactly in Preselector. But I don&#39;t have a clue what filter or\n&gt;&gt;&gt;&gt;&gt; rule can help me. Any suggestions?\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt; Att.\n&gt;&gt;&gt;&gt;&gt; Elverton.\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt; =&gt;  The original message:\n&gt;&gt;&gt;&gt;&gt; ----------------------------------------------------------\n&gt;&gt;&gt;&gt;&gt;   Hello Gordon,\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;   My name is Elverton. I&#39;m doing a research in a metric to estimate the numbers\n&gt;&gt;&gt;&gt;&gt; of URL of a domain. I have a problem to solve and you think you can help me.\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;   I want to make a complete graph of all URL&#39;s collected but all I have from\n&gt;&gt;&gt;&gt;&gt; crawl.log is the &quot;father&quot; of the URL and the URL. This would be necessary but\n&gt;&gt;&gt;&gt;&gt; I have an misundertanding about one thing: If heritrix collect one URL,\n&gt;&gt;&gt;&gt;&gt; suppose &quot;yahoo.com&quot; from &quot;google.com&quot;. If the heritrix enter in &quot;amazon.com&quot;\n&gt;&gt;&gt;&gt;&gt; and found &quot;yahoo.com&quot; again, in crawl.log will appear:\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;   - - - yahoo.com - google.com\n&gt;&gt;&gt;&gt;&gt;   - - - yahoo.com - amazon.com\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;   or only:\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;   - - - yahoo.com - google.com\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;   So, the heritrix will ignore the found in &quot;amazon.com&quot; because it was already\n&gt;&gt;&gt;&gt;&gt; found in &quot;google.com&quot;?\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;   Att.\n&gt;&gt;&gt;&gt;&gt;   Elverton.\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt; ----------------------------------------------------------\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt; =&gt;  Gordon&#39;s answer:\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt; ----------------------------------------------------------\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt; You&#39;re correct, the crawl.log is not enough info to make a full web\n&gt;&gt;&gt;&gt;&gt; graph... it only records the exact paths that led to a URI being first\n&gt;&gt;&gt;&gt;&gt; discovered. You&#39;d need to log more from the crawler before it &#39;uniques&#39;\n&gt;&gt;&gt;&gt;&gt; the URIs for crawling purposes, or perform a post-crawl analysis on the\n&gt;&gt;&gt;&gt;&gt; full link-containing content, to create the web graph.\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt; - Gordon\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt; ----------------------------------------------------------\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------\n&gt;\n&gt; Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n\n"}}