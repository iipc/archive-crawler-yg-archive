{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":196959921,"authorName":"Sam","from":"Sam &lt;L33tminion@...&gt;","profile":"l33tminion","replyTo":"LIST","senderId":"kO_yD1KkjaYdW7sJ5iqsZN3WsbTgKX4MVSoDK55fpC19jnD4vHuj3IOOhpO0QxA64GzzU0oNpdSuDHES1nrpDrY","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Re: can anyone explain some concepts of Crawl Scope?","postDate":"1105562564","msgId":1357,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDM3ZTcxOTBmMDUwMTEyMTI0MjdjY2Y0OUBtYWlsLmdtYWlsLmNvbT4=","inReplyToHeader":"PDQxRTQyODg4LjkwOTA5MDFAYXJjaGl2ZS5vcmc+","referencesHeader":"PGNydmc2dStoMW1wQGVHcm91cHMuY29tPiA8NDFFNDI4ODguOTA5MDkwMUBhcmNoaXZlLm9yZz4="},"prevInTopic":1352,"nextInTopic":1358,"prevInTime":1356,"nextInTime":1358,"topicId":1302,"numMessagesInTopic":11,"msgSnippet":"use-bdb-already-included seems like it would be a very useful option for our project, but I can t find it in the web interface (even building from CVS, using","rawEmail":"Return-Path: &lt;l33tminion@...&gt;\r\nX-Sender: l33tminion@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 6278 invoked from network); 12 Jan 2005 20:42:45 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m5.grp.scd.yahoo.com with QMQP; 12 Jan 2005 20:42:45 -0000\r\nReceived: from unknown (HELO rproxy.gmail.com) (64.233.170.196)\n  by mta6.grp.scd.yahoo.com with SMTP; 12 Jan 2005 20:42:45 -0000\r\nReceived: by rproxy.gmail.com with SMTP id g11so77145rne\n        for &lt;archive-crawler@yahoogroups.com&gt;; Wed, 12 Jan 2005 12:42:45 -0800 (PST)\r\nDomainKey-Signature: a=rsa-sha1; q=dns; c=nofws;\n        s=beta; d=gmail.com;\n        h=received:message-id:date:from:reply-to:to:subject:in-reply-to:mime-version:content-type:content-transfer-encoding:references;\n        b=JJwKwfU5zkDA4hV2X0sr1oACJEdTRlglvdx0syyAg2decHDwPjU37dSBvNsyL25hXQroZtk/Ep2z061RwPCzxPv33DrZebKiI2Y4CAO1waZ/ftU/fhzcozCydVynFBLKYmRpqo9oec8BsIWbgganyG1UMl2ocR7BIg4fobqijp4=\r\nReceived: by 10.38.161.13 with SMTP id j13mr11373rne;\n        Wed, 12 Jan 2005 12:42:44 -0800 (PST)\r\nReceived: by 10.38.125.47 with HTTP; Wed, 12 Jan 2005 12:42:44 -0800 (PST)\r\nMessage-ID: &lt;37e7190f05011212427ccf49@...&gt;\r\nDate: Wed, 12 Jan 2005 15:42:44 -0500\r\nTo: archive-crawler@yahoogroups.com\r\nIn-Reply-To: &lt;41E42888.9090901@...&gt;\r\nMime-Version: 1.0\r\nContent-Type: text/plain; charset=US-ASCII\r\nContent-Transfer-Encoding: 7bit\r\nReferences: &lt;crvg6u+h1mp@...&gt; &lt;41E42888.9090901@...&gt;\r\nX-eGroups-Remote-IP: 64.233.170.196\r\nFrom: Sam &lt;L33tminion@...&gt;\r\nReply-To: Sam &lt;l33tminion@...&gt;\r\nSubject: Re: [archive-crawler] Re: can anyone explain some concepts of Crawl Scope?\r\nX-Yahoo-Group-Post: member; u=196959921\r\nX-Yahoo-Profile: l33tminion\r\n\r\n&quot;use-bdb-already-included&quot; seems like it would be a very useful option\nfor our project, but I can&#39;t find it in the web interface (even\nbuilding from CVS, using BdbFrontier, and showing expert settings). \nHow do I get this option?\n\nThanks for your assistance.\n\n-Sam\n\n\nOn Tue, 11 Jan 2005 20:27:04 +0100, Michael Stack &lt;stack@...&gt; wrote:\n&gt; \n&gt; bjhong02 wrote:\n&gt; \n&gt; &gt; ...\n&gt; &gt; I set &#39;hold-queues&#39; to true and &#39;host-queues-memory-capacity&#39; from\n&gt; &gt; 800 to 80. but after about 2-3 minutes, the number of active threads\n&gt; &gt; droped to zero. I don&#39;t know why. the queued url and used memory are\n&gt; &gt; still very low at that time.\n&gt; \n&gt; This sounds like an issue other than memory.  What does your frontier\n&gt; report say the threads are doing (What JVM?  What platform?).\n&gt; \n&gt; &gt;\n&gt; &gt; could you explain the meaning of some parameters for frontier, such\n&gt; &gt; as &quot;hold-queues&quot;, &quot;preference-embed-hops&quot;, &quot;host-valence&quot;, &quot;force-\n&gt; &gt; queue-assignment&quot;, &quot;host-queues-memory-capacity&quot;, &quot;use-bdb-already-\n&gt; &gt; included&quot;. since I can not find them in user manual.\n&gt; \n&gt; Are the details that are under the help question marks in the settings\n&gt; page not sufficent?  I reproduce them below.  Let me know if you need\n&gt; more detail.\n&gt; \n&gt; use-bdb-already-included: &quot;Use disk-based Berkeley DB to hold the set of\n&gt; Already Included URIs. The Already Included URI set is by-default kept\n&gt; in memory. The continuous growth of this URI set in memory is one cause\n&gt; of out of memory exceptions.  Enabling this option, the Already Included\n&gt; set is kept on-disk in a Berkeley DB table. Enabling this feature will\n&gt; cause the crawler to harvest more documents before it runs out of memory\n&gt; at the cost of the crawler harvesting at a (progressively) slightly\n&gt; slower rate. Lookups in BDB as opposed to lookups done against a\n&gt; RAM-based Already Included set take about 4 times longer when the\n&gt; Already Included set is 10million items (0.5ms vs. ~2ms).  BDB Already\n&gt; Included lookups slow as the set grows at ~Log(n) rate.&quot;\n&gt; host-queues-memory-capacity: &quot;Size of each host queue&#39;s in-memory head.\n&gt; Once each grows beyond this size additional items will be written to a\n&gt; file on disk. Default value is 200 (i.e. 200 items kept in memory).  A\n&gt; high value means more RAM used per host queue while a low value will\n&gt; require more disk I/O. Lowest legal value is one.\n&gt; force-queue-assignment: &quot;The queue name into which to force URIs. Should\n&gt; be left blank at global level.  Specify a per-domain/per-host override\n&gt; to force URIs into a particular named queue, regardless of the\n&gt; assignment policy in effect (domain or ip-based politeness).  This could\n&gt; be used on domains known to all be from the same small set of IPs (eg\n&gt; blogspot, dailykos, etc.) to simulate IP-based politeness, or it could\n&gt; be used if you wanted to enforce politeness over a whole domain, even\n&gt; though the subdomains are split across many IPs.&quot; (You&#39;d use this\n&gt; facility to avoid hitting a host with many virtual servers too hard).\n&gt; host-valence: &quot;Maximum number of simultaneous requests to a single\n&gt; host.&quot; (This feature is not working reliably).\n&gt; preference-embed-hops: &quot;Number of embedded (or redirected) hops up to\n&gt; which a URI has higher priority scheduling. For example, if set to 1\n&gt; (the default), items such as inline images (1-hop embedded resources)\n&gt; will be scheduled ahead of all regular links (or many-hop resources,\n&gt; like nested frames). If set to zero, no preferencing will occur, and\n&gt; embeds/redirects are scheduled the same as regular links.&quot;\n&gt; hold-queues: &quot;Whether to hold newly-created per-host URI work queues\n&gt; until needed to stay busy. If false (default), all queues may contribute\n&gt; URIs for crawling at all times. If true, queues begin (and collect URIs)\n&gt; in an &#39;inactive&#39; state, and only when the Frontier needs another queue\n&gt; to keep all ToeThreads busy will new queues be activated.\n&gt; \n&gt; St.Ack\n&gt; \n&gt; &gt;\n&gt; &gt; thanks\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; ------------------------------------------------------------------------\n&gt; &gt; *Yahoo! Groups Links*\n&gt; &gt;\n&gt; &gt;     * To visit your group on the web, go to:\n&gt; &gt;       http://groups.yahoo.com/group/archive-crawler/\n&gt; &gt;\n&gt; &gt;     * To unsubscribe from this group, send an email to:\n&gt; &gt;       archive-crawler-unsubscribe@yahoogroups.com\n&gt; &gt;       &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt; &gt;\n&gt; &gt;     * Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt; &gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;.\n&gt; &gt;\n&gt; &gt;\n&gt; \n&gt; \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n&gt; \n&gt;\n\n"}}