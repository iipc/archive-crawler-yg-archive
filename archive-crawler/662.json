{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":164438524,"authorName":"Lars Clausen","from":"Lars Clausen &lt;lc@...&gt;","profile":"lrclause","replyTo":"LIST","senderId":"iuVgx8YGuDaaQBoPxSlJWlohFsnlUyfKaQf_KULURfXt13rcQJc1G6nutrs-bnM7DXfMPaEDLA37XogOJOO4hd16SfQPMq0JueQLFw","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Compression of ARC files","postDate":"1089995319","msgId":662,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDEwODk5OTUzMTguMTkzMy4xNzEuY2FtZWxAcGM3NzAuc2Iuc3RhdHNiaWJsaW90ZWtldC5kaz4=","inReplyToHeader":"PDE2NjMxLjY0MzcwLjc4MzA5NC42MDAyNjZAdGlwaGFyZXMuYmFzaXN0ZWNoLm5ldD4=","referencesHeader":"PDIwMDQwNzE0MDQwMi5pNkU0MmhaMjA3NjVAcG9sbHV4LnN0YXRzYmlibGlvdGVrZXQuZGs+IDwxMDg5NzkwODExLjE5MzMuMjEuY2FtZWxAcGM3NzAuc2Iuc3RhdHNiaWJsaW90ZWtldC5kaz4gPDQwRjU1RkFCLjUwNjA5MDZAYXJjaGl2ZS5vcmc+IDwxMDg5ODczOTUwLjE5MzMuNTQuY2FtZWxAcGM3NzAuc2Iuc3RhdHNiaWJsaW90ZWtldC5kaz4gPDQwRjZDMjA1LjkwNDAzMDJAYXJjaGl2ZS5vcmc+IDwxMDg5OTY3MDI3LjE5MzMuODYuY2FtZWxAcGM3NzAuc2Iuc3RhdHNiaWJsaW90ZWtldC5kaz4gPDE2NjMxLjQ5NjU5LjI1NDQzNy45NzM1NDNAdGlwaGFyZXMuYmFzaXN0ZWNoLm5ldD4gPDEwODk5ODIwMzMuMTkzMy4xMzguY2FtZWxAcGM3NzAuc2Iuc3RhdHNiaWJsaW90ZWtldC5kaz4gPDE2NjMxLjY0MzcwLjc4MzA5NC42MDAyNjZAdGlwaGFyZXMuYmFzaXN0ZWNoLm5ldD4="},"prevInTopic":661,"nextInTopic":663,"prevInTime":661,"nextInTime":663,"topicId":629,"numMessagesInTopic":20,"msgSnippet":"... [...] ... Now try doing that with tens or hundreds of terabytes.  10TB would take 280000 seconds, or over three days.  Most of that will be spent reading ","rawEmail":"Return-Path: &lt;lc@...&gt;\r\nX-Sender: lc@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 99680 invoked from network); 16 Jul 2004 16:32:37 -0000\r\nReceived: from unknown (66.218.66.218)\n  by m22.grp.scd.yahoo.com with QMQP; 16 Jul 2004 16:32:37 -0000\r\nReceived: from unknown (HELO luna.statsbiblioteket.dk) (130.225.24.87)\n  by mta3.grp.scd.yahoo.com with SMTP; 16 Jul 2004 16:32:37 -0000\r\nReceived: from pc770.sb.statsbiblioteket.dk\n (pc770.sb.statsbiblioteket.dk [130.225.24.181]) by luna.statsbiblioteket.dk\n (iPlanet Messaging Server 5.2 HotFix 1.16 (built May 14 2003))\n with ESMTP id &lt;0I0Y0070RDRR4T@...&gt; for\n archive-crawler@yahoogroups.com; Fri, 16 Jul 2004 18:28:39 +0200 (MEST)\r\nDate: Fri, 16 Jul 2004 18:28:39 +0200\r\nIn-reply-to: &lt;16631.64370.783094.600266@...&gt;\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-id: &lt;1089995318.1933.171.camel@...&gt;\r\nOrganization: Statsbiblioteket\r\nMIME-version: 1.0\r\nX-Mailer: Ximian Evolution 1.4.5 (1.4.5-1)\r\nContent-type: text/plain\r\nContent-transfer-encoding: 7BIT\r\nReferences: &lt;200407140402.i6E42hZ20765@...&gt;\n &lt;1089790811.1933.21.camel@...&gt;\n &lt;40F55FAB.5060906@...&gt;\n &lt;1089873950.1933.54.camel@...&gt;\n &lt;40F6C205.9040302@...&gt;\n &lt;1089967027.1933.86.camel@...&gt;\n &lt;16631.49659.254437.973543@...&gt;\n &lt;1089982033.1933.138.camel@...&gt;\n &lt;16631.64370.783094.600266@...&gt;\r\nX-eGroups-Remote-IP: 130.225.24.87\r\nFrom: Lars Clausen &lt;lc@...&gt;\r\nSubject: Re: [archive-crawler] Compression of ARC files\r\nX-Yahoo-Group-Post: member; u=164438524\r\nX-Yahoo-Profile: lrclause\r\n\r\nOn Fri, 2004-07-16 at 17:59, Tom Emerson wrote:\n&gt; Lars Clausen writes:\n[...]\n&gt; \n&gt; True. The way I handle this in libarc is that I inflate and examine\n&gt; enough of the record to extract the URL header, and from there I just\n&gt; inflate the rest of the gzip entry without investigating the bytes. It\n&gt; is time consuming, but it works. To test this, I just instrumented my\n&gt; arcdump utility to report the time spent building its internal index:\n&gt; on an 100MB gziped ARC file containing 11,941 entries it took 2.8\n&gt; seconds on my 1.8 GHz G5. Assuming that you spend those 2.8 seconds\n&gt; once to generate a CDX file, it isn&#39;t horrible, I suppose.\n\nNow try doing that with tens or hundreds of terabytes.  10TB would take\n280000 seconds, or over three days.  Most of that will be spent reading\ndata that is not used and should be skippable.  Did you in your test\nmake sure the file wasn&#39;t in memory?  If you have to read the whole\nthing from disk, it takes a lot longer.  On our main file server, just\nreading a 100MB file takes 6 seconds.  That would up the time for 10TB\nto over a week.  \n\nThe ARC format was particularly designed so that you did not ever have\nto go through all the files, you could just read the metadata lines and\nskip the bodies to make the index, then use the index to get the entries\nyou want.  That&#39;s a not insignificant part of what makes it effective.\n\n&gt; &gt; Of course, the proposed idea of having the metadata\n&gt; \n&gt; The more I thought about your idea on my drive into the office this\n&gt; morning, the more I like it. Keep the URL record uncompressed, and\n&gt; include a compression method and offset to the start of the next\n&gt; entry.\n\nYou&#39;d lose the zmore/zless usability bit, though.  I&#39;m not sure which\nI&#39;d prefer.\n\n&gt; \n&gt; &gt; To understand a gzipped ARC file, you either have to have an index or\n&gt; &gt; you must parse and uncompress it from the beginning.  There&#39;s no going\n&gt; &gt; into the middle of it and finding the headers.  While it&#39;s not the\n&gt; &gt; integrity of the file that is destroyed, it does make index-less work on\n&gt; &gt; the file a lot harder.\n&gt; \n&gt; You can&#39;t go into the middle of an uncompressed ARC file and easily\n&gt; find the headers either.\n\n/^http:&#92;/&#92;/[^ ]* [0-9]+&#92;.[0-9]+&#92;.[0-9]+&#92;.[0-9]+/ is nigh foolproof.  \n\n&gt; It also depends on the tools. With libarc working with index-less\n&gt; files is trivial.\n\nIt&#39;s also important that the tools be easy to reconstruct in the far\nfuture.\n\n-Lars\n\n\n"}}