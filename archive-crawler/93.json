{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"&quot;Gordon Mohr&quot; &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"etxgHwN1i8VM7ovxxuR_2qgg7UMNeVtgKHg_zThoetOl126mdiewnLmZFaxkP3dIRPztVvY3u2zbAZISJRZzzrTG79BF-Zmpew","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: Google compersions","postDate":"1057023533","msgId":93,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDAwMjEwMWMzM2Y3MSQ5OTVkMDM5MCQ0OGYwZWRkMUBXT1JLU1RBVElPTjIxPg==","referencesHeader":"PFBpbmUuTE5YLjQuMzMuMDMwNjMwMTczOTM3MC4xNzc3MS0xMDAwMDBAaG9tZXNlcnZlci5hcmNoaXZlLm9yZz4="},"prevInTopic":0,"nextInTopic":0,"prevInTime":92,"nextInTime":94,"topicId":93,"numMessagesInTopic":1,"msgSnippet":"[moved to archive-crawler discussion list] I have some ideas in the Wiki at... http://crawler.archive.org/cgi-bin/wiki.pl/wiki.pl?TestingCoverageAgainstGoogle ","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 99362 invoked from network); 1 Jul 2003 01:37:39 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m12.grp.scd.yahoo.com with QMQP; 1 Jul 2003 01:37:39 -0000\r\nReceived: from unknown (HELO mail.archive.org) (209.237.232.56)\n  by mta2.grp.scd.yahoo.com with SMTP; 1 Jul 2003 01:37:39 -0000\r\nReceived: from WORKSTATION21 (b116-dyn-72.archive.org [209.237.240.72])\n\tby mail.archive.org (8.12.8/8.10.2) with SMTP id h610kulQ025524\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Mon, 30 Jun 2003 17:47:11 -0700\r\nMessage-ID: &lt;002101c33f71$995d0390$48f0edd1@WORKSTATION21&gt;\r\nTo: &lt;archive-crawler@yahoogroups.com&gt;\r\nReferences: &lt;Pine.LNX.4.33.0306301739370.17771-100000@...&gt;\r\nSubject: Re: Google compersions\r\nDate: Mon, 30 Jun 2003 18:38:53 -0700\r\nMIME-Version: 1.0\r\nContent-Type: text/plain;\n\tcharset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: 7bit\r\nX-Priority: 3\r\nX-MSMail-Priority: Normal\r\nX-Mailer: Microsoft Outlook Express 6.00.2800.1158\r\nX-MimeOLE: Produced By Microsoft MimeOLE V6.00.2800.1165\r\nFrom: &quot;Gordon Mohr&quot; &lt;gojomo@...&gt;\r\nX-Yahoo-Group-Post: member; u=137285340\r\nX-Yahoo-Profile: gojomo\r\n\r\n[moved to archive-crawler discussion list]\n\nI have some ideas in the Wiki at...\n\n   http://crawler.archive.org/cgi-bin/wiki.pl/wiki.pl?TestingCoverageAgainstGoogle\n\nIt&#39;d be good if you could post your additions there.\n\nI&#39;m not sure of the difference between &#39;allinurl&#39; and &#39;inurl&#39;, but I\nhave noticed that both order-sensitive. Compare:\n\n  site:archive.org allinurl:movies\n  http://www.google.com/search?q=site%3Aarchive.org+allinurl%3Amovies\n  (0 results)\n\n  allinurl:movies site:archive.org\n  http://www.google.com/search?q=allinurl%3Amovies+site%3Aarchive.org\n  (over 2000 results)\n\nAlso, while trying out different combinations of the above, Google suddenly\nstopped working for me! I may have tripped some anti-abuse/anti-reverse-\nengineering guard.\n\nThe key is going to be choosing the right queries to elicit the most\nuseful comparisions. I think starting from our crawls, we should\ntry to craft queries that we would expect to return X results (where\nX &lt; 1000). We then get the actual results Y, and can compare our\ndataset for that query against Google&#39;s.\n\nIdeally, also, Y would be less than 1000, so that we know that within\nthe test set, we have a perfect view of our and Google&#39;s crawl. (We\nmight vary X over time in order to get a more desirable Y.)\n\n- Gordon\n\n\n----- Original Message ----- \nFrom: &quot;Igor Ranitovic&quot; &lt;igor@...&gt;\nTo: &lt;gordon@...&gt;\nCc: &quot;Michele Kimpton&quot; &lt;michele@...&gt;\nSent: Monday, June 30, 2003 6:05 PM\nSubject: Google compersions\n\n\n&gt; Just a thought on how we can use google to compare the coverage of our\n&gt; crawls.\n&gt;\n&gt; Google&#39;s advance search allows to search for any term in URLs.\n&gt; So we can have the following query\n&gt; allinurl: htm OR html OR jpg OR gif OR swf OR png site:name_of_a_site\n&gt;\n&gt; Of course the list of terms in allinurl should be more complete to cover\n&gt; most of file extensions.\n&gt;\n&gt; Google API allows 1000 queries a day so if we have more than 1000 host\n&gt; to be compared/searched, we can combined sites in our query:\n&gt; site:site1 OR site:site2 OR ...\n&gt;\n&gt; Limits:\n&gt; I believe that Google API limits the max number of returned results per\n&gt; query. I think that is 1000 (Google web site has limit set to 100).\n&gt; So lets say that limit is 1000 per query, and maximum number of queries per\n&gt; day is 1000, then we can scrape a list of million URLs (1000X1000) per\n&gt; day.\n&gt;\n&gt; Please send me any comments.\n&gt;\n&gt; Take care.\n&gt; i.\n&gt;\n&gt; P.S.\n&gt;\n&gt; Example (search on archive.org result in 22,600 results):\n&gt;\n&gt;\nhttp://www.google.com/search?num=100&hl=en&lr=&ie=UTF-8&oe=UTF-8&as_qdr=all&q=allinurl%3A++html+OR+jpg+OR+gif+OR+swf+OR+png+OR+images+OR+txt+OR+php+site%3Aarchive.org&btnG=Google+Search\n&gt;\n\n\n"}}