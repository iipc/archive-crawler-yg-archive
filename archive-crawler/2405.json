{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"stack","from":"stack &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"6Hrcb1kJTCPqayFyJ3_GhrlYwsuPN4QSAC0GfX3rRn9DYRIFCHJ7EGvbXUKvdOHEx0tYFj4N11X6sZcnPhcSSA","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Re: Large crawl experience (like, 500M links)","postDate":"1134075587","msgId":2405,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQzOTg5RUMzLjEwNjA2MDJAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGRuYTRvbit0Y2pzQGVHcm91cHMuY29tPg==","referencesHeader":"PGRuYTRvbit0Y2pzQGVHcm91cHMuY29tPg=="},"prevInTopic":2403,"nextInTopic":2447,"prevInTime":2404,"nextInTime":2406,"topicId":2391,"numMessagesInTopic":12,"msgSnippet":"... I d suggest you startup a proofing test crawl with BroadScope and see it does. On machines with specs like those listed below we ve pulled down ... was not","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 47468 invoked from network); 8 Dec 2005 21:00:11 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m22.grp.scd.yahoo.com with QMQP; 8 Dec 2005 21:00:11 -0000\r\nReceived: from unknown (HELO dns.duboce.net) (63.203.238.114)\n  by mta2.grp.scd.yahoo.com with SMTP; 8 Dec 2005 21:00:11 -0000\r\nReceived: from [192.168.1.105] ([192.168.1.105])\n\t(authenticated)\n\tby dns-eth1.duboce.net (8.10.2/8.10.2) with ESMTP id jB8Jsne11777\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Thu, 8 Dec 2005 11:54:49 -0800\r\nMessage-ID: &lt;43989EC3.1060602@...&gt;\r\nDate: Thu, 08 Dec 2005 12:59:47 -0800\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; PPC Mac OS X Mach-O; en-US; rv:1.7.8) Gecko/20050511\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;dna4on+tcjs@...&gt;\r\nIn-Reply-To: &lt;dna4on+tcjs@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 2:12:4:0\r\nFrom: stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] Re: Large crawl experience (like, 500M links)\r\nX-Yahoo-Group-Post: member; u=168599281; y=OPp12w5gSsH6_wRdQ5eEE0qYoH_Nvlqy55nJGCS1SnwmlwMqH9L7Wvvt\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\njoehung302 wrote:\n\n&gt;\n&gt; &gt; Use the bloom filter option for the already-seen in BdbFrontier. \n&gt; Seems\n&gt; &gt; to work better when a machine goes above 30-50million.  Bloom\n&gt; becomes\n&gt; &gt; saturated at 125million so thats about the upperbound per machine at\n&gt; the\n&gt; &gt; moment unless you up the bloom filter size  (but its already big and\n&gt; &gt; you&#39;ll start eating into heap the crawler is using going about its\n&gt; other\n&gt; &gt; business).  Thereafter the rate of false positives -- reports that\n&gt; we&#39;ve\n&gt; &gt; seen an URL when in fact we haven&#39;t -- starts to increase (Read the\n&gt; &gt; BloomFilter javadoc for more on its workings).\n&gt; &gt;\n&gt;\n&gt; How confident do you guys feel that if I use broad-scope I can go\n&gt; above 50M links (or even 100M links) without OOME on a single machine?\n\n\nI&#39;d suggest you startup a proofing test crawl with BroadScope and see it \ndoes.\n\nOn machines with specs like those listed below we&#39;ve pulled down \n &gt;50Million documents per instance with &gt;125million discovered.  Scope \nwas not BroadScope.  Once or twice we OOME&#39;d but thought is that \nprobable cause has been addressed in 1.6 release (If there is an OOME, \nyou can checkpoint, restart and recover the crawl.  Often it will \ncontinue the crawl as it avoids an exact replay of the circumstances \nthat brought on the OOME).\n\nOne thing I forgot to add to yesterday&#39;s list is regular checkpointing \n-- every 4 hours or so.\n\nSt.Ack\n\n\n-bash-3.00$ uname -a\nLinux crawling015.archive.org 2.6.11-1.27_FC3smp #1 SMP Tue May 17 \n20:43:11 EDT 2005 i686 athlon i386 GNU/Linux\n\n-bash-3.00$ more /etc/issue\nFedora Core release 3 (Heidelberg)\nKernel &#92;r on an &#92;m\n\nDual AMD Opteron(tm) Processor 246  w/ cpu MHz         : 2009.374 and \ncache size      : 1024 KB\n\n[crawling013 5] ~ &gt; /lib/libc.so.6\nGNU C Library stable release version 2.3.4 (20050218), by Roland McGrath \net al.\nCopyright (C) 2005 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.\nThere is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A\nPARTICULAR PURPOSE.\nConfigured for i586-suse-linux.\nCompiled by GNU CC version 3.3.5 20050117 (prerelease) (SUSE Linux).\nCompiled on a Linux 2.6.9 system on 2005-06-10.\nAvailable extensions:\n      GNU libio by Per Bothner\n      crypt add-on version 2.1 by Michael Glad and others\n      linuxthreads-0.10 by Xavier Leroy\n      GNU Libidn by Simon Josefsson\n      NoVersion patch for broken glibc 2.0 binaries\n      BIND-8.2.3-T5B\n      libthread_db work sponsored by Alpha Processor Inc\n      NIS(YP)/NIS+ NSS modules 0.19 by Thorsten Kukuk\nThread-local storage support included.\nFor bug reporting instructions, please see:\n&lt;http://www.gnu.org/software/libc/bugs.html&gt;.\n\n\n\n\nWe used sun 1.5.0:\n\n-bash-3.00$ /usr/local/jdk1.5.0_03/bin/java -version\njava version &quot;1.5.0_03&quot;\nJava(TM) 2 Runtime Environment, Standard Edition (build 1.5.0_03-b07)\nJava HotSpot(TM) Server VM (build 1.5.0_03-b07, mixed mode)\n\n\n\n&gt; That to me that seems to be the deciding factor on whether we should\n&gt; start with 5 beefy machines and hope each one can go up to 100M links,\n&gt; or with 10 less beefy machines and each one can go up to 50M links\n&gt; without OOME.\n&gt;\n&gt; I know I&#39;m shooting darts in the dark now...I have to start the\n&gt; project planning soon so I&#39;d like to take my best guess with all the\n&gt; advices I can get.\n&gt;\n&gt; cheers,\n&gt; -joe\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------------------------------------------\n&gt; YAHOO! GROUPS LINKS\n&gt;\n&gt;     *  Visit your group &quot;archive-crawler\n&gt;       &lt;http://groups.yahoo.com/group/archive-crawler&gt;&quot; on the web.\n&gt;        \n&gt;     *  To unsubscribe from this group, send an email to:\n&gt;        archive-crawler-unsubscribe@yahoogroups.com\n&gt;       &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;        \n&gt;     *  Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;.\n&gt;\n&gt;\n&gt; ------------------------------------------------------------------------\n&gt;\n\n\n"}}