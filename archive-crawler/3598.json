{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":284768837,"authorName":"Maximilian Schoefmann","from":"&quot;Maximilian Schoefmann&quot; &lt;schoefma@...&gt;","replyTo":"LIST","senderId":"mjscDiKWsockGD1auCElLyZb9GccBcCc22IeaoHN-VaUKzs24r_AfLROa1yQFp7NPrOi0M1jrnsw-opCnCeG3l770zkv1j2d4Qs2nS2HG7G_HaC0c4GlKw","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Re: [DeDuplicator] Skipping URLs marked as      duplicates from being indexed","postDate":"1166199267","msgId":3598,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDI2Mjg1LjE5My4xODAuMTg5LjE1OC4xMTY2MTk5MjY3LnNxdWlycmVsQHdlYm1haWwuaWZpLmxtdS5kZT4=","inReplyToHeader":"PGVsdWNsdStuYXRxQGVHcm91cHMuY29tPg==","referencesHeader":"PDIwMjc2LjE5My4xODAuMTg5LjE1OC4xMTY2MTI4MzcwLnNxdWlycmVsQHdlYm1haWwuaWZpLmxtdS5kZT4gICAgPGVsdWNsdStuYXRxQGVHcm91cHMuY29tPg=="},"prevInTopic":3597,"nextInTopic":3599,"prevInTime":3597,"nextInTime":3599,"topicId":3594,"numMessagesInTopic":5,"msgSnippet":"Hey Kris, ... I m doing very frequent crawls of the same sites and have automated updating the deduplicator index after every crawl. Your DeDuplicator is ","rawEmail":"Return-Path: &lt;schoefma@...&gt;\r\nX-Sender: schoefma@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 18884 invoked from network); 15 Dec 2006 16:15:35 -0000\r\nReceived: from unknown (66.218.67.36)\n  by m39.grp.scd.yahoo.com with QMQP; 15 Dec 2006 16:15:35 -0000\r\nReceived: from unknown (HELO kokytos.rz.ifi.lmu.de) (141.84.214.13)\n  by mta10.grp.scd.yahoo.com with SMTP; 15 Dec 2006 16:15:35 -0000\r\nReceived: from minotaurus.cip.informatik.uni-muenchen.de (news.ifi.lmu.de [141.84.220.21])\n\tby kokytos.rz.ifi.lmu.de (Postfix) with ESMTP id 64E5A43FC7\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Fri, 15 Dec 2006 17:14:27 +0100 (CET)\r\nReceived: from webmail.ifi.lmu.de (localhost [127.0.0.1])\n\tby minotaurus.cip.informatik.uni-muenchen.de (Postfix) with ESMTP id 350163B9DCE\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Fri, 15 Dec 2006 17:14:27 +0100 (CET)\r\nReceived: from 193.180.189.158\n        (SquirrelMail authenticated user schoefma)\n        by webmail.ifi.lmu.de with HTTP;\n        Fri, 15 Dec 2006 17:14:27 +0100 (CET)\r\nMessage-ID: &lt;26285.193.180.189.158.1166199267.squirrel@...&gt;\r\nIn-Reply-To: &lt;eluclu+natq@...&gt;\r\nReferences: &lt;20276.193.180.189.158.1166128370.squirrel@...&gt;\n    &lt;eluclu+natq@...&gt;\r\nDate: Fri, 15 Dec 2006 17:14:27 +0100 (CET)\r\nTo: archive-crawler@yahoogroups.com\r\nUser-Agent: SquirrelMail/1.4.4\r\nMIME-Version: 1.0\r\nContent-Type: multipart/mixed;boundary=&quot;----=_20061215171427_67762&quot;\r\nX-Priority: 3 (Normal)\r\nImportance: Normal\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: &quot;Maximilian Schoefmann&quot; &lt;schoefma@...&gt;\r\nSubject: Re: [archive-crawler] Re: [DeDuplicator] Skipping URLs marked as \n     duplicates from being indexed\r\nX-Yahoo-Group-Post: member; u=284768837\r\n\r\n\r\n------=_20061215171427_67762\r\nContent-Type: text/plain; charset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: 8bit\r\n\r\nHey Kris,\n\n&gt; (...) If you are\n&gt; adding to the index after each crawl then, yes, it would make sense to\n&gt; offer that option.\n\nI&#39;m doing very frequent crawls of the same sites and have automated\nupdating the deduplicator index after every crawl. Your DeDuplicator is\nreally saving me a lot of disk space (and CPU cycles for adding the\ncontent to the NutchWax index) - thanks for sharing this module.\n\n&gt; Adding this as an option might however be interesting. Feel free to\n&gt; send me a patch and I&#39;ll look into integrating it into the module.\n\nfind my patch attached (the patch is against CVS Head where parseLinde is\nnot static yet).\nThe change in CrawlLogIterator could be more elegant, but I didn&#39;t want to\ninterfere too much.\n\nGreetings from Stockholm & have a nice weekend,\n\nMax\r\n------=_20061215171427_67762\r\nContent-Type: application/octet-stream; name=&quot;skip-duplicates.patch&quot;\r\nContent-Disposition: attachment; filename=&quot;skip-duplicates.patch&quot;\r\n\r\n[ Attachment content not displayed ]\r\n------=_20061215171427_67762--\r\n\n"}}