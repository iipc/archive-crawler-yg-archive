{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":359501713,"authorName":"Tomas Ukkonen","from":"&quot;Tomas Ukkonen&quot; &lt;tomas.ukkonen@...&gt;","replyTo":"LIST","senderId":"5aEZxmP790zm9uFLduXP5tLV_sWbXn9Gfh9cMY1F4Bb7rE5SgzpC3RUzgTlEi8Ccv98LAG0OXoWHMp_25BySrklf60Irt9QPK6WK6qIZpBmg0g","spamInfo":{"isSpam":false,"reason":"12"},"subject":"HTTP traffic compression support in Heritrix?","postDate":"1226063364","msgId":5568,"canDelete":false,"contentTrasformed":false,"systemMessage":true,"headers":{"messageIdInHeader":"PDAwMDYwMWM5NDBkYSQwZTI4NzM3MCQ3NDQ3ZDY4MEBhZC5oZWxzaW5raS5maT4="},"prevInTopic":0,"nextInTopic":0,"prevInTime":5567,"nextInTime":5569,"topicId":5568,"numMessagesInTopic":1,"msgSnippet":"Hi to all, In order to try to save bandwidth when harvesting I have investigated Heritrix 1.14 s ability to process compressed HTTP traffic supported by HTTP","rawEmail":"Return-Path: &lt;tomas.ukkonen@...&gt;\r\nReceived: (qmail 68514 invoked from network); 7 Nov 2008 17:21:43 -0000\r\nReceived: from unknown (66.218.67.95)\n  by m42.grp.scd.yahoo.com with QMQP; 7 Nov 2008 17:21:43 -0000\r\nReceived: from unknown (HELO n25a.bullet.sp1.yahoo.com) (209.131.38.237)\n  by mta16.grp.scd.yahoo.com with SMTP; 7 Nov 2008 17:21:43 -0000\r\nReceived: from [69.147.65.150] by n25.bullet.sp1.yahoo.com with NNFMP; 07 Nov 2008 17:21:41 -0000\r\nReceived: from [66.218.66.74] by t7.bullet.mail.sp1.yahoo.com with NNFMP; 07 Nov 2008 17:21:41 -0000\r\nX-Sender: tomas.ukkonen@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 2053 invoked from network); 7 Nov 2008 13:09:27 -0000\r\nX-Received: from unknown (66.218.67.95)\n  by m46.grp.scd.yahoo.com with QMQP; 7 Nov 2008 13:09:27 -0000\r\nX-Received: from unknown (HELO sender-02.it.helsinki.fi) (128.214.205.137)\n  by mta16.grp.scd.yahoo.com with SMTP; 7 Nov 2008 13:09:26 -0000\r\nX-Received: from KKV30 (KKV30.lib.helsinki.fi [128.214.71.116])\n\tby sender-02.it.helsinki.fi (8.13.8/8.13.8) with ESMTP id mA7D9OXK023845;\n\tFri, 7 Nov 2008 15:09:24 +0200\r\nTo: &lt;archive-crawler@yahoogroups.com&gt;\r\nCc: &lt;Kaisa.Kaunonen@...&gt;\r\nDate: Fri, 7 Nov 2008 15:09:24 +0200\r\nOrganization: Kansalliskirjasto / National Library of Finland\r\nMessage-ID: &lt;000601c940da$0e287370$7447d680@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: text/plain;\n\tcharset=&quot;us-ascii&quot;\r\nContent-Transfer-Encoding: 7bit\r\nX-Mailer: Microsoft Office Outlook 11\r\nX-MimeOLE: Produced By Microsoft MimeOLE V6.00.2900.3350\r\nThread-Index: AclA2g4aNymyTT4mSBKuAla3hVc/Fw==\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;Tomas Ukkonen&quot; &lt;tomas.ukkonen@...&gt;\r\nSubject: HTTP traffic compression support in Heritrix?\r\nX-Yahoo-Group-Post: member; u=359501713\r\nX-Yahoo-Newman-Property: groups-system\r\nX-eGroups-Approved-By: gojomo &lt;gojomo@...&gt; via web; 07 Nov 2008 17:21:39 -0000\r\n\r\nHi to all, \n\nIn order to try to save bandwidth when harvesting I have \ninvestigated Heritrix 1.14&#39;s ability to process compressed \nHTTP traffic supported by HTTP 1.1. \n\nIt seems that Heritrix 1.14.x doesn&#39;t support processing \n(for example) gzipped data. I can get compressed replies \nfrom HTTP servers by adding extra header: \n&quot;Content-Encoding: gzip&quot; but it seems that Heritrix link \nextractors cannot process compressed data. \n\nSearching previously archived discussions it seems \nthat someone else have bought this point up before (below). \n\n* Has anyone done anything in order to add support \n  for compression? \n\nBased on my previous experiences using compression in general \nhurts transfer rates but it can be very useful in special cases \n(like when transferring textual (HTML) data). \n\n\n&gt; Re: [archive-crawler] Re: A basic question about Accept-Headers and\nHeritrix\n&gt; \n&gt; It looks like the Apache HttpClient library we use doesn&#39;t support gzip\n&gt; transfer-encoding, but some discussion of how it could be done (and one\n&gt; person&#39;s implementation) has started. See for example this mid-thread\n&gt; comment on the HttpClient list:\n&gt; \n&gt;\nhttp://mail-archives.apache.org/mod_mbox/jakarta-httpclient-user/200512.mbox\n/%3c&#92;\n&gt; 439B3A9F.30809@...%3e\n&gt; \n&gt; However, I&#39;m not sure you&#39;d want to do any decompression in HttpClient,\n&gt; instead deferring that until the content needs to be scanned (if at all)\n&gt; for text/links/etc.\n&gt; \n&gt; A reasonable place to do decompression might be near where you get a\n&gt; useful &#39;replay&#39; of the content: HttpRecorder.getReplayInputStream() and\n&gt; HttpRecorded.getReplayCharSequence().\n&gt; \n&gt; But, in our usual archival mode of thinking, if the response was\n&gt; received compressed, we&#39;d want to write it to our ARCs compressed, so\n&gt; that the recorded copy in the ARC file exactly matches what the server\n&gt; provided. So at least with the getReplayInputStream() operation, you&#39;d\n&gt; sometimes want transfer-encoding-decoded content, and sometimes not.\n&gt; \n&gt; Hope this helps,\n&gt; \n&gt; - Gordon @ IA\n&gt; \n&gt; Michael Stack wrote:\n&gt; &gt; pandae667 wrote:\n&gt; &gt;&gt; I&#39;d even like to help with that feature, but I have no clue where it\n&gt; &gt;&gt; would have to fit into the Heritrix architecture so far.\n&gt; &gt; Start by looking at FetchHTTP:\n&gt; &gt;\nhttp://crawler.archive.org/xref/org/archive/crawler/fetcher/FetchHTTP.html.\n&gt; &gt; You might add an option in the constructor that says always solicit\n&gt; &gt; gzip&#39;d response. In the FetchHTTP context you&#39;ll figure whether the\n&gt; &gt; server has actually sent gzipped content going by its response -- see\n&gt; &gt; around line 397 -- and then, the tricky part, you&#39;ll need to gunzip\n&gt; &gt; whats been recorded to disk after the download has completed just before\n&gt; &gt; you leave the innerProcess method around line 485 (See HttpRecord --\n&gt; &gt; it&#39;ll give you access to the download).\n&gt; \n\n\n-- \nTomas Ukkonen\nInformation Systems Specialist\nKansalliskirjasto / \nThe National Library of Finland\nphone +358-50-4150557\nemail tomas.ukkonen@... \nwww   http://www.kansalliskirjasto.fi \n      http://www.nationallibrary.fi\n\n\n"}}