{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":445716684,"authorName":"Elverton","from":"&quot;Elverton&quot; &lt;uelverton@...&gt;","profile":"elvertonfazzion","replyTo":"LIST","senderId":"YydLXuP2kDZ0D2mv2C3rN5_SqwtYZ3NEe10yydOFTLUAOr_lSHLIzcmRat15yw7FQPRT8AIQxru3V67qvdZxNnMlJCtNnFdVjA","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Stucked in 690 million discovered.","postDate":"1343399751","msgId":7731,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGp1dTkwNyt1Zm1pQGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":7732,"prevInTime":7729,"nextInTime":7732,"topicId":7731,"numMessagesInTopic":6,"msgSnippet":"Hello everybody. Well, I m having a big trouble this time. Before I explain the problem, here is the system configuration: - 24 GB RAM - Intel(R) Xeon(R) CPU","rawEmail":"Return-Path: &lt;uelverton@...&gt;\r\nX-Sender: uelverton@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 23541 invoked from network); 27 Jul 2012 14:35:52 -0000\r\nX-Received: from unknown (98.137.34.46)\n  by m13.grp.sp2.yahoo.com with QMQP; 27 Jul 2012 14:35:52 -0000\r\nX-Received: from unknown (HELO ng7-vm5.bullet.mail.gq1.yahoo.com) (98.136.219.83)\n  by mta3.grp.sp2.yahoo.com with SMTP; 27 Jul 2012 14:35:52 -0000\r\nX-Received: from [98.137.0.88] by ng7.bullet.mail.gq1.yahoo.com with NNFMP; 27 Jul 2012 14:35:51 -0000\r\nX-Received: from [98.137.34.73] by tg8.bullet.mail.gq1.yahoo.com with NNFMP; 27 Jul 2012 14:35:51 -0000\r\nDate: Fri, 27 Jul 2012 14:35:51 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;juu907+ufmi@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;Elverton&quot; &lt;uelverton@...&gt;\r\nSubject: Stucked in 690 million discovered.\r\nX-Yahoo-Group-Post: member; u=445716684; y=DmVm-C7VhwBDF5Es0oCsO6dQXBbe_EcDAF2J68WHnSLIDYgRVjrmOvdA\r\nX-Yahoo-Profile: elvertonfazzion\r\n\r\nHello everybody.\n\nWell, I&#39;m having a big trouble this time. Before I explai=\r\nn the problem, here is the system configuration:\n\n- 24 GB RAM\n- Intel(R) Xe=\r\non(R) CPU E5520 @ 2.27GHz\n- 1.8TB hard disk for Heritrix. (I don&#39;t use warc=\r\n in this crawl. My only target is to know how many (approx.) URLs a domain =\r\nhas.) The usage of the disk is: used 500GB, free 1.3TB.\n- 16GB java heap si=\r\nze for heritrix.\n- Java 1.7.0_05\n\nHere is the Heritrix configuration that I=\r\n consider helpful to the\nproblem:\n\n- bdb-cache-percent =3D 25\n- frontier =\r\n=3D BdbFrontier\n- max-delay-ms =3D 10000\n- min-delay-ms =3D 2000\n- respect-=\r\ncrawl-delay-up-to-secs =3D 300\n- max-retries =3D 10\n- retry-delay-seconds =\r\n=3D 30\n- timeout-seconds =3D 1200\n- sotimeout-ms =3D 20000\n\n% -------------=\r\n-----------------------------------------------\n\nSo, my problem is: the cra=\r\nwl stucked in 690 million discovered. (Queued it&#39;s around 520 million and d=\r\nownloaded is around 170 million).\n\nThe strange thing is the download/uri ra=\r\nte.\n\nDocs/s(avg): 53.2(60.77)\nKB/s(avg): 2069(3205)\n\nIt continues, in some =\r\nway, good in theory (about 3 or 4 million uri crawled per day if you have 5=\r\n3.2 uri&#39;s during all day), but the real crawled per day is below 500.000 (d=\r\niscovered). \n\nLooking at some number in the last five days:\nQueued    Downl=\r\noaded\n541054381 133121289\n535322185 138522175\n530280577 143176680\n525907149=\r\n 147086865\n520568517 151604201\n\nNotice that the queued decreases at the &quot;sa=\r\nme&quot; rate that downloaded increases. The problem could be getting URIs to th=\r\ne queue. A possible is the URIs discovered now had be crawled before, and d=\r\noesn&#39;t go the the queue anymore. But the domain I&#39;m crawling has about 2 mi=\r\nllion domains and I got only 70.000, so there&#39;re many URI&#39;s to be crawled y=\r\net. :)\n\nOther possibility I thought could be a swap problem (too much I/O).=\r\n For my surprise (using vmstat), the swpd is 0. \n\nAnother problem could be =\r\nknow if a URI was crawled already. \nBefore the URI goes to the frontier, he=\r\nritrix verifies it in a queue, using the hash technique. If the crawling is=\r\n big enough, the search get slower, even using hash, because there are many=\r\n URI&#39;s for a key in hash table.\n\nBut, I really don&#39;t know the exactly probl=\r\nem. Anyone had this problem or could point a direction?\n\nThanks,\nElverton.\n=\r\n\n\n"}}