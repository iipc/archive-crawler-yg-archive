{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":457922030,"authorName":"fatal.lexwow","from":"&quot;fatal.lexwow&quot; &lt;fatal.lexwow@...&gt;","profile":"fatal.lexwow","replyTo":"LIST","senderId":"6SuK9P7qDw-rGVr5QFHDLR7FV--DkfPx2LHoFy-GwY67P7eR9rpxgv_1_LKupATFAl8w0kYsY7HAD66KdV9xbjcVzE_oz1hPFmvCVsU","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: Heritrix for writing extracted URIs rather than ARCs","postDate":"1279603768","msgId":6615,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGkyM2M3byszNWlqQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDRDMjUyNDJDLjQwMjA0MDVAYXJjaGl2ZS5vcmc+"},"prevInTopic":6601,"nextInTopic":6617,"prevInTime":6614,"nextInTime":6616,"topicId":6596,"numMessagesInTopic":6,"msgSnippet":"Hi, Is there a way to write my own post processor similiar to LinksScoper which applies rules defined in Scope(decideRules) one by one. My motive is to filter","rawEmail":"Return-Path: &lt;fatal.lexwow@...&gt;\r\nX-Sender: fatal.lexwow@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 67560 invoked from network); 20 Jul 2010 05:31:11 -0000\r\nX-Received: from unknown (66.196.94.106)\n  by m3.grp.sp2.yahoo.com with QMQP; 20 Jul 2010 05:31:11 -0000\r\nX-Received: from unknown (HELO n43d.bullet.mail.sp1.yahoo.com) (66.163.169.157)\n  by mta2.grp.re1.yahoo.com with SMTP; 20 Jul 2010 05:31:11 -0000\r\nX-Received: from [69.147.65.172] by n43.bullet.mail.sp1.yahoo.com with NNFMP; 20 Jul 2010 05:29:29 -0000\r\nX-Received: from [98.137.34.34] by t14.bullet.mail.sp1.yahoo.com with NNFMP; 20 Jul 2010 05:29:29 -0000\r\nDate: Tue, 20 Jul 2010 05:29:28 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;i23c7o+35ij@...&gt;\r\nIn-Reply-To: &lt;4C25242C.4020405@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nFrom: &quot;fatal.lexwow&quot; &lt;fatal.lexwow@...&gt;\r\nSubject: Re: Heritrix for writing extracted URIs rather than ARCs\r\nX-Yahoo-Group-Post: member; u=457922030; y=YXDjH22futYya7A_8nQCYHhFDtbIwijdv_rs2gFi0hBqxgULjPnV\r\nX-Yahoo-Profile: fatal.lexwow\r\n\r\n\nHi,\n\nIs there a way to write my own post processor similiar to LinksScoper=\r\n\nwhich applies rules defined in Scope(decideRules) one by one. My motive is=\r\n to filter extracted links on basis of few rules, not all the rules defined=\r\n in Scope.\nThanks a lot. Please I need help in this regard.\n\n\n--- In archiv=\r\ne-crawler@yahoogroups.com, Gordon Mohr &lt;gojomo@...&gt; wrote:\n&gt;\n&gt; The crawl.lo=\r\ng does offer each URI that was visited, and includes as \n&gt; reference the ex=\r\nact URI from which it was discovered. It doesn&#39;t include \n&gt; *all* outlinks/=\r\ninlinks; just those that were actually followed. (So, \n&gt; which paths it sho=\r\nws is sensitive to some fairly arbitrary \n&gt; ordering/timing issues.)\n&gt; \n&gt; I=\r\nf in fact you want every link, or in a particular format, you&#39;ll need \n&gt; to=\r\n try other approaches.\n&gt; \n&gt; If you choose to write crawled content as &#39;WARC=\r\n&#39; files, which is the \n&gt; default in our recommended Heritrix-3 (3.0.0+) con=\r\nfiguration, a \n&gt; &#39;metadata&#39; record will be written for each crawled URI (al=\r\nongside the \n&gt; &#39;response&#39; and &#39;request&#39; records). This contains a rudimenta=\r\nry listing \n&gt; of the outlinks found from each URI that, with a little massa=\r\nging, might \n&gt; meet your needs.\n&gt; \n&gt; To get output exactly as you described=\r\n...\n&gt; \n&gt; ORIGIN-URI-1\tDESTINATION-URI-1\n&gt; ORIGIN-URI-1\tDESTINATION-URI-2\n&gt; =\r\nORIGIN-URI-1\tDESTINATION-URI-3\n&gt; ORIGIN-URI-2\tDESTINATION-URI-4\n&gt; etc.\n&gt; \n&gt;=\r\n ...you would need to write your own dump code. In the Heritrix \n&gt; architec=\r\nture, this would most likely involve supplying your own \n&gt; &#39;Processor&#39; subc=\r\nlass, and placing it into the list (aka &#39;chain&#39;) of \n&gt; Processors at a suit=\r\nable position -- after all link-extraction is \n&gt; performed. (You might addi=\r\ntionally position this Processor before any \n&gt; link-rejecting &#39;scoping&#39; occ=\r\nurs, if you want *all* outlinks, or after \n&gt; scoping, if you only want thos=\r\ne that otherwise fit your crawl definition.)\n&gt; \n&gt; This Processor can be wri=\r\ntten in Java as long as it&#39;s available from the \n&gt; classpath at the time of=\r\n JVM startup. It can also be written in several \n&gt; other scripting language=\r\ns that work on the JVM.\n&gt; \n&gt; The same general strategy works in either the =\r\nlatest Heritrix-1 release \n&gt; (1.14.4) or Heritrix-3 (3.0.0). However, H3 is=\r\n a little more welcoming \n&gt; to this kind of incremental extension: it&#39;s eas=\r\nier to specify arbitrary \n&gt; classes in your configuration, and more bundled=\r\n scripting languages \n&gt; (Beanshell, Groovy, JavaScript). The downside of H3=\r\n is that you have to \n&gt; be comfortable editing a largish XML configuration =\r\nfile, filled with \n&gt; Java terminology, to customize crawls.\n&gt; \n&gt; Hope this =\r\nhelps,\n&gt; \n&gt; - Gordon @ IA\n&gt; \n&gt; \n&gt; On 6/25/10 4:43 AM, Federico Maggi wrote:=\r\n\n&gt; &gt; On Jun 24, 2010, at 9:54 PM, Gabriel Vasile wrote:\n&gt; &gt;\n&gt; &gt;&gt; The inform=\r\nation you want is in the crawl.log\n&gt; &gt;\n&gt; &gt; \tit seems to me that entries are=\r\n inserted into crawl.log only when a certain URI is visited, not when it&#39;s =\r\nfound.\n&gt; &gt;\n&gt; &gt; This is &quot;OK&quot;, since I&#39;d have to wait for the entire crawl to=\r\n finish in order to see all the URI encountered.\n&gt; &gt;\n&gt; &gt; Isn&#39;t there a way =\r\nto log URIs right after they got extracted (and put in queue)?\n&gt; &gt;\n&gt; &gt; Than=\r\nks!\n&gt; &gt; -- Fede\n&gt; &gt;\n&gt; &gt; ------------------------------------\n&gt; &gt;\n&gt; &gt; Yahoo!=\r\n Groups Links\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}