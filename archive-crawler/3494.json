{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"Michael Stack","from":"Michael Stack &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"Gh_HVE52HNBRPT_E3e2ZnwJkMb4Ghe9u4lpcHw1wx72OmpHnNgvOYYobtW33TozsmnIlNmF6izhcOi7plZ6DGNL3n59zRtAm","spamInfo":{"isSpam":false,"reason":"3"},"subject":"Re: [archive-crawler] Exception Support","postDate":"1162320019","msgId":3494,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ1NDc5ODkzLjQwOTAxMDlAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGVpNWM4byt1azczQGVHcm91cHMuY29tPg==","referencesHeader":"PGVpNWM4byt1azczQGVHcm91cHMuY29tPg=="},"prevInTopic":3492,"nextInTopic":0,"prevInTime":3493,"nextInTime":3495,"topicId":3492,"numMessagesInTopic":2,"msgSnippet":"You saw the User Manual section, 4. A quick guide to running your first crawl job (http://crawler.archive.org/articles/user_manual/tutorial.html), and the ","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 42692 invoked from network); 31 Oct 2006 18:42:02 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m22.grp.scd.yahoo.com with QMQP; 31 Oct 2006 18:42:00 -0000\r\nReceived: from unknown (HELO dns.duboce.net) (63.203.238.118)\n  by mta2.grp.scd.yahoo.com with SMTP; 31 Oct 2006 18:41:57 -0000\r\nReceived: by dns.duboce.net (Postfix, from userid 1008)\n\tid 44BEDCE33; Tue, 31 Oct 2006 09:23:34 -0800 (PST)\r\nX-Spam-Checker-Version: SpamAssassin 3.1.4 (2006-07-26) on dns.duboce.net\r\nX-Spam-Level: \r\nX-Spam-Status: No, score=-4.7 required=5.0 tests=ALL_TRUSTED,AWL,BAYES_00,\n\tUPPERCASE_25_50 autolearn=ham version=3.1.4\r\nReceived: from [192.168.1.10] (debord.duboce.net [192.168.1.10])\n\tby dns.duboce.net (Postfix) with ESMTP id E35FACE31\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Tue, 31 Oct 2006 09:23:26 -0800 (PST)\r\nMessage-ID: &lt;45479893.4090109@...&gt;\r\nDate: Tue, 31 Oct 2006 10:40:19 -0800\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.8.0.7) Gecko/20060910 SeaMonkey/1.0.5\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;ei5c8o+uk73@...&gt;\r\nIn-Reply-To: &lt;ei5c8o+uk73@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 2:3:4:0\r\nFrom: Michael Stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] Exception Support\r\nX-Yahoo-Group-Post: member; u=168599281; y=EqZS6q1zroDcOfMjnlRNu9uFw6kcQHCSR4JAItc_2WsiauXCzVOsGfUN\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\nYou saw the User Manual section, &#39;4. A quick guide to running your first \ncrawl job&#39; \n(http://crawler.archive.org/articles/user_manual/tutorial.html), and the \nFAQ?  Please let us know how you find the documentation lacking.  If you \nsend in patches for the doc., we&#39;ll apply them. Or you could add a page \nto the wiki on &#39;Problems starting a Crawl&#39; (or some such).\n\nYours,\nSt.Ack\n\n\nedge_adel wrote:\n&gt;\n&gt; Is there Clear and simple documentation for having problems starting a\n&gt; crawl? I had much difficulty using the wiki. If such a place doesn&#39;t\n&gt; exist I would love to set one up. I have a need for a good crawler,\n&gt; so Im hoping this project fills that void.\n&gt;\n&gt;  \n\n\n"}}