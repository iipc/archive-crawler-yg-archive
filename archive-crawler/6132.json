{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":212342429,"authorName":"Pranay Pandey","from":"Pranay Pandey &lt;sspranay@...&gt;","profile":"sspranay","replyTo":"LIST","senderId":"OXM6bplWzExvXXQCZbbHxMrXQXO2VNvLNWeny8pmACZVpxvJGYcd1WEp8Bk10zYSOTAAbR8myqg37SKZ0NHmtyiWflPKvr-luw","spamInfo":{"isSpam":false,"reason":"12"},"subject":"analysing progress-statistics.log","postDate":"1256741142","msgId":6132,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDMxMjA0MS43ODM4Ny5xbUB3ZWI0MzEzNi5tYWlsLnNwMS55YWhvby5jb20+"},"prevInTopic":0,"nextInTopic":6133,"prevInTime":6131,"nextInTime":6133,"topicId":6132,"numMessagesInTopic":3,"msgSnippet":"Hi, I had set up a crawl job to run for 6 hours using H3-beta. I had it configured to be least polite and number of parallel queue was set to 5. After","rawEmail":"Return-Path: &lt;sspranay@...&gt;\r\nX-Sender: sspranay@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 48364 invoked from network); 28 Oct 2009 14:46:44 -0000\r\nX-Received: from unknown (98.137.34.45)\n  by m2.grp.sp2.yahoo.com with QMQP; 28 Oct 2009 14:46:44 -0000\r\nX-Received: from unknown (HELO web43136.mail.sp1.yahoo.com) (216.252.121.66)\n  by mta2.grp.sp2.yahoo.com with SMTP; 28 Oct 2009 14:46:44 -0000\r\nX-Received: (qmail 79551 invoked by uid 60001); 28 Oct 2009 14:45:42 -0000\r\nMessage-ID: &lt;312041.78387.qm@...&gt;\r\nX-YMail-OSG: MNbB71AVM1lgPcoPZbQaj0z4HlCqq4HkjFqGKSXg0MU15jaExL.oKF.weGlMItPb1pkme_0ngnzlWJbo7FcDZ_9VBPu.C_iSxn4QvQ1dhYE3Vl7Lq4WeLSXW3DcmhFN1lJTPKyZJ0YEdfUhsFshXTFD8WDVRlQrDFd16XJvAM2ny7YdhL.Z3L1r0pf8se4dMVv_fByTBiKRjZuI39eL6gDu5b2VHhiYR11Sgj0E7plzM3HNbdzNQebU0aoO.RtaKFuG10jC3_H_5Z3.XwPkNReYDlrmzCSwDptZ25TUxR4yUutjCqA--\r\nX-Received: from [204.194.77.3] by web43136.mail.sp1.yahoo.com via HTTP; Wed, 28 Oct 2009 07:45:42 PDT\r\nX-Mailer: YahooMailClassic/7.0.14 YahooMailWebService/0.7.361.4\r\nDate: Wed, 28 Oct 2009 07:45:42 -0700 (PDT)\r\nTo: archive-crawler@yahoogroups.com\r\nMIME-Version: 1.0\r\nContent-Type: multipart/alternative; boundary=&quot;0-251285528-1256741142=:78387&quot;\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Pranay Pandey &lt;sspranay@...&gt;\r\nSubject: analysing progress-statistics.log\r\nX-Yahoo-Group-Post: member; u=212342429; y=vRV9b-pP-Q1ZDBk0cTNRda8eDomGEmF7MHz3C9Xh1lWJuF4\r\nX-Yahoo-Profile: sspranay\r\n\r\n\r\n--0-251285528-1256741142=:78387\r\nContent-Type: text/plain; charset=iso-8859-1\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n\nHi,\n\nI had set up a crawl job to run for 6 hours using H3-beta. I had it c=\r\nonfigured to be least polite and number of parallel queue was set to 5. Aft=\r\ner completion, when I looked at the avg download rate (docs/sec), it was 0.=\r\n9 docs/sec. Some of the targeted contents were not archived. \n\nTracking dow=\r\nn the reason for low download rate, I noticed that for almost 4 out of 6 ho=\r\nurs , the download rate was showing up 0. Here are some of the lines of the=\r\n progress-statistics.log files:\n\nAfter an hour of start:\n2009-10-27T23:41:2=\r\n1Z=A0=A0=A0=A0=A0=A0 18792=A0=A0=A0=A0=A0=A0=A0 2697=A0=A0=A0=A0=A0=A0=A0 1=\r\n5071=A0=A0=A0=A0=A0=A0=A0 3.5(3.85)=A0=A0 210(192)=A0=A0=A0=A0=A0=A0=A0=A0=\r\n=A0=A0 133=A0=A0=A0=A0=A0=A0=A0=A0=A0=A0=A0=A0 2=A0=A0=A0=A0=A0=A0 134688=\r\n=A0=A0=A0=A0=A0=A0=A0 217152=A0=A0=A0=A0=A0=A0=A0=A0=A0=A0=A0 1=A0=A0=A0=A0=\r\n=A0=A0=A0 1019=A0=A0=A0=A0=A0=A0=A0=A0=A0 17\n\nAfter ~2 hours:\n2009-10-28T00=\r\n:44:41Z=A0=A0=A0=A0=A0=A0 21300=A0=A0=A0=A0=A0=A0=A0=A0 350=A0=A0=A0=A0=A0=\r\n=A0=A0 19849=A0=A0=A0=A0=A0=A0=A0=A0=A0 0(2.57)=A0=A0=A0=A0 0(135)=A0=A0=A0=\r\n=A0=A0=A0=A0=A0=A0=A0 146=A0=A0=A0=A0=A0=A0=A0=A0=A0=A0=A0=A0 0=A0=A0=A0=A0=\r\n=A0=A0 199768=A0=A0=A0=A0=A0=A0=A0 216896=A0=A0=A0=A0=A0=A0=A0=A0=A0=A0=A0 =\r\n1=A0=A0=A0=A0=A0=A0=A0=A0=A0=A0 0=A0=A0=A0=A0=A0=A0=A0=A0=A0=A0 2\n\nAt termi=\r\nnation: \n2009-10-28T04:36:01Z=A0=A0=A0=A0=A0=A0 21300=A0=A0=A0=A0=A0=A0=A0=\r\n=A0 350=A0=A0=A0=A0=A0=A0=A0 19849=A0=A0=A0=A0=A0=A0=A0=A0=A0 0(0.92)=A0=A0=\r\n=A0=A0=A0 0(48)=A0=A0=A0=A0=A0=A0=A0=A0=A0=A0 146=A0=A0=A0=A0=A0=A0=A0=A0=\r\n=A0=A0=A0=A0 0=A0=A0=A0=A0=A0=A0 119000=A0=A0=A0=A0=A0=A0=A0 168896=A0=A0=\r\n=A0=A0=A0=A0=A0=A0=A0=A0=A0 1=A0=A0=A0=A0=A0=A0=A0=A0=A0=A0 0=A0=A0=A0=A0=\r\n=A0=A0=A0=A0=A0=A0 2\n\nAs can been seen, for about 4 hours, the number of UR=\r\nIs queued up stayed stagnant at 350. What could be causing this? Some of th=\r\ne contents well within the scope were not crawled. Is there a way I can acc=\r\ness the &#39;queued&#39; URIs?\nCandidateScoper.log and FrontierPreparer.log are emp=\r\nty.\n\nRegards,\nPranay\n\n\n\n\n      \r\n--0-251285528-1256741142=:78387\r\nContent-Type: text/html; charset=iso-8859-1\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n&lt;table cellspacing=3D&quot;0&quot; cellpadding=3D&quot;0&quot; border=3D&quot;0&quot; &gt;&lt;tr&gt;&lt;td valign=3D&quot;=\r\ntop&quot; style=3D&quot;font: inherit;&quot;&gt;&lt;br&gt;Hi,&lt;br&gt;&lt;br&gt;I had set up a crawl job to ru=\r\nn for 6 hours using H3-beta. I had it configured to be least polite and num=\r\nber of parallel queue was set to 5. After completion, when I looked at the =\r\navg download rate (docs/sec), it was 0.9 docs/sec. Some of the targeted con=\r\ntents were not archived. &lt;br&gt;&lt;br&gt;Tracking down the reason for low download =\r\nrate, I noticed that for almost 4 out of 6 hours , the download rate was sh=\r\nowing up 0. Here are some of the lines of the progress-statistics.log files=\r\n:&lt;br&gt;&lt;br&gt;After an hour of start:&lt;br&gt;2009-10-27T23:41:21Z&nbsp;&nbsp;&nbsp;&=\r\nnbsp;&nbsp;&nbsp; &lt;span style=3D&quot;font-weight: bold;&quot;&gt;18792&nbsp;&nbsp;&nbsp=\r\n;&nbsp;&nbsp;&nbsp;&nbsp; 2697&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 15=\r\n071&nbsp;&lt;/span&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;span style=3D&quot;color: r=\r\ngb(255, 0, 0);&quot;&gt; 3.5(3.85&lt;/span&gt;)&nbsp;&nbsp;\n 210(192)&nbsp;&nbsp;&nbsp;&n=\r\nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 133&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=\r\nnbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=\r\nbsp; 134688&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 217152&nbsp;&nbsp;&nb=\r\nsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1&nbsp;&nbsp;&nbsp;&nbs=\r\np;&nbsp;&nbsp;&nbsp; 1019&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=\r\nbsp; 17&lt;br&gt;&lt;br&gt;After ~2 hours:&lt;br&gt;2009-10-28T00:44:41Z&nbsp;&nbsp;&nbsp;&nb=\r\nsp;&nbsp;&nbsp;&lt;span style=3D&quot;font-weight: bold;&quot;&gt; 21300&nbsp;&nbsp;&nbsp;&=\r\nnbsp;&nbsp;&nbsp;&nbsp;&nbsp; 350&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=\r\n 19849&lt;/span&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;span st=\r\nyle=3D&quot;color: rgb(255, 0, 0);&quot;&gt; &lt;span style=3D&quot;font-weight: bold;&quot;&gt;0(2.57)&lt;=\r\n/span&gt;&lt;/span&gt;&nbsp;&nbsp;&nbsp;&nbsp; 0(135)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=\r\nnbsp;&nbsp;&nbsp;&nbsp;&nbsp; 146&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 19976=\r\n8&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 216896&nbsp;&nbsp;&nbsp;&nbsp;&=\r\nnbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=\r\nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=\r\nsp;&nbsp;&nbsp; 2&lt;br&gt;&lt;br&gt;At termination: &lt;br&gt;2009-10-28T04:36:01Z&nbsp;&nbs=\r\np;&nbsp;&nbsp;&nbsp;&nbsp; &lt;span style=3D&quot;font-weight: bold;&quot;&gt;21300&nbsp;&n=\r\nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 350&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=\r\nnbsp;&nbsp; 19849&lt;/span&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=\r\nsp; &lt;span style=3D&quot;font-weight: bold; color: rgb(255, 0, 0);&quot;&gt;0(0.92)&nbsp;=\r\n&nbsp;&lt;/span&gt;&nbsp;&nbsp;&nbsp; 0(48)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=\r\nbsp;&nbsp;&nbsp;&nbsp; 146&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=\r\nnbsp;&nbsp;&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 119000&nbsp;&=\r\nnbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n 168896&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=\r\nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=\r\nsp;&nbsp;&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=\r\np;&nbsp; 2&lt;br&gt;&lt;br&gt;As can been seen, for about 4 hours, the number of URIs q=\r\nueued up stayed stagnant at 350. What could be causing this? Some of the co=\r\nntents well within the scope were not crawled. Is there a way I can access =\r\nthe &#39;queued&#39; URIs?&lt;br&gt;CandidateScoper.log and FrontierPreparer.log are empt=\r\ny.&lt;br&gt;&lt;br&gt;Regards,&lt;br&gt;Pranay&lt;br&gt;&lt;div style=3D&quot;color: rgb(0, 0, 191);&quot; id=3D=\r\n&quot;RTEContent&quot;&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;=\r\nbr&gt;\n\n      \r\n--0-251285528-1256741142=:78387--\r\n\n"}}