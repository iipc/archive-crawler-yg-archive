{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"RMa7kEzVR9n_kQaDTIE2N0GqbPatnswOuIgsQ95T06v-cqAXPsfWqcuT8_AMjXcSGGRTNOMBOii3rLYldiwZk7UjW62jugg","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] Seed List using in Heritrix","postDate":"1278452955","msgId":6603,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRDMzNBNERCLjgwNzAxMDlAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGkwdDg3ZSt1bGo2QGVHcm91cHMuY29tPg==","referencesHeader":"PGkwdDg3ZSt1bGo2QGVHcm91cHMuY29tPg=="},"prevInTopic":6602,"nextInTopic":0,"prevInTime":6602,"nextInTime":6604,"topicId":6602,"numMessagesInTopic":2,"msgSnippet":"... That directive should ideally be: +http://(it, ...so that it accepts URIs with an exact .IT top-level-domain, but not others that might begin it . (The","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 7360 invoked from network); 6 Jul 2010 21:49:30 -0000\r\nX-Received: from unknown (66.196.94.107)\n  by m14.grp.re1.yahoo.com with QMQP; 6 Jul 2010 21:49:30 -0000\r\nX-Received: from unknown (HELO relay03.pair.com) (209.68.5.17)\n  by mta3.grp.re1.yahoo.com with SMTP; 6 Jul 2010 21:49:30 -0000\r\nX-Received: (qmail 15463 invoked from network); 6 Jul 2010 21:49:16 -0000\r\nX-Received: from 208.70.27.190 (HELO silverbook.local) (208.70.27.190)\n  by relay03.pair.com with SMTP; 6 Jul 2010 21:49:16 -0000\r\nX-pair-Authenticated: 208.70.27.190\r\nMessage-ID: &lt;4C33A4DB.8070109@...&gt;\r\nDate: Tue, 06 Jul 2010 14:49:15 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.6; en-US; rv:1.9.1.10) Gecko/20100512 Thunderbird/3.0.5\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: &quot;compa.marco&quot; &lt;compa.marco@...&gt;\r\nReferences: &lt;i0t87e+ulj6@...&gt;\r\nIn-Reply-To: &lt;i0t87e+ulj6@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Seed List using in Heritrix\r\nX-Yahoo-Group-Post: member; u=137285340; y=Ce-pQwn2qL0dB6Imnuy-412T2ctOK6C5YB7XG434528B\r\nX-Yahoo-Profile: gojomo\r\n\r\nOn 7/5/10 11:27 AM, compa.marco wrote:\n&gt; Hi all, i want to use heritrix to crawl an entire domain like .it .\n&gt; Is there some specific seed list i should give to Heritrix seed list( other than specify +http://(it using the SurtPrefix Module) that can be useful to do the crawl i want?\n\nThat directive should ideally be:\n\n+http://(it,\n\n...so that it accepts URIs with an exact .IT top-level-domain, but not \nothers that might begin &quot;it&quot;. (The point is academic here, as there \naren&#39;t any such other TLDs, but this can be an issue when people are \ncrafting other SURT prefixes.)\n\nNote that this only causes the crawler to rule-in discovered URIs that \nfit the pattern -- it doesn&#39;t actually help the crawler find any/all .IT \ndomain names.\n\n&gt; I know Heritrix can use the links scanned and then start crawling them, but is there any other tips for cover all the italian web in the crawl??\n\nYou should use a mixture of sources to get as many .IT sites as you can, \nand then you hope that most others are discovered by links between sites.\n\nSome groups doing national-TLD crawls have mined other public or \ncommercially-available lists of domain names. For example, you might \ndownload/scan Wikipedia or DMOZ for all .IT outlinks.\n\nIn some countries a relationship with the official registrar(s) allows \naccess to a list of all registered names -- though even this would not \ntell you all the subdomains that might be running web servers.\n\nOthers have done a broader crawl, of all the web, without storing all \nresults, in order to better discover the domain names of some subset of \nTLDs, like national TLDs.\n\nWhen the Internet Archive has done crawls of national TLDs, we have \noften used our internal records of websites discovered at any time in \nthe 13-year history of our worldwide web archive, but these lists are \nnot publicly available.\n\n- Gordon @ IA\n\n"}}