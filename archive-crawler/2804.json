{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"Michael Stack","from":"Michael Stack &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"TIZ-pw5JHv7m0GBNAiN_FP6s56rVXcnDEe3mTDgzRc8kz94goNPFXws4OOZFg0Qotdrh4d3HnFOspnXJT78zifAciwlKegjo","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] send-range: true -&gt; doesn&#39;t honor robots.txt anymore","postDate":"1145894573","msgId":2804,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ0NENGNkFELjYwNzA5MDFAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDYuMi41LjYuMC4yMDA2MDQyNDAyNTE1MC4wMWMzNzk0OEBkaWdpdGhpLmRlPg==","referencesHeader":"PDYuMi41LjYuMC4yMDA2MDQyNDAyNTE1MC4wMWMzNzk0OEBkaWdpdGhpLmRlPg=="},"prevInTopic":2800,"nextInTopic":2805,"prevInTime":2803,"nextInTime":2805,"topicId":2800,"numMessagesInTopic":4,"msgSnippet":"... I think you are correct.  Here is where we save off the downloaded robots.txt file into the corresponding CrawlServer: ","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 82443 invoked from network); 24 Apr 2006 16:02:29 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m2.grp.scd.yahoo.com with QMQP; 24 Apr 2006 16:02:28 -0000\r\nReceived: from unknown (HELO dns.duboce.net) (63.203.238.114)\n  by mta1.grp.scd.yahoo.com with SMTP; 24 Apr 2006 16:02:28 -0000\r\nReceived: from [192.168.1.105] ([192.168.1.105])\n\tby dns-eth1.duboce.net (8.10.2/8.10.2) with ESMTP id k3OEoTw11920;\n\tMon, 24 Apr 2006 07:50:29 -0700\r\nMessage-ID: &lt;444CF6AD.6070901@...&gt;\r\nDate: Mon, 24 Apr 2006 09:02:53 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; PPC Mac OS X Mach-O; en-US; rv:1.8.0.1) Gecko/20060127 SeaMonkey/1.0\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;6.2.5.6.0.20060424025150.01c37948@...&gt;\r\nIn-Reply-To: &lt;6.2.5.6.0.20060424025150.01c37948@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: Michael Stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] send-range: true -&gt; doesn&#39;t honor robots.txt\n anymore\r\nX-Yahoo-Group-Post: member; u=168599281; y=RT1iGNw0S0RClzzjxD2cTaFp6vU5jhn2tBoFxktqcJ729er7cZhM0i7-\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\nThimo Eichstaedt wrote:\n&gt; Hi,\n&gt;\n&gt; I am using Heritrix 1.6.0. And I have exprienced a strange behaviour:\n&gt;\n&gt; When setting send-range to true, Heritrix doesn&#39;t honor the entries\n&gt; in robots.txt anymore ! When setting send-range back to false, it \n&gt; works right.\n&gt;\n&gt; I think it could be related to the response code &quot;206&quot; instead of\n&gt; &quot;200&quot; of the webserver when using the &quot;range&quot; header.\n\nI think you are correct.  Here is where we save off the downloaded \nrobots.txt file into the corresponding CrawlServer: \nhttp://crawler.archive.org/xref/org/archive/crawler/datamodel/CrawlServer.html#133.  \nIf the return code is not 200 explicitly, we treat it as equivalent of \nno robots at all and so act as though we have free rein to download all \nof the site.\n\nLooks like we should act as though we got a 200 for at least 203 and \nperhaps a 206.  Meantime, I&#39;ve made an issue.\n\nThanks for debugging what was going on as well as the order and seed to \nillustrate the problem.\n\nSt.Ack\n\n"}}