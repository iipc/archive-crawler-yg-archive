{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"D1jOGceups0R5U31tHpfzgJE8Drx1ZCH0k1yjSd951uJqwa49j1yzz78qJMXdtU872xU6QbwAFT5KrN6bgaTxqmiNkhDnNc","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Heritrix Checkpointing High-Level Design","postDate":"1074635341","msgId":244,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQwMERBMjRELjMwMjA0MDNAYXJjaGl2ZS5vcmc+"},"prevInTopic":0,"nextInTopic":257,"prevInTime":243,"nextInTime":245,"topicId":244,"numMessagesInTopic":13,"msgSnippet":"BACKGROUND/REQUIREMENTS: We adopt the general definition of checkpointing from a Mercator paper: # Checkpointing is an important part of any long-running","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 52800 invoked from network); 20 Jan 2004 21:49:03 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m6.grp.scd.yahoo.com with QMQP; 20 Jan 2004 21:49:03 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (209.237.232.202)\n  by mta5.grp.scd.yahoo.com with SMTP; 20 Jan 2004 21:49:03 -0000\r\nReceived: (qmail 10742 invoked by uid 100); 20 Jan 2004 21:46:54 -0000\r\nReceived: from b116-dyn-43.archive.org (HELO archive.org) (gojomo@...@209.237.240.43)\n  by mail-dev.archive.org with SMTP; 20 Jan 2004 21:46:54 -0000\r\nMessage-ID: &lt;400DA24D.3020403@...&gt;\r\nDate: Tue, 20 Jan 2004 13:49:01 -0800\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.6b) Gecko/20031205 Thunderbird/0.4\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nContent-Type: text/plain; charset=windows-1252; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nX-Spam-Status: No, hits=-0.9 required=6.0\n\ttests=AWL,BAYES_10,USER_AGENT_MOZILLA_UA\n\tversion=2.55\r\nX-Spam-Level: \r\nX-Spam-Checker-Version: SpamAssassin 2.55 (1.174.2.19-2003-05-19-exp)\r\nX-eGroups-Remote-IP: 209.237.232.202\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Heritrix Checkpointing High-Level Design\r\nX-Yahoo-Group-Post: member; u=137285340\r\nX-Yahoo-Profile: gojomo\r\n\r\nBACKGROUND/REQUIREMENTS:\n\nWe adopt the general definition of checkpointing from a Mercator paper:\n\n# Checkpointing is an important part of any long-running process\n# such as a web crawl. By checkpointing we mean writing a\n# representation of the crawlerï¿½s state to stable storage that, in\n# the event of a failure, is sufficient to allow the crawler to\n# recover its state by reading the checkpoint and to resume crawling\n# from the exact state it was in at the time of the checkpoint. By\n# this definition, in the event of a failure, any work performed\n# after the most recent checkpoint is lost, but none of the work up\n# to the most recent checkpoint.\n(http://citeseer.nj.nec.com/najork01highperformance.html)\n\nWe expect automatic checkpoints to occur at operator-specified\nintervals -- most likely on the order of hours or a full day. We\nalso would like the operator to be able to trigger a checkpoint\nat their discretion.\n\nUnlike Mercator checkpoints, we would prefer that it be possible\nto resume from any checkpoint, not just the most recent. However,\nto reclaim disk space, operators should be able to discard old,\nunneeded checkpoints.\n\nIdeally, a checkpoint will be completely sufficient to resume a\ncrawl -- no other original launch materials should be necessary --\nand the checkpoint files should be sufficiently self-contained to\nallow them to be moved to and resumed from alternate machines.\n\nSimplifying assumptions and limitations we&#39;ll accept:\n\n  - Information that can (and usually is) replenished\n    in the course of a crawl, such as robots.txt info\n    and DNS info, may be left out of a checkpoint and\n    refetched upon resume.\n\n  - Checkpointing may have a minor effect on the order\n    in which URIs are visited, or the number of times\n    which certain repeatable URIs (like robots/DNS)\n    are visited.\n\n  - Erring slightly on the side of duplication/revisitation,\n    in logs or ARC files, is acceptable for our purposes,\n    if it otherwise simplifies or accelerates the process.\n\n  - When an individual worker ToeThread hangs or\n    spins indefinitely in an uninterruptible manner,\n    we will accept whatever small inconsistency\n    might be introduced by ignoring its status and\n    going forward with a checkpoint. (For example,\n    if a buggy Processor at any point in the chain\n    never completes, checkpointing should still\n    be possible, the problem-causing URI should be\n    noted, and our data may suffer side effects of its\n    partial processing.)\n\n  - Logs begin in new files upon each checkpoint; to\n    see the log over the whole crawl, the files must\n    be concatenated. (This makes checkpointing easier\n    but some of the log-viewing admin UI harder.) The\n    Mercator approach is to name the current logs\n    LOGNAME.tmp, then rename them LOGNAME.00001, etc.,\n    after each checkpoint, and we will adopt this\n    same convention.\n\nAnd further a simplifications we&#39;ll accept for the\ninitial implementation:\n\n  - Checkpointing in progress may noticeably halt\n    crawler progress; essentially all in-progress URIs\n    must complete their processing (or time out) before\n    a checkpoint proceeds. (We will refine this to\n    minimize the crawler-pause time as possible.)\n\nCHECKPOINT OVERVIEW\n\nCrawl operator perspective:\n\nUI reflects a &quot;next checkpoint will be&quot; number. Operator\nrequests a checkpoint. UI reflects that checkpoint is in\nprogress. Checkpoint may take many minutes. Upon completion,\ncheckpoint summary info is available in a list of checkpoints\namong the other crawl reports. A subdirectory of the main\ncrawl output directory holds all generated checkpoint info.\nCopying that directory to a remote location is sufficient\nto restart the crawl later.\n\nWhen user wants to resume from a checkpoint, they can\nbrowse a list of all known checkpoints (or point crawler\nto a previously unknown checkpoint). Checkpoint is\nfirst loaded in &#39;paused&#39; mode, allowing state to be\nviewed and paramters to be tuned. Then, crawl can be\nresumed on request. Previous post-checkpoint output may\nbe clobbered in-place. (For example, when resuming\ncheckpoint 00004, previous files that were building\ntowards old checkpoint 00005 will be overwritten.)\n\nIn the code:\n\nCrawlController receives a checkpoint request. A flag\nis set indicating the control thread should initiate a\ncheckpoint.\n\nNo further URIs are emitted from the Frontier for\nprocessing. The checkpoint routine, in the main control\nthread, waits for all ToeThreads to complete their\ncurrent URIs, subject to a maximum wait. (Any URIs still\nin process at the end of the wait period are noted as\nproblematic -- and logged as either special errors or\nreturned to the Frontier.)\n\nThe checkpoint begins: each notable component of\nthe system -- implementers of the Checkpointable\ninterface -- are sent the prepare(checkpointNumber,\nstoreDirectory) message. As necessary, they pass\nthis to their subcomponents.\n\nGenerally, the checkpointing of an object involves:\n  (1) Writing its important in-memory state to\n      one or more files.\n  (2) Duplicating any on-disk state to the checkpoint\n      directory. (In some cases, this may be possible\n      with filesystem hard-links rather than actual\n      copies.)\n\nTo resume from a checkpoint, the CrawlController would\nreceive a resume-request with an origin directory. It\nwould reconstitute the parts of the crawl, primarily by\nconstructing new instances which read their state from\nthe origin directory, copying data as necessary to the\n&quot;running&quot; disk space. (A resume should not alter the\nstored checkpoint in any way.)\n\nCHECKPOINT FRAMEWORK\n\nEach ToeThread wraps its per-URI processing with:\n\n    crawlLock.acquireShared(); // crawlLock is a shared-exclusive\n                               // (AKA &#39;readwrite&#39;) lock\n    // all processing\n    crawlLock.releaseShared();\n\n(This lock may be refined later to leave out early\nprocessing stages, possibly up through fetching,\nwhich can be harmlessly considered to never have\nbegun.)\n\nThe CrawlController controlThread, when it detects\na checkpoint has been requested, runs a checkpoint\nrountine which is roughly:\n\n    crawlLock.acquireExclusive();\n    versionId++;\n    prepare(versionId, checkpointDirectory); // actually does the checkpointing, passing\n                                             // prepare() calls to subcomponents\n    commit(versionId, checkpointDirectory);  // marks the checkpoint as complete, cleans up\n    crawlLock.releaseExclusive();\n\nKey parts of the system, starting with CrawlController,\nimplement interface Checkpointable, which includes\nmethods:\n  - prepare(int versionId, File checkpointDirectory)\n  - commit(int versionId, File checkpointDirectory)\n  - resume(File originDirectory)\n\nIMPLICATIONS ACROSS CODE\n\nOf course, every component which must recover its running\nstate to enable a resume-from-checkpoint must implement\nCheckpointable and have the proper Checkpointable methods\ncalled from the other components which bind it to the\nCrawlController.\n\nThe Web UI will require instrumentation for setting\ncheckpoint intervals, manually triggering checkpoints,\nlisting available checkpoints, and triggering resumes.\n\n- Gordon\n\n"}}