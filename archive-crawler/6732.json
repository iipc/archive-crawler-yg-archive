{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":465980601,"authorName":"Zach Bailey","from":"Zach Bailey &lt;zach.bailey@...&gt;","replyTo":"LIST","senderId":"cUAxatsaHHyPAzcgZyJY_nnhFfhJPOvgKd2CbVwqvChXvUI59-zgonVZSzAH21ejVEmxheDNkCYnY389PBSGr24QOz-XKSfDEKu-mXU","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Suggested Heap for Crawling Hundreds of Thousands - Millions of URLs?","postDate":"1284575119","msgId":6732,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEFBTkxrVGk9THVpdEpwUEtqRlJXNkFqa1BIRmtjOGgyZG1NOUN4OWh4QkhZX0BtYWlsLmdtYWlsLmNvbT4="},"prevInTopic":0,"nextInTopic":6733,"prevInTime":6729,"nextInTime":6733,"topicId":6732,"numMessagesInTopic":2,"msgSnippet":"Some general hardware and JVM sizing questions - What is the suggested approach to indexing hundreds of thousands - millions of URLs? Some things I was","rawEmail":"Return-Path: &lt;zach.bailey@...&gt;\r\nX-Sender: zach.bailey@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 45243 invoked from network); 15 Sep 2010 18:25:20 -0000\r\nX-Received: from unknown (98.137.34.44)\n  by m6.grp.sp2.yahoo.com with QMQP; 15 Sep 2010 18:25:20 -0000\r\nX-Received: from unknown (HELO mail-wy0-f176.google.com) (74.125.82.176)\n  by mta1.grp.sp2.yahoo.com with SMTP; 15 Sep 2010 18:25:20 -0000\r\nX-Received: by mail-wy0-f176.google.com with SMTP id 23so509666wyf.7\n        for &lt;archive-crawler@yahoogroups.com&gt;; Wed, 15 Sep 2010 11:25:19 -0700 (PDT)\r\nMIME-Version: 1.0\r\nX-Received: by 10.227.144.4 with SMTP id x4mr1761440wbu.59.1284575119105; Wed,\n 15 Sep 2010 11:25:19 -0700 (PDT)\r\nX-Received: by 10.216.47.7 with HTTP; Wed, 15 Sep 2010 11:25:19 -0700 (PDT)\r\nDate: Wed, 15 Sep 2010 14:25:19 -0400\r\nMessage-ID: &lt;AANLkTi=LuitJpPKjFRW6AjkPHFkc8h2dmM9Cx9hxBHY_@...&gt;\r\nTo: archive-crawler &lt;archive-crawler@yahoogroups.com&gt;\r\nContent-Type: multipart/alternative; boundary=0016368332d6a9610e049050733f\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Zach Bailey &lt;zach.bailey@...&gt;\r\nSubject: Suggested Heap for Crawling Hundreds of Thousands - Millions of URLs?\r\nX-Yahoo-Group-Post: member; u=465980601\r\n\r\n\r\n--0016368332d6a9610e049050733f\r\nContent-Type: text/plain; charset=ISO-8859-1\r\n\r\nSome general hardware and JVM sizing questions -\n\nWhat is the suggested approach to indexing hundreds of thousands - millions\nof URLs? Some things I was thinking about:\n\n1.) Memory - since the Frontier URIs are held in memory, the heap needs to\nbe rather massive - on the order of a couple gigabytes. Are there any\nalternative frontiers that don&#39;t use in-memory stores? In general heaps\nabove a couple gigabytes are tough to maintain due to JVM GC issues.\n\n2.) Disk Space - for the initial run I really only care about HTML content -\nno images, JS, CSS, etc. I have turned off the JS/CSS/SWF extractors but the\ncrawl still seems to be pulling down images. Is this because the\nExtractorHtml returns &lt;img src&gt; tags as indexable? Is there a way to disable\nthat behavior? I really only care about links to other pages, not images.\n\nOnce I have this issue tackled I don&#39;t believe disk space should be an issue\nat all considering how well raw text compresses.\n\n3.) Bottlenecks - in general assuming the internet connection is fast\nenough, am I going to be I/O bound or CPU bound? What optimizations could be\nexplored at that point?\n\nThanks again for any insight or experiences doing a large crawl like this.\n\n-Zach\n\r\n--0016368332d6a9610e049050733f\r\nContent-Type: text/html; charset=ISO-8859-1\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nSome general hardware and JVM sizing questions -&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;What is=\r\n the suggested approach to indexing hundreds of thousands - millions of URL=\r\ns? Some things I was thinking about:&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;1.) Memory - =\r\nsince the Frontier URIs are held in memory, the heap needs to be rather mas=\r\nsive - on the order of a couple gigabytes. Are there any alternative fronti=\r\ners that don&#39;t use in-memory stores? In general heaps above a couple gi=\r\ngabytes are tough to maintain due to JVM GC issues.&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;d=\r\niv&gt;2.) Disk Space - for the initial run I really only care about HTML conte=\r\nnt - no images, JS, CSS, etc. I have turned off the JS/CSS/SWF extractors b=\r\nut the crawl still seems to be pulling down images. Is this because the Ext=\r\nractorHtml returns &lt;img src&gt; tags as indexable? Is there a way to dis=\r\nable that behavior? I really only care about links to other pages, not imag=\r\nes.=A0&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Once I have this issue tackled I don&#39;t=\r\n believe disk space should be an issue at all considering how well raw text=\r\n compresses.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;3.) Bottlenecks - in general assuming=\r\n the internet connection is fast enough, am I going to be I/O bound or CPU =\r\nbound? What optimizations could be explored at that point?&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;=\r\n/div&gt;&lt;div&gt;Thanks again for any insight or experiences doing a large crawl l=\r\nike this.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;-Zach&lt;/div&gt;\n\r\n--0016368332d6a9610e049050733f--\r\n\n"}}