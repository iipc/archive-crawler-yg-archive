{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":139911393,"authorName":"thiru_sundaram","from":"&quot;thiru_sundaram&quot; &lt;thiru_sundaram@...&gt;","profile":"thiru_sundaram","replyTo":"LIST","senderId":"CVsIMBcDQg1GC1kE99rEcid2sFDGCtoIQa2n74NMRRVRA1qOzw1kzATlczikfLJT5lHDxF9IBFxY5InrIUjrALJy97HdkPyhJ_IT28mnYLyJ3Q","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Crawl using Proxy","postDate":"1156774258","msgId":3220,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGVjdXRoaSs1bDJwQGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":3221,"prevInTime":3219,"nextInTime":3221,"topicId":3220,"numMessagesInTopic":3,"msgSnippet":"Hi all, I setup configuration to crawl a website using proxy. But some time i get the below exception [ in local-errors.log]. Heritrix stops crawling after","rawEmail":"Return-Path: &lt;thiru_sundaram@...&gt;\r\nX-Sender: thiru_sundaram@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 98393 invoked from network); 28 Aug 2006 14:11:04 -0000\r\nReceived: from unknown (66.218.67.35)\n  by m35.grp.scd.yahoo.com with QMQP; 28 Aug 2006 14:11:04 -0000\r\nReceived: from unknown (HELO n17a.bullet.sc5.yahoo.com) (66.163.187.160)\n  by mta9.grp.scd.yahoo.com with SMTP; 28 Aug 2006 14:11:03 -0000\r\nReceived: from [66.163.187.120] by n17.bullet.sc5.yahoo.com with NNFMP; 28 Aug 2006 14:10:58 -0000\r\nReceived: from [66.218.69.2] by t1.bullet.sc5.yahoo.com with NNFMP; 28 Aug 2006 14:10:58 -0000\r\nReceived: from [66.218.66.90] by t2.bullet.scd.yahoo.com with NNFMP; 28 Aug 2006 14:10:58 -0000\r\nDate: Mon, 28 Aug 2006 14:10:58 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;ecuthi+5l2p@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;thiru_sundaram&quot; &lt;thiru_sundaram@...&gt;\r\nSubject: Crawl using Proxy\r\nX-Yahoo-Group-Post: member; u=139911393; y=UjhNBtTOdohxMnYGBF6R7rN1UndxkoML_wOrgNKCwq3kYEJ26aGeacs\r\nX-Yahoo-Profile: thiru_sundaram\r\n\r\nHi all,\nI setup configuration to crawl a website using proxy. But some time=\r\n i\nget the below exception [ in local-errors.log]. Heritrix stops\ncrawling =\r\nafter that. If i pause and resume the job through UI, it\nagain starts from =\r\nthe point it left out. Any idea why socket time out\nexception for one url m=\r\nakes heritrix stop crawling ?\n\nI have given below the error pattern\n2006-08=\r\n-28T12:30:23.174Z    -2          - &quot;url1&quot; L &quot;url2&quot; no-type #022\n- - - le:So=\r\ncketTimeoutException@HTTP\n        at java.net.SocketTimeoutException: Read =\r\ntimed out\n        at java.net.SocketInputStream.read(SocketInputStream.java=\r\n:129)\n        at java.io.BufferedInputStream.fill(BufferedInputStream.java:=\r\n218)\n        at java.io.BufferedInputStream.read(BufferedInputStream.java:2=\r\n35)\n        at\norg.archive.io.RecordingInputStream.read(RecordingInputStrea=\r\nm.java:96)\n        at\norg.apache.commons.httpclient.HttpParser.readRawLine(=\r\nHttpParser.java:77)\n        at\norg.apache.commons.httpclient.HttpParser.rea=\r\ndLine(HttpParser.java:105)\n        at\norg.apache.commons.httpclient.HttpCon=\r\nnection.readLine(HttpConnection.java:1129)\n        at\norg.apache.commons.ht=\r\ntpclient.HttpMethodBase.readStatusLine(HttpMethodBase.java:1850)\n        at=\r\n\norg.apache.commons.httpclient.HttpMethodBase.readResponse(HttpMethodBase.j=\r\nava:1610)\n        at\norg.apache.commons.httpclient.HttpMethodBase.execute(H=\r\nttpMethodBase.java:1000)\n        at\norg.archive.httpclient.HttpRecorderGetM=\r\nethod.execute(HttpRecorderGetMethod.java:117)\n        at\norg.apache.commons=\r\n.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:393=\r\n)\n        at\norg.apache.commons.httpclient.HttpMethodDirector.executeMethod=\r\n(HttpMethodDirector.java:168)\n        at\norg.apache.commons.httpclient.Http=\r\nClient.executeMethod(HttpClient.java:396)\n        at\norg.apache.commons.htt=\r\npclient.HttpClient.executeMethod(HttpClient.java:324)\n        at\norg.archiv=\r\ne.crawler.fetcher.FetchHTTP.innerProcess(FetchHTTP.java:408)\n        at\norg=\r\n.archive.crawler.framework.Processor.process(Processor.java:103)\n        at=\r\n\norg.archive.crawler.framework.ToeThread.processCrawlUri(ToeThread.java:306=\r\n)\n        at org.archive.crawler.framework.ToeThread.run(ToeThread.java:153=\r\n)\n\n\n\n\n\n\n"}}