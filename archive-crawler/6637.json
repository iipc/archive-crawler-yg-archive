{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"f7L8ueKaOWTApy3VWcAvXUMzhToEOr1z3_6vetFAwPqS8mBbfMOJwf6S5sCwKbhtOXD-AEwKSEqkwQ7Hjt_PWiTZ4NWM1l4","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] rebuild crawl.log","postDate":"1280781427","msgId":6637,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRDNTcyQzczLjIwNTA0MDhAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PFAtSVJDLUVYQkUwMUdadU5ZMVMwMDAwMDZmMkBFWC5VQ09QLkVEVT4=","referencesHeader":"PEE1NDZGQkRGN0QyNUIzNDY4NTI3RTlERDAxMThDNTYyMDI5NUJDMDFAU0JFTTM1RVhDMTAxMS5lZmQuaW50cmEuYWRtaW4uY2g+IDxQLUlSQy1FWEJFMDFHWnVOWTFTMDAwMDA2ZjJARVguVUNPUC5FRFU+"},"prevInTopic":6629,"nextInTopic":0,"prevInTime":6636,"nextInTime":6638,"topicId":6626,"numMessagesInTopic":4,"msgSnippet":"As Erik notes, not all the information in the crawl.log is in an ARC file. An ARC contains: [URL] [fetch-timestamp] [MIME] [status-code] [ARC-record-length] ","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 22097 invoked from network); 2 Aug 2010 20:37:21 -0000\r\nX-Received: from unknown (66.196.94.107)\n  by m2.grp.sp2.yahoo.com with QMQP; 2 Aug 2010 20:37:21 -0000\r\nX-Received: from unknown (HELO relay02.pair.com) (209.68.5.16)\n  by mta3.grp.re1.yahoo.com with SMTP; 2 Aug 2010 20:37:21 -0000\r\nX-Received: (qmail 67279 invoked from network); 2 Aug 2010 20:37:07 -0000\r\nX-Received: from 208.70.27.190 (HELO silverbook.local) (208.70.27.190)\n  by relay02.pair.com with SMTP; 2 Aug 2010 20:37:07 -0000\r\nX-pair-Authenticated: 208.70.27.190\r\nMessage-ID: &lt;4C572C73.2050408@...&gt;\r\nDate: Mon, 02 Aug 2010 13:37:07 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.6; en-US; rv:1.9.1.11) Gecko/20100711 Thunderbird/3.0.6\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: Erik Hetzner &lt;erik.hetzner@...&gt;\r\nReferences: &lt;A546FBDF7D25B3468527E9DD0118C5620295BC01@...&gt; &lt;P-IRC-EXBE01GZuNY1S000006f2@...&gt;\r\nIn-Reply-To: &lt;P-IRC-EXBE01GZuNY1S000006f2@...&gt;\r\nContent-Type: text/plain; charset=UTF-8; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] rebuild crawl.log\r\nX-Yahoo-Group-Post: member; u=137285340; y=mgeXzEgSIG3_i5rNocqEL2MZNtPbnKMJRppxc7Md-z4n\r\nX-Yahoo-Profile: gojomo\r\n\r\nAs Erik notes, not all the information in the crawl.log is in an ARC file.\n\nAn ARC contains:\n\n[URL] [fetch-timestamp] [MIME] [status-code] [ARC-record-length]\n[HTTP-Response]\n\nA crawl.log line is:\n\n[log-timestamp] [status-code] [content-length] [URL] [hops-path] &#92;\n  [via-URL] [MIME] [thread#] [fetch-timestamp+fetch-duration] &#92;\n  [content-sha1] [source-tag-if-any] [annotations-if-any]\n\nAs you can see, there&#39;s not complete overlap. Some of the crawl.log \nlines could be extracted from looking inside the record (content-length, \nsha1), and others via simulating a re-crawl against the ARCs (hops-path, \nvia-URL), but there&#39;s no existing code to do so.\n\nWARCs have more ability to store crawl-time metadata, and thus more of \nthe crawl.log-line is often present in some form, but still not all of \nit. Perhaps, it should be -- except for any bit that wasn&#39;t available at \nWARC-writing time (log-timestamp and late annotations).\n\n- Gordon @ IA\n\nOn 7/30/10 1:31 PM, Erik Hetzner wrote:\n&gt; At Fri, 30 Jul 2010 09:03:12 +0200,\n&gt; &lt;mac.kobus@...&gt;  wrote:\n&gt;&gt;\n&gt;&gt; Hi everybody,\n&gt;&gt;\n&gt;&gt; usually we use Heritrix to harvest single websites, so they come each with their own crawl.log.\n&gt;&gt;\n&gt;&gt; In our Ingestprocess the crawl.log is used to verify the content of the delivered ARC-files.\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; Now I want to ingest (some externally crawled) ARC-files, that actually donÂ´t have a crawl.log.\n&gt;&gt;\n&gt;&gt; Here are my questions:\n&gt;&gt;\n&gt;&gt; 1.       Is it possible to rebuild a crawl.log from existing ARC-files?\n&gt;\n&gt; No, generally, because the crawl.log contains information not present\n&gt; in the ARC files. For WARC files it may be a different story.\n&gt;\n&gt; However you could build a mostly equivalent version of a crawl.log\n&gt; from an existing set of ARC files, with timestamps, URLs, response\n&gt; codes, etc. You would be missing at least (if I recall correctly) the\n&gt; time the fetch took, the discovery path (the LXXE looking string) as\n&gt; well as some entries which do not generate an ARC entry.\n&gt;\n&gt; Probably the Heritrix devs have more accurate information.\n&gt;\n&gt; best, Erik Hetzner\n&gt;\n&gt;\n&gt;\n&gt; Sent from my free software system&lt;http://fsf.org/&gt;.\n\n"}}