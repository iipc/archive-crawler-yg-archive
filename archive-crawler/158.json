{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":149694377,"authorName":"Parker Thompson","from":"Parker Thompson &lt;parkert@...&gt;","profile":"michaelparkerthompson","replyTo":"LIST","senderId":"A8TsZCJwZvBn8ea_GO0lwCgNAwl5f2s17AkiDJxneePHOEsOLUSEmfos2VymxnA3rDDXFyr7AXwHrS2X-ppxRAruYDjUhSsmR5MvNA","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] &quot;Garden&quot; Tests Wanted","postDate":"1067296437","msgId":158,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PFBpbmUuTE5YLjQuMzMuMDMxMDI3MTQzMzE4MC4yMDQwNi0xMDAwMDBAaG9tZXNlcnZlci5hcmNoaXZlLm9yZz4=","inReplyToHeader":"PDNGOUQ3M0RCLjQwNzAwMDRAYXJjaGl2ZS5vcmc+"},"prevInTopic":157,"nextInTopic":159,"prevInTime":157,"nextInTime":159,"topicId":157,"numMessagesInTopic":3,"msgSnippet":"Along the same linkes it also might be useful to think of test classes . By this I mean that at some point we ll want to have a coherent hierarchy of","rawEmail":"Return-Path: &lt;parkert@...&gt;\r\nX-Sender: parkert@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 99811 invoked from network); 27 Oct 2003 23:14:33 -0000\r\nReceived: from unknown (66.218.66.218)\n  by m6.grp.scd.yahoo.com with QMQP; 27 Oct 2003 23:14:33 -0000\r\nReceived: from unknown (HELO homeserver.archive.org) (209.237.233.202)\n  by mta3.grp.scd.yahoo.com with SMTP; 27 Oct 2003 23:14:33 -0000\r\nReceived: from localhost (parkert@localhost)\n\tby homeserver.archive.org (8.11.6/8.11.6) with ESMTP id h9RNE3s12790\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Mon, 27 Oct 2003 15:14:18 -0800\r\nX-Authentication-Warning: homeserver.archive.org: parkert owned process doing -bs\r\nDate: Mon, 27 Oct 2003 15:13:57 -0800 (PST)\r\nTo: &lt;archive-crawler@yahoogroups.com&gt;\r\nSubject: Re: [archive-crawler] &quot;Garden&quot; Tests Wanted\r\nIn-Reply-To: &lt;3F9D73DB.4070004@...&gt;\r\nMessage-ID: &lt;Pine.LNX.4.33.0310271433180.20406-100000@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: TEXT/PLAIN; charset=US-ASCII\r\nFrom: Parker Thompson &lt;parkert@...&gt;\r\nX-Yahoo-Group-Post: member; u=149694377\r\nX-Yahoo-Profile: michaelparkerthompson\r\n\r\n\nAlong the same linkes it also might be useful to think of &quot;test classes&quot;.  \nBy this I mean that at some point we&#39;ll want to have a coherent hierarchy\nof tests/groups of tests where we can just plug new tests into the\nappropriate slot, e.g.:\n\nAll Tests\n - Authentication Tests\n   o Knows Cookies\n   o Knows Session IDs\n   o Fills out Forms\n - Fetching Tests\n   o Gets mime type x\n   o Gets mime type y\n - Parsing Tests\n   o Link Extraction Tests\n\t- PDF URIs \n\t- Flash URIs\n\t- RDF resource URIs\n\t- [x]HTML\n\t  o Vanilla hrefs\n\t  o Relative links\n\t  o html object fetches\n - Degenerate Cases (graceful failures)\n   o Infinite content\n     \t- Infinite breadth\n     \t- Infinite depth\n\t  o Soft 404s\n   o Temporal Failures\n\t- Infinite trickle\n\t- Broken connections\n...\n\nThis may be the sort of thing we do after developing a good corpus of\ntests (create a &quot;grab bag&quot;, then organize it), but if anyone wants to\npropose a scheme I&#39;m all ears.  \n\nIf we do this correctly we can make it really easy to think about various\ncrawlers in terms of thier &quot;areas of competence&quot;.  For example, we can say\n&quot;crawler x is better in areas y, z, and q, but not as good at things like\na, b, and c&quot; rather than saying &quot;crawler x passed 18/20 tests, crawler z\npassed 19/20, crawler z must be better&quot;.\n\nSuggestions?\n\npt.\n-- \nParker Thompson\nThe Internet Archive\n510.541.0125\n\nOn Mon, 27 Oct 2003, Gordon Mohr wrote:\n\n|In our meeting Friday, we resolved to each create 3 new test\n|cases for our crawler &quot;test garden&quot;. This is an expandable\n|collection of web-server content against which any crawler&#39;s\n|ability to retrieve certain documents, while avoiding others,\n|can be tested. For now, the results are evaluated by\n|postprocessing the crawler logs, though we may move to a system\n|where the server uses its own logs to evaluate crawler\n|behavior.\n|\n|By creating a batch of new standalone tests, we hope to...\n|\n|   (1) expand the number of available tests\n|   (2) gain insight into the ease with which\n|       new tests can be contributed\n|   (3) probe any limitations of the expressiveness\n|       of the current approach (are there things we\n|       want to test, but cannot?)\n|   (4) probe how well the approach scales as the\n|       number/variety of tests grows\n|\n|For reference, Parker&#39;s original note about the garden\n|setup and practices is appended below.\n|\n|So that we don&#39;t overlap, and as an example of the kinds\n|of tests that would be useful, I intend my tests to be:\n|\n|  (1) Are absolute URIs extracted properly in\n|      included (&quot;&lt;script src=&quot;) Javascript files?\n|\n|      Expected result: Heritrix does not yet parse\n|      Javscript in standalone JS files -- only in HTML --\n|      and so would fail this test right now. But the\n|      our current best-effort search for URI-like\n|      strings in Javascript code could easily be placed\n|      in a new Javascript Extractor prtocessor, so\n|      we expect Heritrix to pass this test soon.\n|\n|  (2) Are relative URIs extracted properly in\n|      included (&quot;&lt;script src=&quot;) Javascript files?\n|\n|      Expected result: Need to do more research;\n|      I&#39;m not sure if they should be interpreted\n|      relative to the JS file URI or the page that\n|      included it. As above, Heritrix would fail\n|      currently but should pass soon.\n|\n|  (3) Are URIs that are created via concatenation\n|      of Javascript string variables or string variables\n|      and string literals extracted properly?\n|\n|      Expected result: No crawler I know of yet handles\n|      this. Someday, perhaps.\n|\n|So as should be clear, these tests don&#39;t have to be\n|things we believe current crawlers do (or must) achieve.\n|Any open or closed bugs in our Sourceforge Bug Tracker\n|might also be good candidates for new test cases.\n|\n|Anyone else following the Heritrix project is also\n|welcome to submit tests in the appropriate form, or\n|comments about what should be testable.\n|\n|I&#39;d like to integrate any new tests onto crawl08 by the\n|end of this week.\n|\n|- Gordon\n|\n|\n|================================================================\n|Parker Thompson (parkert@...) wrote:\n| &gt; Today I checked into cvs a new test garden that should make automated\n| &gt; testing a whole lot easier.  I&#39;ve attached a readme.txt that explains how\n| &gt; the tools work and what&#39;s available.  You should be able to check out this\n| &gt; code from anywhere and use it witout modification (tests will let you know\n| &gt; if/when this is not the case).\n| &gt;\n| &gt; To see it in action check out:\n| &gt;\n| &gt;   http://crawl08.archive.org/\n| &gt;\n| &gt; For a file manifest:\n| &gt;\n| &gt;   http://crawl08.archive.org/?links=1\n| &gt;\n| &gt; Note: You may run any/all of the reporting scripts locally (results.cgi\n| &gt; and testreport.pl) even if the garden is remote, though they fetch\n| &gt; configuration information real-time based on the log files being parsed,\n| &gt; so you will need an internet connection when evaluating test results.\n| &gt;\n| &gt; Let me know if you have any questions,\n| &gt;\n| &gt; pt.\n| &gt;\n| &gt;\n| &gt; ------------------------------------------------------------------------\n| &gt;\n| &gt; Heritrix Web-based Test Suite\n| &gt; -----------------------------\n| &gt;\n| &gt; I. Introduction\n| &gt;\n| &gt; The following is a description of the functionaly provided by the Heritrix\n| &gt; web-based test suite.  This suite is meant to be a set of &quot;unit tests&quot;,\n| &gt; that can exist individually or as part of &quot;test suites&quot;.\n| &gt;\n| &gt; II. Installing\n| &gt;\n| &gt; To install these tests, just put the directory which came with this file\n| &gt; somewhere in the apache document tree, so it&#39;s viewable from the web, make\n| &gt; sure the path to perl is correct in each cgi (default is /usr/bin/perl),\n| &gt; change it if it is not, make sure you can execute cgis (see httpd.conf),\n| &gt; make sure index.cgi is a valid index (see httpd.conf), and you should be\n| &gt; set.\n| &gt;\n| &gt; Addionally, if you want the infinite breadth test to work you must make\n| &gt; sure the host on which these tests reside has a dns entry in the form of:\n| &gt;\n| &gt;   *.host.org\n| &gt;\n| &gt; so that infinite-content.cgi can create arbitrarily-named aliases.\n| &gt;\n| &gt; II. Running All Test\n| &gt;\n| &gt; To run all tests just point the crawler at the test directory.  It will be\n| &gt; presented with links to each test.\n| &gt;\n| &gt; III. Single Tests\n| &gt;\n| &gt; To run a single test, or test suite, point the crawler at the test\n| &gt; directory with the argument &#39;?test=name&#39; where name is the directory name\n| &gt; of the test or suite.  By convention this is &#39;testX&#39; where X is the test\n| &gt; number (e.g. http://test.archive.org/?test=test23).\n| &gt;\n| &gt; This will display a page with links to only the test specified, and any\n| &gt; tests on which the specified test is dependent.\n| &gt;\n| &gt; IV. Test Suites\n| &gt;\n| &gt; Test suites are simply tests that contain dependencies that are themselves\n| &gt; tests.  This terminology is just used to make it easier with people\n| &gt; already familiar with unit testing in other contexts.  To execute a single\n| &gt; test suite see the directions above for &#39;Single Tests&#39;.\n| &gt;\n| &gt; V. Viewing Results\n| &gt;\n| &gt; When you run the crawler several log files are created.  These contain\n| &gt; information about what pages were visited by the crawler.  You will want\n| &gt; to locate the file &#39;uri-processing.log&#39; in your ouput directory, which\n| &gt; will be used to determine what succeded and what failed.\n| &gt;\n| &gt; Once you have located this file you have two ways to view the results.\n| &gt;\n| &gt; A. Web-based Interface\n| &gt;\n| &gt; Included in this package is a script called &#39;report.cgi&#39; that will allow\n| &gt; you to upload a log file, which it will then parse, reporting on the tests\n| &gt; seen during your crawl.\n| &gt;\n| &gt; This should be most convienent when your garden is on a remote host and\n| &gt; you don&#39;t want to move log files around manually, or can&#39;t run the\n| &gt; command-line tool locally.\n| &gt;\n| &gt; B. Command-line Interface\n| &gt;\n| &gt; There is also a command-line tool that can be used to parse uri-processing\n| &gt; logs.  This tool is located in the root garden directory (where this\n| &gt; readme is) and is called &#39;testreport.pl&#39;.  It can be used to generate\n| &gt; reports similar to those produced by the web-based interface, which can\n| &gt; either be dumped to standard out, or emailed to a recipient list.\n| &gt;\n| &gt; Usage is as follows:\n| &gt;\n| &gt;   testreport.pl [-mail &lt;mailto list comma-delimited&gt;] &lt;heritrix log file&gt;\n| &gt;\n| &gt; Examples:\n| &gt;   ./testreport.pl uri-processing.log\n| &gt;   ./testreport.pl -mail a@...,b@... uri-processing.log\n| &gt;\n| &gt; VI. Test Configuration Files\n| &gt;\n| &gt; Tests are simply collections of files to be crawled, and a configuration\n| &gt; file that can e used to evaluate the results.  Tests have the following\n| &gt; properties:\n| &gt;\n| &gt; - The top-level test directory must be placed in the garden&#39;s root.\n| &gt;\n| &gt; - All files required by a test are contained within the tests&#39; directory\n| &gt; tree (though this tree may be arbitrarily complex).\n| &gt;\n| &gt; - The top-level directory must be named testXXX where XXX is a positive\n| &gt; integer and is unique within the garden.\n| &gt;\n| &gt; - The top-level test directory must contain a file called test.conf that\n| &gt; defines the tests&#39; properties.\n| &gt;\n| &gt; Test configuration files are defined using a simple key:value pair syntax.\n| &gt; Valid tags are:\n| &gt;\n| &gt; name - human readable name for the test\n| &gt; find - require a uri be found.\n| &gt; omit - require a uri be omitted.\n| &gt; test - require another test as a prerequisite.\n| &gt; info - a comment to be presented in the report.\n| &gt;\n| &gt; All URIs within the configuration file, including tests, are specified as\n| &gt; relative paths.\n| &gt;\n| &gt; A. Best Practices for Defining Tests\n| &gt;\n| &gt; While the &#39;name&#39; tag may contain any human readable string, it is\n| &gt; considered a best practice to prefix the test name with &#39;Test X&#39;, and use\n| &gt; a descriptive name.\n| &gt;\n| &gt; B. Example Configuration File\n| &gt;\n| &gt; name: Test 101\n| &gt; find: subdirectory/hardtofindlink.html\n| &gt; find: anothersub/sneakylink.html\n| &gt; omit: excluded/by/robots/page.html\n| &gt; omit: commented/out/link/page.html\n| &gt; test: ../test5\n| &gt; test: ../test46\n| &gt; test: ../test99\n| &gt; info: Note: Make sure you copied test101/robots.txt to your document root.\n| &gt;\n| &gt; VII. Special Arguments to Test Index (advanced)\n| &gt;\n| &gt; A. Generating Infinite Content\n| &gt;\n| &gt; If you wish to do crawler performance testing you may use the test index\n| &gt; to generate an infinite (more or less) amount of content by calling\n| &gt; index.cgi with the argument &#39;infinite=1&#39;, as in:\n| &gt;\n| &gt;   http://host.org/path/to/test/index/?infinite=1\n| &gt;\n| &gt; This will generate the appropriate links.\n| &gt;\n| &gt; Note:  To have this work the host &#39;host&#39; must have a dns entry that\n| &gt; resolves *.host.org to the host on which the files live, and apache must\n| &gt; be set up with the appropriate VirtualHost entries.\n| &gt;\n| &gt; B. Show Links to Test Requirements/Exclusions\n| &gt;\n| &gt; In general you will not want the test index to provide hyperlinks to a\n| &gt; test&#39;s requirements/omissions, since the crawler should be forced to\n| &gt; &quot;discover them&quot;.  However, if you&#39;d like to view an index with all URIs\n| &gt; hyperlinked for ease of browsing, you may pass the test index the argument\n| &gt; &#39;links=1&#39; as in:\n| &gt;\n| &gt;   http://host.org/path/to/test/index/?links=1\n| &gt;\n| &gt;\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|To unsubscribe from this group, send an email to:\n|archive-crawler-unsubscribe@yahoogroups.com\n|\n| \n|\n|Your use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/ \n|\n|\n\n\n"}}