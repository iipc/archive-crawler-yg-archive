{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"JHG21f5BN9C4lM6h4JbjYVYeI0QC4AVUDY1yaa91Jj1JqrtPJBn56YvB-GIgYVsZhSVPfqejFvDfri-dZJwsKVYtqfqrE_Q","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Re: DNS Lookup","postDate":"1324157273","msgId":7463,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRFRUQwOTU5LjcwNzAwMDNAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGpjaW4zcSs4dDdwQGVHcm91cHMuY29tPg==","referencesHeader":"PGpjaW4zcSs4dDdwQGVHcm91cHMuY29tPg=="},"prevInTopic":7462,"nextInTopic":7465,"prevInTime":7462,"nextInTime":7464,"topicId":7420,"numMessagesInTopic":9,"msgSnippet":"Those settings are fragile with respect to transient web problems - if an URI is unreachable for just (5*5) 25 seconds it will reach final failure state, and","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 65423 invoked from network); 17 Dec 2011 21:27:55 -0000\r\nX-Received: from unknown (98.137.35.161)\n  by m7.grp.sp2.yahoo.com with QMQP; 17 Dec 2011 21:27:55 -0000\r\nX-Received: from unknown (HELO relay00.pair.com) (209.68.5.9)\n  by mta5.grp.sp2.yahoo.com with SMTP; 17 Dec 2011 21:27:55 -0000\r\nX-Received: (qmail 66913 invoked by uid 0); 17 Dec 2011 21:27:53 -0000\r\nX-Received: from 76.218.213.38 (HELO silverbook.local) (76.218.213.38)\n  by relay00.pair.com with SMTP; 17 Dec 2011 21:27:53 -0000\r\nX-pair-Authenticated: 76.218.213.38\r\nMessage-ID: &lt;4EED0959.7070003@...&gt;\r\nDate: Sat, 17 Dec 2011 13:27:53 -0800\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.7; rv:8.0) Gecko/20111105 Thunderbird/8.0\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;jcin3q+8t7p@...&gt;\r\nIn-Reply-To: &lt;jcin3q+8t7p@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Re: DNS Lookup\r\nX-Yahoo-Group-Post: member; u=137285340; y=uFIWtDwNoQBnYykd4DU4iA9cN6nylfGAUqZHFO9pKqYE\r\nX-Yahoo-Profile: gojomo\r\n\r\nThose settings are fragile with respect to transient web problems - if \nan URI is unreachable for just (5*5) 25 seconds it will reach final \nfailure state, and appear in the crawl.log as a failure.\n\nBut, that and the fact the crawl reached real &#39;Finished&#39; status means \nany URIs that were tried should appear in the crawl.log.\n\nIf URIs you expected the crawl to try don&#39;t appear in the crawl.log, \nthey were probably ruled-out by your defined crawl scope.\n\n- Gordon\n\nOn 12/17/11 10:30 AM, thomas.zeithaml wrote:\n&gt; My config is:\n&gt;\n&gt;          &lt;property name=&quot;snoozeLongMs&quot; value=&quot;3000&quot;/&gt;\n&gt;          &lt;property name=&quot;retryDelaySeconds&quot; value=&quot;5&quot;/&gt;\n&gt;          &lt;property name=&quot;maxRetries&quot; value=&quot;5&quot;/&gt;\n&gt;\n&gt; an crawl summary:\n&gt;\n&gt; crawl name: basic\n&gt; crawl status: Finished\n&gt; duration: 6m28s596ms\n&gt;\n&gt; seeds crawled: 1\n&gt; seeds uncrawled: 0\n&gt;\n&gt; hosts visited: 14\n&gt;\n&gt; URIs processed: 466\n&gt; URI successes: 444\n&gt; URI failures: 2\n&gt; URI disregards: 20\n&gt;\n&gt; novel URIs: 0\n&gt;\n&gt; total crawled bytes: 8791790 (8.4 MiB)\n&gt; novel crawled bytes: 8791790 (8.4 MiB)\n&gt;\n&gt; URIs/sec: 1.14\n&gt; KB/sec: 22\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; --- In archive-crawler@yahoogroups.com, Gordon Mohr&lt;gojomo@...&gt;  wrote:\n&gt;&gt;\n&gt;&gt; How long did you wait?\n&gt;&gt;\n&gt;&gt; With the default retryDelay (900 seconds) and maxRetries (30), a single\n&gt;&gt; URI (either a dns:baddddd-hostname.com or then\n&gt;&gt; http://baddddd-hostname.com/) will take 7.5 hours to exhaust all its\n&gt;&gt; retries, and thus show up as a final failure in crawl.log.\n&gt;&gt;\n&gt;&gt; You can set these lower, but only at the risk that transient\n&gt;&gt; network/server issues cause the crawler to give up on URIs that would be\n&gt;&gt; available with just a little more patience. (And, the maxRetries should\n&gt;&gt; always be 3 or more, to accommodate some usual crawler-code practices\n&gt;&gt; that sometimes notice a URI should be deferred until after a\n&gt;&gt; prerequisite is fetched, so trigger using up retries even when there are\n&gt;&gt; no network/server problems.)\n&gt;&gt;\n&gt;&gt; - Gordon\n&gt;&gt;\n&gt;&gt; On 12/17/11 8:27 AM, thomas.zeithaml wrote:\n&gt;&gt;&gt; Hi Noah,\n&gt;&gt;&gt; thanks, but on http://bit.ly/rw6epX i ut some links (in the footer) to some not existing domains.\n&gt;&gt;&gt;\n&gt;&gt;&gt; These links are not listet in hosts.txt or any crawler logs.\n&gt;&gt;&gt; So i think when DNS Lookup fails the job is not working fine.\n&gt;&gt;&gt;\n&gt;&gt;&gt; Maybe you can crawl the domain - and take a look for these domains ?\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; best regards\n&gt;&gt;&gt; Tom\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; --- In archive-crawler@yahoogroups.com, Noah Levitt&lt;nlevitt@&gt;   wrote:\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Hello Tom,\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Enable alsoCheckVia on your (accepting) SurtPrefixedDecideRule.\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;        &lt;!-- ...then ACCEPT those within configured/seed-implied SURT prefixes... --&gt;\n&gt;&gt;&gt;&gt;        &lt;bean class=&quot;org.archive.modules.deciderules.surt.SurtPrefixedDecideRule&quot;&gt;\n&gt;&gt;&gt;&gt;         &lt;property name=&quot;alsoCheckVia&quot; value=&quot;true&quot; /&gt;\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Description of alsoCheckVia from the javadoc: &quot;Whether to also make the configured decision if a URI&#39;s &#39;via&#39; URI (the URI from which it was discovered) in SURT form begins with any of the established prefixes. For example, can be used to ACCEPT URIs that are &#39;one hop off&#39; URIs fitting the SURT prefixes.&quot;\n&gt;&gt;&gt;&gt; https://github.com/internetarchive/heritrix3/blob/master/modules/src/main/java/org/archive/modules/deciderules/surt/SurtPrefixedDecideRule.java\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Noah\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; On 2011-12-15 07:24 , thomas.zeithaml wrote:\n&gt;&gt;&gt;&gt;&gt; Hi Noah,\n&gt;&gt;&gt;&gt;&gt; i want only one step away from my seed.\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt; So:\n&gt;&gt;&gt;&gt;&gt; 1. www.domain-a.com have a link to -&gt;    www.domain-a.com/site-1\n&gt;&gt;&gt;&gt;&gt; 2. www.domain-a.com/site-1 link to -&gt;    www.domain-b.com/site-2 (external)\n&gt;&gt;&gt;&gt;&gt; 3. crawl only www.domain-b.com/site-2 and make a dns check\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt; In some cases i have a dns lookup in hosts.txt. But it seems only when the DNS Lookup not failed.\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt; What did i need for settings ?\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt; best regards\n&gt;&gt;&gt;&gt;&gt; Tom\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt; --- In archive-crawler@yahoogroups.com, Noah Levitt&lt;nlevitt@&gt;    wrote:\n&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt; Hello Tom,\n&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt; Not sure I fully understand what you&#39;re trying to accomplish. Do you\n&gt;&gt;&gt;&gt;&gt;&gt; want to follow all links? In that case, change the initial\n&gt;&gt;&gt;&gt;&gt;&gt; RejectDecideRule in your scope to an AcceptDecideRule. Do you want to\n&gt;&gt;&gt;&gt;&gt;&gt; crawl links one hop off from the initial sites? Then you may want to try\n&gt;&gt;&gt;&gt;&gt;&gt; alsoCheckVia. Or are you trying to do something more complicated, like\n&gt;&gt;&gt;&gt;&gt;&gt; dns lookups for all offsite links, even if the links themselves are not\n&gt;&gt;&gt;&gt;&gt;&gt; crawled? In that case you might need to write a custom extractor and\n&gt;&gt;&gt;&gt;&gt;&gt; perhaps custom scope rules as well.\n&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt; Noah\n&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt; On 12/06/2011 06:57 AM, thomas.zeithaml wrote:\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; Hello,\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; i want to crawl a domain with some external links.\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; All external links are reported in the WARC Files.\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; But some of these links don&#39;t get listet in the hosts.txt.\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; There is also no DNS Lookup for these links\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; Config:\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; &lt;ref bean=&quot;fetchDns&quot;/&gt;     is set\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;         &lt;bean id=&quot;fetchDns&quot; class=&quot;org.archive.modules.fetcher.FetchDNS&quot;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;             &lt;property name=&quot;acceptNonDnsResolves&quot; value=&quot;true&quot; /&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;             &lt;property name=&quot;digestContent&quot; value=&quot;false&quot; /&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;             &lt;property name=&quot;digestAlgorithm&quot; value=&quot;sha1&quot; /&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;         &lt;/bean&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; and also:\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; alsoCheckVia = true\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; Did somebody have some hints ?\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; best regards\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; Tom\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; ------------------------------------\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; Yahoo! Groups Links\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt; ------------------------------------\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt; Yahoo! Groups Links\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; ------------------------------------\n&gt;&gt;&gt;\n&gt;&gt;&gt; Yahoo! Groups Links\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------\n&gt;\n&gt; Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n\n"}}