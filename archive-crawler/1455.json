{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":210551673,"authorName":"John R. Frank","from":"&quot;John R. Frank&quot; &lt;jrf@...&gt;","profile":"tamarind473","replyTo":"LIST","senderId":"g4ZuvMkFm-NyiFELinjRXmLabLGsVa1s7uwx2jIJ8VIEt0xc2rQLdKUxnXgxBQ5STO3wCUQiOUxZscd2m238RzyKds4","spamInfo":{"isSpam":false,"reason":"0"},"subject":"RE: [archive-crawler] continuous crawling proposal","postDate":"1107270642","msgId":1455,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PFBpbmUuTE5YLjQuNTYuMDUwMjAxMTAwNjMzMC4xNTY2NUBwaWtlc3BlYWsubWV0YWNhcnRhLmNvbT4=","inReplyToHeader":"PDA2NzhEQjE5NjhFQUM3NDA5Q0MzRDBBQjdBMTFCODRBMDZFQzQwQHNrYXJmdXIuYm9rLmxvY2FsPg==","referencesHeader":"PDA2NzhEQjE5NjhFQUM3NDA5Q0MzRDBBQjdBMTFCODRBMDZFQzQwQHNrYXJmdXIuYm9rLmxvY2FsPg=="},"prevInTopic":1454,"nextInTopic":1456,"prevInTime":1454,"nextInTime":1456,"topicId":1452,"numMessagesInTopic":24,"msgSnippet":"Kris, I was aware of your AR module and should have asked a couple questions about it in that earlier post.  The algorithm I suggested could be written as a","rawEmail":"Return-Path: &lt;jrf@...&gt;\r\nX-Sender: jrf@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 61155 invoked from network); 1 Feb 2005 15:10:44 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m3.grp.scd.yahoo.com with QMQP; 1 Feb 2005 15:10:44 -0000\r\nReceived: from unknown (HELO pikespeak.metacarta.com) (66.92.95.164)\n  by mta6.grp.scd.yahoo.com with SMTP; 1 Feb 2005 15:10:43 -0000\r\nReceived: from jrf (helo=localhost)\n\tby pikespeak.metacarta.com with local-esmtp (Exim 3.35 #1 (Debian))\n\tid 1Cvzfu-00045P-00\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Tue, 01 Feb 2005 10:10:42 -0500\r\nDate: Tue, 1 Feb 2005 10:10:42 -0500 (EST)\r\nX-X-Sender: jrf@...\r\nTo: archive-crawler@yahoogroups.com\r\nIn-Reply-To: &lt;0678DB1968EAC7409CC3D0AB7A11B84A06EC40@...&gt;\r\nMessage-ID: &lt;Pine.LNX.4.56.0502011006330.15665@...&gt;\r\nReferences: &lt;0678DB1968EAC7409CC3D0AB7A11B84A06EC40@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: TEXT/PLAIN; charset=iso-8859-1\r\nContent-Transfer-Encoding: QUOTED-PRINTABLE\r\nSender:  &lt;jrf@...&gt;\r\nX-eGroups-Remote-IP: 66.92.95.164\r\nFrom: &quot;John R. Frank&quot; &lt;jrf@...&gt;\r\nSubject: RE: [archive-crawler] continuous crawling proposal\r\nX-Yahoo-Group-Post: member; u=210551673\r\nX-Yahoo-Profile: tamarind473\r\n\r\nKris,\n\nI was aware of your AR module and should have asked a couple questio=\r\nns\nabout it in that earlier post.  The algorithm I suggested could be writt=\r\nen\nas a subclass to your WaitEvaluator.\n\nThe big issue with AR is:  why is =\r\na new Frontier required for this?  The\nBDB-based Frontier solves (or will s=\r\noon solve :) several scalability\nissues that our crucial for production use=\r\n of Heritrix (at least IMHO).\n\nAs far as I can see, the only requirement of=\r\n the Frontier is logic to\nprevent dequeuing before the time determined by t=\r\nhe WaitEvaluator.  Is\nthis true?  Or did I miss something?\n\nI&#39;ll keep you p=\r\nosted on content hashing.\n\nJohn\n\n\n\nOn Tue, 1 Feb 2005, Kristinn Sigurdsson =\r\nwrote:\n\n&gt; Yes, the AR module (currently available as a branch of the Heritr=\r\nix project,\n&gt; http://crawltools.archive.org:8080/cruisecontrol/buildresults=\r\n/BRANCH-heritri\n&gt; x-Kris-ARbranch2) provides the functionality required for=\r\n incrimental\n&gt; crawling.\n&gt;\n&gt; To do this it implements a new Frontier that u=\r\nses priority queues for the\n&gt; URIs (this also does away with the &#39;already i=\r\nncluded fingerprints of URIs).\n&gt;\n&gt; A processor (dubbed a WaitEvaluator) is =\r\ninserted to calculate the &#39;time of\n&gt; next processing&#39; before a URI is retur=\r\nned to the Frontier. Currently the\n&gt; WaitEvaluator uses a much simpler algo=\r\nrithm than John discusses, but a more\n&gt; sophisticated one could easily repl=\r\nace it.\n&gt;\n&gt; Currently it relies on a strict hash for content changes (altho=\r\nugh a\n&gt; processor for prestripping problematic sections using regular expre=\r\nssions is\n&gt; provided). If you have ideas for better content hashes, I&#39;d lov=\r\ne to hear\n&gt; them.\n&gt;\n&gt; Currently this add on to Heritrix is being tested, if=\r\n all goes well it will\n&gt; become a part of of the next Heritrix release.\n&gt;\n&gt;=\r\n - Kris\n&gt;\n&gt; -----Original Message-----\n&gt; From: Bjarne Andersen [mailto:bja@=\r\nstatsbiblioteket.dk]\n&gt; Sent: 1. febr=FAar 2005 08:53\n&gt; To: archive-crawler@=\r\nyahoogroups.com\n&gt; Subject: Re: [archive-crawler] continuous crawling propos=\r\nal\n&gt;\n&gt;\n&gt; You might want to take a look at the Automated Revisiting Module b=\r\neing\n&gt; developed at the moment by kris@...\n&gt;\n&gt; It does implement a =\r\nnew Frontier including a new Queing-mechanism along\n&gt; with a simple algorit=\r\nm to decide when to bring URI&#39;s to the top of the\n&gt; queue (based on histori=\r\ncal results - next-ready-time goes either up or\n&gt; down everytime a page is =\r\nfetched and compared to the last fetch)\n&gt;\n&gt; It is available from the contin=\r\nous build box at crawler.archive.org (a\n&gt; CVS-brach called *_AR....)\n&gt;\n&gt; be=\r\nst\n&gt; Bjarne Andersen\n&gt;\n&gt; John R. Frank wrote:\n&gt; &gt; Stack,\n&gt; &gt;\n&gt; &gt; What do yo=\r\nu think of these three steps as a possible way to implement\n&gt; &gt; continuous =\r\ncrawling in Heritrix?  Details for each of these three are\n&gt; &gt; discussed be=\r\nlow.\n&gt; &gt;\n&gt; &gt; 1) extend the work queue&#39;s logic to only dequeue &quot;ready&quot; URLs\n=\r\n&gt; &gt;\n&gt; &gt; 2) decide when to recheck a given page based on a simple model\n&gt; &gt;\n=\r\n&gt; &gt; 3) detect substantive page changes and store the info in AlreadySeen\n&gt; =\r\n&gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; 1) To do this, we need a queueing mechanism that blocks the d=\r\nequeuing of a\n&gt; &gt; CrawlURI until we are past its assigned next &quot;okay to cra=\r\nwl&quot; moment.\n&gt; &gt; Where should we store this timestamp?  As you said, the BDB=\r\n keys are\n&gt; &gt; overloaded with too much meaning already, so putting a second=\r\ns since the\n&gt; &gt; epoch in there is not so good:\n&gt; &gt;\n&gt; http://crawler.archive=\r\n.org/xref/org/archive/crawler/frontier/BdbMultipleWork\n&gt; Queues.html#246\n&gt; =\r\n&gt;\n&gt; &gt; Perhaps this timestamp belongs in CandidateURI where the\n&gt; &gt; scheduli=\r\nngDirective pieces are?  For example, if the schedulingDirective\n&gt; &gt; is neg=\r\native, then it could be interpreted as a timestamp.  So for a\n&gt; &gt; document =\r\nnext Wednesday, it would get:\n&gt; &gt;\n&gt; &gt; jrf@localhost~$ date +%s -d &quot;Feb 9 01=\r\n:20:29 EST 2005&quot;\n&gt; &gt; 1107930029\n&gt; &gt;\n&gt; &gt; with a minus sign in front:  -11079=\r\n30029\n&gt; &gt;\n&gt; &gt; Adding `date +%s -d now` now to that will give a positive num=\r\nber when it\n&gt; &gt; is okay to crawl.  This would require modifications to the =\r\nfour-bit\n&gt; &gt; interpretation of priority in the BDB key computation.  An esc=\r\nape value\n&gt; &gt; of 1111 might tell the queue that it needs to look in the obj=\r\nect to find\n&gt; &gt; the value of the timestamp.\n&gt; &gt;\n&gt; &gt; The problem with this i=\r\ns that suddenly the queue is not a queue, because\n&gt; &gt; the keys are the sort=\r\ning mechanism on the queue in the BDB implementation,\n&gt; &gt; right?  Do you se=\r\ne a way fix to this besides cycling through all the curi\n&gt; &gt; with 1111 look=\r\ning at the full value of the timestamp?\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; 2) To compute the t=\r\nime at which to refetch, we can predict the likelihood\n&gt; &gt; that the page ha=\r\ns been modified as a function of time since last modified.\n&gt; &gt; See below fo=\r\nr discussion of detecting last modified.  An easy function to\n&gt; &gt; use for t=\r\nhis modeling comes from the Michaelis-Menton model of enzyme\n&gt; &gt; kinetics:\n=\r\n&gt; &gt;\n&gt; &gt;       t is time elapsed after a modification of the content\n&gt; &gt;\n&gt; &gt;=\r\n       P(t) is the probability that the page has changed by time t\n&gt; &gt;\n&gt; &gt; =\r\n                         a\n&gt; &gt;                       k t\n&gt; &gt;              P=\r\n(t) =3D  ---------------\n&gt; &gt;                            a\n&gt; &gt;              =\r\n      1  + k t\n&gt; &gt;\n&gt; &gt; At small t, P is small.  At large t, P tends to 1, i=\r\n.e. certainty of\n&gt; &gt; change.  It is easiest to choose a=3D2, which is the s=\r\nmallest integer value\n&gt; &gt; that gives step-like behavior.  We can then set k=\r\n by fitting this function\n&gt; &gt; to any given page&#39;s history (details below).\n=\r\n&gt; &gt;\n&gt; &gt; Given k, we can use P(t) to predict when to refetch a document.  We=\r\n pick a\n&gt; &gt; threshold probability above which we want to refetch.  If we se=\r\nt it low,\n&gt; &gt; then we want to recheck more often.  If we set it high, that =\r\nmeans we&#39;re\n&gt; &gt; willing to tolerate more stale content in order to not rech=\r\neck as often.\n&gt; &gt;\n&gt; &gt; When P(t) exceeds the chosen threshold, then we want =\r\nto recheck it.  By\n&gt; &gt; inverting the probability function, this threshold g=\r\nives us a time to\n&gt; &gt; wait before rechecking the page:\n&gt; &gt;\n&gt; &gt;             =\r\n     k                (-1/a)\n&gt; &gt;        t =3D ( ----------   -   k )\n&gt; &gt;   =\r\n           threshold\n&gt; &gt;\n&gt; &gt;    For clarity that is:\n&gt; &gt;    t =3D (((k / th=\r\nreshold) - k ) ^ (-1/a))\n&gt; &gt;\n&gt; &gt; t is the time interval between the most re=\r\ncent known modification event\n&gt; &gt; and that time in the future when the expe=\r\ncted probability of change is\n&gt; &gt; just above threshold.  For robustness, we=\r\n should define a time within\n&gt; &gt; which all pages must be rechecked.  In pyt=\r\nhon, the function might look\n&gt; &gt; like:\n&gt; &gt;\n&gt; &gt; def delay(k, threshold):\n&gt; &gt;=\r\n     Days =3D 60 * 60 * 24\n&gt; &gt;     maxRecheckDelay =3D 20 * Days\n&gt; &gt;     th=\r\nresholdDelay =3D (((k / threshold) - k ) ^ (-1/alpha))\n&gt; &gt;     return minim=\r\num(maxRecheckDelay, thresholdDelay)\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; 3. Since last-modified info=\r\nrmation is not universally provided by document\n&gt; &gt; repositories, we need a=\r\n mechanism to detect substantive content changes\n&gt; &gt; and record them in the=\r\n BDB.  I&#39;m looking into tools for this kind of\n&gt; &gt; content hashing that cou=\r\nld be run in the extractor chain and stored in the\n&gt; &gt; object that gets int=\r\no BDB.\n&gt; &gt;\n&gt; &gt; Suppose we have such a content hash, then the interval of ti=\r\nme between two\n&gt; &gt; known modification events is an upper bound because ther=\r\ne could have been\n&gt; &gt; a modification event that we did not observe between =\r\nthese observed\n&gt; &gt; events.  If these upper bounds are not far off the real =\r\nvalue, then we can\n&gt; &gt; accurately approximate the probability of modificati=\r\non at half the\n&gt; &gt; observed interval as being 50%.  That is, we use the pre=\r\nviously observed\n&gt; &gt; modification intervals to estimate what the next actua=\r\nl interval will be.\n&gt; &gt; If the average of the last, say, five observed inte=\r\nrvals is T, then we\n&gt; &gt; estimate that at (T/2) in the future, the probabili=\r\nty of modification will\n&gt; &gt; be 50%.  This let&#39;s us estimate a value for k b=\r\nased on previously observed\n&gt; &gt; modification intervals:\n&gt; &gt;\n&gt; &gt;            =\r\n    -a\n&gt; &gt;        k =3D (T/2)    which for a=3D2 is (two over T) squared.\n&gt;=\r\n &gt;\n&gt; &gt;\n&gt; &gt; Some logic is required to make sure that only the last few, say =\r\nfive,\n&gt; &gt; meaningful modification intervals are averaged to make T.  This m=\r\noving\n&gt; &gt; window average allows Heritrix to more rapidly adapt to pages tha=\r\nt have\n&gt; &gt; varying update frequencies, which is most pages.\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; Tho=\r\nughts?  Reactions?\n&gt; &gt;\n&gt; &gt; John\n\n"}}