{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"stack","from":"stack &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"UNWTzj526s0qg3ZowLFGmN2THtTgvLR0OQ0hFJgg9iYOEwrcybBMn1SBsQHDqsN7TWgzGwbq_ZnYv_CCjeQ03g","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Links Structure","postDate":"1104892087","msgId":1320,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQxREI1MEI3LjkwNzA4MDhAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDIwMDUwMTA0MTM1OTU1Ljk3NjcwLnFtYWlsQHdlYjYwNTAxLm1haWwueWFob28uY29tPg==","referencesHeader":"PDIwMDUwMTA0MTM1OTU1Ljk3NjcwLnFtYWlsQHdlYjYwNTAxLm1haWwueWFob28uY29tPg=="},"prevInTopic":1319,"nextInTopic":1321,"prevInTime":1319,"nextInTime":1321,"topicId":1319,"numMessagesInTopic":9,"msgSnippet":"... We don t have publically-available tools currently that will allow you to extract document links post crawl.  We have to add them. We currently use","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 23091 invoked from network); 5 Jan 2005 02:35:31 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m8.grp.scd.yahoo.com with QMQP; 5 Jan 2005 02:35:31 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (207.241.224.172)\n  by mta4.grp.scd.yahoo.com with SMTP; 5 Jan 2005 02:35:31 -0000\r\nReceived: (qmail 20386 invoked by uid 100); 5 Jan 2005 02:20:51 -0000\r\nReceived: from debord.archive.org (HELO ?207.241.238.140?) (stack@...@207.241.238.140)\n  by mail-dev.archive.org with SMTP; 5 Jan 2005 02:20:51 -0000\r\nMessage-ID: &lt;41DB50B7.9070808@...&gt;\r\nDate: Tue, 04 Jan 2005 18:28:07 -0800\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.7.3) Gecko/20041007 Debian/1.7.3-5\r\nX-Accept-Language: en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;20050104135955.97670.qmail@...&gt;\r\nIn-Reply-To: &lt;20050104135955.97670.qmail@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=0.8 required=6.5 tests=AWL autolearn=no version=2.63\r\nX-eGroups-Remote-IP: 207.241.224.172\r\nFrom: stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] Links Structure\r\nX-Yahoo-Group-Post: member; u=168599281\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\nNiti Witthayawiroj wrote:\n\n&gt; Hallo All,\n&gt;\n&gt; I used Heritrix to crawl some hosts and my crawl job\n&gt; is finished. I would like to get the links structure\n&gt; of pages that are carwled. Can you tell me about the\n&gt; format of the links structure and How i can get it.\n&gt;\n&gt; For example: the format of links structure(or other\n&gt; format, may be links with pageId)\n&gt;\n&gt; from http://a.com/a.html\n&gt; to http://a.com/b.html\n&gt; to http://a.com/c.html\n&gt;\n&gt; from http://a.com/b.html\n&gt; to http://a.com/a.html\n&gt; to http://a.com/c.html\n&gt; ...\n\nWe don&#39;t have publically-available tools currently that will allow you \nto extract document links post crawl.  We have to add them. We currently \nuse proprietary tools here at the Archive for doing this but intend to \nmove off them with time. \n\nWe have various ideas for how to implement the link extraction tools -- \nusually based off some rerunning of the Heritrix extractors against the \ndownloaded ARCs -- but we just haven&#39;t gotten around to it yet.  There&#39;s \nalso a feature request to drop links found in a page as we crawl.\n\nThe crawl.log will list how a page was discovered.\n\nSt.Ack\n\n\n&gt;\n&gt; Thank so much\n&gt; Niti\n&gt;\n&gt;\n&gt;            \n&gt; __________________________________\n&gt; Do you Yahoo!?\n&gt; The all-new My Yahoo! - What will yours do?\n&gt; http://my.yahoo.com\n&gt;\n&gt; ------------------------------------------------------------------------\n&gt; *Yahoo! Groups Links*\n&gt;\n&gt;     * To visit your group on the web, go to:\n&gt;       http://groups.yahoo.com/group/archive-crawler/\n&gt;        \n&gt;     * To unsubscribe from this group, send an email to:\n&gt;       archive-crawler-unsubscribe@yahoogroups.com\n&gt;       &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;        \n&gt;     * Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;.\n&gt;\n&gt;\n\n\n"}}