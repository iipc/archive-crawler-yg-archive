{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"0IuK4igDCAbb_S-dGxt91tSCWFuUGVVXGBkdotypcnnm0jjMoVCCiVjAWzZd4PV7eTsdAxPDyfpu7JgJwVBiwuE7HURR17o","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] java.io.IOException: mark/reset not supported","postDate":"1174616990","msgId":3945,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ2MDMzQjlFLjQwMjAxMDRAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PFBpbmUuV05ULjQuNjQuMDcwMzIyMTU0ODI2MC45MDBAY2l0cml4My5wdWJsaWMuaHUtYmVybGluLmRlPg==","referencesHeader":"PGV0cDVwYys0a2F1QGVHcm91cHMuY29tPiA8NDYwMTYzMzMuODA2MDIwMUBhcmNoaXZlLm9yZz4gPFBpbmUuV05ULjQuNjQuMDcwMzIyMTU0ODI2MC45MDBAY2l0cml4My5wdWJsaWMuaHUtYmVybGluLmRlPg=="},"prevInTopic":3943,"nextInTopic":4007,"prevInTime":3944,"nextInTime":3946,"topicId":3933,"numMessagesInTopic":6,"msgSnippet":"Bert - My failure to reproduce the problem was due to another request header I still had set from other testing. (Apparently, the Bad Behavior extension","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 68255 invoked from network); 23 Mar 2007 02:28:34 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m41a.grp.scd.yahoo.com with QMQP; 23 Mar 2007 02:28:34 -0000\r\nReceived: from unknown (HELO mail.archive.org) (207.241.233.246)\n  by mta6.grp.scd.yahoo.com with SMTP; 23 Mar 2007 02:28:33 -0000\r\nReceived: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id C3DDF141BC298\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Thu, 22 Mar 2007 19:28:02 -0700 (PDT)\r\nReceived: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id 12084-01-77 for &lt;archive-crawler@yahoogroups.com&gt;;\n\tThu, 22 Mar 2007 19:28:01 -0700 (PDT)\r\nReceived: from [192.168.1.203] (c-76-102-230-150.hsd1.ca.comcast.net [76.102.230.150])\n\tby mail.archive.org (Postfix) with ESMTP id 478E6141BC278\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Thu, 22 Mar 2007 19:28:01 -0700 (PDT)\r\nMessage-ID: &lt;46033B9E.4020104@...&gt;\r\nDate: Thu, 22 Mar 2007 19:29:50 -0700\r\nUser-Agent: Thunderbird 1.5.0.9 (X11/20070104)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;etp5pc+4kau@...&gt; &lt;46016333.8060201@...&gt; &lt;Pine.WNT.4.64.0703221548260.900@...-berlin.de&gt;\r\nIn-Reply-To: &lt;Pine.WNT.4.64.0703221548260.900@...-berlin.de&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Virus-Scanned: Debian amavisd-new at archive.org\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] java.io.IOException: mark/reset not supported\r\nX-Yahoo-Group-Post: member; u=137285340; y=5IIhG0IvQDhtgFJ0nHHXU9NDIOUMtmo8jhkLopRriSZo\r\nX-Yahoo-Profile: gojomo\r\n\r\nBert -\n\nMy failure to reproduce the problem was due to another request header I \nstill had set from other testing. (Apparently, the &#39;Bad Behavior&#39; \nextension looks very unfavorably on the &#39;Range&#39; header.) This led me to \nmake a wrong assumption about the cause of the problem being some other \naspect of &#39;Bad Behavior&#39; countermeasures.\n\nI&#39;ve now been able to reproduce the problem, and it seems related to the \nserver&#39;s use of a &#39;Transfer-Encoding&#39; of type &#39;chunked&#39;, as defined in \nHTTP/1.1.\n\nHeritrix has previously chosen not to support this encoding, because it \ncomplicates later access operations (such as Wayback replay), and had in \nour experience been nonessential: a server which receives an HTTP/1.0 \nrequest (like Heritrix generates) should refrain from using this encoding.\n\n(See &lt;http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html#sec3.6&gt;, \nwhich says: &quot;A server MUST NOT send transfer-codings to an HTTP/1.0 \nclient.&quot;)\n\nAs a result, when Heritrix receives the unexpected (and technically \nillegal) chunked transfer-encoding, a code path through the HTTP client \nlibrary previously untested triggers the error you see, because for this \ntransfer-encoding the HTTP client library is expecting more from our \nrecording-IO classes than is implemented.\n\nEven though the server in this case is violating the spec, we of course \nwant to be able to harvest anything that&#39;s viewable in popular browsers, \nso this is considered a bug. I&#39;ve created an issue at:\n\nhttp://webteam.archive.org/jira/browse/HER-1109\n\nI think I see an easy fix, which works in my limited testing and has \nbeen committed to Heritrix SVN for wider testing. With a few days \ntesting, we could slot this (along with a number of other fixes) for an \n  1.12.1 bugfix release in the next week or two.\n\n(Though we have no plans to do an official 1.10.3 bugfix release, the \nfix should also work if applied to 1.10.2 source code -- if for any \nreason you need a quick fix in older software.)\n\nI&#39;ll post an update of the fix status after it receives more testing.\n\n- Gordon @ IA\n\nBert Wendland wrote:\n&gt; Thank you, Gordon,\n&gt; \n&gt; That&#39;s really strange: I made several tests and I did not get at all this \n&gt; 400 Bad Behavior. On the contrary, I always received a proper robots.txt \n&gt; (sorry - I did not mention this in my first posting):\n&gt; \n&gt; =====================================================================\n&gt; http://presse.parti-socialiste.fr/robots.txt 195.20.198.84 20070320155645 \n&gt; text/html 292\n&gt; HTTP/1.1 200 OK\n&gt; Date: Tue, 20 Mar 2007 15:56:45 GMT\n&gt; Server: Apache\n&gt; Set-Cookie: bb2_screener_=1174406205+141.20.5.196; path=/\n&gt; X-Pingback: http://presse.parti-socialiste.fr/xmlrpc.php\n&gt; Content-Length: 24\n&gt; Connection: close\n&gt; Content-Type: text/html; charset=UTF-8\n&gt; \n&gt; User-agent: *\n&gt; Disallow:\n&gt; =====================================================================\n&gt; \n&gt; The IOException occured (and still occurs) when the crawler was fetching \n&gt; the root page. Your hint concerning IP ranges gave me the idea to repeat \n&gt; the test using a proxy in the US (69.88.144.161). The result did not \n&gt; change.\n&gt; \n&gt; If you would like to do further testing at your site, here are some other \n&gt; hosts of that domain which cause this error (the only exception is the \n&gt; &quot;mother&quot; of all, www.parti-socialiste.fr, which is still crawlable):\n&gt; \n&gt; agriculture.parti-socialiste.fr\n&gt; cesc.parti-socialiste.fr\n&gt; culture.parti-socialiste.fr\n&gt; discours.parti-socialiste.fr\n&gt; egalite.parti-socialiste.fr\n&gt; entreprises.parti-socialiste.fr\n&gt; environnement.parti-socialiste.fr\n&gt; fonctionnement.parti-socialiste.fr\n&gt; formation.parti-socialiste.fr\n&gt; hebdo.parti-socialiste.fr\n&gt; histoire.parti-socialiste.fr\n&gt; industrie.parti-socialiste.fr\n&gt; libertes.parti-socialiste.fr\n&gt; militant.parti-socialiste.fr\n&gt; presse.parti-socialiste.fr\n&gt; projet.parti-socialiste.fr\n&gt; securite.parti-socialiste.fr\n&gt; servicespublics.parti-socialiste.fr\n&gt; sntic.parti-socialiste.fr\n&gt; \n&gt; Less important for us, however, but also causing IOExceptions:\n&gt; \n&gt; www.pierrebedier.net\n&gt; www.djtonio.fr\n&gt; \n&gt; Can you send me, please, your order.xml that you used for your test?\n&gt; \n&gt; Best regards,\n&gt;    Bert\n&gt; \n&gt; \n&gt; \n&gt; On Wed, 21 Mar 2007, 12:07, Gordon Mohr wrote:\n&gt; \n&gt;&gt; Bert Wendland wrote:\n&gt;&gt;&gt; Hello everybody,\n&gt;&gt;&gt;\n&gt;&gt;&gt; We are getting more and more difficulties to crawl particular hosts of\n&gt;&gt;&gt; the domain parti-socialiste.fr. After getting the host&#39;s DNS, the\n&gt;&gt;&gt; crawler blocks with &quot;IOException: mark/reset not supported&quot; (see\n&gt;&gt;&gt; below). The error is the same with 1.10.1 and 1.12.0., jre is\n&gt;&gt;&gt; 1.5.0_06-b05.\n&gt;&gt;&gt;\n&gt;&gt;&gt; The problem began to occur a few days ago. So I guess they changed\n&gt;&gt;&gt; something on their servers that Heritrix cannot handle anymore. What\n&gt;&gt;&gt; can I do?\n&gt;&gt; I think there are several issues here.\n&gt;&gt;\n&gt;&gt; When I try to crawl the site, I don&#39;t get your error but I do get (for\n&gt;&gt; both robots and the root page):\n&gt;&gt;\n&gt;&gt; =====================================================================\n&gt;&gt; http://presse.parti-socialiste.fr/robots.txt 195.20.198.84\n&gt;&gt; 20070321161951 text/html 1065\n&gt;&gt; HTTP/1.1 400 Bad Behavior\n&gt;&gt; Date: Wed, 21 Mar 2007 16:18:04 GMT\n&gt;&gt; Server: Apache\n&gt;&gt; Status: 400 Bad Behavior\n&gt;&gt; Content-Length: 892\n&gt;&gt; Connection: close\n&gt;&gt; Content-Type: text/html\n&gt;&gt;\n&gt;&gt; &lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot;\n&gt;&gt; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd&quot;&gt;\n&gt;&gt; &lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt;\n&gt;&gt; &lt;head&gt;\n&gt;&gt; &lt;title&gt;HTTP Error 400&lt;/title&gt;\n&gt;&gt; &lt;/head&gt;\n&gt;&gt; &lt;body&gt;\n&gt;&gt; &lt;h1&gt;Error 400&lt;/h1&gt;\n&gt;&gt; &lt;p&gt;We&#39;re sorry, but we could not fulfill your request for\n&gt;&gt; /robots.txt on this server.&lt;/p&gt;\n&gt;&gt; &lt;p&gt;The automated program you are using is not permitted to access this\n&gt;&gt; server. Please use a different program or a standard Web browser.&lt;/p&gt;\n&gt;&gt; &lt;p&gt;Your technical support key is: &lt;strong&gt;43b4-cbd4-7ad0-4a8a&lt;/strong&gt;&lt;/p&gt;\n&gt;&gt; &lt;p&gt;You can use this key to &lt;a\n&gt;&gt; href=&quot;http://www.ioerror.us/bb2-support-key?key=43b4-cbd4-7ad0-4a8a&quot;&gt;fix\n&gt;&gt; this problem yourself&lt;/a&gt;.&lt;/p&gt;\n&gt;&gt; &lt;p&gt;If you are unable to fix the problem yourself, please contact &lt;a\n&gt;&gt; href=&quot;mailto:julien.bezille+nospam@...&quot;&gt;julien.bezille at\n&gt;&gt; free.fr&lt;/a&gt; and be sure to provide the technical support key shown\n&gt;&gt; above.&lt;/p&gt;\n&gt;&gt; =====================================================================\n&gt;&gt;\n&gt;&gt; They appear to be using a PHP plug-in called &#39;Bad Behavior&#39; which aims\n&gt;&gt; to detect and block misbehaving robots.\n&gt;&gt;\n&gt;&gt; That I received the above error on my first try, even while respecting\n&gt;&gt; robots, indicates that the plug-in may have a built-in configuration\n&gt;&gt; against the &#39;heritrix&#39; user-agent.\n&gt;&gt;\n&gt;&gt; Your error may be the result of an even-more strict countermeasure they\n&gt;&gt; are taking against your user-agent or IP ranges, based on either a\n&gt;&gt; perception that you are not following robots or over-crawling their site.\n&gt;&gt;\n&gt;&gt; So, I believe the shortest route to resolving this problem will be to\n&gt;&gt; take it up with the site webmaster.\n&gt;&gt;\n&gt;&gt; The form of the error you are receiving is strange to me; the\n&gt;&gt; InputStream inside our HttpConnection should support mark/reset. So it\n&gt;&gt; is possible that their countermeasure is exercising a code path in\n&gt;&gt; Heritrix with a heretofore unknown bug. (Perhaps a retry triggered by\n&gt;&gt; their actions is skipping our usual wrapping.)\n&gt;&gt;\n&gt;&gt; I will create an issue and continue to investigating this error stack,\n&gt;&gt; but given the message I received I believe even if this stack is\n&gt;&gt; resolved, you will have trouble crawling this site unless the webmaster\n&gt;&gt; adjusts their countermeasures.\n&gt;&gt;\n&gt;&gt; Hope this helps,\n&gt;&gt;\n&gt;&gt; - Gordon @ IA\n&gt;&gt;\n&gt;&gt;&gt; Thanks for help,\n&gt;&gt;&gt;   Bert\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; 2007-03-20T13:18:13.388Z    -2          1\n&gt;&gt;&gt; http://presse.parti-socialiste.fr/ - - text/html #040 - - -\n&gt;&gt;&gt; le:IOException@HTTP\n&gt;&gt;&gt;  java.io.IOException: mark/reset not supported\n&gt;&gt;&gt; \tat java.io.InputStream.reset(Unknown Source)\n&gt;&gt;&gt; \tat\n&gt;&gt;&gt; org.apache.commons.httpclient.HttpConnection.isResponseAvailable(HttpConnection.java:933)\n&gt;&gt;&gt; \tat\n&gt;&gt;&gt; org.apache.commons.httpclient.HttpMethodBase.readResponseBody(HttpMethodBase.java:1717)\n&gt;&gt;&gt; \tat\n&gt;&gt;&gt; org.apache.commons.httpclient.HttpMethodBase.readResponseBody(HttpMethodBase.java:1660)\n&gt;&gt;&gt; \tat\n&gt;&gt;&gt; org.archive.httpclient.HttpRecorderGetMethod.readResponseBody(HttpRecorderGetMethod.java:99)\n&gt;&gt;&gt; \tat\n&gt;&gt;&gt; org.archive.crawler.fetcher.FetchHTTP$2.readResponseBody(FetchHTTP.java:441)\n&gt;&gt;&gt; \tat\n&gt;&gt;&gt; org.apache.commons.httpclient.HttpMethodBase.readResponse(HttpMethodBase.java:1623)\n&gt;&gt;&gt; \tat\n&gt;&gt;&gt; org.apache.commons.httpclient.HttpMethodBase.execute(HttpMethodBase.java:1000)\n&gt;&gt;&gt; \tat\n&gt;&gt;&gt; org.archive.httpclient.HttpRecorderGetMethod.execute(HttpRecorderGetMethod.java:117)\n&gt;&gt;&gt; \tat\n&gt;&gt;&gt; org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:397)\n&gt;&gt;&gt; \tat\n&gt;&gt;&gt; org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:170)\n&gt;&gt;&gt; \tat\n&gt;&gt;&gt; org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:396)\n&gt;&gt;&gt; \tat\n&gt;&gt;&gt; org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:346)\n&gt;&gt;&gt; \tat org.archive.crawler.fetcher.FetchHTTP.innerProcess(FetchHTTP.java:458)\n&gt;&gt;&gt; \tat org.archive.crawler.framework.Processor.process(Processor.java:103)\n&gt;&gt;&gt; \tat\n&gt;&gt;&gt; org.archive.crawler.framework.ToeThread.processCrawlUri(ToeThread.java:304)\n&gt;&gt;&gt; \tat org.archive.crawler.framework.ToeThread.run(ToeThread.java:153)\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; Yahoo! Groups Links\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;\n&gt; \n&gt; \n&gt;  \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n\n"}}