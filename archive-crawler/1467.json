{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":210551673,"authorName":"John R. Frank","from":"&quot;John R. Frank&quot; &lt;jrf@...&gt;","profile":"tamarind473","replyTo":"LIST","senderId":"1FY5cYq64MmD9JXm0MsZpcognkaW-CHIJ1NcMQTcOouEGdqRPJkOir2sa4oD5m2hibXL6ppYkQ2wlhTCHn9kr7eZhwA","spamInfo":{"isSpam":false,"reason":"0"},"subject":"RE: [archive-crawler] continuous crawling proposal","postDate":"1107306753","msgId":1467,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PFBpbmUuTE5YLjQuNTYuMDUwMjAxMTk0NTQ0MC4xODA1MUBwaWtlc3BlYWsubWV0YWNhcnRhLmNvbT4=","inReplyToHeader":"PDA2NzhEQjE5NjhFQUM3NDA5Q0MzRDBBQjdBMTFCODRBMDZFQzQ3QHNrYXJmdXIuYm9rLmxvY2FsPg==","referencesHeader":"PDA2NzhEQjE5NjhFQUM3NDA5Q0MzRDBBQjdBMTFCODRBMDZFQzQ3QHNrYXJmdXIuYm9rLmxvY2FsPg=="},"prevInTopic":1456,"nextInTopic":1473,"prevInTime":1466,"nextInTime":1468,"topicId":1452,"numMessagesInTopic":24,"msgSnippet":"Hi Kris, Help me get up to speed with what your thinking here.  I m obviously totally new here, so take my questions as interest not argument. ... A duplicate","rawEmail":"Return-Path: &lt;jrf@...&gt;\r\nX-Sender: jrf@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 69116 invoked from network); 2 Feb 2005 01:12:35 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m10.grp.scd.yahoo.com with QMQP; 2 Feb 2005 01:12:35 -0000\r\nReceived: from unknown (HELO pikespeak.metacarta.com) (66.92.95.164)\n  by mta5.grp.scd.yahoo.com with SMTP; 2 Feb 2005 01:12:34 -0000\r\nReceived: from jrf (helo=localhost)\n\tby pikespeak.metacarta.com with local-esmtp (Exim 3.35 #1 (Debian))\n\tid 1Cw94L-0004qo-00\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Tue, 01 Feb 2005 20:12:33 -0500\r\nDate: Tue, 1 Feb 2005 20:12:33 -0500 (EST)\r\nX-X-Sender: jrf@...\r\nTo: archive-crawler@yahoogroups.com\r\nIn-Reply-To: &lt;0678DB1968EAC7409CC3D0AB7A11B84A06EC47@...&gt;\r\nMessage-ID: &lt;Pine.LNX.4.56.0502011945440.18051@...&gt;\r\nReferences: &lt;0678DB1968EAC7409CC3D0AB7A11B84A06EC47@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: TEXT/PLAIN; charset=US-ASCII\r\nSender:  &lt;jrf@...&gt;\r\nX-eGroups-Remote-IP: 66.92.95.164\r\nFrom: &quot;John R. Frank&quot; &lt;jrf@...&gt;\r\nSubject: RE: [archive-crawler] continuous crawling proposal\r\nX-Yahoo-Group-Post: member; u=210551673\r\nX-Yahoo-Profile: tamarind473\r\n\r\nHi Kris,\n\nHelp me get up to speed with what your thinking here.  I&#39;m obviously\ntotally new here, so take my questions as interest not argument.\n\n&gt; The BdbFrontier uses an &#39;already seen&#39; map to reject duplicates. Clearly\n&gt; this is unacceptable.  The ARFrontier uses the actual queues to weed out\n&gt; duplicates.\n\nA duplicate is a duplicate in both systems, right?  Any efficient way of\ndeleting duplicates is functional, even if some are more elegant than\nothers, right?  What am I missing?\n\n\n&gt; The ARFrontier implements a significantly different HostQueue structure,\n&gt; tailored for repeated crawling of the same URIs. These maintain a\n&gt; priority queue of their URIs, when it is safe to issue them and so\n&gt; forth. The ARFrontier does NOT discard the AList contents (only parts of\n&gt; it) when a CURI is completed, but rather stores it for next time.\n&gt; Currently the BdbFrontier completely discards the CURI and all its data\n&gt; on successful completion of processing.\n\nRight, this would clearly have to change in BDB Frontier to make it useful\nfor repeating crawls.  That&#39;s part of what I was hoping Stack would help\nus do in BDBFrontier :)\n\n\n&gt; Both frontiers use BDB to serialize data.\n\nTrue, and they reimplement the layer between the queue and BDB.  If\nthere&#39;s a common set of services that could be offered by a &quot;store URI&quot;\ncapability, then multiple queuing strategies can use the *same* BDB for\nall URIs.\n\nSuch modularity allows us to change crawling strategies more easily.\nModularity here comes at the cost of agreeing on a common CURI design and\nkeying/querying structure for the CURI database.  Are there other costs\nbesides this?\n\n\n&gt; With the addition of an AbstractFrontier it may be possible to have the\n&gt; ARFrontier utilize that and thus limit duplication of code.\n\nMore than limiting code duplication, it keeps human resources focused on a\nsmaller body of code.  Am I correct in thinking that Stack&#39;s BDBFrontier\nwill be a &quot;default&quot; Frontier that gets much more use than anything not\nactively/directly supported by archive.org developers?  I might have\nmisread that... did I?\n\nI think what you&#39;ve been creating in ARFrontier is really neat and I&#39;d\nlike to see it fully integrated into the central core of Heritrix, rather\nthan an optional add-on that doesn&#39;t necessarily fully interoperate with\nfuture enhancements.\n\n\n&gt; The plain truth however is that iterative and snapshot crawling make\n&gt; very different demands on resources etc.  The BdbFrontier isimplemented\n&gt; with the clear intention of optimizing it for large scale, non repeating\n&gt; crawls. The ARFrontier is however designed for repeatedly crawling the\n&gt; same set of URIs and adds a considerable amount of management for that\n&gt; task. An example of this, the ARFrontier will always ensure (within\n&gt; politeness constricts) that the URI most overdue for a visit will be the\n&gt; next one issued.  The BdbFrontier offers little guarantee as to what URI\n&gt; will be issued next, except the queues are FIFO and allows for queues to\n&gt; be held inactive when enough active queues are being used.\n\nDoes the timestamping that I suggested to Stack achieve this &quot;most\noverdue&quot; goal?  I think it does, or did I miss something?\n\nI think it allows resources to be utilized equally efficiently by both\ncrawling schemes.\n\n\n&gt; I&#39;ll admit that you could construct a single Frontier to serve both\n&gt; purposes, but it would be a matter of compromise. It is (in my opinion)\n&gt; better to have specialized Frontiers for (what are fundamentally)\n&gt; different crawling strategies.\n\nDo different queueing strategies have to be different entire Frontiers?\nI&#39;d love to see all your learning from building the ARFrontier influence\nthe currently active development going into the BDBFrontier.\n\n\n&gt; The ARFrontier is furthermore designed as a generic repeating frontier\n&gt; (I&#39;m planing on renaming it Repeating or RevisitingFrontier since it\n&gt; does not contain any adaptive ability itself) and allows the processors\n&gt; to greatly affect the ordering by which URIs are issued. This is a\n&gt; function that I do not foresee in the BdbFrontier (at least not with the\n&gt; level of granularity the ARFrontier provides).\n\nSame question here as above about the timestamping technique.  Have you\ndevised other types of influences on the URIs besides when to crawl them?\nI&#39;m not able to think of anything that cannot be mapped into a timestamp\nafter which you wish it were already crawled.\n\n"}}