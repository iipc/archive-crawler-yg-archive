{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"Michael Stack","from":"Michael Stack &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"QOfNaXj-CUJ7URtb3JPIDCRu43SoiYTyYIdIb2YYYAgARDr8Qw3kR6U0NWcBiuwW4S8jUwIxFBqdL4WAUWACj_LXty2OlHZS","spamInfo":{"isSpam":false,"reason":"3"},"subject":"Re: [archive-crawler] How to specify exclusion list for heritrix ?","postDate":"1163007763","msgId":3513,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ1NTIxNzEzLjkwNzA1QGFyY2hpdmUub3JnPg==","inReplyToHeader":"PGVpc2s0Zys2dmdzQGVHcm91cHMuY29tPg==","referencesHeader":"PGVpc2s0Zys2dmdzQGVHcm91cHMuY29tPg=="},"prevInTopic":3510,"nextInTopic":3518,"prevInTime":3512,"nextInTime":3514,"topicId":3510,"numMessagesInTopic":5,"msgSnippet":"Check out 6.1.1.2. DecidingScope in the user manual: http://crawler.archive.org/articles/user_manual/config.html.  Try adding decide rule(s)  to REJECT your","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 88804 invoked from network); 8 Nov 2006 17:44:39 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m27.grp.scd.yahoo.com with QMQP; 8 Nov 2006 17:44:39 -0000\r\nReceived: from unknown (HELO dns.duboce.net) (63.203.238.118)\n  by mta2.grp.scd.yahoo.com with SMTP; 8 Nov 2006 17:44:35 -0000\r\nReceived: by dns.duboce.net (Postfix, from userid 1008)\n\tid 91F95CE2F; Wed,  8 Nov 2006 08:25:25 -0800 (PST)\r\nX-Spam-Checker-Version: SpamAssassin 3.1.4 (2006-07-26) on dns.duboce.net\r\nX-Spam-Level: \r\nX-Spam-Status: No, score=-4.4 required=5.0 tests=ALL_TRUSTED,AWL,BAYES_00,\n\tUPPERCASE_25_50 autolearn=ham version=3.1.4\r\nReceived: from [192.168.1.10] (debord.duboce.net [192.168.1.10])\n\tby dns.duboce.net (Postfix) with ESMTP id 610FDCDB1;\n\tWed,  8 Nov 2006 08:25:21 -0800 (PST)\r\nMessage-ID: &lt;45521713.90705@...&gt;\r\nDate: Wed, 08 Nov 2006 09:42:43 -0800\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.8.0.7) Gecko/20060910 SeaMonkey/1.0.5\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;eisk4g+6vgs@...&gt;\r\nIn-Reply-To: &lt;eisk4g+6vgs@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 2:3:4:0\r\nFrom: Michael Stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] How to specify exclusion list for heritrix\n ?\r\nX-Yahoo-Group-Post: member; u=168599281; y=tuOpVXkIA0ViDqAlW-w3xnL9pYMJ3B2KzUr9A7WoBCU_VpZGl82BzxX-\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\nCheck out &#39;6.1.1.2. DecidingScope&#39; in the user manual: \nhttp://crawler.archive.org/articles/user_manual/config.html.  Try adding \ndecide rule(s)  to REJECT your list of exclusions.  At the end of the \ncited section it describes how to enable logging of decide rule \nprocessing so you can watch as URLs earn a REJECT or ACCEPT.\nYours,\nSt.Ack\n\n\n\njls_nayak1983 wrote:\n&gt;\n&gt; Hi Max,\n&gt;\n&gt; I am using Heritrix1.10.1 and jdk1.5 on window platform. I am\n&gt; able to crawl successfully the site specified in the seeds.txt file. I\n&gt; am getting the resulted arc file. Upto this, its fine. Now i want the\n&gt; hertirx not to crawl some specified urls. Means I want to specify the\n&gt; exclusion list for the heritrix. But I dont know how to do that.\n&gt; Please guide me if anyone have answer for my question.\n&gt;\n&gt; Thanks\n&gt; J.L. Nayak\n&gt;\n&gt;  \n\n\n"}}