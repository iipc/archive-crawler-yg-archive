{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"stack","from":"stack &lt;stack@...&gt;","replyTo":"LIST","senderId":"2PnEchAsOHozMl20nD2SAuLmyNPZldPtzPCwQrnPxc7E4hQrDhV3noXxnhocQBlHuoFlOWJdNZwRSgHt_DRC4Q","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] crawl.log field descriptions","postDate":"1097770177","msgId":1089,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQxNkVBNEMxLjUwNTAyMDNAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDE2NzUwLjQwMTM2Ljk3MDg2MS40MDkyMjBAdGlwaGFyZXMuYmFzaXN0ZWNoLm5ldD4=","referencesHeader":"PDE2NzQ5LjI2MzkxLjQ3MTM0Mi4yOTQ0NzFAdGlwaGFyZXMuYmFzaXN0ZWNoLm5ldD4JPDQxNkQ4N0U3LjUwNjA5MDhAYXJjaGl2ZS5vcmc+IDwxNjc1MC40MDEzNi45NzA4NjEuNDA5MjIwQHRpcGhhcmVzLmJhc2lzdGVjaC5uZXQ+"},"prevInTopic":1087,"nextInTopic":0,"prevInTime":1088,"nextInTime":1090,"topicId":1083,"numMessagesInTopic":4,"msgSnippet":"... General plan is to build a meaty glossary and then mess with xinclude to duplicate the meaty snippets throughout the docs (Haven t gotten to the xinclude","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 90312 invoked from network); 14 Oct 2004 16:16:20 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m23.grp.scd.yahoo.com with QMQP; 14 Oct 2004 16:16:20 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (207.241.224.172)\n  by mta4.grp.scd.yahoo.com with SMTP; 14 Oct 2004 16:16:20 -0000\r\nReceived: (qmail 11368 invoked by uid 100); 14 Oct 2004 16:05:04 -0000\r\nReceived: from debord.archive.org (HELO ?207.241.238.140?) (stack@...@207.241.238.140)\n  by mail-dev.archive.org with SMTP; 14 Oct 2004 16:05:04 -0000\r\nMessage-ID: &lt;416EA4C1.5050203@...&gt;\r\nDate: Thu, 14 Oct 2004 09:09:37 -0700\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.7.2) Gecko/20040820 Debian/1.7.2-4\r\nX-Accept-Language: en-us\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;16749.26391.471342.294471@...&gt;\t&lt;416D87E7.5060908@...&gt; &lt;16750.40136.970861.409220@...&gt;\r\nIn-Reply-To: &lt;16750.40136.970861.409220@...&gt;\r\nContent-Type: text/plain; charset=us-ascii; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=0.1 required=7.0 tests=AWL autolearn=no version=2.63\r\nX-eGroups-Remote-IP: 207.241.224.172\r\nFrom: stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] crawl.log field descriptions\r\nX-Yahoo-Group-Post: member; u=168599281\r\n\r\nTom Emerson wrote:\n\n&gt;stack writes:\n&gt;  \n&gt;\n&gt;&gt;The user manual has a coarse description.  See &#39;8.2.1. crawl.log&#39; in \n&gt;&gt;http://crawler.archive.org/articles/user_manual.html.  It could be \n&gt;&gt;tightened up.  Send over your doc. and I&#39;ll add it in if its better than \n&gt;&gt;whats currently in the user manual Tom.\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;Of course when I went looking the User Manual wasn&#39;t available online\n&gt;yet. What I ended up with is pretty much what&#39;s there. I would find it\n&gt;more readable if there weren&#39;t links to the glossary --- I&#39;d rather\n&gt;see the information inlined, and perhaps include some examples.\n&gt;\n&gt;  \n&gt;\nGeneral plan is to build a meaty glossary and then mess with xinclude to \nduplicate the meaty snippets throughout the docs (Haven&#39;t gotten to the \nxinclude messing yet).\n\n&gt;Also the annotations field can also contain timeTrunc and lenTrunc\n&gt;annotations, in addition to the number of attempts.\n&gt;  \n&gt;\nI did an edit of the crawl.log section and added in the above.\n\nThanks for the feedback boss,\nSt.Ack\n\n&gt;    -tree\n&gt;\n&gt;  \n&gt;\n\n\n"}}