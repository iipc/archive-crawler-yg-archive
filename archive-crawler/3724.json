{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":292966479,"authorName":"Artem Antonov","from":"Artem Antonov &lt;antonov.artem@...&gt;","profile":"antonov.artem","replyTo":"LIST","senderId":"oNrZyN4k0mtyCG-E25KdCEwSPKQin2xC60ncH9is7b84ZLzYhYKhZcEPQBbkj3_ZB7gtFDonNtA1QNuc-1V7ezFYUoMMbeZypLeUUN4P","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Re: Fetch process","postDate":"1169201305","msgId":3724,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDUxOTc1Mi44NTI2LnFtQHdlYjU4OTEzLm1haWwucmUxLnlhaG9vLmNvbT4=","inReplyToHeader":"PDQ1QjAzMUI2LjMwNTA1MDZAYXJjaGl2ZS5vcmc+"},"prevInTopic":3722,"nextInTopic":3729,"prevInTime":3723,"nextInTime":3725,"topicId":3637,"numMessagesInTopic":18,"msgSnippet":"Hi Igor, I ve tried the following rules sequence:  ","rawEmail":"Return-Path: &lt;antonov.artem@...&gt;\r\nX-Sender: antonov.artem@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 65967 invoked from network); 19 Jan 2007 10:09:25 -0000\r\nReceived: from unknown (66.218.67.33)\n  by m39.grp.scd.yahoo.com with QMQP; 19 Jan 2007 10:09:25 -0000\r\nReceived: from unknown (HELO web58913.mail.re1.yahoo.com) (66.196.100.248)\n  by mta7.grp.scd.yahoo.com with SMTP; 19 Jan 2007 10:09:25 -0000\r\nReceived: (qmail 9795 invoked by uid 60001); 19 Jan 2007 10:08:25 -0000\r\nX-YMail-OSG: jWFyT28VM1naHuM48ycV.2EEP5WeR32CBqfUuz1y\r\nReceived: from [193.111.239.18] by web58913.mail.re1.yahoo.com via HTTP; Fri, 19 Jan 2007 02:08:25 PST\r\nDate: Fri, 19 Jan 2007 02:08:25 -0800 (PST)\r\nTo: archive-crawler@yahoogroups.com\r\nIn-Reply-To: &lt;45B031B6.3050506@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: multipart/alternative; boundary=&quot;0-336351338-1169201305=:8526&quot;\r\nContent-Transfer-Encoding: 8bit\r\nMessage-ID: &lt;519752.8526.qm@...&gt;\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: Artem Antonov &lt;antonov.artem@...&gt;\r\nSubject: Re: [archive-crawler] Re: Fetch process\r\nX-Yahoo-Group-Post: member; u=292966479; y=24dijTRh5nd0xn2X1izgCf3ltyjRtOJoHtjCgJZOx45ANMypSZ7Meg\r\nX-Yahoo-Profile: antonov.artem\r\n\r\n\r\n--0-336351338-1169201305=:8526\r\nContent-Type: text/plain; charset=iso-8859-1\r\nContent-Transfer-Encoding: 8bit\r\n\r\nHi Igor,\n \n I&#39;ve tried the following rules sequence:\n \n &lt;newObject name=&quot;scope&quot; class=&quot;org.archive.crawler.deciderules.DecidingScope&quot;&gt;\n       &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n       &lt;string name=&quot;seedsfile&quot;&gt;seeds.txt&lt;/string&gt;\n       &lt;boolean name=&quot;reread-seeds-on-config&quot;&gt;true&lt;/boolean&gt;\n       &lt;newObject name=&quot;decide-rules&quot; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n         &lt;map name=&quot;rules&quot;&gt;\n           &lt;newObject name=&quot;rejectByDefault&quot; class=&quot;org.archive.crawler.deciderules.RejectDecideRule&quot;&gt;\n           &lt;/newObject&gt;\n           &lt;newObject name=&quot;onDomainsDecideRule&quot; class=&quot;org.archive.crawler.deciderules.OnDomainsDecideRule&quot;&gt;\n             &lt;string name=&quot;decision&quot;&gt;ACCEPT&lt;/string&gt;\n             &lt;string name=&quot;surts-source-file&quot;&gt;&lt;/string&gt;\n             &lt;boolean name=&quot;seeds-as-surt-prefixes&quot;&gt;true&lt;/boolean&gt;\n             &lt;string name=&quot;surts-dump-file&quot;&gt;&lt;/string&gt;\n             &lt;boolean name=&quot;also-check-via&quot;&gt;false&lt;/boolean&gt;\n             &lt;boolean name=&quot;rebuild-on-reconfig&quot;&gt;true&lt;/boolean&gt;\n           &lt;/newObject&gt;\n           &lt;newObject name=&quot;rejectIfTooManyHops&quot; class=&quot;org.archive.crawler.deciderules.TooManyHopsDecideRule&quot;&gt;\n             &lt;integer name=&quot;max-hops&quot;&gt;3&lt;/integer&gt;\n           &lt;/newObject&gt;\n           &lt;newObject name=&quot;acceptIfTranscluded&quot; class=&quot;org.archive.crawler.deciderules.TransclusionDecideRule&quot;&gt;\n             &lt;integer name=&quot;max-trans-hops&quot;&gt;2&lt;/integer&gt;\n           &lt;/newObject&gt;\n           &lt;newObject name=&quot;rejectIfPathological&quot; class=&quot;org.archive.crawler.deciderules.PathologicalPathDecideRule&quot;&gt;\n             &lt;integer name=&quot;max-repetitions&quot;&gt;2&lt;/integer&gt;\n           &lt;/newObject&gt;\n           &lt;newObject name=&quot;rejectIfTooManyPathSegs&quot; class=&quot;org.archive.crawler.deciderules.TooManyPathSegmentsDecideRule&quot;&gt;\n             &lt;integer name=&quot;max-path-depth&quot;&gt;5&lt;/integer&gt;\n           &lt;/newObject&gt;\n           &lt;newObject name=&quot;filePattern&quot; class=&quot;org.archive.crawler.deciderules.NotMatchesFilePatternDecideRule&quot;&gt;\n             &lt;string name=&quot;decision&quot;&gt;REJECT&lt;/string&gt;\n             &lt;string name=&quot;use-preset-pattern&quot;&gt;Custom&lt;/string&gt;\n             &lt;string name=&quot;regexp&quot;&gt;^(?i)^.*&#92;.(?:html?|doc|ppt)$&lt;/string&gt;\n           &lt;/newObject&gt;\n         &lt;/map&gt;\n       &lt;/newObject&gt;\n     &lt;/newObject&gt;\n \n But I got an -5000 error after start the Heritrix.\n \n If I change the last rule to the:\n \n &lt;newObject name=&quot;filePattern&quot; class=&quot;org.archive.crawler.deciderules.MatchesFilePatternDecideRule&quot;&gt;\n             &lt;string name=&quot;decision&quot;&gt;ACCEPT&lt;/string&gt;\n             &lt;string name=&quot;use-preset-pattern&quot;&gt;Custom&lt;/string&gt;\n             &lt;string name=&quot;regexp&quot;&gt;.*(?i)(&#92;.(doc|pdf|ppt|swf))$&lt;/string&gt;\n &lt;/newObject&gt;\n \n I get again all files from the domain I&#39;m interested in. What is wrong?\n \n Thanks.\n \n Regards,\n Artem.\n\nIgor Ranitovic &lt;igor@...&gt; wrote:                                  Hi Artem,\n \n &gt; 1) OnHostDecideRule - to accept anything on same hosts.     \n &gt; 2) NotOnHostsDecideRule - to reject anything on not same hosts.     \n &gt; 3) OnDomainsDecideRule - to accept anything on same domains.     \n &gt; 4) NotOnDomainsDecideRule - to reject anything not on same domains.     \n \n If all 4 rules are using seeds.txt file to create prefixes then you \n don&#39;t need rules 1,2 and 4:\n  - rule 1 is not needed since rule 3 is broader in scope.\n  - rule 2 has no effect since very first rule you have rejects all URIs \n by default (see the order file and RejectDecideRule).\n  - rule 4 is not need for same reason as the rule 2.\n \n &gt; Yes, now I save to ARC only html/text files.    \n &gt; I&#39;m trying to do: extract only links (from html) to some     \n &gt; files (in this case, *.doc and *.ppt) and save only these links to     \n &gt; the crawl.log file. \n &gt;   \n &gt; In other words, I want to restrict fetching and processing of all  \n &gt; URIs that not end with the specified pattern.  \n \n Would this work?\n \n 1) reject all URIs by default (RejectDecideRule)\n 2) accept all URIs within domain (OnDomainsDecideRule)\n 3) reject all URIs that don&#39;t match specified files extension \n (NoMatchesFilePatternDecideRule). If you want only htm(l), docs and ppts \n use &#39;^(?i)^.*&#92;.(?:html?|doc|ppt)$&#39;\n \n Take care,\n i.\n \n &gt; Thanks.  \n &gt;     \n &gt; Regards,  \n &gt; Artem.   \n &gt;      \n &gt;       \n &gt; --- In archive-crawler@yahoogroups.com, Igor Ranitovic &lt;igor@...&gt;      \n &gt; wrote:      \n &gt;&gt;      \n &gt;&gt; Hi Artem,      \n &gt;&gt;       \n &gt;&gt; I am not sure why you have the following decide rule sequence:      \n &gt;&gt;       \n &gt;&gt; 1) Accept OnHostsDecideRule      \n &gt;&gt; 2) Then you reject OnHostsDecideRule. I am not sure what you are      \n &gt; trying       \n &gt;&gt; to do here.      \n &gt;&gt; 3) Accept OnDomainsDecideRule - what is you scope? Do you want to      \n &gt; crawl       \n &gt;&gt; in domain or host scope?      \n &gt;&gt; 3) Again you reject tOnDomainsDecideRule.      \n &gt;&gt;       \n &gt;&gt;&gt;      &gt; Thanks a lot for help.      \n &gt;&gt;&gt;      &gt; I&#39;ve added ContentTypeRegExFilter to the      \n &gt; &#39;midfetch-filter&#39; and      \n &gt;&gt;&gt;      &gt; &#39;write-processors&#39; sections, and now only html/text      \n &gt; contents are      \n &gt;&gt;&gt;      &gt; saved into the ARC file.      \n &gt;&gt;&gt;      &gt;      \n &gt;&gt;&gt;      &gt; The one problem I couldn&#39;t solve is to accept only URIs      \n &gt; that end      \n &gt;&gt;&gt;      &gt; with the specified pattern (for example, &quot;.doc, *.ppt&quot;).      \n &gt;&gt;       \n &gt;&gt; What are you trying to do? You want to allow (fetch and process)      \n &gt; only       \n &gt;&gt; .doc and .ppt, but save only html/text to ARC files.      \n &gt;&gt;       \n &gt;&gt; Take care,      \n &gt;&gt; i.      \n &gt;&gt;      \n &gt;       \n &gt; \n &gt; \n &gt; \n &gt;  \n &gt; Yahoo! Groups Links\n &gt; \n &gt; \n &gt; \n \n \n     \n                       \n\n \n---------------------------------\nSucker-punch spam with award-winning protection.\n Try the free Yahoo! Mail Beta.\r\n--0-336351338-1169201305=:8526\r\nContent-Type: text/html; charset=iso-8859-1\r\nContent-Transfer-Encoding: 8bit\r\n\r\nHi Igor,&lt;br&gt; &lt;br&gt; I&#39;ve tried the following rules sequence:&lt;br&gt; &lt;br&gt; &lt;newObject name=&quot;scope&quot; class=&quot;org.archive.crawler.deciderules.DecidingScope&quot;&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;string name=&quot;seedsfile&quot;&gt;seeds.txt&lt;/string&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;boolean name=&quot;reread-seeds-on-config&quot;&gt;true&lt;/boolean&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;newObject name=&quot;decide-rules&quot; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;map name=&quot;rules&quot;&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;newObject name=&quot;rejectByDefault&quot; class=&quot;org.archive.crawler.deciderules.RejectDecideRule&quot;&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;/newObject&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;newObject name=&quot;onDomainsDecideRule&quot;\n class=&quot;org.archive.crawler.deciderules.OnDomainsDecideRule&quot;&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;string name=&quot;decision&quot;&gt;ACCEPT&lt;/string&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;string name=&quot;surts-source-file&quot;&gt;&lt;/string&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;boolean name=&quot;seeds-as-surt-prefixes&quot;&gt;true&lt;/boolean&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;string name=&quot;surts-dump-file&quot;&gt;&lt;/string&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;boolean name=&quot;also-check-via&quot;&gt;false&lt;/boolean&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;boolean name=&quot;rebuild-on-reconfig&quot;&gt;true&lt;/boolean&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;/newObject&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n &lt;newObject name=&quot;rejectIfTooManyHops&quot; class=&quot;org.archive.crawler.deciderules.TooManyHopsDecideRule&quot;&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;integer name=&quot;max-hops&quot;&gt;3&lt;/integer&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;/newObject&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;newObject name=&quot;acceptIfTranscluded&quot; class=&quot;org.archive.crawler.deciderules.TransclusionDecideRule&quot;&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;integer name=&quot;max-trans-hops&quot;&gt;2&lt;/integer&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;/newObject&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;newObject name=&quot;rejectIfPathological&quot; class=&quot;org.archive.crawler.deciderules.PathologicalPathDecideRule&quot;&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;integer name=&quot;max-repetitions&quot;&gt;2&lt;/integer&gt;&lt;br&gt;\n &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;/newObject&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;newObject name=&quot;rejectIfTooManyPathSegs&quot; class=&quot;org.archive.crawler.deciderules.TooManyPathSegmentsDecideRule&quot;&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;integer name=&quot;max-path-depth&quot;&gt;5&lt;/integer&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;/newObject&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;newObject name=&quot;filePattern&quot; class=&quot;org.archive.crawler.deciderules.NotMatchesFilePatternDecideRule&quot;&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;string name=&quot;decision&quot;&gt;REJECT&lt;/string&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;string name=&quot;use-preset-pattern&quot;&gt;Custom&lt;/string&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;string\n name=&quot;regexp&quot;&gt;^(?i)^.*&#92;.(?:html?|doc|ppt)$&lt;/string&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;/newObject&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;/map&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;/newObject&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp; &lt;/newObject&gt;&lt;br&gt; &lt;br&gt; But I got an -5000 error after start the Heritrix.&lt;br&gt; &lt;br&gt; If I change the last rule to the:&lt;br&gt; &lt;br&gt; &lt;newObject name=&quot;filePattern&quot; class=&quot;org.archive.crawler.deciderules.MatchesFilePatternDecideRule&quot;&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;string name=&quot;decision&quot;&gt;ACCEPT&lt;/string&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;string name=&quot;use-preset-pattern&quot;&gt;Custom&lt;/string&gt;&lt;br&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;string name=&quot;regexp&quot;&gt;.*(?i)(&#92;.(doc|pdf|ppt|swf))$&lt;/string&gt;&lt;br&gt; &lt;/newObject&gt;&lt;br&gt; &lt;br&gt; I get again all files from the domain I&#39;m\n interested in. What is wrong?&lt;br&gt; &lt;br&gt; Thanks.&lt;br&gt; &lt;br&gt; Regards,&lt;br&gt; Artem.&lt;br&gt;&lt;br&gt;&lt;b&gt;&lt;i&gt;Igor Ranitovic &lt;igor@...&gt;&lt;/i&gt;&lt;/b&gt; wrote:&lt;blockquote class=&quot;replbq&quot; style=&quot;border-left: 2px solid rgb(16, 16, 255); margin-left: 5px; padding-left: 5px;&quot;&gt;     &lt;!-- Network content --&gt;           &lt;div id=&quot;ygrp-text&quot;&gt;             &lt;div&gt;Hi Artem,&lt;br&gt; &lt;br&gt; &gt; 1) OnHostDecideRule - to accept anything on same hosts.     &lt;br&gt; &gt; 2) NotOnHostsDecideRul&lt;wbr&gt;e - to reject anything on not same hosts.     &lt;br&gt; &gt; 3) OnDomainsDecideRule - to accept anything on same domains.     &lt;br&gt; &gt; 4) NotOnDomainsDecideR&lt;wbr&gt;ule - to reject anything not on same domains.     &lt;br&gt; &lt;br&gt; If all 4 rules are using seeds.txt file to create prefixes then you &lt;br&gt; don&#39;t need\n rules 1,2 and 4:&lt;br&gt;  - rule 1 is not needed since rule 3 is broader in scope.&lt;br&gt;  - rule 2 has no effect since very first rule you have rejects all URIs &lt;br&gt; by default (see the order file and RejectDecideRule)&lt;wbr&gt;.&lt;br&gt;  - rule 4 is not need for same reason as the rule 2.&lt;br&gt; &lt;br&gt; &gt; Yes, now I save to ARC only html/text files.    &lt;br&gt; &gt; I&#39;m trying to do: extract only links (from html) to some     &lt;br&gt; &gt; files (in this case, *.doc and *.ppt) and save only these links to     &lt;br&gt; &gt; the crawl.log file. &lt;br&gt; &gt;   &lt;br&gt; &gt; In other words, I want to restrict fetching and processing of all  &lt;br&gt; &gt; URIs that not end with the specified pattern.  &lt;br&gt; &lt;br&gt; Would this work?&lt;br&gt; &lt;br&gt; 1) reject all URIs by default (RejectDecideRule)&lt;br&gt; 2) accept all URIs within domain (OnDomainsDecideRul&lt;wbr&gt;e)&lt;br&gt; 3) reject all URIs that don&#39;t match specified files extension &lt;br&gt; (NoMatchesFilePatte&lt;wbr&gt;rnDecideRule)&lt;wbr&gt;. If you want only htm(l), docs and ppts &lt;br&gt; use\n &#39;^(?i)^.*&#92;.(&lt;wbr&gt;?:html?|doc|&lt;wbr&gt;ppt)$&#39;&lt;br&gt; &lt;br&gt; Take care,&lt;br&gt; i.&lt;br&gt; &lt;br&gt; &gt; Thanks.  &lt;br&gt; &gt;     &lt;br&gt; &gt; Regards,  &lt;br&gt; &gt; Artem.   &lt;br&gt; &gt;      &lt;br&gt; &gt;       &lt;br&gt; &gt; --- In &lt;a href=&quot;mailto:archive-crawler%40yahoogroups.com&quot;&gt;archive-crawler@&lt;wbr&gt;yahoogroups.&lt;wbr&gt;com&lt;/a&gt;, Igor Ranitovic &lt;igor@...&gt;      &lt;br&gt; &gt; wrote:      &lt;br&gt; &gt;&gt;      &lt;br&gt; &gt;&gt; Hi Artem,      &lt;br&gt; &gt;&gt;       &lt;br&gt; &gt;&gt; I am not sure why you have the following decide rule sequence:      &lt;br&gt; &gt;&gt;       &lt;br&gt; &gt;&gt; 1) Accept OnHostsDecideRule      &lt;br&gt; &gt;&gt; 2) Then you reject OnHostsDecideRule. I am not sure what you are      &lt;br&gt; &gt; trying       &lt;br&gt; &gt;&gt; to do here.      &lt;br&gt; &gt;&gt; 3) Accept OnDomainsDecideRule - what is you scope? Do you want to      &lt;br&gt; &gt; crawl       &lt;br&gt; &gt;&gt; in domain or host scope?      &lt;br&gt; &gt;&gt; 3) Again you reject tOnDomainsDecideRul&lt;wbr&gt;e.      &lt;br&gt; &gt;&gt;       &lt;br&gt; &gt;&gt;&gt;      &gt; Thanks a lot for\n help.      &lt;br&gt; &gt;&gt;&gt;      &gt; I&#39;ve added ContentTypeRegExFil&lt;wbr&gt;ter to the      &lt;br&gt; &gt; &#39;midfetch-filter&#39; and      &lt;br&gt; &gt;&gt;&gt;      &gt; &#39;write-processors&#39; sections, and now only html/text      &lt;br&gt; &gt; contents are      &lt;br&gt; &gt;&gt;&gt;      &gt; saved into the ARC file.      &lt;br&gt; &gt;&gt;&gt;      &gt;      &lt;br&gt; &gt;&gt;&gt;      &gt; The one problem I couldn&#39;t solve is to accept only URIs      &lt;br&gt; &gt; that end      &lt;br&gt; &gt;&gt;&gt;      &gt; with the specified pattern (for example, &quot;.doc, *.ppt&quot;).      &lt;br&gt; &gt;&gt;       &lt;br&gt; &gt;&gt; What are you trying to do? You want to allow (fetch and process)      &lt;br&gt; &gt; only       &lt;br&gt; &gt;&gt; .doc and .ppt, but save only html/text to ARC files.      &lt;br&gt; &gt;&gt;       &lt;br&gt; &gt;&gt; Take care,      &lt;br&gt; &gt;&gt; i.      &lt;br&gt; &gt;&gt;      &lt;br&gt; &gt;       &lt;br&gt; &gt; &lt;br&gt; &gt; &lt;br&gt; &gt; &lt;br&gt; &gt;  &lt;br&gt; &gt; Yahoo! Groups Links&lt;br&gt; &gt; &lt;br&gt; &gt; &lt;br&gt; &gt; &lt;br&gt; &lt;br&gt; &lt;/div&gt;     &lt;/div&gt;       \n   &lt;!--End group email --&gt; \n &lt;/blockquote&gt;&lt;br&gt;&lt;p&gt;&#32;\n\n&lt;hr size=1&gt;&lt;a href=&quot;\nhttp://us.rd.yahoo.com/evt=49981/*http://advision.webevents.yahoo.com/mailbeta/features_spam.html&quot;&gt;Sucker-punch spam&lt;/a&gt; with award-winning protection.&lt;br&gt; Try the &lt;a href=&quot;\nhttp://us.rd.yahoo.com/evt=49981/*http://advision.webevents.yahoo.com/mailbeta/features_spam.html&quot;&gt;free Yahoo! Mail Beta.&lt;/a&gt;\r\n--0-336351338-1169201305=:8526--\r\n\n"}}