{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"daSpJ5Ex97KMLPvo0enEsnn1FnBmQ-7S24-6Dkn_hbdkSDZ7SlsLDGosgdrhLa6lAFIIBBezXYsJtpiUoX9ibRlFjsWDcj4","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Lowering stack size (-Xss)?","postDate":"1221162413","msgId":5468,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ4Qzk3NUFELjcwNDA1MDhAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PFAtSVJDLUVYQkUwMUF3MTlEQnEwMDAwMTY4OUBFWC5VQ09QLkVEVT4=","referencesHeader":"PFAtSVJDLUVYQkUwMUF3MTlEQnEwMDAwMTY4OUBFWC5VQ09QLkVEVT4="},"prevInTopic":5467,"nextInTopic":5469,"prevInTime":5467,"nextInTime":5469,"topicId":5467,"numMessagesInTopic":5,"msgSnippet":"Thoughts: What out-of-memory error do you get, exactly? (Can you trigger the same error under Java 1.6, which sometimes gives more informative OOME/error ","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 44978 invoked from network); 11 Sep 2008 19:46:53 -0000\r\nX-Received: from unknown (66.218.67.96)\n  by m52.grp.scd.yahoo.com with QMQP; 11 Sep 2008 19:46:53 -0000\r\nX-Received: from unknown (HELO relay02.pair.com) (209.68.5.16)\n  by mta17.grp.scd.yahoo.com with SMTP; 11 Sep 2008 19:46:53 -0000\r\nX-Received: (qmail 84891 invoked from network); 11 Sep 2008 19:46:52 -0000\r\nX-Received: from unknown (HELO ?192.168.1.88?) (unknown)\n  by unknown with SMTP; 11 Sep 2008 19:46:52 -0000\r\nX-pair-Authenticated: 67.170.220.186\r\nMessage-ID: &lt;48C975AD.7040508@...&gt;\r\nDate: Thu, 11 Sep 2008 12:46:53 -0700\r\nUser-Agent: Thunderbird 2.0.0.16 (Windows/20080708)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;P-IRC-EXBE01Aw19DBq00001689@...&gt;\r\nIn-Reply-To: &lt;P-IRC-EXBE01Aw19DBq00001689@...&gt;\r\nContent-Type: text/plain; charset=UTF-8; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Lowering stack size (-Xss)?\r\nX-Yahoo-Group-Post: member; u=137285340; y=DwTH9tvAFjA5HBw39Ly5UyXytbnWrrKbbQxs4UOJdYPS\r\nX-Yahoo-Profile: gojomo\r\n\r\nThoughts:\n\nWhat out-of-memory error do you get, exactly? (Can you trigger the same \nerror under Java 1.6, which sometimes gives more informative OOME/error \nmessages?)\n\nSince the stack space is used per thread, by configuring your crawls to \nuse fewer ToeThreads, you may also be able to expand the number of \nsimultaneous crawlers in a JVM. (Heritrix currently launches the \nconfigured number of threads, and keeps them idle, even if unneeded. \nThis behavior could be changed if the cost of idle threads was deemed \nhigh, but it would not be a simple low-risk change. More radically, the \nnumber of threads could be set per JVM, and any number of crawls could \nshare the same pool of worker threads, if this threads/stacksize was \ncommonly the critical deployment bottleneck.)\n\nBecause stack space comes from non-heap memory, this may be a case where \nmaking your heap space smaller paradoxically allows you to launch more \ncrawlers/threads, given a specific -Xss setting, without hitting an error.\n\nThe risk of using smaller stack size settings would be hitting \nStackOveflowErrors in crawler code. In my experience, the deepest \nrecursion that happens in Heritrix is in the regular-expression \nlink-extraction, against certain worst-case input. We&#39;ve added a number \nof guards against this risk -- capping match sizes and adding explicit \ncatch-and-recover code against StackOverflowError in Extractors -- but I \nstill suspect that&#39;s the most likely first place to hit problems with \nsmaller -Xss values.\n\nDoes 64bit Solaris have the option of running 32bit JVMs in a \ncompatibility mode? While this would limit the heap size any one JVM \ncould use, the same objects take significantly less space in a 32bit JVM \ncompred to a 64bit JVM. (I&#39;ve heard an estimate that a heap with the \nsame objects in it can be around 40% larger in a 64bit JVM than a 32bit \nJVM. I suspect the same inflation is present in stack sizes.) So, you \nmight effectively get more crawlers by running 4-to-8 32bit JVMs than 1 \n64bit JVM.\n\nHope this helps,\n\n- Gordon @ IA\n\nErik Hetzner wrote:\n&gt; Hi all.\n&gt; \n&gt; I’m experimenting with squeezing more crawlers out of a single JVM in\n&gt; Heritrix. (Background: it is possible to run multiple crawlers in a\n&gt; single JVM, and we do that at CDL to get more individual crawls.) The\n&gt; most I can seem to get without running of memory (not heap) is 20 with\n&gt; the default stack size. But I seem to be able to get 50 crawlers if I\n&gt; reduce the stack size (using the -Xss java option). I’m wondering if\n&gt; anybody has any comment or experience with this? Thanks.\n&gt; \n&gt; Sun Fire X4500\n&gt; 2 dual core opterons.\n&gt; 16G phys. memory.\n&gt; \n&gt; Java(TM) 2 Runtime Environment, Standard Edition (build 1.5.0_15-b04)\n&gt; Java HotSpot(TM) Server VM (build 1.5.0_15-b04, mixed mode)\n&gt; \n&gt; -Xmx2048m\n&gt; -Xss128k (to run 50 crawlers, default maxes out at 20 crawlers)\n&gt; \n&gt; Heritrix 1.14.0\n&gt; \n&gt; best,\n&gt; Erik Hetzner\n&gt; \n&gt; \n&gt; ------------------------------------------------------------------------\n&gt; \n&gt; ;; Erik Hetzner, California Digital Library\n&gt; ;; gnupg key id: 1024D/01DB07E3\n\n"}}