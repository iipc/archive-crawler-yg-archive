{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":511156237,"authorName":"hatoum13","from":"&quot;hatoum13&quot; &lt;hatoum13@...&gt;","profile":"hatoum13","replyTo":"LIST","senderId":"QSqDeaUUvZVQc5tO4FcC_WlrzCs7mW9xul9jWABKfIbd_a8wKWOgWyUY_AZLWRtmB0OICr-koSC0GMpTUQ1_z2HZIHTG","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: questions on how to setup Heritrix 3 on two machines","postDate":"1328107778","msgId":7602,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGpnYmplMitmYzd0QGVHcm91cHMuY29tPg==","inReplyToHeader":"PGpnYmg1OCttOW9qQGVHcm91cHMuY29tPg=="},"prevInTopic":7599,"nextInTopic":7603,"prevInTime":7601,"nextInTime":7603,"topicId":7341,"numMessagesInTopic":9,"msgSnippet":"Hi Davi, Thanks for your response, Apparently you are talking about the same machine (physically one computer). In my case, i have technical constraints which","rawEmail":"Return-Path: &lt;hatoum13@...&gt;\r\nX-Sender: hatoum13@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 79352 invoked from network); 1 Feb 2012 14:49:41 -0000\r\nX-Received: from unknown (98.137.34.46)\n  by m13.grp.sp2.yahoo.com with QMQP; 1 Feb 2012 14:49:41 -0000\r\nX-Received: from unknown (HELO ng8-ip2.bullet.mail.bf1.yahoo.com) (98.139.165.58)\n  by mta3.grp.sp2.yahoo.com with SMTP; 1 Feb 2012 14:49:40 -0000\r\nX-Received: from [98.139.164.125] by ng8.bullet.mail.bf1.yahoo.com with NNFMP; 01 Feb 2012 14:49:39 -0000\r\nX-Received: from [69.147.65.147] by tg6.bullet.mail.bf1.yahoo.com with NNFMP; 01 Feb 2012 14:49:39 -0000\r\nX-Received: from [98.137.34.35] by t10.bullet.mail.sp1.yahoo.com with NNFMP; 01 Feb 2012 14:49:39 -0000\r\nDate: Wed, 01 Feb 2012 14:49:38 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;jgbje2+fc7t@...&gt;\r\nIn-Reply-To: &lt;jgbh58+m9oj@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;hatoum13&quot; &lt;hatoum13@...&gt;\r\nSubject: Re: questions on how to setup Heritrix 3 on two machines\r\nX-Yahoo-Group-Post: member; u=511156237; y=GpLbcgKFUqElXpsuYrOITJwoXOH3zl6dNNinY_Gj2m7Psbk\r\nX-Yahoo-Profile: hatoum13\r\n\r\nHi Davi,\n\nThanks for your response,\n\nApparently you are talking about the s=\r\name machine (physically one computer).\n\nIn my case, i have technical constr=\r\naints which is a very limited memory in my machines (3 GB for each one) and=\r\n I want to accelerate the crawl by launching it in two machines (connected =\r\nin the same network) :\n1 st machine : instance with 2 GB of memory \n2 nd ma=\r\nchine : instance with 2 GB of memory \nMy question is : Can the two instance=\r\ns works together on the same seeds.txt (which contains 12 millions line)?\n\n=\r\n\n--- In archive-crawler@yahoogroups.com, &quot;david_pane1&quot; &lt;dpane@...&gt; wrote:\n&gt;=\r\n\n&gt; \n&gt; \n&gt; After creating a job on the mail page on the Heritrix web interfac=\r\ne, under &quot;Add Job Directory&quot;(in example below the jobname is myjob1), place=\r\n your seed file into the jobname directory.\n&gt; \n&gt; From the directory where y=\r\nou installed heritrix, you will see a directory jobs, inside jobs will be a=\r\n directory named &quot;jobname&quot;&quot;\n&gt; \n&gt; .../HeritrixInstallDirectory/jobs/myjob1/s=\r\needs.txt\n&gt; \n&gt; each instance should have the identical seed list placed in i=\r\nts jobs directory.  Seed list should have a format like this:\n&gt; \n&gt; \n&gt; http:=\r\n//www.domain.com/\n&gt; http://www.domain2.com/\n&gt; http://www.domain3.com/\n&gt; htt=\r\np://www.domain4.com/\n&gt; \n&gt; I hop this helps\n&gt; \n&gt; --David\n&gt; --- In archive-cr=\r\nawler@yahoogroups.com, &quot;hatoum13&quot; &lt;hatoum13@&gt; wrote:\n&gt; &gt;\n&gt; &gt; Hi,\n&gt; &gt; \n&gt; &gt; I=\r\n&#39;m trying to install H3 on 2 different machines (in a local network) to cra=\r\nwl a large seeds file (more than 10 millions URL), I&#39;m faced to little prob=\r\nlem, how can I put the same seeds file for both instances?\n&gt; &gt; \n&gt; &gt; I tried=\r\n to make the file reachable from a web server but the Job can&#39;t be built be=\r\ncause of an exception when it&#39;s creating the seed&#39;s bean.\n&gt; &gt; \n&gt; &gt; Thanks\n&gt;=\r\n &gt; \n&gt; &gt; --- In archive-crawler@yahoogroups.com, &quot;david_pane1&quot; &lt;dpane@&gt; wrot=\r\ne:\n&gt; &gt; &gt;\n&gt; &gt; &gt; With some effort, tips from Gordan and using the H1 to get a=\r\nn idea of the property names of the HashCrawlMapper, I was able to successf=\r\nully configure and run a two machine test crawl.  I figured I would post th=\r\nis for others to refer to in the future.  \n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; Using the de=\r\nfault crawler-beans.cxml, I added the following (in addition to the necessa=\r\nry user-agent and the seed list changes )\n&gt; &gt; &gt; \n&gt; &gt; &gt; I defined the follow=\r\ning in crawler-beans.cxml on machine 1:\n&gt; &gt; &gt;   &lt;bean id=3D&quot;hashCrawlMapper=\r\nProcessor&quot; class=3D&quot;org.archive.crawler.processor.HashCrawlMapper&quot;&gt;\n&gt; &gt; &gt;  =\r\n\t&lt;property name=3D&quot;localName&quot;      value=3D&quot;0&quot; /&gt;\n&gt; &gt; &gt; \t&lt;property name=3D&quot;=\r\ndiversionDir&quot;   value=3D&quot;diversions&quot; /&gt;\n&gt; &gt; &gt; \t&lt;property name=3D&quot;checkUri&quot; =\r\n      value=3D&quot;True&quot; /&gt;\n&gt; &gt; &gt; \t&lt;property name=3D&quot;checkOutlinks&quot;  value=3D&quot;F=\r\nalse&quot; /&gt;\n&gt; &gt; &gt; \t&lt;property name=3D&quot;rotationDigits&quot; value=3D&quot;10&quot; /&gt;\n&gt; &gt; &gt; \t&lt;p=\r\nroperty name=3D&quot;crawlerCount&quot;   value=3D&quot;2&quot; /&gt;\n&gt; &gt; &gt;   &lt;/bean&gt;\n&gt; &gt; &gt; \n&gt; &gt; &gt;=\r\n \n&gt; &gt; &gt; and this definition on machine #2 (only change was local-name value=\r\n):\n&gt; &gt; &gt; \n&gt; &gt; &gt;   &lt;bean id=3D&quot;hashCrawlMapperProcessor&quot; class=3D&quot;org.archiv=\r\ne.crawler.processor.HashCrawlMapper&quot;&gt;\n&gt; &gt; &gt;  \t&lt;property name=3D&quot;localName&quot; =\r\n     value=3D&quot;1&quot; /&gt;\n&gt; &gt; &gt; \t&lt;property name=3D&quot;diversionDir&quot;   value=3D&quot;diver=\r\nsions&quot; /&gt;\n&gt; &gt; &gt; \t&lt;property name=3D&quot;checkUri&quot;       value=3D&quot;True&quot; /&gt;\n&gt; &gt; &gt; =\r\n\t&lt;property name=3D&quot;checkOutlinks&quot;  value=3D&quot;False&quot; /&gt;\n&gt; &gt; &gt; \t&lt;property name=\r\n=3D&quot;rotationDigits&quot; value=3D&quot;10&quot; /&gt;\n&gt; &gt; &gt; \t&lt;property name=3D&quot;crawlerCount&quot; =\r\n  value=3D&quot;2&quot; /&gt;\n&gt; &gt; &gt;   &lt;/bean&gt;\n&gt; &gt; &gt; \n&gt; &gt; &gt; Then I added in call to hashC=\r\nrawlMapperProcessor in the candidateProcessors chain.\n&gt; &gt; &gt; \n&gt; &gt; &gt;  &lt;!-- no=\r\nw, processors are assembled into ordered CandidateChain bean --&gt;\n&gt; &gt; &gt;  &lt;be=\r\nan id=3D&quot;candidateProcessors&quot; class=3D&quot;org.archive.modules.CandidateChain&quot;&gt;=\r\n\n&gt; &gt; &gt;   &lt;property name=3D&quot;processors&quot;&gt;\n&gt; &gt; &gt;    &lt;list&gt;\n&gt; &gt; &gt;     &lt;!-- appl=\r\ny scoping rules to each individual candidate URI... --&gt;\n&gt; &gt; &gt;     &lt;ref bean=\r\n=3D&quot;candidateScoper&quot;/&gt;\n&gt; &gt; &gt;     &lt;!-- check every URI discovered even befor=\r\ne it is ever enqueued --&gt;\n&gt; &gt; &gt;     &lt;ref bean=3D&quot;hashCrawlMapperProcessor&quot;/=\r\n&gt;\n&gt; &gt; &gt; \n&gt; &gt; &gt;     &lt;!-- ...then prepare those ACCEPTed to be enqueued to fr=\r\nontier. --&gt;\n&gt; &gt; &gt;     &lt;ref bean=3D&quot;preparer&quot;/&gt;\n&gt; &gt; &gt;    &lt;/list&gt;\n&gt; &gt; &gt;   &lt;/p=\r\nroperty&gt;\n&gt; &gt; &gt;  &lt;/bean&gt;\n&gt; &gt; &gt; \n&gt; &gt; &gt; and a call to hashCrawlMapperProcessor=\r\n in the FetchChain\n&gt; &gt; &gt; \n&gt; &gt; &gt;  &lt;!-- now, processors are assembled into or=\r\ndered FetchChain bean --&gt;\n&gt; &gt; &gt;  &lt;bean id=3D&quot;fetchProcessors&quot; class=3D&quot;org.=\r\narchive.modules.FetchChain&quot;&gt;\n&gt; &gt; &gt;   &lt;property name=3D&quot;processors&quot;&gt;\n&gt; &gt; &gt;  =\r\n  &lt;list&gt;\n&gt; &gt; &gt; \n&gt; &gt; &gt;     &lt;!-- re-check scope, if so enabled... --&gt;\n&gt; &gt; &gt;  =\r\n   &lt;ref bean=3D&quot;preselector&quot;/&gt;\n&gt; &gt; &gt; \n&gt; &gt; &gt;     &lt;ref bean=3D&quot;hashCrawlMappe=\r\nrProcessor&quot;/&gt;\n&gt; &gt; &gt; \n&gt; &gt; &gt; .\n&gt; &gt; &gt; .\n&gt; &gt; &gt; .\n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; \n&gt; &gt; &gt; --D=\r\navid\n&gt; &gt; &gt; \n&gt; &gt; &gt; --- In archive-crawler@yahoogroups.com, &quot;david_pane1&quot; &lt;dp=\r\nane@&gt; wrote:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; I am new to using Heritrix 3 and have only lim=\r\nited experience with H1.  I would like to setup H3 on two (maybe more in th=\r\ne future) machines for a distributed crawl.  I would also like to apply the=\r\n HashCrawlMapper to the processing chains so the URIs are shared between th=\r\ne two crawlers. \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Although there are discussions about mult=\r\niple machine crawls and the use of HashCrawlMapper, I could not find specif=\r\nics on the setup of this (i.e even an example crawler-beans.cxml with a def=\r\nault configuration).   I understand that both crawlers should have the same=\r\n configuration.  However, how do you assign a crawler/node name to each so =\r\nthat the HashCrawlMapper can assign URIs and each crawler understands which=\r\n ones to crawl.?\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Additionally, when attempting to define a=\r\n name bean for the HashCrawlMapper I am unclear on how to identify the avai=\r\nlable property names and values.  (And this is true for any bean that is no=\r\nt clearly defined as the default crawler-beans.cxml.)\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; I un=\r\nderstand that the customization of the configuration for optimal performanc=\r\ne may take many iterations, but can anyone help me define the initial confi=\r\nguration of a two crawler/machine system which would work as a distributed =\r\ncrawl.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Thank you,\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; -David\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; =\r\n&gt;\n&gt;\n\n\n\n"}}