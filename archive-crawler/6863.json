{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"BD-R5Z4rphnt9yiHOixAf0rbnJwfAfgpD7HZYUaj5WBiACzsNKB-P7p2ZD1t1KDg1jnfe1NztdCxXd3lpURpUuCOuTHuqbE","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Flushing crawl.log","postDate":"1291659388","msgId":6863,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRDRkQyODdDLjgwOTA4MDFAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDRDRjNFOEVGLjMwNjAzMDVAYXJjaGl2ZS5vcmc+","referencesHeader":"PGljdnM3dCtpdG1vQGVHcm91cHMuY29tPiA8NENGM0U4RUYuMzA2MDMwNUBhcmNoaXZlLm9yZz4="},"prevInTopic":6835,"nextInTopic":6864,"prevInTime":6862,"nextInTime":6864,"topicId":6834,"numMessagesInTopic":4,"msgSnippet":"A followup question: Are you watching the crawl.log to monitor progress only through the web interface, or through an outside tool? I ask because one mixed","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 78622 invoked from network); 6 Dec 2010 18:16:30 -0000\r\nX-Received: from unknown (66.196.94.107)\n  by m15.grp.re1.yahoo.com with QMQP; 6 Dec 2010 18:16:30 -0000\r\nX-Received: from unknown (HELO relay02.pair.com) (209.68.5.16)\n  by mta3.grp.re1.yahoo.com with SMTP; 6 Dec 2010 18:16:30 -0000\r\nX-Received: (qmail 5489 invoked by uid 0); 6 Dec 2010 18:16:29 -0000\r\nX-Received: from 208.70.27.190 (HELO silverbook.local) (208.70.27.190)\n  by relay02.pair.com with SMTP; 6 Dec 2010 18:16:29 -0000\r\nX-pair-Authenticated: 208.70.27.190\r\nMessage-ID: &lt;4CFD287C.8090801@...&gt;\r\nDate: Mon, 06 Dec 2010 10:16:28 -0800\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.6; en-US; rv:1.9.2.12) Gecko/20101027 Thunderbird/3.1.6\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: kstn4321 &lt;kasatani@...&gt;\r\nReferences: &lt;icvs7t+itmo@...&gt; &lt;4CF3E8EF.3060305@...&gt;\r\nIn-Reply-To: &lt;4CF3E8EF.3060305@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Flushing crawl.log\r\nX-Yahoo-Group-Post: member; u=137285340; y=U6Dk5sSXZc6sj9P7vQT6udzv8GIDv9mjN9JSRsPMHInz\r\nX-Yahoo-Profile: gojomo\r\n\r\nA followup question:\n\nAre you watching the crawl.log to monitor progress only through the web \ninterface, or through an outside tool?\n\nI ask because one mixed approach might be to force a flush on the logs \non every interaction with the web UI. Then, the web UI will always see \nlogs up to the latest line, but when not being watched the logs would \nflush less frequently.\n\n- Gordon @ IA\n\nOn 11/29/10 9:54 AM, Gordon Mohr wrote:\n&gt; Good catch; the side-effects of this batching on monitoring a crawl\n&gt; through crawl.log were unintended. We&#39;ll probably roll this back, or\n&gt; figure some other way to have line-by-line resolution on the tail of the\n&gt; crawl.log even if writing is batched.\n&gt;\n&gt; FYI, there have been a number of large changes on SVN TRUNK (-SNAPSHOT)\n&gt; related to performance experiments, and more are coming -- so even\n&gt; moreso than usual, if you&#39;re working with a build directly from SVN or\n&gt; the developer build box: keep an eye out for anomalies, beware of new\n&gt; bugs and regressions, and let us know via this list or the JIRA issue\n&gt; system of any problems you encounter.\n&gt;\n&gt; - Gordon @ IA\n&gt;\n&gt; On 11/29/10 1:37 AM, kstn4321 wrote:\n&gt;&gt; Hello,\n&gt;&gt;\n&gt;&gt; I am using Heritrix 3.0.1-SNAPSHOT and found that it now doesn&#39;t flush the logs very frequently, which makes it hard to watch crawl.log to see if the crawling is going well.\n&gt;&gt;\n&gt;&gt; The corresponding code seems to be flush() method in GenerationFileHandler.java which was added in r7012.\n&gt;&gt; I know that is was added to improve performance, but it makes me very hard to test the crawl settings. Is it possible to revert this change or make it configurable so that you can flush every X records instead of the hard-coded 100?\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; ------------------------------------\n&gt;&gt;\n&gt;&gt; Yahoo! Groups Links\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;\n&gt;\n&gt; ------------------------------------\n&gt;\n&gt; Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n\n"}}