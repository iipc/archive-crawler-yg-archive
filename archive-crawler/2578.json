{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr (archive.org)","from":"&quot;Gordon Mohr (archive.org)&quot; &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"KK0AJJfvRbjOQqsSEMcBm7AUpJEoX6eADPdHhRylnNGno_gV4A_NXRGAHg0ZZWsrpV7G3W2K-3-0ltCgCHDvImi364Gxeq8cxdYmNa_9wno_Uxl3sUWv","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Politeness proposal, and CrawlHost class","postDate":"1138044539","msgId":2578,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQzRDUyRTdCLjIwOTA1MDVAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDQzRDEzRDU5LjgwOTA3MDBAbWV0YWNhcnRhLmNvbT4=","referencesHeader":"PDQzRDEzRDU5LjgwOTA3MDBAbWV0YWNhcnRhLmNvbT4="},"prevInTopic":2574,"nextInTopic":2580,"prevInTime":2577,"nextInTime":2579,"topicId":2574,"numMessagesInTopic":5,"msgSnippet":"... CrawlHost instances are managed by the ServerCache -- which uses a SoftReference-based scheme to let unreferenced CrawlHost instances leave main memory,","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 81185 invoked from network); 23 Jan 2006 19:32:05 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m9.grp.scd.yahoo.com with QMQP; 23 Jan 2006 19:32:05 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (207.241.224.171)\n  by mta4.grp.scd.yahoo.com with SMTP; 23 Jan 2006 19:32:05 -0000\r\nReceived: (qmail 5807 invoked by uid 100); 23 Jan 2006 19:23:12 -0000\r\nReceived: from adsl-71-130-102-78.dsl.pltn13.pacbell.net (HELO ?192.168.1.10?) (gojomo@...@71.130.102.78)\n  by mail-dev.archive.org with SMTP; 23 Jan 2006 19:23:12 -0000\r\nMessage-ID: &lt;43D52E7B.2090505@...&gt;\r\nDate: Mon, 23 Jan 2006 11:28:59 -0800\r\nUser-Agent: Mozilla Thunderbird 1.0.7-1.1.fc3 (X11/20050929)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;43D13D59.8090700@...&gt;\r\nIn-Reply-To: &lt;43D13D59.8090700@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=-84.0 required=7.0 tests=AWL,USER_IN_WHITELIST \n\tautolearn=no version=2.63\r\nX-eGroups-Msg-Info: 2:12:4:0\r\nFrom: &quot;Gordon Mohr (archive.org)&quot; &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Politeness proposal, and CrawlHost class\r\nX-Yahoo-Group-Post: member; u=137285340; y=ikzofUTxOyhm9M8PSqlT-0bLiaBSTuDA1g9A41vWRc9U\r\nX-Yahoo-Profile: gojomo\r\n\r\nKarl Wright wrote:\n&gt; Hi,\n&gt; \n&gt; We encountered a new politeness complaint recently.  Basically, the \n&gt; proprietor noticed our crawl not because of excessive bandwidth \n&gt; consumption or even number of hits, but because we just continued to \n&gt; steadily read documents over 4 days.\n&gt; \n&gt; It seems like it might be therefore a good idea to have a new politeness \n&gt; parameter set which would limit the total fetches in a specified period \n&gt; of time.  I&#39;m looking for advice on implementing such a politeness feature.\n&gt; \n&gt; The problem basically is where the fetch statistics over the last n days \n&gt; should be kept.  The CrawlHost class seems an obvious choice.  However, \n&gt; I believe that this class&#39; size is a major determiner of the total \n&gt; amount of memory Heritrix requires for a crawl.  Is this true?  Or, if I \n&gt; made CrawlHost significantly larger, should I expect there to be little \n&gt; impact on the memory requirements of the crawler?\n\nCrawlHost instances are managed by the ServerCache -- which uses a\nSoftReference-based scheme to let unreferenced CrawlHost instances\nleave main memory, and only brings them back when they are again\nneeded.\n\nSo, you don&#39;t need to worry too much about their instance sizes. The\nsame goes for CrawlServer instances -- which exist one per host+port\n(and cache robots info), as opposed to CrawlHosts which exist one per\nhostname (and cache DNS info).\n\nAre you sure the target site&#39;s needs can&#39;t be met simply by increasing\nthe existing politeness delays? While those settings don&#39;t offer a\nstrict documents-per-period quota, they do offer enough flexibility to\nreduce the number of documents fetched by any desired factor.\n\nFor example, doubling the &#39;delay-factor&#39;, &#39;min-delay-ms&#39;, and\n&#39;max-delay-ms&#39; settings should roughly cut in half the number of\nrequests against a site.\n\n(I presume that it&#39;s generally better to space requests out evenly, rather\nthan pulse on and off. That is, if you&#39;re going to hit a site 4K times\nover a four-day period, it&#39;s be better to do 1K a day, roughly 40 every\nhour, than to do 2K every other day, and 0 on the off days.)\n\nThe key method for including alternate information about politeness\ndelays is AbstractFrontier.politenessDelayFor(). Considering your\nneed, this method could be changed to look inside the CrawlURI to\nsee if an earlier step/Processor had already calculated a delay, and\nuse that rather than the default calculation. That would make it\neasier for custom delays to be effected without editting/overriding\nthe core Frontier code. If you need this change, let us know and I&#39;ll\nlook into the possibility further.\n\nHope this helps,\n\n- Gordon @ IA\n\n"}}