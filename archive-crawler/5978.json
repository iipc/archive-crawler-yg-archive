{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137477665,"authorName":"igor@archive.org","from":"igor@...","profile":"iranitovic","replyTo":"LIST","senderId":"IeMw_YYSyEHyNd73HwRLzAJpJmdviTdPA7donyGvalZ15tWF37908Lu7iua99UNl-gAdz9r6TA","spamInfo":{"isSpam":false,"reason":"3"},"subject":"Re: [archive-crawler] Can I split seeds for a HashCrawlMapper      crawl?","postDate":"1250126477","msgId":5978,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDYxMTA1LjM4Ljk5LjQyLjI0NC4xMjUwMTI2NDc3LnNxdWlycmVsQG1haWwuYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGg1djBuMitlcXRyQGVHcm91cHMuY29tPg==","referencesHeader":"PGg1djBuMitlcXRyQGVHcm91cHMuY29tPg=="},"prevInTopic":5976,"nextInTopic":5982,"prevInTime":5977,"nextInTime":5979,"topicId":5971,"numMessagesInTopic":8,"msgSnippet":"Hi Joe, In the past I used to this without splitting the seeds. I used two identical HashCrawlMapper processors: one before the preselector and one after the","rawEmail":"Return-Path: &lt;igor@...&gt;\r\nX-Sender: igor@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 26427 invoked from network); 13 Aug 2009 01:21:55 -0000\r\nX-Received: from unknown (69.147.108.202)\n  by m5.grp.re1.yahoo.com with QMQP; 13 Aug 2009 01:21:55 -0000\r\nX-Received: from unknown (HELO mail.archive.org) (207.241.231.239)\n  by mta3.grp.re1.yahoo.com with SMTP; 13 Aug 2009 01:21:55 -0000\r\nX-Received: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id 33F3328A65C\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Wed, 12 Aug 2009 18:21:25 -0700 (PDT)\r\nX-Received: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id Yoqp6-QVd+T8 for &lt;archive-crawler@yahoogroups.com&gt;;\n\tWed, 12 Aug 2009 18:21:17 -0700 (PDT)\r\nX-Received: from mail.archive.org (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id 0B32A28A64F\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Wed, 12 Aug 2009 18:21:17 -0700 (PDT)\r\nX-Received: from 38.99.42.244\n        (SquirrelMail authenticated user igor@...)\n        by mail.archive.org with HTTP;\n        Wed, 12 Aug 2009 18:21:17 -0700 (PDT)\r\nMessage-ID: &lt;61105.38.99.42.244.1250126477.squirrel@...&gt;\r\nIn-Reply-To: &lt;h5v0n2+eqtr@...&gt;\r\nReferences: &lt;h5v0n2+eqtr@...&gt;\r\nDate: Wed, 12 Aug 2009 18:21:17 -0700 (PDT)\r\nTo: archive-crawler@yahoogroups.com\r\nUser-Agent: SquirrelMail/1.4.10a\r\nMIME-Version: 1.0\r\nContent-Type: text/plain;charset=iso-8859-1\r\nContent-Transfer-Encoding: 8bit\r\nX-Priority: 3 (Normal)\r\nImportance: Normal\r\nX-eGroups-Msg-Info: 2:3:4:0:0\r\nFrom: igor@...\r\nSubject: Re: [archive-crawler] Can I split seeds for a HashCrawlMapper \n     crawl?\r\nX-Yahoo-Group-Post: member; u=137477665; y=nbuf2qxWXwDLb7JkUPo1_ByXHClvglQ7kIOB2s9j2p79xDvXIg\r\nX-Yahoo-Profile: iranitovic\r\n\r\nHi Joe,\n\nIn the past I used to this without splitting the seeds. I used two\nidentical HashCrawlMapper processors: one before the preselector and one\nafter the link scoper.\n\nThis way, each crawling node schedules all of the seeds but crawls only\nones defined by the HashCrawlMapper. What I liked about this is that all\nof the nodes will have the same scope (if based on seeds) which can handy.\n\nHope this helps.\ni.\n\n\n&gt; I&#39;m using Heritrix 1.14.3.\n&gt;\n&gt; Let&#39;s say I have\n&gt; 1. one big seed list consisting of 1MM seeds.\n&gt; 2. 2 crawler instances to implement HashCrawlMapper.\n&gt; 3. The crawl scope is domain + 1 (implemented through OnDomainDecideRule\n&gt; with &quot;seeds-as-surt-prefixes&quot;==true and &quot;also-check-via&quot;==true).\n&gt;\n&gt; Can I split the seeds using the same HashCrawlMapper rule so that each\n&gt; crawler would only get seeds that are within its scope? Would there be any\n&gt; difference if I use the same 1MM seeds for both crawlers?\n&gt;\n&gt;\n&gt; The reason why I want to do this is, I have 20MM seeds among 12 crawlers.\n&gt; I&#39;ve tested with one instance handling 20MM seeds and it doesn&#39;t seem to\n&gt; work. If I can split the seeds so that each cralwer starts with URLs that\n&gt; belong to themselves it should make the crawl process easier....\n&gt;\n&gt; Thanks,\n&gt; -Joe\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------\n&gt;\n&gt; Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n&gt;\n\n\n\n"}}