{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"stack","from":"stack &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"Y9cUFRkTg0kLGk8eSyLsVy-CJ0fR7wyPvCdR7sknEsXoSWJreBndmejSDXADUYdjKmcryrh77vredba11K889A","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Heritrix 1.4 can&#39;t launch job - Fatal InitializationException","postDate":"1124318733","msgId":2120,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQzMDNCRTBELjUwMzA4MDJAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDAwZjUwMWM1OWNkZSQwNmQ3YjVjMCRiZDVlNmU5NEBNQzE1MjA4Pg==","referencesHeader":"PDAwODAwMWM1OWMzNiRmMWFlZjdmMCRiZDVlNmU5NEBNQzE1MjA4PiA8NDJGN0ExNDkuNzAxMDcwNkBhcmNoaXZlLm9yZz4gPDAwZjUwMWM1OWNkZSQwNmQ3YjVjMCRiZDVlNmU5NEBNQzE1MjA4Pg=="},"prevInTopic":2097,"nextInTopic":2210,"prevInTime":2119,"nextInTime":2121,"topicId":2087,"numMessagesInTopic":6,"msgSnippet":"... Whats the version on your IBM JVM (Is it the latest?)  Would you mind trying a sun jvm?  I ve not seen this exception before.  Its a strange complaint from","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 41918 invoked from network); 17 Aug 2005 22:54:50 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m35.grp.scd.yahoo.com with QMQP; 17 Aug 2005 22:54:50 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (207.241.224.172)\n  by mta1.grp.scd.yahoo.com with SMTP; 17 Aug 2005 22:54:50 -0000\r\nReceived: (qmail 17494 invoked by uid 100); 17 Aug 2005 22:54:49 -0000\r\nReceived: from adsl-71-130-102-78.dsl.pltn13.pacbell.net (HELO ?192.168.1.8?) (stack@...@71.130.102.78)\n  by mail-dev.archive.org with SMTP; 17 Aug 2005 22:54:49 -0000\r\nMessage-ID: &lt;4303BE0D.5030802@...&gt;\r\nDate: Wed, 17 Aug 2005 15:45:33 -0700\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.7.8) Gecko/20050513 Debian/1.7.8-1\r\nX-Accept-Language: en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;008001c59c36$f1aef7f0$bd5e6e94@MC15208&gt; &lt;42F7A149.7010706@...&gt; &lt;00f501c59cde$06d7b5c0$bd5e6e94@MC15208&gt;\r\nIn-Reply-To: &lt;00f501c59cde$06d7b5c0$bd5e6e94@MC15208&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=-88.5 required=7.0 tests=AWL,HOT_NASTY,HTML_40_50,\n\tHTML_MESSAGE,PORN_4,USER_IN_WHITELIST autolearn=no version=2.63\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] Heritrix 1.4 can&#39;t launch job - Fatal InitializationException\r\nX-Yahoo-Group-Post: member; u=168599281; y=GHCP4OYZBw5AHgOwBwOKbbX5OWcMbIMPVK3BzmLNSI81ylLr2sXpMZL4\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\nCharles Foetz wrote:\n\n&gt; Note: This mail contains the stack trace and I&#39;ve attached the \n&gt; order.xml file too\n&gt;  \n&gt; I&#39;m running J2RE 1.4.2 IBM on SuSE Enterprise Server V.9\n&gt; The job ends right away and all my log files are 0 bytes\n\nWhats the version on your IBM JVM (Is it the latest?)  Would you mind \ntrying a sun jvm?  I&#39;ve not seen this exception before.  Its a strange \ncomplaint from the Reference class internals about our passing of a null \nreference queue but the queue shouldn&#39;t be null; its a data member that \nshould be setup on initialized of the surrounding CachedBdbMap class.\n\nYours,\nSt.Ack\n\n&gt;  \n&gt;  \n&gt; ----- Original Message -----\n&gt;\n&gt;     *From:* stack &lt;mailto:stack@...&gt;\n&gt;     *To:* archive-crawler@yahoogroups.com\n&gt;     &lt;mailto:archive-crawler@yahoogroups.com&gt;\n&gt;     *Sent:* Monday, August 08, 2005 8:15 PM\n&gt;     *Subject:* Re: [archive-crawler] Heritrix 1.4 can&#39;t launch job -\n&gt;     Fatal InitializationException\n&gt;\n&gt;      \n&gt;     Charles Foetz wrote:\n&gt;\n&gt;     &gt; Hello fellow crawlers,\n&gt;     &gt; \n&gt;     &gt; At Luxembourg&#39;s national library we&#39;re taking our first steps in\n&gt;     &gt; crawling. I&#39;m looking at this myself at the moment, I&#39;ve managed\n&gt;     &gt; to successfully crawl, store, search, retrieve and display some\n&gt;     sites\n&gt;     &gt; as a prototype, using H1.2 for the crawling part. When I installed\n&gt;     &gt; H1.4 a month ago, it didn&#39;t work and I assumed an interference\n&gt;     issue\n&gt;     &gt; with 1.2 (an environment variable or something), but after a new\n&gt;     clean\n&gt;     &gt; server installation (re-installing SuSe Enterprise 9 and then\n&gt;     H1.4) I\n&gt;     &gt; get the same error as soon as I try the first default job (using\n&gt;     one\n&gt;     &gt; seed, having set the &quot;user-agent&quot; and &quot;from&quot; fields correctly):\n&gt;     &gt; \n&gt;     &gt; Symptoms:\n&gt;     &gt; \n&gt;     &gt; - The job completes almost as soon as it starts,\n&gt;\n&gt;     This sounds like this issue:\n&gt;     http://crawler.archive.org/faq.html#windowsstart.  Do you have\n&gt;     your own\n&gt;     wrapper script starting up Heritrix or are you using stock\n&gt;     $HERITRIX_HOME/bin/heritrix?\n&gt;\n&gt; I don&#39;t use any wrapper script, I start it with\n&gt;  \n&gt; export HERITRIX_HOME=/usr/local/heritrix-1.4.0/\n&gt; $HERITRIX_HOME/bin/heritrix -p 8084\n&gt;  \n&gt; (I&#39;ve also tried without the -port option and ran it on 8080 - same \n&gt; results)\n&gt;\n&gt;\n&gt;     &gt; - &quot;No statistics associated with job&quot; in the reports\n&gt;     &gt; - No page is crawled or archived (specified arcs folder isn&#39;t even\n&gt;     &gt; created)\n&gt;     &gt; - on the Jobs tab under &quot;Completed jobs&quot; I read &quot;Could not\n&gt;     launch job\n&gt;     &gt; - Fatal initializationException - A fatal InitializationException\n&gt;     &gt; occured when loading job:Unable to setup crawl modules:\n&gt;     &gt; java.lang.NullPointerException: Reference Queue cannot be null&quot;.\n&gt;\n&gt;     May we see the full stack trace for the exception?  Might give us\n&gt;     a clue\n&gt;     (Is this being done on an NFS mount?  If so, try running on a\n&gt;     local disk).\n&gt;\n&gt; Here&#39;s the stack track:\n&gt; ----------------------------------\n&gt; ----------------------------------\n&gt;  \n&gt; Unable to setup crawl modules:\n&gt; java.lang.NullPointerException: Reference queue cannot\n&gt; be null\n&gt;\n&gt; Associated Throwable: java.lang.NullPointerException:\n&gt; Reference queue cannot be null\n&gt;\n&gt;   Message:\n&gt;     Reference queue cannot be null\n&gt;\n&gt;   Stacktrace:\n&gt; java.lang.NullPointerException: Reference queue cannot\n&gt; be null\n&gt; at java.lang.ref.Reference.(Reference.java:226)\n&gt; at\n&gt; java.lang.ref.PhantomReference.(PhantomReference.java:72)\n&gt; at\n&gt; org.archive.util.CachedBdbMap$PhantomEntry.(CachedBdbMap.java:463)\n&gt; at\n&gt; org.archive.util.CachedBdbMap$SoftEntry.(CachedBdbMap.java:497)\n&gt; at\n&gt; org.archive.util.CachedBdbMap.put(CachedBdbMap.java:378)\n&gt; at\n&gt; org.archive.crawler.frontier.BdbFrontier.getQueueFor(BdbFrontier.java:475)\n&gt; at\n&gt; org.archive.crawler.frontier.BdbFrontier.sendToQueue(BdbFrontier.java:349)\n&gt; at\n&gt; org.archive.crawler.frontier.BdbFrontier.receive(BdbFrontier.java:338)\n&gt; at\n&gt; org.archive.crawler.util.BdbUriUniqFilter.add(BdbUriUniqFilter.java:265)\n&gt; at\n&gt; org.archive.crawler.util.BdbUriUniqFilter.add(BdbUriUniqFilter.java:224)\n&gt; at\n&gt; org.archive.crawler.frontier.BdbFrontier.schedule(BdbFrontier.java:321)\n&gt; at\n&gt; org.archive.crawler.frontier.AbstractFrontier.loadSeeds(AbstractFrontier.java:412)\n&gt; at\n&gt; org.archive.crawler.frontier.BdbFrontier.initialize(BdbFrontier.java:244)\n&gt; at\n&gt; org.archive.crawler.framework.CrawlController.setupCrawlModules(CrawlController.java:572)\n&gt; at\n&gt; org.archive.crawler.framework.CrawlController.initialize(CrawlController.java:336)\n&gt; at\n&gt; org.archive.crawler.admin.CrawlJobHandler.startNextJobInternal(CrawlJobHandler.java:1050)\n&gt; at\n&gt; org.archive.crawler.admin.CrawlJobHandler$2.run(CrawlJobHandler.java:1016)\n&gt; at java.lang.Thread.run(Thread.java:567)\n&gt;\n&gt;\n&gt;     &gt; \n&gt;     &gt; What am I missing? Does any part of the job initialzation differ\n&gt;     &gt; signigicantly from H1.2?\n&gt;     &gt; \n&gt;\n&gt;     I&#39;d doubt you&#39;re missing anything.  1.4 should run just like 1.2.\n&gt;     Yours,\n&gt;     St.Ack\n&gt;\n&gt;     &gt; Any ideas or hints greatly appreciated.\n&gt;     &gt; \n&gt;     &gt; Charlie\n&gt;     &gt;\n&gt;\n&gt;\n&gt; ------------------------------------------------------------------------\n&gt; YAHOO! GROUPS LINKS\n&gt;\n&gt;     *  Visit your group &quot;archive-crawler\n&gt;       &lt;http://groups.yahoo.com/group/archive-crawler&gt;&quot; on the web.\n&gt;        \n&gt;     *  To unsubscribe from this group, send an email to:\n&gt;        archive-crawler-unsubscribe@yahoogroups.com\n&gt;       &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;        \n&gt;     *  Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;.\n&gt;\n&gt;\n&gt; ------------------------------------------------------------------------\n&gt;\n&gt;------------------------------------------------------------------------\n&gt;\n&gt;&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;crawl-order xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;heritrix_settings.xsd&quot;&gt;\n&gt;  &lt;meta&gt;\n&gt;    &lt;name&gt;TestRun&lt;/name&gt;\n&gt;    &lt;description&gt;Default Profile&lt;/description&gt;\n&gt;    &lt;operator&gt;Admin&lt;/operator&gt;\n&gt;    &lt;organization&gt;&lt;/organization&gt;\n&gt;    &lt;audience&gt;&lt;/audience&gt;\n&gt;    &lt;date&gt;20050809120352&lt;/date&gt;\n&gt;  &lt;/meta&gt;\n&gt;  &lt;controller&gt;\n&gt;    &lt;string name=&quot;settings-directory&quot;&gt;settings&lt;/string&gt;\n&gt;    &lt;string name=&quot;disk-path&quot;&gt;&lt;/string&gt;\n&gt;    &lt;string name=&quot;logs-path&quot;&gt;logs&lt;/string&gt;\n&gt;    &lt;string name=&quot;checkpoints-path&quot;&gt;checkpoints&lt;/string&gt;\n&gt;    &lt;string name=&quot;state-path&quot;&gt;state&lt;/string&gt;\n&gt;    &lt;string name=&quot;scratch-path&quot;&gt;scratch&lt;/string&gt;\n&gt;    &lt;long name=&quot;max-bytes-download&quot;&gt;0&lt;/long&gt;\n&gt;    &lt;long name=&quot;max-document-download&quot;&gt;0&lt;/long&gt;\n&gt;    &lt;long name=&quot;max-time-sec&quot;&gt;0&lt;/long&gt;\n&gt;    &lt;integer name=&quot;max-toe-threads&quot;&gt;50&lt;/integer&gt;\n&gt;    &lt;integer name=&quot;recorder-out-buffer-bytes&quot;&gt;4096&lt;/integer&gt;\n&gt;    &lt;integer name=&quot;recorder-in-buffer-bytes&quot;&gt;65536&lt;/integer&gt;\n&gt;    &lt;integer name=&quot;bdb-cache-percent&quot;&gt;0&lt;/integer&gt;\n&gt;    &lt;newObject name=&quot;scope&quot; class=&quot;org.archive.crawler.scope.DomainScope&quot;&gt;\n&gt;      &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;      &lt;string name=&quot;seedsfile&quot;&gt;seeds.txt&lt;/string&gt;\n&gt;      &lt;integer name=&quot;max-link-hops&quot;&gt;25&lt;/integer&gt;\n&gt;      &lt;integer name=&quot;max-trans-hops&quot;&gt;5&lt;/integer&gt;\n&gt;      &lt;newObject name=&quot;exclude-filter&quot; class=&quot;org.archive.crawler.filter.OrFilter&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;boolean name=&quot;if-matches-return&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;          &lt;newObject name=&quot;pathdepth&quot; class=&quot;org.archive.crawler.filter.PathDepthFilter&quot;&gt;\n&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;            &lt;integer name=&quot;max-path-depth&quot;&gt;20&lt;/integer&gt;\n&gt;            &lt;boolean name=&quot;path-less-or-equal-return&quot;&gt;false&lt;/boolean&gt;\n&gt;          &lt;/newObject&gt;\n&gt;          &lt;newObject name=&quot;pathologicalpath&quot; class=&quot;org.archive.crawler.filter.PathologicalPathFilter&quot;&gt;\n&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;            &lt;integer name=&quot;repetitions&quot;&gt;3&lt;/integer&gt;\n&gt;          &lt;/newObject&gt;\n&gt;        &lt;/map&gt;\n&gt;      &lt;/newObject&gt;\n&gt;      &lt;newObject name=&quot;additionalScopeFocus&quot; class=&quot;org.archive.crawler.filter.FilePatternFilter&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;boolean name=&quot;if-match-return&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;string name=&quot;use-default-patterns&quot;&gt;All&lt;/string&gt;\n&gt;        &lt;string name=&quot;regexp&quot;&gt;&lt;/string&gt;\n&gt;      &lt;/newObject&gt;\n&gt;      &lt;newObject name=&quot;transitiveFilter&quot; class=&quot;org.archive.crawler.filter.TransclusionFilter&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;integer name=&quot;max-speculative-hops&quot;&gt;1&lt;/integer&gt;\n&gt;        &lt;integer name=&quot;max-referral-hops&quot;&gt;-1&lt;/integer&gt;\n&gt;        &lt;integer name=&quot;max-embed-hops&quot;&gt;-1&lt;/integer&gt;\n&gt;      &lt;/newObject&gt;\n&gt;    &lt;/newObject&gt;\n&gt;    &lt;map name=&quot;http-headers&quot;&gt;\n&gt;      &lt;string name=&quot;user-agent&quot;&gt;Mozilla/5.0 (compatible; heritrix/1.4.0 +http://www.xxxx.xx&lt;/string&gt;\n&gt;      &lt;string name=&quot;from&quot;&gt;xxxx.xxxx@...&lt;/string&gt;\n&gt;    &lt;/map&gt;\n&gt;    &lt;newObject name=&quot;robots-honoring-policy&quot; class=&quot;org.archive.crawler.datamodel.RobotsHonoringPolicy&quot;&gt;\n&gt;      &lt;string name=&quot;type&quot;&gt;classic&lt;/string&gt;\n&gt;      &lt;boolean name=&quot;masquerade&quot;&gt;false&lt;/boolean&gt;\n&gt;      &lt;text name=&quot;custom-robots&quot;&gt;&lt;/text&gt;\n&gt;      &lt;stringList name=&quot;user-agents&quot;&gt;\n&gt;      &lt;/stringList&gt;\n&gt;    &lt;/newObject&gt;\n&gt;    &lt;newObject name=&quot;frontier&quot; class=&quot;org.archive.crawler.frontier.BdbFrontier&quot;&gt;\n&gt;      &lt;float name=&quot;delay-factor&quot;&gt;5.0&lt;/float&gt;\n&gt;      &lt;integer name=&quot;max-delay-ms&quot;&gt;5000&lt;/integer&gt;\n&gt;      &lt;integer name=&quot;min-delay-ms&quot;&gt;500&lt;/integer&gt;\n&gt;      &lt;integer name=&quot;max-retries&quot;&gt;30&lt;/integer&gt;\n&gt;      &lt;long name=&quot;retry-delay-seconds&quot;&gt;900&lt;/long&gt;\n&gt;      &lt;integer name=&quot;preference-embed-hops&quot;&gt;1&lt;/integer&gt;\n&gt;      &lt;integer name=&quot;total-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt;      &lt;integer name=&quot;max-per-host-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt;      &lt;boolean name=&quot;ip-politeness&quot;&gt;false&lt;/boolean&gt;\n&gt;      &lt;string name=&quot;force-queue-assignment&quot;&gt;&lt;/string&gt;\n&gt;      &lt;boolean name=&quot;pause-at-finish&quot;&gt;false&lt;/boolean&gt;\n&gt;      &lt;boolean name=&quot;hold-queues&quot;&gt;true&lt;/boolean&gt;\n&gt;      &lt;integer name=&quot;balance-replenish-amount&quot;&gt;3000&lt;/integer&gt;\n&gt;      &lt;long name=&quot;queue-total-budget&quot;&gt;-1&lt;/long&gt;\n&gt;      &lt;string name=&quot;cost-policy&quot;&gt;org.archive.crawler.frontier.ZeroCostAssignmentPolicy&lt;/string&gt;\n&gt;    &lt;/newObject&gt;\n&gt;    &lt;map name=&quot;uri-canonicalization-rules&quot;&gt;\n&gt;      &lt;newObject name=&quot;Lowercase&quot; class=&quot;org.archive.crawler.url.canonicalize.LowercaseRule&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;      &lt;/newObject&gt;\n&gt;      &lt;newObject name=&quot;Userinfo&quot; class=&quot;org.archive.crawler.url.canonicalize.StripUserinfoRule&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;      &lt;/newObject&gt;\n&gt;      &lt;newObject name=&quot;WWW&quot; class=&quot;org.archive.crawler.url.canonicalize.StripWWWRule&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;      &lt;/newObject&gt;\n&gt;      &lt;newObject name=&quot;SessionIDs&quot; class=&quot;org.archive.crawler.url.canonicalize.StripSessionIDs&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;      &lt;/newObject&gt;\n&gt;      &lt;newObject name=&quot;QueryStrPrefix&quot; class=&quot;org.archive.crawler.url.canonicalize.FixupQueryStr&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;      &lt;/newObject&gt;\n&gt;    &lt;/map&gt;\n&gt;    &lt;map name=&quot;pre-fetch-processors&quot;&gt;\n&gt;      &lt;newObject name=&quot;Preselector&quot; class=&quot;org.archive.crawler.prefetch.Preselector&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;        &lt;/map&gt;\n&gt;        &lt;boolean name=&quot;recheck-scope&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;boolean name=&quot;block-all&quot;&gt;false&lt;/boolean&gt;\n&gt;        &lt;string name=&quot;block-by-regexp&quot;&gt;&lt;/string&gt;\n&gt;      &lt;/newObject&gt;\n&gt;      &lt;newObject name=&quot;Preprocessor&quot; class=&quot;org.archive.crawler.prefetch.PreconditionEnforcer&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;        &lt;/map&gt;\n&gt;        &lt;integer name=&quot;ip-validity-duration-seconds&quot;&gt;21600&lt;/integer&gt;\n&gt;        &lt;integer name=&quot;robot-validity-duration-seconds&quot;&gt;86400&lt;/integer&gt;\n&gt;      &lt;/newObject&gt;\n&gt;    &lt;/map&gt;\n&gt;    &lt;map name=&quot;fetch-processors&quot;&gt;\n&gt;      &lt;newObject name=&quot;DNS&quot; class=&quot;org.archive.crawler.fetcher.FetchDNS&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;        &lt;/map&gt;\n&gt;        &lt;boolean name=&quot;accept-non-dns-resolves&quot;&gt;false&lt;/boolean&gt;\n&gt;      &lt;/newObject&gt;\n&gt;      &lt;newObject name=&quot;HTTP&quot; class=&quot;org.archive.crawler.fetcher.FetchHTTP&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;        &lt;/map&gt;\n&gt;        &lt;map name=&quot;midfetch-filters&quot;&gt;\n&gt;        &lt;/map&gt;\n&gt;        &lt;integer name=&quot;timeout-seconds&quot;&gt;1200&lt;/integer&gt;\n&gt;        &lt;integer name=&quot;sotimeout-ms&quot;&gt;20000&lt;/integer&gt;\n&gt;        &lt;long name=&quot;max-length-bytes&quot;&gt;0&lt;/long&gt;\n&gt;        &lt;string name=&quot;load-cookies-from-file&quot;&gt;&lt;/string&gt;\n&gt;        &lt;string name=&quot;save-cookies-to-file&quot;&gt;&lt;/string&gt;\n&gt;        &lt;string name=&quot;trust-level&quot;&gt;open&lt;/string&gt;\n&gt;        &lt;stringList name=&quot;accept-headers&quot;&gt;\n&gt;        &lt;/stringList&gt;\n&gt;        &lt;string name=&quot;http-proxy-host&quot;&gt;&lt;/string&gt;\n&gt;        &lt;string name=&quot;http-proxy-port&quot;&gt;&lt;/string&gt;\n&gt;        &lt;string name=&quot;default-encoding&quot;&gt;ISO-8859-1&lt;/string&gt;\n&gt;        &lt;boolean name=&quot;sha1-content&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;boolean name=&quot;send-connection-close&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;boolean name=&quot;send-referer&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;boolean name=&quot;send-range&quot;&gt;false&lt;/boolean&gt;\n&gt;      &lt;/newObject&gt;\n&gt;    &lt;/map&gt;\n&gt;    &lt;map name=&quot;extract-processors&quot;&gt;\n&gt;      &lt;newObject name=&quot;ExtractorHTTP&quot; class=&quot;org.archive.crawler.extractor.ExtractorHTTP&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;        &lt;/map&gt;\n&gt;      &lt;/newObject&gt;\n&gt;      &lt;newObject name=&quot;ExtractorHTML&quot; class=&quot;org.archive.crawler.extractor.ExtractorHTML&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;        &lt;/map&gt;\n&gt;      &lt;/newObject&gt;\n&gt;      &lt;newObject name=&quot;ExtractorCSS&quot; class=&quot;org.archive.crawler.extractor.ExtractorCSS&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;        &lt;/map&gt;\n&gt;      &lt;/newObject&gt;\n&gt;      &lt;newObject name=&quot;ExtractorJS&quot; class=&quot;org.archive.crawler.extractor.ExtractorJS&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;        &lt;/map&gt;\n&gt;      &lt;/newObject&gt;\n&gt;      &lt;newObject name=&quot;ExtractorSWF&quot; class=&quot;org.archive.crawler.extractor.ExtractorSWF&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;        &lt;/map&gt;\n&gt;      &lt;/newObject&gt;\n&gt;    &lt;/map&gt;\n&gt;    &lt;map name=&quot;write-processors&quot;&gt;\n&gt;      &lt;newObject name=&quot;Archiver&quot; class=&quot;org.archive.crawler.writer.ARCWriterProcessor&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;        &lt;/map&gt;\n&gt;        &lt;boolean name=&quot;compress&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;string name=&quot;prefix&quot;&gt;IAH&lt;/string&gt;\n&gt;        &lt;string name=&quot;suffix&quot;&gt;${HOSTNAME}&lt;/string&gt;\n&gt;        &lt;integer name=&quot;max-size-bytes&quot;&gt;100000000&lt;/integer&gt;\n&gt;        &lt;stringList name=&quot;path&quot;&gt;\n&gt;          &lt;string&gt;arcs&lt;/string&gt;\n&gt;        &lt;/stringList&gt;\n&gt;        &lt;integer name=&quot;pool-max-active&quot;&gt;5&lt;/integer&gt;\n&gt;        &lt;integer name=&quot;pool-max-wait&quot;&gt;300000&lt;/integer&gt;\n&gt;        &lt;long name=&quot;total-bytes-to-write&quot;&gt;0&lt;/long&gt;\n&gt;      &lt;/newObject&gt;\n&gt;    &lt;/map&gt;\n&gt;    &lt;map name=&quot;post-processors&quot;&gt;\n&gt;      &lt;newObject name=&quot;Updater&quot; class=&quot;org.archive.crawler.postprocessor.CrawlStateUpdater&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;        &lt;/map&gt;\n&gt;      &lt;/newObject&gt;\n&gt;      &lt;newObject name=&quot;Postselector&quot; class=&quot;org.archive.crawler.postprocessor.Postselector&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;        &lt;/map&gt;\n&gt;        &lt;boolean name=&quot;seed-redirects-new-seed&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;boolean name=&quot;override-logger&quot;&gt;false&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;scope-rejected-uri-log-filters&quot;&gt;\n&gt;        &lt;/map&gt;\n&gt;      &lt;/newObject&gt;\n&gt;    &lt;/map&gt;\n&gt;    &lt;map name=&quot;loggers&quot;&gt;\n&gt;      &lt;newObject name=&quot;crawl-statistics&quot; class=&quot;org.archive.crawler.admin.StatisticsTracker&quot;&gt;\n&gt;        &lt;integer name=&quot;interval-seconds&quot;&gt;20&lt;/integer&gt;\n&gt;      &lt;/newObject&gt;\n&gt;    &lt;/map&gt;\n&gt;    &lt;string name=&quot;recover-path&quot;&gt;&lt;/string&gt;\n&gt;    &lt;boolean name=&quot;recover-retain-failures&quot;&gt;false&lt;/boolean&gt;\n&gt;    &lt;newObject name=&quot;credential-store&quot; class=&quot;org.archive.crawler.datamodel.CredentialStore&quot;&gt;\n&gt;      &lt;map name=&quot;credentials&quot;&gt;\n&gt;      &lt;/map&gt;\n&gt;    &lt;/newObject&gt;\n&gt;  &lt;/controller&gt;\n&gt;&lt;/crawl-order&gt;\n&gt;  \n&gt;\n\n\n"}}