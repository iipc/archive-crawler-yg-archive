{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":509351030,"authorName":"Unreal","from":"&quot;Unreal&quot; &lt;gc76@...&gt;","profile":"grcnj","replyTo":"LIST","senderId":"M8doBSm3_kfST5I5ziWRdVs7HVYMBER13fdH2E2UqApkGGjqFXYP2ClTb_h-Dfy8HElI_T8RrIYmo9vFDG-5","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Crawling forever - vs. nutch","postDate":"1322917383","msgId":7416,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGpiZDZtNys1NW42QGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":7432,"prevInTime":7415,"nextInTime":7417,"topicId":7416,"numMessagesInTopic":2,"msgSnippet":"Hi Hoping someone can shed some light on this. I ran a crawl on imdb.com using nutch and it took just under 4 hours. I tried heritrix 3 and v1 but each so far","rawEmail":"Return-Path: &lt;gc76@...&gt;\r\nX-Sender: gc76@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 22686 invoked from network); 3 Dec 2011 13:03:03 -0000\r\nX-Received: from unknown (98.137.35.160)\n  by m14.grp.sp2.yahoo.com with QMQP; 3 Dec 2011 13:03:03 -0000\r\nX-Received: from unknown (HELO n46b.bullet.mail.sp1.yahoo.com) (66.163.168.160)\n  by mta4.grp.sp2.yahoo.com with SMTP; 3 Dec 2011 13:03:03 -0000\r\nX-Received: from [69.147.65.151] by n46.bullet.mail.sp1.yahoo.com with NNFMP; 03 Dec 2011 13:03:03 -0000\r\nX-Received: from [98.137.34.73] by t5.bullet.mail.sp1.yahoo.com with NNFMP; 03 Dec 2011 13:03:03 -0000\r\nDate: Sat, 03 Dec 2011 13:03:03 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;jbd6m7+55n6@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Unreal&quot; &lt;gc76@...&gt;\r\nSubject: Crawling forever - vs. nutch\r\nX-Yahoo-Group-Post: member; u=509351030; y=9Kcq43vReNVsR1tqZAz5repjIU2DN19kQzPXEOwp2Jk\r\nX-Yahoo-Profile: grcnj\r\n\r\nHi\nHoping someone can shed some light on this. I ran a crawl on imdb.com us=\r\ning nutch and it took just under 4 hours. I tried heritrix 3 and v1 but eac=\r\nh so far have exceeded 24 hours to the point I had to terminate. The reason=\r\n I switched to heritrix is the goal is to test my indexing, and nutch index=\r\ned the crawl to a format I cant use. (need arc)\nI am assuming I still can n=\r\not get my decide rules correct as it appears to be downloading alot of gifs=\r\n no matter where I place the rules. As I type this the crawl report is show=\r\ning 29,000 gifs vs just 6000 txt/html. The ToeThreads report shows data I c=\r\nan not quite understand, here are the first 20 or so lines:\n\nToe threads re=\r\nport - 201112031257\n Job being crawled: imdb\n Number of toe threads in pool=\r\n: 50 (0 active)\n   ToeThread #1\n[ToeThread #1: \n -no CrawlURI- \n    WAITING=\r\n for 6m7s593ms\n    step: ABOUT_TO_GET_URI for 6m7s593ms\n    sun.misc.Unsafe=\r\n.park(Native Method)\n    java.util.concurrent.locks.LockSupport.parkNanos(L=\r\nockSupport.java:226)\n    java.util.concurrent.locks.AbstractQueuedSynchroni=\r\nzer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)\n    ja=\r\nva.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)\n =\r\n   org.archive.crawler.frontier.WorkQueueFrontier.next(WorkQueueFrontier.ja=\r\nva:643)\n    org.archive.crawler.framework.ToeThread.run(ToeThread.java:147)=\r\n\n]\n   ToeThread #2\n[ToeThread #2: \n -no CrawlURI- \n    WAITING for 22m54s29=\r\n6ms\n    step: ABOUT_TO_GET_URI for 22m54s296ms\n    sun.misc.Unsafe.park(Nat=\r\nive Method)\n    java.util.concurrent.locks.LockSupport.parkNanos(LockSuppor=\r\nt.java:226)\n    java.util.concurrent.locks.AbstractQueuedSynchronizer$Condi=\r\ntionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)\n    java.util.c=\r\noncurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)\n    org.ar=\r\nchive.crawler.frontier.WorkQueueFrontier.next(WorkQueueFrontier.java:643)\n =\r\n   org.archive.crawler.framework.ToeThread\n\nMy decide rules look like this:=\r\n\n&lt;newObject name=3D&quot;decide-rules&quot; class=3D&quot;org.archive.crawler.deciderules.=\r\nDecideRuleSequence&quot;&gt;\n        &lt;map name=3D&quot;rules&quot;&gt;\n          &lt;newObject name=\r\n=3D&quot;acceptbyDefault&quot; class=3D&quot;org.archive.crawler.deciderules.AcceptDecideR=\r\nule&quot;&gt;\n          &lt;/newObject&gt;\n          &lt;newObject name=3D&quot;notIMDB&quot; class=3D=\r\n&quot;org.archive.crawler.deciderules.NotMatchesRegExpDecideRule&quot;&gt;\n            &lt;=\r\nstring name=3D&quot;decision&quot;&gt;REJECT&lt;/string&gt;\n            &lt;string name=3D&quot;regexp=\r\n&quot;&gt;.*(imdb.com).*&lt;/string&gt;\n          &lt;/newObject&gt;\n          &lt;newObject name=\r\n=3D&quot;specific&quot; class=3D&quot;org.archive.crawler.deciderules.MatchesRegExpDecideR=\r\nule&quot;&gt;\n            &lt;string name=3D&quot;decision&quot;&gt;REJECT&lt;/string&gt;\n            &lt;st=\r\nring name=3D&quot;regexp&quot;&gt;.*(login|&#92;/register|&#92;/api|&#92;/special|&#92;/click|&#92;/rss).*&lt;/=\r\nstring&gt;\n          &lt;/newObject&gt;\n          &lt;newObject name=3D&quot;notIMG&quot; class=\r\n=3D&quot;org.archive.crawler.deciderules.MatchesFilePatternDecideRule&quot;&gt;\n        =\r\n    &lt;string name=3D&quot;decision&quot;&gt;REJECT&lt;/string&gt;\n            &lt;string name=3D&quot;u=\r\nse-preset-pattern&quot;&gt;Custom&lt;/string&gt;\n            &lt;string name=3D&quot;regexp&quot;&gt;.*(j=\r\npg|png|gif|css|rss|js|doc|pdf|ppt|swf)$&lt;/string&gt;\n          &lt;/newObject&gt;\n   =\r\n       &lt;newObject name=3D&quot;defaultNOimg&quot; class=3D&quot;org.archive.crawler.decide=\r\nrules.MatchesFilePatternDecideRule&quot;&gt;\n            &lt;string name=3D&quot;decision&quot;&gt;=\r\nREJECT&lt;/string&gt;\n            &lt;string name=3D&quot;use-preset-pattern&quot;&gt;Images&lt;/str=\r\ning&gt;\n            &lt;string name=3D&quot;regexp&quot;/&gt;\n          &lt;/newObject&gt;\n        &lt;=\r\n/map&gt;\n      &lt;/newObject&gt;\n\nI&#39;ve tried various orders of this using custom im=\r\nage rejects or the preset, but I still see the image/gif increasing.\n\nCould=\r\n this be the reason for the long crawl time or is it something else. Its my=\r\n first time using this so I am sure the possibilities are endless. \n\nThanks=\r\n!\n\n\n\n\n"}}