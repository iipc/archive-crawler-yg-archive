{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":188703988,"authorName":"Williamson, Mark","from":"&quot;Williamson, Mark&quot; &lt;Mark.Williamson@...&gt;","replyTo":"LIST","senderId":"F-JGCBZbwk0Gzr6jnUKWipR7Vs_dmLaNn1tI-s5Dhe-IJTm4H7oD-1sIqDusQ1-AQOVMH5MCXPRyzvEAdHM79Ww2u5mNSIvyO5vs_aVvby5i","spamInfo":{"isSpam":false,"reason":"0"},"subject":"RE: [archive-crawler] Proxy","postDate":"1089225804","msgId":594,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDM0MzU0MENGODlDMjc3NDI4OUU3RjNDOUVFNEY1REYxMDU1M0E1OUJAbnQtbG9uZXgxLmJsLnVrPg=="},"prevInTopic":591,"nextInTopic":709,"prevInTime":593,"nextInTime":595,"topicId":568,"numMessagesInTopic":20,"msgSnippet":"That looks fine. Sorry about the quality - the next one will be better :-) I ve not come across the dns going through a proxy - I guess if there is a local dns","rawEmail":"Return-Path: &lt;Mark.Williamson@...&gt;\r\nX-Sender: Mark.Williamson@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 91384 invoked from network); 7 Jul 2004 18:42:51 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m22.grp.scd.yahoo.com with QMQP; 7 Jul 2004 18:42:51 -0000\r\nReceived: from unknown (HELO nt-lonex1.bl.uk) (193.60.210.60)\n  by mta4.grp.scd.yahoo.com with SMTP; 7 Jul 2004 18:42:48 -0000\r\nReceived: by nt-lonex1.bl.uk with Internet Mail Service (5.5.2657.72)\n\tid &lt;NAT9C0V3&gt;; Wed, 7 Jul 2004 19:43:26 +0100\r\nMessage-ID: &lt;343540CF89C2774289E7F3C9EE4F5DF10553A59B@...&gt;\r\nTo: &#39;stack &#39; &lt;stack@...&gt;, &quot;&#39;archive-crawler@yahoogroups.com &#39;&quot;\n\t &lt;archive-crawler@yahoogroups.com&gt;\r\nDate: Wed, 7 Jul 2004 19:43:24 +0100 \r\nMIME-Version: 1.0\r\nX-Mailer: Internet Mail Service (5.5.2657.72)\r\nList-Unsubscribe: &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com&gt;\r\nContent-Type: text/plain;\n\tcharset=&quot;iso-8859-1&quot;\r\nX-eGroups-Remote-IP: 193.60.210.60\r\nFrom: &quot;Williamson, Mark&quot; &lt;Mark.Williamson@...&gt;\r\nSubject: RE: [archive-crawler] Proxy\r\nX-Yahoo-Group-Post: member; u=188703988\r\n\r\n That looks fine. Sorry about the quality - the \nnext one will be better :-)\n\nI&#39;ve not come across the dns going through a proxy - I \nguess if there is a local dns then it will be configured \nat a machine level. \n\nMy sourceforge user name is &quot;junklight&quot; \n\ncatch you later\n\nmark \n\n-----Original Message-----\nFrom: stack\nTo: archive-crawler@yahoogroups.com\nSent: 7/7/04 7:04 PM\nSubject: Re: [archive-crawler] Proxy\n\nYour a good man Mark.\n\nThe patch is a little ugly for sure (smile).  I went through it and \nextracted the attached (I made proxy an expert setting).  Does it look \nright to you?  I tried it and all seems to work properly.  DNS doesn&#39;t \ngo via the proxy but I figure thats probably ok?\n\nOk if I add you as a contributor to heritrix?\n\nGood stuff,\nSt.Ack\n\n\nmark williamson wrote:\n\n&gt;Hi, \n&gt;\n&gt;here is a patch to add the a proxy server to the crawl\n&gt;settings. Patch wise its awful because I auto formated \n&gt;the code in Eclipse and so the format of the code doesn&#39;t \n&gt;fit properly and the patch then removes the whole file and \n&gt;adds a new one :-( \n&gt;\n&gt;The way I solved problems like this in my last company was to \n&gt;require *everyone* to run the code autoformatter in Eclipse \n&gt;prior to check in. That way everyones coding idiosyncrasies where \n&gt;smoothed away and diffs etc. all worked very nicely.\n&gt;\n&gt;The proxy and host can be set in the job settings using this \n&gt;patch. \n&gt;\n&gt;cheers \n&gt;\n&gt;mark \n&gt;\n&gt;\n&gt;\n&gt; \n&gt;Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n&gt; \n&gt;  \n&gt;\n&gt;-----------------------------------------------------------------------\n-\n&gt;\n&gt;diff -aur AOCBase/src/java/org/archive/crawler/fetcher/FetchHTTP.java\nArchiveOpenCrawler/src/java/org/archive/crawler/fetcher/FetchHTTP.java\n&gt;--- AOCBase/src/java/org/archive/crawler/fetcher/FetchHTTP.java\n2004-07-06 12:04:33.000000000 +0100\n&gt;+++\nArchiveOpenCrawler/src/java/org/archive/crawler/fetcher/FetchHTTP.java\n2004-07-06 16:47:57.000000000 +0100\n&gt;@@ -81,858 +81,922 @@\n&gt; /**\n&gt;  * HTTP fetcher that uses &lt;a\n&gt;  * href=&quot;http://jakarta.apache.org/commons/httpclient/&quot;&gt;Apache Jakarta\nCommons\n&gt;- * HttpClient&lt;/a&gt; library.\n&gt;- *\n&gt;+ * HttpClient &lt;/a&gt; library.\n&gt;+ * \n&gt;  * @author Gordon Mohr\n&gt;  * @author Igor Ranitovic\n&gt;  * @author others\n&gt;  * @version $Id: FetchHTTP.java,v 1.51 2004/06/24 00:11:24 gojomo Exp\n$\n&gt;  */\n&gt; public class FetchHTTP extends Processor\n&gt;-    \timplements CoreAttributeConstants, FetchStatusCodes {\n&gt;-    // be robust against trivial implementation changes\n&gt;-    private static final long serialVersionUID =\nArchiveUtils.classnameBasedUID(FetchHTTP.class,1);\n&gt;-    \n&gt;-    private static Logger logger =\nLogger.getLogger(FetchHTTP.class.getName());\n&gt;-\n&gt;-    public static final String ATTR_TIMEOUT_SECONDS =\n&quot;timeout-seconds&quot;;\n&gt;-    public static final String ATTR_SOTIMEOUT_MS = &quot;sotimeout-ms&quot;;\n&gt;-    public static final String ATTR_MAX_LENGTH_BYTES =\n&quot;max-length-bytes&quot;;\n&gt;-    public static final String ATTR_LOAD_COOKIES =\n&quot;load-cookies-from-file&quot;;\n&gt;-    public static final String ATTR_SAVE_COOKIES =\n&quot;save-cookies-to-file&quot;;\n&gt;-\n&gt;-    private static Integer DEFAULT_TIMEOUT_SECONDS = new\nInteger(1200);\n&gt;-    private static Integer DEFAULT_SOTIMEOUT_MS = new Integer(20000);\n&gt;-    private static Long DEFAULT_MAX_LENGTH_BYTES = new\nLong(Long.MAX_VALUE);\n&gt;-\n&gt;-   /**\n&gt;-     * Default setting for HttpClient&#39;s &quot;strict mode&quot;.\n&gt;-     * In strict mode, Cookies are served on a single header.\n&gt;-     */\n&gt;-    private static final boolean DEFAULT_HTTPCLIENT_STRICT = true;\n&gt;-\n&gt;-    /**\n&gt;-     * SSL trust level setting attribute name.\n&gt;-     */\n&gt;-    public static final String ATTR_TRUST = &quot;trust-level&quot;;\n&gt;-\n&gt;-    transient PatchedHttpClient http = null;\n&gt;-\n&gt;-    private int soTimeout;\n&gt;-\n&gt;-    /**\n&gt;-     * How many &#39;instant retries&#39; of HttpRecoverableExceptions have\noccurred\n&gt;-     */\n&gt;-    // Would like to be &#39;long&#39;, but longs aren&#39;t atomic\n&gt;-    private int recoveryRetries = 0;\n&gt;-\n&gt;-    // Would like to be &#39;long&#39;, but longs aren&#39;t atomic\n&gt;-    private int curisHandled = 0;\n&gt;-\n&gt;-    /**\n&gt;-     * Constructor.\n&gt;-     *\n&gt;-     * @param name Name of this processor.\n&gt;-     */\n&gt;-    public FetchHTTP(String name) {\n&gt;-        super(name, &quot;HTTP Fetcher&quot;);\n&gt;-        Type e;\n&gt;-        addElementToDefinition(new SimpleType(ATTR_TIMEOUT_SECONDS,\n&gt;-            &quot;If the fetch is not completed in this number of seconds,&quot;\n&gt;-            + &quot; give up&quot;, DEFAULT_TIMEOUT_SECONDS));\n&gt;-        e = addElementToDefinition(new SimpleType(ATTR_SOTIMEOUT_MS,\n&gt;-            &quot;If the socket is unresponsive for this number of\nmilliseconds, &quot;\n&gt;-            + &quot;give up (and retry later)&quot;, DEFAULT_SOTIMEOUT_MS));\n&gt;-        e.setExpertSetting(true);\n&gt;-        addElementToDefinition(new SimpleType(ATTR_MAX_LENGTH_BYTES,\n&gt;-            &quot;Max length in bytes to fetch (truncate at this length)&quot;,\n&gt;-            DEFAULT_MAX_LENGTH_BYTES));\n&gt;-        e = addElementToDefinition(new SimpleType(ATTR_LOAD_COOKIES,\n&gt;-            &quot;File to preload cookies from&quot;, &quot;&quot;));\n&gt;-        e.setExpertSetting(true);\n&gt;-        e = addElementToDefinition(new SimpleType(ATTR_SAVE_COOKIES,\n&gt;-            &quot;When crawl finishes save cookies to this file&quot;, &quot;&quot;));\n&gt;-        e.setExpertSetting(true);\n&gt;-        e = addElementToDefinition(new SimpleType(ATTR_TRUST,\n&gt;-            &quot;SSL certificate trust level.  Range is from the default\n&#39;open&#39;&quot;\n&gt;-            + &quot; (trust all certs including expired, selfsigned, and\nthose for&quot;\n&gt;-            + &quot; which we do not have a CA) through &#39;loose&#39; (trust all\nvalid&quot;\n&gt;-            + &quot; certificates including selfsigned), &#39;normal&#39; (all\nvalid&quot;\n&gt;-            + &quot; certificates not including selfsigned) to &#39;strict&#39;\n(Cert is&quot;\n&gt;-            + &quot; valid and DN must match servername)&quot;,\n&gt;-            ConfigurableX509TrustManager.DEFAULT,\n&gt;-            ConfigurableX509TrustManager.LEVELS_AS_ARRAY));\n&gt;-        e.setOverrideable(false);\n&gt;-        e.setExpertSetting(true);\n&gt;-    }\n&gt;-\n&gt;-    protected void innerProcess(CrawlURI curi) throws\nInterruptedException {\n&gt;-        if (!canFetch(curi)) {\n&gt;-            // Cannot fetch this, due to protocol, retries, or other\nproblems\n&gt;-            return;\n&gt;-        }\n&gt;-\n&gt;-        this.curisHandled++;\n&gt;-\n&gt;-        // Note begin time\n&gt;-        curi.getAList().putLong(A_FETCH_BEGAN_TIME,\nSystem.currentTimeMillis());\n&gt;-\n&gt;-        // Get a reference to the HttpRecorder that is set into this\nToeThread.\n&gt;-        HttpRecorder rec = HttpRecorder.getHttpRecorder();\n&gt;-        HttpMethod method = curi.isPost()?\n&gt;-            (HttpMethod)new HttpRecorderPostMethod(\n&gt;-                curi.getUURI().toString(), rec):\n&gt;-            (HttpMethod)new HttpRecorderGetMethod(\n&gt;-                curi.getUURI().toString(), rec);\n&gt;-        configureMethod(curi, method);\n&gt;-        boolean addedCredentials = populateCredentials(curi, method);\n&gt;-        int immediateRetries = 0;\n&gt;-        while (true) {\n&gt;-            // Retry until success (break) or unrecoverable exception\n&gt;-            // (early return)\n&gt;-            try {\n&gt;-                // TODO: make this initial reading subject to the same\n&gt;-                // length/timeout limits; currently only the soTimeout\n&gt;-                // is effective here, once the connection succeeds\n&gt;-                this.http.executeMethod(method);\n&gt;-                break;\n&gt;-            } catch (HttpRecoverableException e) {\n&gt;-                checkForInterrupt();\n&gt;-                if (immediateRetries &lt; getMaxImmediateRetries()) {\n&gt;-                    // See &quot;[ 910219 ] [httpclient] unable...starting\nwith&quot;\n&gt;-                    //\nhttp://sourceforge.net/tracker/?group_id=73833&atid=539099&func=detail&a\nid=910219\n&gt;-                    // for the justification for this loop.\n&gt;-                    this.recoveryRetries++;\n&gt;-                    immediateRetries++;\n&gt;-                    continue;\n&gt;-                } else {\n&gt;-                    // Treat as connect failed\n&gt;-                    failedExecuteCleanup(method, curi, e);\n&gt;-                    return;\n&gt;-                }\n&gt;-            } catch (IOException e) {\n&gt;-                failedExecuteCleanup(method, curi, e);\n&gt;-                return;\n&gt;-            } catch (ArrayIndexOutOfBoundsException e) {\n&gt;-                // For weird windows-only ArrayIndex exceptions in\nnative\n&gt;-                // code... see\n&gt;-                //\nhttp://forum.java.sun.com/thread.jsp?forum=11&thread=378356\n&gt;-                // treating as if it were an IOException\n&gt;-                failedExecuteCleanup(method, curi, e);\n&gt;-                return;\n&gt;-            }\n&gt;-        }\n&gt;-\n&gt;-        try {\n&gt;-            // Force read-to-end, so that any socket hangs occur here,\n&gt;-            // not in later modules\n&gt;-\nrec.getRecordedInput().readFullyOrUntil(getMaxLength(curi),\n&gt;-                1000 * getTimeout(curi));\n&gt;-        } catch (RecorderTimeoutException ex) {\n&gt;-            curi.addAnnotation(&quot;timeTrunc&quot;);\n&gt;-        } catch (RecorderLengthExceededException ex) {\n&gt;-            curi.addAnnotation(&quot;lengthTrunc&quot;);\n&gt;-        } catch (IOException e) {\n&gt;-            cleanup(method, curi, e, &quot;readFully&quot;, S_CONNECT_LOST);\n&gt;-            return;\n&gt;-        } catch (ArrayIndexOutOfBoundsException e) {\n&gt;-            // For weird windows-only ArrayIndex exceptions from\nnative code\n&gt;-            // see\nhttp://forum.java.sun.com/thread.jsp?forum=11&thread=378356\n&gt;-            // treating as if it were an IOException\n&gt;-            cleanup(method, curi, e, &quot;readFully&quot;, S_CONNECT_LOST);\n&gt;-            return;\n&gt;-        } finally {\n&gt;-            method.releaseConnection();\n&gt;-        }\n&gt;-\n&gt;-        // Note completion time\n&gt;-        curi.getAList().putLong(A_FETCH_COMPLETED_TIME,\n&gt;-            System.currentTimeMillis());\n&gt;-\n&gt;-        // Set the response charset into the HttpRecord if available.\n&gt;-\nrec.setCharacterEncoding(((HttpMethodBase)method).getResponseCharSet());\n&gt;-\n&gt;-        // Set httpRecorder into curi for convenience of subsequent\nprocessors.\n&gt;-        curi.setHttpRecorder(rec);\n&gt;-\n&gt;-        int statusCode = method.getStatusCode();\n&gt;-        long contentSize =\ncuri.getHttpRecorder().getRecordedInput().getSize();\n&gt;-        curi.setContentSize(contentSize);\n&gt;-        curi.setFetchStatus(statusCode);\n&gt;-        Header ct = method.getResponseHeader(&quot;content-type&quot;);\n&gt;-        curi.setContentType((ct == null)? null: ct.getValue());\n&gt;-        if (logger.isLoggable(Level.FINE)) {\n&gt;-            logger.fine((curi.isPost()? &quot;POST&quot;: &quot;GET&quot;) + &quot; &quot; +\n&gt;-            \t\tcuri.getUURI().toString() + &quot; &quot; + statusCode + &quot;\n&quot; +\n&gt;-                contentSize + &quot; &quot; + curi.getContentType());\n&gt;-        }\n&gt;-\n&gt;-        if (curi.isSuccess() && addedCredentials) {\n&gt;-            // Promote the credentials from the CrawlURI to the\nCrawlServer\n&gt;-            // so they are available for all subsequent CrawlURIs on\nthis\n&gt;-            // server.\n&gt;-            promoteCredentials(curi);\n&gt;-            if (logger.isLoggable(Level.FINE)) {\n&gt;-                // Print out the cookie.  Might help with the\ndebugging.\n&gt;-                Header setCookie =\nmethod.getResponseHeader(&quot;set-cookie&quot;);\n&gt;-                if (setCookie != null) {\n&gt;-                    logger.fine(setCookie.toString().trim());\n&gt;-                }\n&gt;-            }\n&gt;-        } else if (statusCode == HttpStatus.SC_UNAUTHORIZED) {\n&gt;-            // 401 is not &#39;success&#39;.\n&gt;-            handle401(method, curi);\n&gt;-        }\n&gt;-\n&gt;-        // Save off the GetMethod just in case needed by subsequent\nprocessors.\n&gt;-        curi.getAList().putObject(A_HTTP_TRANSACTION, method);\n&gt;-    }\n&gt;-\n&gt;-    /**\n&gt;-     * Cleanup after a failed method execute.\n&gt;-     * @param curi CrawlURI we failed on.\n&gt;-     * @param method Method we failed on.\n&gt;-     * @param exception Exception we failed with.\n&gt;-     */\n&gt;-    private void failedExecuteCleanup(final HttpMethod method,\n&gt;-            final CrawlURI curi, final Exception exception) {\n&gt;-        cleanup(method, curi, exception, &quot;executeMethod&quot;,\nS_CONNECT_FAILED);\n&gt;-    }\n&gt;-    /**\n&gt;-     * Cleanup after a failed method execute.\n&gt;-     * @param curi CrawlURI we failed on.\n&gt;-     * @param method Method we failed on.\n&gt;-     * @param exception Exception we failed with.\n&gt;-     * @param message Message to log with failure.\n&gt;-     * @param status Status to set on the fetch.\n&gt;-     */\n&gt;-    private void cleanup(final HttpMethod method, final CrawlURI curi,\n&gt;-            final Exception exception, final String message, final int\nstatus) {\n&gt;-        curi.addLocalizedError(this.getName(), exception, message);\n&gt;-        curi.setFetchStatus(status);\n&gt;-\n&gt;-        // Its ok if releaseConnection is called multiple times: i.e.\nhere and\n&gt;-        // in the finally that is at end of one of the innerProcess\nblocks\n&gt;-        // above.\n&gt;-        method.releaseConnection();\n&gt;-    }\n&gt;-\n&gt;-    /**\n&gt;-     * @return maximum immediate retures.\n&gt;-     */\n&gt;-    private int getMaxImmediateRetries() {\n&gt;-        // TODO make configurable\n&gt;-        return 5;\n&gt;-    }\n&gt;-\n&gt;-    /**\n&gt;-     * Can this processor fetch the given CrawlURI. May set a fetch\n&gt;-     * status if this processor would usually handle the CrawlURI,\n&gt;-     * but cannot in this instance.\n&gt;-     *\n&gt;-     * @param curi\n&gt;-     * @return True if processor can fetch.\n&gt;-     */\n&gt;-    private boolean canFetch(CrawlURI curi) {\n&gt;-        String scheme = curi.getUURI().getScheme();\n&gt;-         if (!(scheme.equals(&quot;http&quot;) || scheme.equals(&quot;https&quot;))) {\n&gt;-             // handles only plain http and https\n&gt;-             return false;\n&gt;-         }\n&gt;-\n&gt;-//         System.out.println(curi.toString() + &quot; : &quot; +\ncuri.getFetchAttempts());\n&gt;-//         if (curi.getFetchAttempts() &gt;= getMaxFetchAttempts(curi)) {\n&gt;-//             curi.setFetchStatus(S_TOO_MANY_RETRIES);\n&gt;-//             return false;\n&gt;-//         }\n&gt;-\n&gt;-         // make sure the dns lookup succeeded\n&gt;-         if (curi.getServer().getHost().getIP() == null\n&gt;-             && curi.getServer().getHost().hasBeenLookedUp()) {\n&gt;-             curi.setFetchStatus(S_DOMAIN_UNRESOLVABLE);\n&gt;-             return false;\n&gt;-         }\n&gt;-        return true;\n&gt;-    }\n&gt;-\n&gt;-    /**\n&gt;-     * Configure the HttpMethod setting options and headers.\n&gt;-     *\n&gt;-     * @param curi CrawlURI from which we pull configuration.\n&gt;-     * @param get The GetMethod to configure.\n&gt;-     */\n&gt;-    private void configureMethod(CrawlURI curi, HttpMethod method)\n&gt;-    {\n&gt;-        // Don&#39;t auto-follow redirects\n&gt;-        method.setFollowRedirects(false);\n&gt;-\n&gt;-        // Set strict on the client; whatever the client&#39;s mode\noverrides\n&gt;-        // the methods mode inside in the depths of executeMethod.\n&gt;-        this.http.setStrictMode(DEFAULT_HTTPCLIENT_STRICT);\n&gt;-\n&gt;-        // Use only HTTP/1.0 (to avoid receiving chunked responses)\n&gt;-        ((HttpMethodBase)method).setHttp11(false);\n&gt;-\n&gt;-        CrawlOrder order = getSettingsHandler().getOrder();\n&gt;-        String userAgent = curi.getUserAgent();\n&gt;-        if (userAgent == null) {\n&gt;-            userAgent = order.getUserAgent(curi);\n&gt;-        }\n&gt;-        method.setRequestHeader(&quot;User-Agent&quot;, userAgent);\n&gt;-        method.setRequestHeader(&quot;From&quot;, order.getFrom(curi));\n&gt;-    }\n&gt;-\n&gt;-    /**\n&gt;-     * Add credentials if any to passed &lt;code&gt;method&lt;/code&gt;.\n&gt;-     *\n&gt;-     * Do credential handling.  Credentials are in two places.  1.\nCredentials\n&gt;-     * that succeeded are added to the CrawlServer (Or rather, avatars\nfor\n&gt;-     * credentials are whats added because its not safe to keep around\n&gt;-     * references to credentials).  2. Credentials to be tried are in\nthe curi.\n&gt;-     * Returns true if found credentials to be tried.\n&gt;-     *\n&gt;-     * @param curi Current CrawlURI.\n&gt;-     * @param method The method to add to.\n&gt;-     * @return True if prepopulated &lt;code&gt;method&lt;/code&gt; with\ncredentials AND the\n&gt;-     * credentials came from the &lt;code&gt;curi&lt;/code&gt;, not from the\nCrawlServer.\n&gt;-     * The former is  special in that if the &lt;code&gt;curi&lt;/curi&gt;\ncredentials\n&gt;-     * succeed, then the caller needs to promote them from the\nCrawlURI to the\n&gt;-     * CrawlServer so they are available for all subsequent CrawlURIs\non this\n&gt;-     * server.\n&gt;-     */\n&gt;-    private boolean populateCredentials(CrawlURI curi, HttpMethod\nmethod) {\n&gt;-\n&gt;-        // First look at the server avatars. Add any that are to be\nvolunteered\n&gt;-        // on every request (e.g. RFC2617 credentials).  Every time\ncreds will\n&gt;-        // return true when we call &#39;isEveryTime().\n&gt;-        if (curi.getServer().hasCredentialAvatars()) {\n&gt;-            Set avatars = curi.getServer().getCredentialAvatars();\n&gt;-            for (Iterator i = avatars.iterator(); i.hasNext();) {\n&gt;-                CredentialAvatar ca = (CredentialAvatar)i.next();\n&gt;-                Credential c = ca.getCredential(getSettingsHandler(),\ncuri);\n&gt;-                if (c.isEveryTime()) {\n&gt;-                    c.populate(curi, this.http, method,\nca.getPayload());\n&gt;-                }\n&gt;-            }\n&gt;-        }\n&gt;-\n&gt;-        boolean result = false;\n&gt;-\n&gt;-        // Now look in the curi.  The Curi will have credentials\nloaded either\n&gt;-        // by the handle401 method if its a rfc2617 or it&#39;ll have been\nset into\n&gt;-        // the curi by the preconditionenforcer as this login uri came\nthrough.\n&gt;-        if (curi.hasCredentialAvatars()) {\n&gt;-            Set avatars = curi.getCredentialAvatars();\n&gt;-            for (Iterator i = avatars.iterator(); i.hasNext();) {\n&gt;-                CredentialAvatar ca = (CredentialAvatar)i.next();\n&gt;-                Credential c = ca.getCredential(getSettingsHandler(),\ncuri);\n&gt;-                if (c.populate(curi, this.http, method,\nca.getPayload())) {\n&gt;-                    result = true;\n&gt;-                }\n&gt;-            }\n&gt;-        }\n&gt;-\n&gt;-        return result;\n&gt;-    }\n&gt;-\n&gt;-    /**\n&gt;-     * Promote successful credential to the server.\n&gt;-     *\n&gt;-     * @param curi CrawlURI whose credentials we are to promote.\n&gt;-     * @param method Method used.\n&gt;-     */\n&gt;-    private void promoteCredentials(final CrawlURI curi) {\n&gt;-        if (!curi.hasCredentialAvatars()) {\n&gt;-            logger.severe(&quot;No credentials to promote when there should\nbe &quot; +\n&gt;-                curi);\n&gt;-        } else {\n&gt;-            Set avatars = curi.getCredentialAvatars();\n&gt;-            for (Iterator i = avatars.iterator(); i.hasNext();) {\n&gt;-                CredentialAvatar ca = (CredentialAvatar)i.next();\n&gt;-                curi.removeCredentialAvatar(ca);\n&gt;-                // The server to attach too may not be the server that\nhosts\n&gt;-                // this passed curi.  It might be of another\nsubdomain.\n&gt;-                // The avatar needs to be added to the server that is\ndependent\n&gt;-                // on this precondition.  Find it by name.  Get the\nname from\n&gt;-                // the credential this avatar represents.\n&gt;-                Credential c = ca.getCredential(getSettingsHandler(),\ncuri);\n&gt;-                String cd = null;\n&gt;-                try {\n&gt;-                    cd = c.getCredentialDomain(curi);\n&gt;-                }\n&gt;-                catch (AttributeNotFoundException e) {\n&gt;-                    logger.severe(&quot;Failed to get cred domain for &quot; +\ncuri +\n&gt;-                        &quot; for &quot; + ca + &quot;: &quot; + e.getMessage());\n&gt;-                }\n&gt;-                if (cd != null) {\n&gt;-                    CrawlServer cs\n&gt;-                        =\ngetController().getServerCache().getServerFor(cd);\n&gt;-                    if (cs != null) {\n&gt;-                        cs.addCredentialAvatar(ca);\n&gt;-                    }\n&gt;-                }\n&gt;-            }\n&gt;-        }\n&gt;-    }\n&gt;-\n&gt;-    /**\n&gt;-     * Server is looking for basic/digest auth credentials (RFC2617).\nIf we have\n&gt;-     * any, put them into the CrawlURI and have it come around again.\nPresence\n&gt;-     * of the credential serves as flag to frontier to requeue\npromptly. If we\n&gt;-     * already tried this domain and still got a 401, then our\ncredentials are\n&gt;-     * bad. Remove them and let this curi die.\n&gt;-     *\n&gt;-     * @param get Method that got a 401.\n&gt;-     * @param curi CrawlURI that got a 401.\n&gt;-     */\n&gt;-    private void handle401(final HttpMethod method, final CrawlURI\ncuri) {\n&gt;-\n&gt;-        AuthScheme authscheme = getAuthScheme(method, curi);\n&gt;-        if (authscheme == null) {\n&gt;-            return;\n&gt;-        }\n&gt;-\n&gt;-        String realm = authscheme.getRealm();\n&gt;-        if (realm == null) {\n&gt;-            return;\n&gt;-        }\n&gt;-\n&gt;-        // Look to see if this curi had rfc2617 avatars loaded.  If\nso, are\n&gt;-        // any of them for this realm?  If so, then the credential\nfailed if\n&gt;-        // we got a 401 and it should be let die a natural 401 death.\n&gt;-        Set curiRfc2617Credentials =\n&gt;-            getCredentials(getSettingsHandler(), curi,\nRfc2617Credential.class);\n&gt;-        Rfc2617Credential extant = Rfc2617Credential.\n&gt;-            getByRealm(curiRfc2617Credentials, realm, curi);\n&gt;-        if (extant != null) {\n&gt;-            // Then, already tried this credential.  Remove ANY\nrfc2617\n&gt;-            // credential since presence of a rfc2617 credential\nserves\n&gt;-            // as flag to frontier to requeue this curi and let the\ncuri\n&gt;-            // die a natural death.\n&gt;-            extant.detachAll(curi);\n&gt;-            logger.fine(&quot;Auth failed (401) though supplied realm &quot; +\n&gt;-                realm + &quot; to &quot; + curi.toString());\n&gt;-        } else {\n&gt;-            // Look see if we have a credential that corresponds to\nthis realm\n&gt;-            // in credential store.  Filter by type and credential\ndomain.  If\n&gt;-            // not, let this curi die. Else, add it to the curi and\nlet it come\n&gt;-            // around again. Add in the AuthScheme we got too.  Its\nneeded when\n&gt;-            // we go to run the Auth on second time around.\n&gt;-            CredentialStore cs =\n&gt;-\nCredentialStore.getCredentialStore(getSettingsHandler());\n&gt;-            if (cs == null) {\n&gt;-                logger.severe(&quot;No credential store for &quot; + curi);\n&gt;-            } else {\n&gt;-                Set storeRfc2617Credentials = cs.subset(curi,\n&gt;-                    Rfc2617Credential.class,\ncuri.getServer().getName());\n&gt;-                if (storeRfc2617Credentials == null ||\n&gt;-                    storeRfc2617Credentials.size() &lt;= 0) {\n&gt;-                    logger.fine(&quot;No rfc2617 credentials for &quot; + curi);\n&gt;-                } else {\n&gt;-                    Rfc2617Credential found = Rfc2617Credential.\n&gt;-                    \t\tgetByRealm(storeRfc2617Credentials,\nrealm, curi);\n&gt;-                    if (found == null) {\n&gt;-                        logger.fine(&quot;No rfc2617 credentials for realm\n&quot; +\n&gt;-                            realm + &quot; in &quot; + curi);\n&gt;-                    } else {\n&gt;-                        found.attach(curi, authscheme);\n&gt;-                        logger.fine(&quot;Found credential for realm &quot; +\nrealm +\n&gt;-                            &quot; in store for &quot; + curi.toString());\n&gt;-                    }\n&gt;-                }\n&gt;-            }\n&gt;-        }\n&gt;-    }\n&gt;-\n&gt;-    /**\n&gt;-     * @param handler Settings Handler.\n&gt;-     * @param curi CrawlURI that got a 401.\n&gt;-     * @param type Class of credential to get from curi.\n&gt;-     * @return Set of credentials attached to this curi.\n&gt;-     */\n&gt;-    private Set getCredentials(SettingsHandler handler, CrawlURI curi,\n&gt;-            Class type) {\n&gt;-        Set result = null;\n&gt;-\n&gt;-        if (curi.hasCredentialAvatars()) {\n&gt;-            for (Iterator i = curi.getCredentialAvatars().iterator();\n&gt;-                    i.hasNext();) {\n&gt;-                CredentialAvatar ca = (CredentialAvatar)i.next();\n&gt;-                if (ca.match(type)) {\n&gt;-                    if (result == null) {\n&gt;-                        result = new HashSet();\n&gt;-                    }\n&gt;-                    result.add(ca.getCredential(handler, curi));\n&gt;-                }\n&gt;-            }\n&gt;-        }\n&gt;-        return result;\n&gt;-    }\n&gt;-\n&gt;-    /**\n&gt;-     * @param get Method that got a 401.\n&gt;-     * @param curi CrawlURI that got a 401.\n&gt;-     * @return Authscheme made from the authenticate header or null if\nfailed to\n&gt;-     * get it.\n&gt;-     */\n&gt;-    private AuthScheme getAuthScheme(final HttpMethod method,\n&gt;-            final CrawlURI curi) {\n&gt;-        AuthScheme result = null;\n&gt;-        Header header =\nmethod.getResponseHeader(HttpAuthenticator.WWW_AUTH);\n&gt;-        if (header == null) {\n&gt;-            logger.info(&quot;No &quot; + HttpAuthenticator.WWW_AUTH + &quot; headers\nthough&quot; +\n&gt;-                &quot; we got a 401: &quot; + curi);\n&gt;-        } else {\n&gt;-            try {\n&gt;-                result =\n&gt;-                    HttpAuthenticator.selectAuthScheme(new Header[]\n{header});\n&gt;-            } catch (MalformedChallengeException e) {\n&gt;-                logger.severe(&quot;Failed to get auth headers: &quot; +\ne.toString() +\n&gt;-                    &quot; &quot; + curi.toString());\n&gt;-            } catch (UnsupportedOperationException uoe) {\n&gt;-                // This is probably a message like this:\n&gt;-                // Authentication scheme(s) not supported:\n&gt;-                // {negotiate,=Negotiate, NTLM}\n&gt;-                // Log it as a warning.  Not much we can do about it.\nReturn\n&gt;-                // null.  We&#39;ll get the 401 in the arcs and a page\nthat says\n&gt;-                // something like &#39;Access denied&#39;.\n&gt;-                logger.warning(curi + &quot;: &quot; + uoe);\n&gt;-            }\n&gt;-        }\n&gt;-        return result;\n&gt;-    }\n&gt;-\n&gt;-    public void initialTasks() {\n&gt;-        this.soTimeout = getSoTimeout(null);\n&gt;-        setupHttp();\n&gt;-\n&gt;-        // load cookies from a file if specified in the order file.\n&gt;-        loadCookies();\n&gt;-    }\n&gt;+\t\timplements\n&gt;+\t\t\tCoreAttributeConstants,\n&gt;+\t\t\tFetchStatusCodes {\n&gt;+\t// be robust against trivial implementation changes\n&gt;+\tprivate static final long serialVersionUID = ArchiveUtils\n&gt;+\t\t\t.classnameBasedUID(FetchHTTP.class, 1);\n&gt;+\n&gt;+\tprivate static Logger logger =\nLogger.getLogger(FetchHTTP.class.getName());\n&gt;+\n&gt;+\tpublic static final String ATTR_HTTP_PROXY_HOST =\n&quot;http-proxy-host&quot;;\n&gt;+\tpublic static final String ATTR_HTTP_PROXY_PORT =\n&quot;http-proxy-port&quot;;\n&gt;+\tpublic static final String ATTR_TIMEOUT_SECONDS =\n&quot;timeout-seconds&quot;;\n&gt;+\tpublic static final String ATTR_SOTIMEOUT_MS = &quot;sotimeout-ms&quot;;\n&gt;+\tpublic static final String ATTR_MAX_LENGTH_BYTES =\n&quot;max-length-bytes&quot;;\n&gt;+\tpublic static final String ATTR_LOAD_COOKIES =\n&quot;load-cookies-from-file&quot;;\n&gt;+\tpublic static final String ATTR_SAVE_COOKIES =\n&quot;save-cookies-to-file&quot;;\n&gt;+\n&gt;+\tprivate static Integer DEFAULT_TIMEOUT_SECONDS = new\nInteger(1200);\n&gt;+\tprivate static Integer DEFAULT_SOTIMEOUT_MS = new\nInteger(20000);\n&gt;+\tprivate static Long DEFAULT_MAX_LENGTH_BYTES = new\nLong(Long.MAX_VALUE);\n&gt;+\n&gt;+\t/**\n&gt;+\t * Default setting for HttpClient&#39;s &quot;strict mode&quot;. In strict\nmode, Cookies\n&gt;+\t * are served on a single header.\n&gt;+\t */\n&gt;+\tprivate static final boolean DEFAULT_HTTPCLIENT_STRICT = true;\n&gt;+\n&gt;+\t/**\n&gt;+\t * SSL trust level setting attribute name.\n&gt;+\t */\n&gt;+\tpublic static final String ATTR_TRUST = &quot;trust-level&quot;;\n&gt;+\n&gt;+\ttransient PatchedHttpClient http = null;\n&gt;+\n&gt;+\tprivate int soTimeout;\n&gt;+\n&gt;+\t/**\n&gt;+\t * How many &#39;instant retries&#39; of HttpRecoverableExceptions have\noccurred\n&gt;+\t */\n&gt;+\t// Would like to be &#39;long&#39;, but longs aren&#39;t atomic\n&gt;+\tprivate int recoveryRetries = 0;\n&gt;+\n&gt;+\t// Would like to be &#39;long&#39;, but longs aren&#39;t atomic\n&gt;+\tprivate int curisHandled = 0;\n&gt;+\n&gt;+\t/**\n&gt;+\t * Constructor.\n&gt;+\t * \n&gt;+\t * @param name\n&gt;+\t *                    Name of this processor.\n&gt;+\t */\n&gt;+\tpublic FetchHTTP(String name) {\n&gt;+\t\tsuper(name, &quot;HTTP Fetcher&quot;);\n&gt;+\t\tType e;\n&gt;+\t\taddElementToDefinition(new\nSimpleType(ATTR_HTTP_PROXY_HOST,\n&gt;+\t\t\t\t&quot;Proxy hostname (set only if needed)&quot;,\n&quot;&quot;));\n&gt;+\t\taddElementToDefinition(new\nSimpleType(ATTR_HTTP_PROXY_PORT,\n&gt;+\t\t\t\t&quot;Proxy port (set only if needed)&quot;, &quot;&quot;));\n&gt;+\t\taddElementToDefinition(new\nSimpleType(ATTR_TIMEOUT_SECONDS,\n&gt;+\t\t\t\t&quot;If the fetch is not completed in this\nnumber of seconds,&quot;\n&gt;+\t\t\t\t\t\t+ &quot; give up&quot;,\nDEFAULT_TIMEOUT_SECONDS));\n&gt;+\t\te = addElementToDefinition(new\nSimpleType(ATTR_SOTIMEOUT_MS,\n&gt;+\t\t\t\t&quot;If the socket is unresponsive for this\nnumber of milliseconds, &quot;\n&gt;+\t\t\t\t\t\t+ &quot;give up (and retry\nlater)&quot;, DEFAULT_SOTIMEOUT_MS));\n&gt;+\t\te.setExpertSetting(true);\n&gt;+\t\taddElementToDefinition(new\nSimpleType(ATTR_MAX_LENGTH_BYTES,\n&gt;+\t\t\t\t&quot;Max length in bytes to fetch (truncate\nat this length)&quot;,\n&gt;+\t\t\t\tDEFAULT_MAX_LENGTH_BYTES));\n&gt;+\t\te = addElementToDefinition(new\nSimpleType(ATTR_LOAD_COOKIES,\n&gt;+\t\t\t\t&quot;File to preload cookies from&quot;, &quot;&quot;));\n&gt;+\t\te.setExpertSetting(true);\n&gt;+\t\te = addElementToDefinition(new\nSimpleType(ATTR_SAVE_COOKIES,\n&gt;+\t\t\t\t&quot;When crawl finishes save cookies to\nthis file&quot;, &quot;&quot;));\n&gt;+\t\te.setExpertSetting(true);\n&gt;+\t\te = addElementToDefinition(new SimpleType(\n&gt;+\t\t\t\tATTR_TRUST,\n&gt;+\t\t\t\t&quot;SSL certificate trust level.  Range is\nfrom the default &#39;open&#39;&quot;\n&gt;+\t\t\t\t\t\t+ &quot; (trust all certs\nincluding expired, selfsigned, and those for&quot;\n&gt;+\t\t\t\t\t\t+ &quot; which we do not have\na CA) through &#39;loose&#39; (trust all valid&quot;\n&gt;+\t\t\t\t\t\t+ &quot; certificates\nincluding selfsigned), &#39;normal&#39; (all valid&quot;\n&gt;+\t\t\t\t\t\t+ &quot; certificates not\nincluding selfsigned) to &#39;strict&#39; (Cert is&quot;\n&gt;+\t\t\t\t\t\t+ &quot; valid and DN must\nmatch servername)&quot;,\n&gt;+\t\t\t\tConfigurableX509TrustManager.DEFAULT,\n&gt;+\nConfigurableX509TrustManager.LEVELS_AS_ARRAY));\n&gt;+\t\te.setOverrideable(false);\n&gt;+\t\te.setExpertSetting(true);\n&gt;+\t}\n&gt;+\n&gt;+\tprotected void innerProcess(CrawlURI curi) throws\nInterruptedException {\n&gt;+\t\tif (!canFetch(curi)) {\n&gt;+\t\t\t// Cannot fetch this, due to protocol, retries,\nor other problems\n&gt;+\t\t\treturn;\n&gt;+\t\t}\n&gt;+\n&gt;+\t\tthis.curisHandled++;\n&gt;+\n&gt;+\t\t// Note begin time\n&gt;+\t\tcuri.getAList().putLong(A_FETCH_BEGAN_TIME,\nSystem.currentTimeMillis());\n&gt;+\n&gt;+\t\t// Get a reference to the HttpRecorder that is set into\nthis ToeThread.\n&gt;+\t\tHttpRecorder rec = HttpRecorder.getHttpRecorder();\n&gt;+\t\tHttpMethod method = curi.isPost()\n&gt;+\t\t\t\t? (HttpMethod) new\nHttpRecorderPostMethod(curi.getUURI()\n&gt;+\t\t\t\t\t\t.toString(), rec)\n&gt;+\t\t\t\t: (HttpMethod) new\nHttpRecorderGetMethod(curi.getUURI()\n&gt;+\t\t\t\t\t\t.toString(), rec);\n&gt;+\t\tconfigureMethod(curi, method);\n&gt;+\t\tboolean addedCredentials = populateCredentials(curi,\nmethod);\n&gt;+\t\tint immediateRetries = 0;\n&gt;+\t\twhile (true) {\n&gt;+\t\t\t// Retry until success (break) or unrecoverable\nexception\n&gt;+\t\t\t// (early return)\n&gt;+\t\t\ttry {\n&gt;+\t\t\t\t// TODO: make this initial reading\nsubject to the same\n&gt;+\t\t\t\t// length/timeout limits; currently only\nthe soTimeout\n&gt;+\t\t\t\t// is effective here, once the\nconnection succeeds\n&gt;+\t\t\t\tthis.http.executeMethod(method);\n&gt;+\t\t\t\tbreak;\n&gt;+\t\t\t} catch (HttpRecoverableException e) {\n&gt;+\t\t\t\tcheckForInterrupt();\n&gt;+\t\t\t\tif (immediateRetries &lt;\ngetMaxImmediateRetries()) {\n&gt;+\t\t\t\t\t// See &quot;[ 910219 ] [httpclient]\nunable...starting with&quot;\n&gt;+\t\t\t\t\t//\nhttp://sourceforge.net/tracker/?group_id=73833&atid=539099&func=detail&a\nid=910219\n&gt;+\t\t\t\t\t// for the justification for\nthis loop.\n&gt;+\t\t\t\t\tthis.recoveryRetries++;\n&gt;+\t\t\t\t\timmediateRetries++;\n&gt;+\t\t\t\t\tcontinue;\n&gt;+\t\t\t\t} else {\n&gt;+\t\t\t\t\t// Treat as connect failed\n&gt;+\t\t\t\t\tfailedExecuteCleanup(method,\ncuri, e);\n&gt;+\t\t\t\t\treturn;\n&gt;+\t\t\t\t}\n&gt;+\t\t\t} catch (IOException e) {\n&gt;+\t\t\t\tfailedExecuteCleanup(method, curi, e);\n&gt;+\t\t\t\treturn;\n&gt;+\t\t\t} catch (ArrayIndexOutOfBoundsException e) {\n&gt;+\t\t\t\t// For weird windows-only ArrayIndex\nexceptions in native\n&gt;+\t\t\t\t// code... see\n&gt;+\t\t\t\t//\nhttp://forum.java.sun.com/thread.jsp?forum=11&thread=378356\n&gt;+\t\t\t\t// treating as if it were an IOException\n&gt;+\t\t\t\tfailedExecuteCleanup(method, curi, e);\n&gt;+\t\t\t\treturn;\n&gt;+\t\t\t}\n&gt;+\t\t}\n&gt;+\n&gt;+\t\ttry {\n&gt;+\t\t\t// Force read-to-end, so that any socket hangs\noccur here,\n&gt;+\t\t\t// not in later modules\n&gt;+\nrec.getRecordedInput().readFullyOrUntil(getMaxLength(curi),\n&gt;+\t\t\t\t\t1000 * getTimeout(curi));\n&gt;+\t\t} catch (RecorderTimeoutException ex) {\n&gt;+\t\t\tcuri.addAnnotation(&quot;timeTrunc&quot;);\n&gt;+\t\t} catch (RecorderLengthExceededException ex) {\n&gt;+\t\t\tcuri.addAnnotation(&quot;lengthTrunc&quot;);\n&gt;+\t\t} catch (IOException e) {\n&gt;+\t\t\tcleanup(method, curi, e, &quot;readFully&quot;,\nS_CONNECT_LOST);\n&gt;+\t\t\treturn;\n&gt;+\t\t} catch (ArrayIndexOutOfBoundsException e) {\n&gt;+\t\t\t// For weird windows-only ArrayIndex exceptions\nfrom native code\n&gt;+\t\t\t// see\nhttp://forum.java.sun.com/thread.jsp?forum=11&thread=378356\n&gt;+\t\t\t// treating as if it were an IOException\n&gt;+\t\t\tcleanup(method, curi, e, &quot;readFully&quot;,\nS_CONNECT_LOST);\n&gt;+\t\t\treturn;\n&gt;+\t\t} finally {\n&gt;+\t\t\tmethod.releaseConnection();\n&gt;+\t\t}\n&gt;+\n&gt;+\t\t// Note completion time\n&gt;+\t\tcuri.getAList().putLong(A_FETCH_COMPLETED_TIME,\n&gt;+\t\t\t\tSystem.currentTimeMillis());\n&gt;+\n&gt;+\t\t// Set the response charset into the HttpRecord if\navailable.\n&gt;+\t\trec\n&gt;+\t\t\t\t.setCharacterEncoding(((HttpMethodBase)\nmethod)\n&gt;+\t\t\t\t\t\t.getResponseCharSet());\n&gt;+\n&gt;+\t\t// Set httpRecorder into curi for convenience of\nsubsequent processors.\n&gt;+\t\tcuri.setHttpRecorder(rec);\n&gt;+\n&gt;+\t\tint statusCode = method.getStatusCode();\n&gt;+\t\tlong contentSize =\ncuri.getHttpRecorder().getRecordedInput().getSize();\n&gt;+\t\tcuri.setContentSize(contentSize);\n&gt;+\t\tcuri.setFetchStatus(statusCode);\n&gt;+\t\tHeader ct = method.getResponseHeader(&quot;content-type&quot;);\n&gt;+\t\tcuri.setContentType((ct == null) ? null :\nct.getValue());\n&gt;+\t\tif (logger.isLoggable(Level.FINE)) {\n&gt;+\t\t\tlogger.fine((curi.isPost() ? &quot;POST&quot; : &quot;GET&quot;) + &quot;\n&quot;\n&gt;+\t\t\t\t\t+ curi.getUURI().toString() + &quot;\n&quot; + statusCode + &quot; &quot;\n&gt;+\t\t\t\t\t+ contentSize + &quot; &quot; +\ncuri.getContentType());\n&gt;+\t\t}\n&gt;+\n&gt;+\t\tif (curi.isSuccess() && addedCredentials) {\n&gt;+\t\t\t// Promote the credentials from the CrawlURI to\nthe CrawlServer\n&gt;+\t\t\t// so they are available for all subsequent\nCrawlURIs on this\n&gt;+\t\t\t// server.\n&gt;+\t\t\tpromoteCredentials(curi);\n&gt;+\t\t\tif (logger.isLoggable(Level.FINE)) {\n&gt;+\t\t\t\t// Print out the cookie. Might help with\nthe debugging.\n&gt;+\t\t\t\tHeader setCookie =\nmethod.getResponseHeader(&quot;set-cookie&quot;);\n&gt;+\t\t\t\tif (setCookie != null) {\n&gt;+\nlogger.fine(setCookie.toString().trim());\n&gt;+\t\t\t\t}\n&gt;+\t\t\t}\n&gt;+\t\t} else if (statusCode == HttpStatus.SC_UNAUTHORIZED) {\n&gt;+\t\t\t// 401 is not &#39;success&#39;.\n&gt;+\t\t\thandle401(method, curi);\n&gt;+\t\t}\n&gt;+\n&gt;+\t\t// Save off the GetMethod just in case needed by\nsubsequent processors.\n&gt;+\t\tcuri.getAList().putObject(A_HTTP_TRANSACTION, method);\n&gt;+\t}\n&gt;+\n&gt;+\t/**\n&gt;+\t * Cleanup after a failed method execute.\n&gt;+\t * \n&gt;+\t * @param curi\n&gt;+\t *                    CrawlURI we failed on.\n&gt;+\t * @param method\n&gt;+\t *                    Method we failed on.\n&gt;+\t * @param exception\n&gt;+\t *                    Exception we failed with.\n&gt;+\t */\n&gt;+\tprivate void failedExecuteCleanup(final HttpMethod method,\n&gt;+\t\t\tfinal CrawlURI curi, final Exception exception)\n{\n&gt;+\t\tcleanup(method, curi, exception, &quot;executeMethod&quot;,\nS_CONNECT_FAILED);\n&gt;+\t}\n&gt;+\n&gt;+\t/**\n&gt;+\t * Cleanup after a failed method execute.\n&gt;+\t * \n&gt;+\t * @param curi\n&gt;+\t *                    CrawlURI we failed on.\n&gt;+\t * @param method\n&gt;+\t *                    Method we failed on.\n&gt;+\t * @param exception\n&gt;+\t *                    Exception we failed with.\n&gt;+\t * @param message\n&gt;+\t *                    Message to log with failure.\n&gt;+\t * @param status\n&gt;+\t *                    Status to set on the fetch.\n&gt;+\t */\n&gt;+\tprivate void cleanup(final HttpMethod method, final CrawlURI\ncuri,\n&gt;+\t\t\tfinal Exception exception, final String message,\nfinal int status) {\n&gt;+\t\tcuri.addLocalizedError(this.getName(), exception,\nmessage);\n&gt;+\t\tcuri.setFetchStatus(status);\n&gt;+\n&gt;+\t\t// Its ok if releaseConnection is called multiple times:\ni.e. here and\n&gt;+\t\t// in the finally that is at end of one of the\ninnerProcess blocks\n&gt;+\t\t// above.\n&gt;+\t\tmethod.releaseConnection();\n&gt;+\t}\n&gt;+\n&gt;+\t/**\n&gt;+\t * @return maximum immediate retures.\n&gt;+\t */\n&gt;+\tprivate int getMaxImmediateRetries() {\n&gt;+\t\t// TODO make configurable\n&gt;+\t\treturn 5;\n&gt;+\t}\n&gt;+\n&gt;+\t/**\n&gt;+\t * Can this processor fetch the given CrawlURI. May set a fetch\nstatus if\n&gt;+\t * this processor would usually handle the CrawlURI, but cannot\nin this\n&gt;+\t * instance.\n&gt;+\t * \n&gt;+\t * @param curi\n&gt;+\t * @return True if processor can fetch.\n&gt;+\t */\n&gt;+\tprivate boolean canFetch(CrawlURI curi) {\n&gt;+\t\tString scheme = curi.getUURI().getScheme();\n&gt;+\t\tif (!(scheme.equals(&quot;http&quot;) || scheme.equals(&quot;https&quot;)))\n{\n&gt;+\t\t\t// handles only plain http and https\n&gt;+\t\t\treturn false;\n&gt;+\t\t}\n&gt;+\n&gt;+\t\t//         System.out.println(curi.toString() + &quot; : &quot; +\n&gt;+\t\t// curi.getFetchAttempts());\n&gt;+\t\t//         if (curi.getFetchAttempts() &gt;=\ngetMaxFetchAttempts(curi)) {\n&gt;+\t\t//             curi.setFetchStatus(S_TOO_MANY_RETRIES);\n&gt;+\t\t//             return false;\n&gt;+\t\t//         }\n&gt;+\n&gt;+\t\t// make sure the dns lookup succeeded\n&gt;+\t\tif (curi.getServer().getHost().getIP() == null\n&gt;+\t\t\t\t&&\ncuri.getServer().getHost().hasBeenLookedUp()) {\n&gt;+\t\t\tcuri.setFetchStatus(S_DOMAIN_UNRESOLVABLE);\n&gt;+\t\t\treturn false;\n&gt;+\t\t}\n&gt;+\t\treturn true;\n&gt;+\t}\n&gt;+\n&gt;+\t/**\n&gt;+\t * Configure the HttpMethod setting options and headers.\n&gt;+\t * \n&gt;+\t * @param curi\n&gt;+\t *                    CrawlURI from which we pull configuration.\n&gt;+\t * @param get\n&gt;+\t *                    The GetMethod to configure.\n&gt;+\t */\n&gt;+\tprivate void configureMethod(CrawlURI curi, HttpMethod method) {\n&gt;+\t\t// Don&#39;t auto-follow redirects\n&gt;+\t\tmethod.setFollowRedirects(false);\n&gt;+\n&gt;+\t\t// Set strict on the client; whatever the client&#39;s mode\noverrides\n&gt;+\t\t// the methods mode inside in the depths of\nexecuteMethod.\n&gt;+\t\tthis.http.setStrictMode(DEFAULT_HTTPCLIENT_STRICT);\n&gt;+\n&gt;+\t\ttry {\n&gt;+\t\t\tString proxy = (String)\ngetAttribute(ATTR_HTTP_PROXY_HOST);\n&gt;+\t\t\tif (proxy.equals(&quot;&quot;) != true) {\n&gt;+\t\t\t\tthis.http.setHttpProxy(proxy);\n&gt;+\t\t\t\tthis.http\n&gt;+\n.setHttpProxyport(Integer\n&gt;+\n.parseInt(((String) getAttribute(ATTR_HTTP_PROXY_PORT))));\n&gt;+\t\t\t}\n&gt;+\t\t} catch (AttributeNotFoundException e) {\n&gt;+\t\t\t// TODO Auto-generated catch block\n&gt;+\t\t\te.printStackTrace();\n&gt;+\t\t} catch (MBeanException e) {\n&gt;+\t\t\t// TODO Auto-generated catch block\n&gt;+\t\t\te.printStackTrace();\n&gt;+\t\t} catch (ReflectionException e) {\n&gt;+\t\t\t// TODO Auto-generated catch block\n&gt;+\t\t\te.printStackTrace();\n&gt;+\t\t}\n&gt;+\n&gt;+\t\t// Use only HTTP/1.0 (to avoid receiving chunked\nresponses)\n&gt;+\t\t((HttpMethodBase) method).setHttp11(false);\n&gt;+\n&gt;+\t\tCrawlOrder order = getSettingsHandler().getOrder();\n&gt;+\t\tString userAgent = curi.getUserAgent();\n&gt;+\t\tif (userAgent == null) {\n&gt;+\t\t\tuserAgent = order.getUserAgent(curi);\n&gt;+\t\t}\n&gt;+\t\tmethod.setRequestHeader(&quot;User-Agent&quot;, userAgent);\n&gt;+\t\tmethod.setRequestHeader(&quot;From&quot;, order.getFrom(curi));\n&gt;+\t}\n&gt;+\n&gt;+\t/**\n&gt;+\t * Add credentials if any to passed &lt;code&gt;method&lt;/code&gt;.\n&gt;+\t * \n&gt;+\t * Do credential handling. Credentials are in two places. 1.\nCredentials\n&gt;+\t * that succeeded are added to the CrawlServer (Or rather,\navatars for\n&gt;+\t * credentials are whats added because its not safe to keep\naround\n&gt;+\t * references to credentials). 2. Credentials to be tried are in\nthe curi.\n&gt;+\t * Returns true if found credentials to be tried.\n&gt;+\t * \n&gt;+\t * @param curi\n&gt;+\t *                    Current CrawlURI.\n&gt;+\t * @param method\n&gt;+\t *                    The method to add to.\n&gt;+\t * @return True if prepopulated &lt;code&gt;method&lt;/code&gt; with\ncredentials AND\n&gt;+\t *               the credentials came from the\n&lt;code&gt;curi&lt;/code&gt;, not from the\n&gt;+\t *               CrawlServer. The former is special in that if\nthe\n&gt;+\t *               &lt;code&gt;curi&lt;/curi&gt; credentials\n&gt;+\t * succeed, then the caller needs to promote them from the\nCrawlURI to the\n&gt;+\t * CrawlServer so they are available for all subsequent\nCrawlURIs on this\n&gt;+\t * server.\n&gt;+\t */\n&gt;+\tprivate boolean populateCredentials(CrawlURI curi, HttpMethod\nmethod) {\n&gt;+\n&gt;+\t\t// First look at the server avatars. Add any that are to\nbe volunteered\n&gt;+\t\t// on every request (e.g. RFC2617 credentials). Every\ntime creds will\n&gt;+\t\t// return true when we call &#39;isEveryTime().\n&gt;+\t\tif (curi.getServer().hasCredentialAvatars()) {\n&gt;+\t\t\tSet avatars =\ncuri.getServer().getCredentialAvatars();\n&gt;+\t\t\tfor (Iterator i = avatars.iterator();\ni.hasNext();) {\n&gt;+\t\t\t\tCredentialAvatar ca = (CredentialAvatar)\ni.next();\n&gt;+\t\t\t\tCredential c =\nca.getCredential(getSettingsHandler(), curi);\n&gt;+\t\t\t\tif (c.isEveryTime()) {\n&gt;+\t\t\t\t\tc.populate(curi, this.http,\nmethod, ca.getPayload());\n&gt;+\t\t\t\t}\n&gt;+\t\t\t}\n&gt;+\t\t}\n&gt;+\n&gt;+\t\tboolean result = false;\n&gt;+\n&gt;+\t\t// Now look in the curi. The Curi will have credentials\nloaded either\n&gt;+\t\t// by the handle401 method if its a rfc2617 or it&#39;ll\nhave been set into\n&gt;+\t\t// the curi by the preconditionenforcer as this login\nuri came through.\n&gt;+\t\tif (curi.hasCredentialAvatars()) {\n&gt;+\t\t\tSet avatars = curi.getCredentialAvatars();\n&gt;+\t\t\tfor (Iterator i = avatars.iterator();\ni.hasNext();) {\n&gt;+\t\t\t\tCredentialAvatar ca = (CredentialAvatar)\ni.next();\n&gt;+\t\t\t\tCredential c =\nca.getCredential(getSettingsHandler(), curi);\n&gt;+\t\t\t\tif (c.populate(curi, this.http, method,\nca.getPayload())) {\n&gt;+\t\t\t\t\tresult = true;\n&gt;+\t\t\t\t}\n&gt;+\t\t\t}\n&gt;+\t\t}\n&gt; \n&gt;-    void setupHttp() throws RuntimeException {\n&gt;+\t\treturn result;\n&gt;+\t}\n&gt;+\n&gt;+\t/**\n&gt;+\t * Promote successful credential to the server.\n&gt;+\t * \n&gt;+\t * @param curi\n&gt;+\t *                    CrawlURI whose credentials we are to\npromote.\n&gt;+\t * @param method\n&gt;+\t *                    Method used.\n&gt;+\t */\n&gt;+\tprivate void promoteCredentials(final CrawlURI curi) {\n&gt;+\t\tif (!curi.hasCredentialAvatars()) {\n&gt;+\t\t\tlogger.severe(&quot;No credentials to promote when\nthere should be &quot;\n&gt;+\t\t\t\t\t+ curi);\n&gt;+\t\t} else {\n&gt;+\t\t\tSet avatars = curi.getCredentialAvatars();\n&gt;+\t\t\tfor (Iterator i = avatars.iterator();\ni.hasNext();) {\n&gt;+\t\t\t\tCredentialAvatar ca = (CredentialAvatar)\ni.next();\n&gt;+\t\t\t\tcuri.removeCredentialAvatar(ca);\n&gt;+\t\t\t\t// The server to attach too may not be\nthe server that hosts\n&gt;+\t\t\t\t// this passed curi. It might be of\nanother subdomain.\n&gt;+\t\t\t\t// The avatar needs to be added to the\nserver that is dependent\n&gt;+\t\t\t\t// on this precondition. Find it by\nname. Get the name from\n&gt;+\t\t\t\t// the credential this avatar\nrepresents.\n&gt;+\t\t\t\tCredential c =\nca.getCredential(getSettingsHandler(), curi);\n&gt;+\t\t\t\tString cd = null;\n&gt;+\t\t\t\ttry {\n&gt;+\t\t\t\t\tcd =\nc.getCredentialDomain(curi);\n&gt;+\t\t\t\t} catch (AttributeNotFoundException e) {\n&gt;+\t\t\t\t\tlogger.severe(&quot;Failed to get\ncred domain for &quot; + curi\n&gt;+\t\t\t\t\t\t\t+ &quot; for &quot; + ca +\n&quot;: &quot; + e.getMessage());\n&gt;+\t\t\t\t}\n&gt;+\t\t\t\tif (cd != null) {\n&gt;+\t\t\t\t\tCrawlServer cs =\ngetController().getServerCache()\n&gt;+\n.getServerFor(cd);\n&gt;+\t\t\t\t\tif (cs != null) {\n&gt;+\ncs.addCredentialAvatar(ca);\n&gt;+\t\t\t\t\t}\n&gt;+\t\t\t\t}\n&gt;+\t\t\t}\n&gt;+\t\t}\n&gt;+\t}\n&gt;+\n&gt;+\t/**\n&gt;+\t * Server is looking for basic/digest auth credentials\n(RFC2617). If we have\n&gt;+\t * any, put them into the CrawlURI and have it come around\nagain. Presence\n&gt;+\t * of the credential serves as flag to frontier to requeue\npromptly. If we\n&gt;+\t * already tried this domain and still got a 401, then our\ncredentials are\n&gt;+\t * bad. Remove them and let this curi die.\n&gt;+\t * \n&gt;+\t * @param get\n&gt;+\t *                    Method that got a 401.\n&gt;+\t * @param curi\n&gt;+\t *                    CrawlURI that got a 401.\n&gt;+\t */\n&gt;+\tprivate void handle401(final HttpMethod method, final CrawlURI\ncuri) {\n&gt;+\n&gt;+\t\tAuthScheme authscheme = getAuthScheme(method, curi);\n&gt;+\t\tif (authscheme == null) {\n&gt;+\t\t\treturn;\n&gt;+\t\t}\n&gt;+\n&gt;+\t\tString realm = authscheme.getRealm();\n&gt;+\t\tif (realm == null) {\n&gt;+\t\t\treturn;\n&gt;+\t\t}\n&gt;+\n&gt;+\t\t// Look to see if this curi had rfc2617 avatars loaded.\nIf so, are\n&gt;+\t\t// any of them for this realm? If so, then the\ncredential failed if\n&gt;+\t\t// we got a 401 and it should be let die a natural 401\ndeath.\n&gt;+\t\tSet curiRfc2617Credentials =\ngetCredentials(getSettingsHandler(), curi,\n&gt;+\t\t\t\tRfc2617Credential.class);\n&gt;+\t\tRfc2617Credential extant = Rfc2617Credential.getByRealm(\n&gt;+\t\t\t\tcuriRfc2617Credentials, realm, curi);\n&gt;+\t\tif (extant != null) {\n&gt;+\t\t\t// Then, already tried this credential. Remove\nANY rfc2617\n&gt;+\t\t\t// credential since presence of a rfc2617\ncredential serves\n&gt;+\t\t\t// as flag to frontier to requeue this curi and\nlet the curi\n&gt;+\t\t\t// die a natural death.\n&gt;+\t\t\textant.detachAll(curi);\n&gt;+\t\t\tlogger.fine(&quot;Auth failed (401) though supplied\nrealm &quot; + realm\n&gt;+\t\t\t\t\t+ &quot; to &quot; + curi.toString());\n&gt;+\t\t} else {\n&gt;+\t\t\t// Look see if we have a credential that\ncorresponds to this realm\n&gt;+\t\t\t// in credential store. Filter by type and\ncredential domain. If\n&gt;+\t\t\t// not, let this curi die. Else, add it to the\ncuri and let it come\n&gt;+\t\t\t// around again. Add in the AuthScheme we got\ntoo. Its needed when\n&gt;+\t\t\t// we go to run the Auth on second time around.\n&gt;+\t\t\tCredentialStore cs = CredentialStore\n&gt;+\n.getCredentialStore(getSettingsHandler());\n&gt;+\t\t\tif (cs == null) {\n&gt;+\t\t\t\tlogger.severe(&quot;No credential store for &quot;\n+ curi);\n&gt;+\t\t\t} else {\n&gt;+\t\t\t\tSet storeRfc2617Credentials =\ncs.subset(curi,\n&gt;+\t\t\t\t\t\tRfc2617Credential.class,\ncuri.getServer().getName());\n&gt;+\t\t\t\tif (storeRfc2617Credentials == null\n&gt;+\t\t\t\t\t\t||\nstoreRfc2617Credentials.size() &lt;= 0) {\n&gt;+\t\t\t\t\tlogger.fine(&quot;No rfc2617\ncredentials for &quot; + curi);\n&gt;+\t\t\t\t} else {\n&gt;+\t\t\t\t\tRfc2617Credential found =\nRfc2617Credential.getByRealm(\n&gt;+\nstoreRfc2617Credentials, realm, curi);\n&gt;+\t\t\t\t\tif (found == null) {\n&gt;+\t\t\t\t\t\tlogger.fine(&quot;No rfc2617\ncredentials for realm &quot; + realm\n&gt;+\t\t\t\t\t\t\t\t+ &quot; in &quot;\n+ curi);\n&gt;+\t\t\t\t\t} else {\n&gt;+\t\t\t\t\t\tfound.attach(curi,\nauthscheme);\n&gt;+\t\t\t\t\t\tlogger.fine(&quot;Found\ncredential for realm &quot; + realm\n&gt;+\t\t\t\t\t\t\t\t+ &quot; in\nstore for &quot; + curi.toString());\n&gt;+\t\t\t\t\t}\n&gt;+\t\t\t\t}\n&gt;+\t\t\t}\n&gt;+\t\t}\n&gt;+\t}\n&gt;+\n&gt;+\t/**\n&gt;+\t * @param handler\n&gt;+\t *                    Settings Handler.\n&gt;+\t * @param curi\n&gt;+\t *                    CrawlURI that got a 401.\n&gt;+\t * @param type\n&gt;+\t *                    Class of credential to get from curi.\n&gt;+\t * @return Set of credentials attached to this curi.\n&gt;+\t */\n&gt;+\tprivate Set getCredentials(SettingsHandler handler, CrawlURI\ncuri,\n&gt;+\t\t\tClass type) {\n&gt;+\t\tSet result = null;\n&gt;+\n&gt;+\t\tif (curi.hasCredentialAvatars()) {\n&gt;+\t\t\tfor (Iterator i =\ncuri.getCredentialAvatars().iterator(); i\n&gt;+\t\t\t\t\t.hasNext();) {\n&gt;+\t\t\t\tCredentialAvatar ca = (CredentialAvatar)\ni.next();\n&gt;+\t\t\t\tif (ca.match(type)) {\n&gt;+\t\t\t\t\tif (result == null) {\n&gt;+\t\t\t\t\t\tresult = new HashSet();\n&gt;+\t\t\t\t\t}\n&gt;+\nresult.add(ca.getCredential(handler, curi));\n&gt;+\t\t\t\t}\n&gt;+\t\t\t}\n&gt;+\t\t}\n&gt;+\t\treturn result;\n&gt;+\t}\n&gt;+\n&gt;+\t/**\n&gt;+\t * @param get\n&gt;+\t *                    Method that got a 401.\n&gt;+\t * @param curi\n&gt;+\t *                    CrawlURI that got a 401.\n&gt;+\t * @return Authscheme made from the authenticate header or null\nif failed to\n&gt;+\t *               get it.\n&gt;+\t */\n&gt;+\tprivate AuthScheme getAuthScheme(final HttpMethod method,\n&gt;+\t\t\tfinal CrawlURI curi) {\n&gt;+\t\tAuthScheme result = null;\n&gt;+\t\tHeader header =\nmethod.getResponseHeader(HttpAuthenticator.WWW_AUTH);\n&gt;+\t\tif (header == null) {\n&gt;+\t\t\tlogger.info(&quot;No &quot; + HttpAuthenticator.WWW_AUTH +\n&quot; headers though&quot;\n&gt;+\t\t\t\t\t+ &quot; we got a 401: &quot; + curi);\n&gt;+\t\t} else {\n&gt;+\t\t\ttry {\n&gt;+\t\t\t\tresult = HttpAuthenticator\n&gt;+\t\t\t\t\t\t.selectAuthScheme(new\nHeader[]{header});\n&gt;+\t\t\t} catch (MalformedChallengeException e) {\n&gt;+\t\t\t\tlogger.severe(&quot;Failed to get auth\nheaders: &quot; + e.toString()\n&gt;+\t\t\t\t\t\t+ &quot; &quot; +\ncuri.toString());\n&gt;+\t\t\t} catch (UnsupportedOperationException uoe) {\n&gt;+\t\t\t\t// This is probably a message like this:\n&gt;+\t\t\t\t// Authentication scheme(s) not\nsupported:\n&gt;+\t\t\t\t// {negotiate,=Negotiate, NTLM}\n&gt;+\t\t\t\t// Log it as a warning. Not much we can\ndo about it. Return\n&gt;+\t\t\t\t// null. We&#39;ll get the 401 in the arcs\nand a page that says\n&gt;+\t\t\t\t// something like &#39;Access denied&#39;.\n&gt;+\t\t\t\tlogger.warning(curi + &quot;: &quot; + uoe);\n&gt;+\t\t\t}\n&gt;+\t\t}\n&gt;+\t\treturn result;\n&gt;+\t}\n&gt;+\n&gt;+\tpublic void initialTasks() {\n&gt;+\t\tthis.soTimeout = getSoTimeout(null);\n&gt;+\t\tsetupHttp();\n&gt;+\n&gt;+\t\t// load cookies from a file if specified in the order\nfile.\n&gt;+\t\tloadCookies();\n&gt;+\t}\n&gt;+\n&gt;+\tvoid setupHttp() throws RuntimeException {\n&gt;\nCookiePolicy.setDefaultPolicy(CookiePolicy.COMPATIBILITY);\n&gt;-        SingleHttpConnectionManager connectionManager =\n&gt;-            new SingleHttpConnectionManager();\n&gt;-        this.http = new PatchedHttpClient(connectionManager);\n&gt;-\n&gt;-        try {\n&gt;-            String trustLevel = (String) getAttribute(ATTR_TRUST);\n&gt;-            Protocol.registerProtocol(&quot;https&quot;, new Protocol(&quot;https&quot;,\n&gt;-                    new ConfigurableTrustManagerProtocolSocketFactory(\n&gt;-                            trustLevel), 443));\n&gt;-        }\n&gt;-\n&gt;-        catch (Exception e) {\n&gt;-            // Convert all to RuntimeException so get an exception out\nif\n&gt;-            // initialization fails.\n&gt;-            throw new RuntimeException(\n&gt;-                    &quot;Failed initialization getting attributes: &quot;\n&gt;-                            + e.getMessage());\n&gt;-        }\n&gt;-\n&gt;-        // Considered same as overall timeout, for now.\n&gt;-        // TODO: When HTTPClient stops using a monitor &#39;waitingThread&#39;\n&gt;-        // thread to watch over the getting of the socket from socket\n&gt;-        // factory and instead supports the java.net.Socket#connect\ntimeout.\n&gt;-        // http.setConnectionTimeout((int)timeout);\n&gt;-        // set per-read() timeout: overall timeout will be checked at\nleast\n&gt;-        // this\n&gt;-        // frequently\n&gt;-        this.http.setTimeout(this.soTimeout);\n&gt;-\t}\n&gt;-\n&gt;-    private int getSoTimeout(CrawlURI curi) {\n&gt;-        Integer res;\n&gt;-        try {\n&gt;-            res = (Integer) getAttribute(ATTR_SOTIMEOUT_MS, curi);\n&gt;-        } catch (Exception e) {\n&gt;-            res = DEFAULT_SOTIMEOUT_MS;\n&gt;-        }\n&gt;-        return res.intValue();\n&gt;-    }\n&gt;-\n&gt;-    private int getTimeout(CrawlURI curi) {\n&gt;-        Integer res;\n&gt;-        try {\n&gt;-            res = (Integer) getAttribute(ATTR_TIMEOUT_SECONDS, curi);\n&gt;-        } catch (Exception e) {\n&gt;-            res = DEFAULT_TIMEOUT_SECONDS;\n&gt;-        }\n&gt;-        return res.intValue();\n&gt;-    }\n&gt;-\n&gt;-    private long getMaxLength(CrawlURI curi) {\n&gt;-        Long res;\n&gt;-        try {\n&gt;-            res = (Long) getAttribute(ATTR_MAX_LENGTH_BYTES, curi);\n&gt;-        } catch (Exception e) {\n&gt;-            res = DEFAULT_MAX_LENGTH_BYTES;\n&gt;-        }\n&gt;-        return res.longValue();\n&gt;-    }\n&gt;-\n&gt;-    /**\n&gt;-     * Load cookies from a file before the first fetch.\n&gt;-     * &lt;p&gt;\n&gt;-     * The file is a text file in the Netscape&#39;s &#39;cookies.txt&#39; file\nformat.&lt;br&gt;\n&gt;-     * Example entry of cookies.txt file:&lt;br&gt;\n&gt;-     * &lt;br&gt;\n&gt;-     * www.archive.org FALSE / FALSE 1074567117 details-visit\ntexts-cralond&lt;br&gt;\n&gt;-     * &lt;br&gt;\n&gt;-     * Each line has 7 tab-separated fields:&lt;br&gt;\n&gt;-     * &lt;li&gt;1. DOMAIN: The domain that created and have access to the\ncookie\n&gt;-     * value.\n&gt;-     * &lt;li&gt;2. FLAG: A TRUE or FALSE value indicating if hosts within\nthe given\n&gt;-     * domain can access the cookie value.\n&gt;-     * &lt;li&gt;3. PATH: The path within the domain that the cookie value\nis valid\n&gt;-     * for.\n&gt;-     * &lt;li&gt;4. SECURE: A TRUE or FALSE value indicating if to use a\nsecure\n&gt;-     * connection to access the cookie value.\n&gt;-     * &lt;li&gt;5. EXPIRATION: The expiration time of the cookie value\n(unix style.)\n&gt;-     * &lt;li&gt;6. NAME: The name of the cookie value\n&gt;-     * &lt;li&gt;7. VALUE: The cookie value\n&gt;-     *\n&gt;-     * @param cookiesFile file in the Netscape&#39;s &#39;cookies.txt&#39; format.\n&gt;-     */\n&gt;-    public void loadCookies(String cookiesFile) {\n&gt;-        // Do nothing if cookiesFile is not specified.\n&gt;-        if (cookiesFile == null || cookiesFile.length() &lt;= 0) {\n&gt;-            return;\n&gt;-        }\n&gt;-        RandomAccessFile raf = null;\n&gt;-        try {\n&gt;-            raf = new RandomAccessFile(cookiesFile, &quot;r&quot;);\n&gt;-            String[] cookieParts;\n&gt;-            String line;\n&gt;-            Cookie cookie = null;\n&gt;-            while ((line = raf.readLine()) != null) {\n&gt;-                // Line that starts with # is commented line,\ntherefore skip it.\n&gt;-                if (!line.startsWith(&quot;#&quot;)) {\n&gt;-                    cookieParts = line.split(&quot;&#92;&#92;t&quot;);\n&gt;-                    if (cookieParts.length == 7) {\n&gt;-                        // Create cookie with not expiration date (-1\nvalue).\n&gt;-                        // TODO: add this as an option.\n&gt;-                        cookie =\n&gt;-                            new Cookie(cookieParts[0], cookieParts[5],\n&gt;-                                cookieParts[6], cookieParts[2], -1,\n&gt;-\nBoolean.valueOf(cookieParts[3]).booleanValue());\n&gt;-\n&gt;-                        if\n(cookieParts[1].toLowerCase().equals(&quot;true&quot;)) {\n&gt;-                            cookie.setDomainAttributeSpecified(true);\n&gt;-                        } else {\n&gt;-                            cookie.setDomainAttributeSpecified(false);\n&gt;-                        }\n&gt;-                        this.http.getState().addCookie(cookie);\n&gt;-                        logger.fine(\n&gt;-                            &quot;Adding cookie: &quot; +\ncookie.toExternalForm());\n&gt;-                    }\n&gt;-                }\n&gt;-            }\n&gt;-        } catch (FileNotFoundException e) {\n&gt;-            // We should probably throw FatalConfigurationException.\n&gt;-            System.out.println(&quot;Could not find file: &quot; + cookiesFile\n&gt;-                    + &quot; (Element: &quot; + ATTR_LOAD_COOKIES + &quot;)&quot;);\n&gt;-\n&gt;-        } catch (IOException e) {\n&gt;-            // We should probably throw FatalConfigurationException.\n&gt;-            e.printStackTrace();\n&gt;-        } finally {\n&gt;-            try {\n&gt;-                if (raf != null) {\n&gt;-                    raf.close();\n&gt;-                }\n&gt;-            } catch (IOException e) {\n&gt;-                e.printStackTrace();\n&gt;-            }\n&gt;-        }\n&gt;-    }\n&gt;-\n&gt;-    /* (non-Javadoc)\n&gt;-     * @see org.archive.crawler.framework.Processor#report()\n&gt;-     */\n&gt;-    public String report() {\n&gt;-        StringBuffer ret = new StringBuffer();\n&gt;-        ret.append(&quot;Processor:\norg.archive.crawler.fetcher.FetchHTTP&#92;n&quot;);\n&gt;-        ret.append(&quot;  Function:          Fetch HTTP URIs&#92;n&quot;);\n&gt;-        ret.append(&quot;  CrawlURIs handled: &quot; + this.curisHandled +\n&quot;&#92;n&quot;);\n&gt;-        ret.append(&quot;  Recovery retries:   &quot; + this.recoveryRetries +\n&quot;&#92;n&#92;n&quot;);\n&gt;-\n&gt;-        return ret.toString();\n&gt;-    }\n&gt;-\n&gt;-\n&gt;-    /**\n&gt;-     * Load cookies from the file specified in the order file.\n&gt;-     *\n&gt;-     * &lt;p&gt;\n&gt;-     * The file is a text file in the Netscape&#39;s &#39;cookies.txt&#39; file\nformat.&lt;br&gt;\n&gt;-     * Example entry of cookies.txt file:&lt;br&gt;\n&gt;-     * &lt;br&gt;\n&gt;-     * www.archive.org FALSE / FALSE 1074567117 details-visit\ntexts-cralond&lt;br&gt;\n&gt;-     * &lt;br&gt;\n&gt;-     * Each line has 7 tab-separated fields:&lt;br&gt;\n&gt;-     * &lt;li&gt;1. DOMAIN: The domain that created and have access to the\ncookie\n&gt;-     * value.\n&gt;-     * &lt;li&gt;2. FLAG: A TRUE or FALSE value indicating if hosts within\nthe given\n&gt;-     * domain can access the cookie value.\n&gt;-     * &lt;li&gt;3. PATH: The path within the domain that the cookie value\nis valid\n&gt;-     * for.\n&gt;-     * &lt;li&gt;4. SECURE: A TRUE or FALSE value indicating if to use a\nsecure\n&gt;-     * connection to access the cookie value.\n&gt;-     * &lt;li&gt;5. EXPIRATION: The expiration time of the cookie value\n(unix style.)\n&gt;-     * &lt;li&gt;6. NAME: The name of the cookie value\n&gt;-     * &lt;li&gt;7. VALUE: The cookie value\n&gt;-     */\n&gt;-    public void loadCookies() {\n&gt;-        try {\n&gt;-            loadCookies((String) getAttribute(ATTR_LOAD_COOKIES));\n&gt;-        } catch (MBeanException e) {\n&gt;-            logger.warning(e.getLocalizedMessage());\n&gt;-        } catch (ReflectionException e) {\n&gt;-            logger.warning(e.getLocalizedMessage());\n&gt;-        } catch (AttributeNotFoundException e) {\n&gt;-            logger.warning(e.getLocalizedMessage());\n&gt;-        }\n&gt;-    }\n&gt;-    /**\n&gt;-     * Saves cookies to the file specified in the order file.\n&gt;-     *\n&gt;-     * Output file is in the Netscape &#39;cookies.txt&#39; format.\n&gt;-     *\n&gt;-     */\n&gt;-    public void saveCookies() {\n&gt;-        try {\n&gt;-            saveCookies((String) getAttribute(ATTR_SAVE_COOKIES));\n&gt;-        } catch (MBeanException e) {\n&gt;-            logger.warning(e.getLocalizedMessage());\n&gt;-        } catch (ReflectionException e) {\n&gt;-            logger.warning(e.getLocalizedMessage());\n&gt;-        } catch (AttributeNotFoundException e) {\n&gt;-            logger.warning(e.getLocalizedMessage());\n&gt;-        }\n&gt;-    }\n&gt;-    /**\n&gt;-     * Saves cookies to a file.\n&gt;-     *\n&gt;-     * Output file is in the Netscape &#39;cookies.txt&#39; format.\n&gt;-     *\n&gt;-     * @param saveCookiesFile output file.\n&gt;-     */\n&gt;-    public void saveCookies(String saveCookiesFile) {\n&gt;-        // Do nothing if cookiesFile is not specified.\n&gt;-        if (saveCookiesFile == null || saveCookiesFile.length() &lt;= 0)\n{\n&gt;-            return;\n&gt;-        }\n&gt;-\n&gt;-        FileOutputStream out = null;\n&gt;-        try {\n&gt;-            out = new FileOutputStream(new File(saveCookiesFile));\n&gt;-            Cookie cookies[] = this.http.getState().getCookies();\n&gt;-            String tab =&quot;&#92;t&quot;;\n&gt;-            out.write(&quot;# Heritrix Cookie File&#92;n&quot;.getBytes());\n&gt;-            out.write(\n&gt;-                &quot;# This file is the Netscape cookies.txt\nformat&#92;n&#92;n&quot;.getBytes());\n&gt;-            for (int i = 0; i &lt; cookies.length; i++) {\n&gt;-                StringBuffer line = new StringBuffer();\n&gt;-                line.append(cookies[i].getDomain());\n&gt;-                line.append(tab);\n&gt;-                line.append(\n&gt;-                    cookies[i].isDomainAttributeSpecified() == true\n&gt;-                        ? &quot;TRUE&quot;\n&gt;-                        : &quot;FALSE&quot;);\n&gt;-                line.append(tab);\n&gt;-                line.append(cookies[i].getPath());\n&gt;-                line.append(tab);\n&gt;-                line.append(\n&gt;-                    cookies[i].getSecure() == true ? &quot;TRUE&quot; :\n&quot;FALSE&quot;);\n&gt;-                line.append(tab);\n&gt;-                line.append(cookies[i].getName());\n&gt;-                line.append(tab);\n&gt;-                line.append(cookies[i].getValue());\n&gt;-                line.append(&quot;&#92;n&quot;);\n&gt;-                out.write(line.toString().getBytes());\n&gt;-            }\n&gt;-        } catch (FileNotFoundException e) {\n&gt;-            // We should probably throw FatalConfigurationException.\n&gt;-            System.out.println(&quot;Could not find file: &quot; +\nsaveCookiesFile\n&gt;-                    + &quot; (Element: &quot; + ATTR_SAVE_COOKIES + &quot;)&quot;);\n&gt;-        } catch (IOException e) {\n&gt;-            e.printStackTrace();\n&gt;-        } finally {\n&gt;-            try {\n&gt;-                if (out != null) {\n&gt;-                    out.close();\n&gt;-                }\n&gt;-            } catch (IOException e) {\n&gt;-                e.printStackTrace();\n&gt;-            }\n&gt;-        }\n&gt;-    }\n&gt;-    /**\n&gt;-     * At the end save cookies to the file specified in the order\nfile.\n&gt;-     *\n&gt;-     * @see org.archive.crawler.framework.Processor#finalTasks()\n&gt;-     */\n&gt;-    public void finalTasks() {\n&gt;-        saveCookies();\n&gt;-    }\n&gt;-\n&gt;-    /* (non-Javadoc)\n&gt;-     * @see\norg.archive.crawler.settings.ModuleType#listUsedFiles(java.util.List)\n&gt;-     */\n&gt;-    protected void listUsedFiles(List list) {\n&gt;-        // List the cookies files\n&gt;-        // Add seed file\n&gt;-        try {\n&gt;-            String tmp = (String)getAttribute(ATTR_LOAD_COOKIES);\n&gt;-            if(tmp != null && tmp.length() &gt; 0){\n&gt;-                File file = getSettingsHandler().\n&gt;-                        getPathRelativeToWorkingDirectory(tmp);\n&gt;-                list.add(file.getAbsolutePath());\n&gt;-            }\n&gt;-            tmp = (String)getAttribute(ATTR_SAVE_COOKIES);\n&gt;-            if(tmp != null && tmp.length() &gt; 0){\n&gt;-                File file = getSettingsHandler().\n&gt;-                        getPathRelativeToWorkingDirectory(tmp);\n&gt;-                list.add(file.getAbsolutePath());\n&gt;-            }\n&gt;-        } catch (AttributeNotFoundException e) {\n&gt;-            // TODO Auto-generated catch block\n&gt;-            e.printStackTrace();\n&gt;-        } catch (MBeanException e) {\n&gt;-            // TODO Auto-generated catch block\n&gt;-            e.printStackTrace();\n&gt;-        } catch (ReflectionException e) {\n&gt;-            // TODO Auto-generated catch block\n&gt;-            e.printStackTrace();\n&gt;-        }\n&gt;-    }\n&gt;-    \n&gt;-    // custom serialization\n&gt;-    private void writeObject(ObjectOutputStream stream) throws\nIOException {\n&gt;-        stream.defaultWriteObject();\n&gt;-        // save cookies\n&gt;-        stream.writeObject(http.getState().getCookies());\n&gt;-    }\n&gt;-    \n&gt;-    private void readObject(ObjectInputStream stream) throws\nIOException, ClassNotFoundException {\n&gt;-        stream.defaultReadObject();\n&gt;-        Cookie cookies[] = (Cookie[]) stream.readObject();\n&gt;-        ObjectPlusFilesInputStream coistream =\n(ObjectPlusFilesInputStream)stream;\n&gt;-        coistream.registerFinishTask( new PostRestore(cookies) );\n&gt;-    }\n&gt;-    \n&gt;-    class PostRestore implements Runnable {\n&gt;-        Cookie cookies[];\n&gt;-        public PostRestore(Cookie cookies[]) {\n&gt;-            this.cookies = cookies;\n&gt;-        }\n&gt;-    \tpublic void run() {\n&gt;-            setupHttp();\n&gt;-            for(int i = 0; i &lt; cookies.length; i++) {\n&gt;-                FetchHTTP.this.http.getState().addCookie(cookies[i]);\n&gt;-            }\n&gt;-        }\n&gt;-    }\n&gt;-}\n&gt;+\t\tSingleHttpConnectionManager connectionManager = new\nSingleHttpConnectionManager();\n&gt;+\t\tthis.http = new PatchedHttpClient(connectionManager);\n&gt;+\n&gt;+\t\ttry {\n&gt;+\t\t\tString trustLevel = (String)\ngetAttribute(ATTR_TRUST);\n&gt;+\t\t\tProtocol.registerProtocol(&quot;https&quot;, new\nProtocol(&quot;https&quot;,\n&gt;+\t\t\t\t\tnew\nConfigurableTrustManagerProtocolSocketFactory(\n&gt;+\t\t\t\t\t\t\ttrustLevel),\n443));\n&gt;+\t\t}\n&gt;+\n&gt;+\t\tcatch (Exception e) {\n&gt;+\t\t\t// Convert all to RuntimeException so get an\nexception out if\n&gt;+\t\t\t// initialization fails.\n&gt;+\t\t\tthrow new RuntimeException(\n&gt;+\t\t\t\t\t&quot;Failed initialization getting\nattributes: &quot;\n&gt;+\t\t\t\t\t\t\t+\ne.getMessage());\n&gt;+\t\t}\n&gt;+\n&gt;+\t\t// Considered same as overall timeout, for now.\n&gt;+\t\t// TODO: When HTTPClient stops using a monitor\n&#39;waitingThread&#39;\n&gt;+\t\t// thread to watch over the getting of the socket from\nsocket\n&gt;+\t\t// factory and instead supports the\njava.net.Socket#connect timeout.\n&gt;+\t\t// http.setConnectionTimeout((int)timeout);\n&gt;+\t\t// set per-read() timeout: overall timeout will be\nchecked at least\n&gt;+\t\t// this\n&gt;+\t\t// frequently\n&gt;+\t\tthis.http.setTimeout(this.soTimeout);\n&gt;+\t}\n&gt;+\n&gt;+\tprivate int getSoTimeout(CrawlURI curi) {\n&gt;+\t\tInteger res;\n&gt;+\t\ttry {\n&gt;+\t\t\tres = (Integer) getAttribute(ATTR_SOTIMEOUT_MS,\ncuri);\n&gt;+\t\t} catch (Exception e) {\n&gt;+\t\t\tres = DEFAULT_SOTIMEOUT_MS;\n&gt;+\t\t}\n&gt;+\t\treturn res.intValue();\n&gt;+\t}\n&gt;+\n&gt;+\tprivate int getTimeout(CrawlURI curi) {\n&gt;+\t\tInteger res;\n&gt;+\t\ttry {\n&gt;+\t\t\tres = (Integer)\ngetAttribute(ATTR_TIMEOUT_SECONDS, curi);\n&gt;+\t\t} catch (Exception e) {\n&gt;+\t\t\tres = DEFAULT_TIMEOUT_SECONDS;\n&gt;+\t\t}\n&gt;+\t\treturn res.intValue();\n&gt;+\t}\n&gt;+\n&gt;+\tprivate long getMaxLength(CrawlURI curi) {\n&gt;+\t\tLong res;\n&gt;+\t\ttry {\n&gt;+\t\t\tres = (Long) getAttribute(ATTR_MAX_LENGTH_BYTES,\ncuri);\n&gt;+\t\t} catch (Exception e) {\n&gt;+\t\t\tres = DEFAULT_MAX_LENGTH_BYTES;\n&gt;+\t\t}\n&gt;+\t\treturn res.longValue();\n&gt;+\t}\n&gt;+\n&gt;+\t/**\n&gt;+\t * Load cookies from a file before the first fetch.\n&gt;+\t * &lt;p&gt;\n&gt;+\t * The file is a text file in the Netscape&#39;s &#39;cookies.txt&#39; file\nformat. &lt;br&gt;\n&gt;+\t * Example entry of cookies.txt file: &lt;br&gt;\n&gt;+\t * &lt;br&gt;\n&gt;+\t * www.archive.org FALSE / FALSE 1074567117 details-visit\ntexts-cralond &lt;br&gt;\n&gt;+\t * &lt;br&gt;\n&gt;+\t * Each line has 7 tab-separated fields: &lt;br&gt;\n&gt;+\t * &lt;li&gt;1. DOMAIN: The domain that created and have access to the\ncookie\n&gt;+\t * value.\n&gt;+\t * &lt;li&gt;2. FLAG: A TRUE or FALSE value indicating if hosts within\nthe given\n&gt;+\t * domain can access the cookie value.\n&gt;+\t * &lt;li&gt;3. PATH: The path within the domain that the cookie value\nis valid\n&gt;+\t * for.\n&gt;+\t * &lt;li&gt;4. SECURE: A TRUE or FALSE value indicating if to use a\nsecure\n&gt;+\t * connection to access the cookie value.\n&gt;+\t * &lt;li&gt;5. EXPIRATION: The expiration time of the cookie value\n(unix style.)\n&gt;+\t * &lt;li&gt;6. NAME: The name of the cookie value\n&gt;+\t * &lt;li&gt;7. VALUE: The cookie value\n&gt;+\t * \n&gt;+\t * @param cookiesFile\n&gt;+\t *                    file in the Netscape&#39;s &#39;cookies.txt&#39;\nformat.\n&gt;+\t */\n&gt;+\tpublic void loadCookies(String cookiesFile) {\n&gt;+\t\t// Do nothing if cookiesFile is not specified.\n&gt;+\t\tif (cookiesFile == null || cookiesFile.length() &lt;= 0) {\n&gt;+\t\t\treturn;\n&gt;+\t\t}\n&gt;+\t\tRandomAccessFile raf = null;\n&gt;+\t\ttry {\n&gt;+\t\t\traf = new RandomAccessFile(cookiesFile, &quot;r&quot;);\n&gt;+\t\t\tString[] cookieParts;\n&gt;+\t\t\tString line;\n&gt;+\t\t\tCookie cookie = null;\n&gt;+\t\t\twhile ((line = raf.readLine()) != null) {\n&gt;+\t\t\t\t// Line that starts with # is commented\nline, therefore skip it.\n&gt;+\t\t\t\tif (!line.startsWith(&quot;#&quot;)) {\n&gt;+\t\t\t\t\tcookieParts = line.split(&quot;&#92;&#92;t&quot;);\n&gt;+\t\t\t\t\tif (cookieParts.length == 7) {\n&gt;+\t\t\t\t\t\t// Create cookie with\nnot expiration date (-1 value).\n&gt;+\t\t\t\t\t\t// TODO: add this as an\noption.\n&gt;+\t\t\t\t\t\tcookie = new\nCookie(cookieParts[0], cookieParts[5],\n&gt;+\ncookieParts[6], cookieParts[2], -1, Boolean\n&gt;+\n.valueOf(cookieParts[3]).booleanValue());\n&gt;+\n&gt;+\t\t\t\t\t\tif\n(cookieParts[1].toLowerCase().equals(&quot;true&quot;)) {\n&gt;+\ncookie.setDomainAttributeSpecified(true);\n&gt;+\t\t\t\t\t\t} else {\n&gt;+\ncookie.setDomainAttributeSpecified(false);\n&gt;+\t\t\t\t\t\t}\n&gt;+\nthis.http.getState().addCookie(cookie);\n&gt;+\t\t\t\t\t\tlogger\n&gt;+\n.fine(&quot;Adding cookie: &quot;\n&gt;+\n+ cookie.toExternalForm());\n&gt;+\t\t\t\t\t}\n&gt;+\t\t\t\t}\n&gt;+\t\t\t}\n&gt;+\t\t} catch (FileNotFoundException e) {\n&gt;+\t\t\t// We should probably throw\nFatalConfigurationException.\n&gt;+\t\t\tSystem.out.println(&quot;Could not find file: &quot; +\ncookiesFile\n&gt;+\t\t\t\t\t+ &quot; (Element: &quot; +\nATTR_LOAD_COOKIES + &quot;)&quot;);\n&gt;+\n&gt;+\t\t} catch (IOException e) {\n&gt;+\t\t\t// We should probably throw\nFatalConfigurationException.\n&gt;+\t\t\te.printStackTrace();\n&gt;+\t\t} finally {\n&gt;+\t\t\ttry {\n&gt;+\t\t\t\tif (raf != null) {\n&gt;+\t\t\t\t\traf.close();\n&gt;+\t\t\t\t}\n&gt;+\t\t\t} catch (IOException e) {\n&gt;+\t\t\t\te.printStackTrace();\n&gt;+\t\t\t}\n&gt;+\t\t}\n&gt;+\t}\n&gt;+\n&gt;+\t/*\n&gt;+\t * (non-Javadoc)\n&gt;+\t * \n&gt;+\t * @see org.archive.crawler.framework.Processor#report()\n&gt;+\t */\n&gt;+\tpublic String report() {\n&gt;+\t\tStringBuffer ret = new StringBuffer();\n&gt;+\t\tret.append(&quot;Processor:\norg.archive.crawler.fetcher.FetchHTTP&#92;n&quot;);\n&gt;+\t\tret.append(&quot;  Function:          Fetch HTTP URIs&#92;n&quot;);\n&gt;+\t\tret.append(&quot;  CrawlURIs handled: &quot; + this.curisHandled +\n&quot;&#92;n&quot;);\n&gt;+\t\tret.append(&quot;  Recovery retries:   &quot; +\nthis.recoveryRetries + &quot;&#92;n&#92;n&quot;);\n&gt;+\n&gt;+\t\treturn ret.toString(\n(Message over 64 KB, truncated)"}}