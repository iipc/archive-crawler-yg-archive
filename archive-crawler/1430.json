{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":164438524,"authorName":"Lars Clausen","from":"Lars Clausen &lt;lc@...&gt;","profile":"lrclause","replyTo":"LIST","senderId":"H3bXzowD9VaOlBhjxbnlxQ-RkV56jjaGFxamhkMjL27dPMGhu_Ia7Ya1h975RzZuJFhTq-NZ4AFnJ7HhtnFgAs3uF0hz7V23DlnBMA","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Memory problems","postDate":"1106731399","msgId":1430,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDExMDY3MzEzOTkuMzI4OC43NS5jYW1lbEBwYzk3Ny5zYi5zdGF0c2JpYmxpb3Rla2V0LmRrPg==","inReplyToHeader":"PDQxRjY5OUE5LjcwNjA5QGFyY2hpdmUub3JnPg==","referencesHeader":"PDExMDY2NjY0NTQuMzI4OC42MC5jYW1lbEBwYzk3Ny5zYi5zdGF0c2JpYmxpb3Rla2V0LmRrPiA8NDFGNjk5QTkuNzA2MDlAYXJjaGl2ZS5vcmc+"},"prevInTopic":1425,"nextInTopic":1431,"prevInTime":1429,"nextInTime":1431,"topicId":1424,"numMessagesInTopic":6,"msgSnippet":"... Sounds good.  That was the only org.archive stuff that seemed to have one hanging piece per run. ... Sorry, I forgot to specify the version, we re actually","rawEmail":"Return-Path: &lt;lc@...&gt;\r\nX-Sender: lc@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 116 invoked from network); 26 Jan 2005 09:23:21 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m21.grp.scd.yahoo.com with QMQP; 26 Jan 2005 09:23:21 -0000\r\nReceived: from unknown (HELO luna.statsbiblioteket.dk) (130.225.24.87)\n  by mta6.grp.scd.yahoo.com with SMTP; 26 Jan 2005 09:23:21 -0000\r\nReceived: from pc977.sb.statsbiblioteket.dk\n (pc977.sb.statsbiblioteket.dk [130.225.24.199]) by luna.statsbiblioteket.dk\n (iPlanet Messaging Server 5.2 HotFix 1.16 (built May 14 2003))\n with ESMTP id &lt;0IAX00L473EVOO@...&gt; for\n archive-crawler@yahoogroups.com; Wed, 26 Jan 2005 10:23:19 +0100 (MET)\r\nDate: Wed, 26 Jan 2005 10:23:19 +0100\r\nIn-reply-to: &lt;41F699A9.70609@...&gt;\r\nTo: Heritrix mailing list &lt;archive-crawler@yahoogroups.com&gt;\r\nMessage-id: &lt;1106731399.3288.75.camel@...&gt;\r\nOrganization: Statsbiblioteket\r\nMIME-version: 1.0\r\nX-Mailer: Ximian Evolution 1.4.5 (1.4.5-9)\r\nContent-type: text/plain\r\nContent-transfer-encoding: 7BIT\r\nReferences: &lt;1106666454.3288.60.camel@...&gt;\n &lt;41F699A9.70609@...&gt;\r\nX-eGroups-Remote-IP: 130.225.24.87\r\nFrom: Lars Clausen &lt;lc@...&gt;\r\nSubject: Re: [archive-crawler] Memory problems\r\nX-Yahoo-Group-Post: member; u=164438524\r\nX-Yahoo-Profile: lrclause\r\n\r\nOn Tue, 2005-01-25 at 20:10, stack wrote:\n&gt; Lars Clausen wrote:\n&gt; \n&gt; &gt; I&#39;ve been doing a little investigation into the memory problems in\n&gt; &gt; Heritrix.  I&#39;m doing unit tests on Heritrix as part of our project, and\n&gt; &gt; there noticed that running Heritrix several times in a row used a lot of\n&gt; &gt; memory, about 100M per run.  I found a memory debugger for Java\n&gt; &gt; (http://jb2works.com/refscan/) &lt;http://jb2works.com/refscan/%29&gt; which \n&gt; &gt; showed me one thing that was in the\n&gt; &gt; archive packages and linear in the number of Heritrix runs:  The\n&gt; &gt; loggers.  For each run, there is one instance of each of\n&gt; &gt; org.archive.crawler.io.LocalErrorFormatter,\n&gt; &gt; org.archive.crawler.io.RuntimeErrorFormatter,\n&gt; &gt; org.archive.crawler.io.StatisticsLogFormatter,\n&gt; &gt; org.archive.crawler.io.UriErrorFormatter, and\n&gt; &gt; org.archive.crawler.io.UriProcessingFormatter, and 5 of\n&gt; &gt; org.archive.io.GenerationFileHandler.  Can&#39;t go much further as I don&#39;t\n&gt; &gt; have my system set up for compiling Heritrix, but maybe this will be\n&gt; &gt; useful to somebody.\n&gt; \n&gt; Thank you for the above Lars.  We were keeping around references to the \n&gt; job loggers.  I&#39;ve just added clearing of the references at end of job \n&gt; completion.  I did some more end-of-job housekeeping while I was at it.  \n&gt; There are still some processors that should register for end of job \n&gt; cleanup but I won&#39;t worry about them for now since memory retained is small.\n\nSounds good.  That was the only org.archive stuff that seemed to have\none hanging piece per run.\n\n&gt; I&#39;ve not experienced Heritrix holding 100megs per job -- at least not \n&gt; since close of &#39;[1055592 ] terminated crawl still hogging memory, \n&gt; causing OOM&#39; \n&gt; (https://sourceforge.net/tracker/index.php?func=detail&aid=1055592&group_id=73833&atid=539099)\n&gt; This bug was fixed post-1.2.0 release on 2004-12-10 so fix is currently \n&gt; only in HEAD.  I can run at least ten jobs in series without OOME&#39;ing in \n&gt; a 128meg heap.  For sure there is a problem if you&#39;re seeing 100megs \n&gt; retained per job.  Lets try and figure it out.\n\nSorry, I forgot to specify the version, we&#39;re actually still at 1.2.0. \nWe&#39;ll see if we can use the HEAD version, but there&#39;s been enough\nchanges that it&#39;s not a simple drop-in replacement.  If we get that\nrunning, I&#39;ll try to run the reference checker again and see if there&#39;s\nanything else.\n\nThanks for the quick response!\n\n-Lars\n\n\n"}}