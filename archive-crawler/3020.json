{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"Michael Stack","from":"Michael Stack &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"9JzW13uccUNKg-l7fpLy-OZFs0dSMZFiHBu2BG1hDC0SC8eqoNSa2ZI6jtUJNL4gknn6ZjZX6C_5aDFv_5V1Lsl9Tyg3aZzl","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Re: getting urls..","postDate":"1152294032","msgId":3020,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ0QUU5QzkwLjkwMDAyMDRAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGU4aTZhdCtncDEwQGVHcm91cHMuY29tPg==","referencesHeader":"PGU4aTZhdCtncDEwQGVHcm91cHMuY29tPg=="},"prevInTopic":3010,"nextInTopic":0,"prevInTime":3019,"nextInTime":3021,"topicId":2892,"numMessagesInTopic":6,"msgSnippet":"... The jdb log are fundamental to the crawler.  They contain all of the crawler state. You might be able to tune the backgound bdbje cleaner thread so it does","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 6524 invoked from network); 7 Jul 2006 17:39:16 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m21.grp.scd.yahoo.com with QMQP; 7 Jul 2006 17:39:16 -0000\r\nReceived: from unknown (HELO dns.duboce.net) (63.203.238.114)\n  by mta6.grp.scd.yahoo.com with SMTP; 7 Jul 2006 17:39:15 -0000\r\nReceived: from [192.168.1.105] ([192.168.1.105])\n\tby dns-eth1.duboce.net (8.10.2/8.10.2) with ESMTP id k67GNQF10367;\n\tFri, 7 Jul 2006 09:23:26 -0700\r\nMessage-ID: &lt;44AE9C90.9000204@...&gt;\r\nDate: Fri, 07 Jul 2006 10:40:32 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; PPC Mac OS X Mach-O; en-US; rv:1.8.0.4) Gecko/20060516 SeaMonkey/1.0.2\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;e8i6at+gp10@...&gt;\r\nIn-Reply-To: &lt;e8i6at+gp10@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: Michael Stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] Re: getting urls..\r\nX-Yahoo-Group-Post: member; u=168599281; y=nt-8H1x8Ud0k6mC1cEp-sAMlABGLHrvZEvoaJnVFYVqafDVueX8kGZer\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\ncallforshadab wrote:\n&gt;\n&gt; Hi,\n&gt;\n&gt; &gt; If you only want URLs that are actually scheduled for crawling --\n&gt; &gt; meaning they pass the in-scope test and aren&#39;t duplicates -- you could\n&gt; &gt; also use the recovery log. Every line beginning &quot;F+&quot; is an URL being\n&gt; &gt; queued for crawling; the only duplicates will be URLs that must be\n&gt; &gt; fetched more than once in a long crawl (robots, DNS, or URLs\n&gt; force-added\n&gt; &gt; by the operator).\n&gt;\n&gt; This is good enough for me.\n&gt; But i found that under $HERITRIX_HOME/jobs/status directory the size\n&gt; of jdb files is increasing so rapidly. I need only recover.gz as you\n&gt; suggested. So how can i have control over jdb&#39;s growing size.\n&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe jdb log are fundamental to the crawler.  They contain all of the \ncrawler state.\n\nYou might be able to tune the backgound bdbje cleaner thread so it does \na better job compacting and cleaning up old bdbje log files.  See \nChapter 8, Managing the Background Threads in the bdbje manual here: \nhttp://www.sleepycat.com/jedocs/GettingStartedGuide/BerkeleyDB-JE-GSG.pdf.  \nIn my experience, the percentage gains in disk space usage at some extra \nCPU cost have been small -- definetly not orders of magnitude improvements.\n\nSt.Ack\n\n\n\n\n"}}