{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"stack","from":"stack &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"uLTSUtAMplH2pVrO4NEY1g9vInNi4ll32yk8cEYrIIUX_fr4dXEbclyVnPlYYmQo9ATARhQ81DQ1Qr38gy-9aA","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] BDB, state, and disk usage, and other questions","postDate":"1116884696","msgId":1870,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQyOTI0RUQ4LjMwODA2MDRAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDE3MDQxLjYzNDc0LjkxNzcyLjkwMjI4MEB0aXBoYXJlcy5iYXNpc3RlY2gubmV0Pg==","referencesHeader":"PDE3MDQxLjYzNDc0LjkxNzcyLjkwMjI4MEB0aXBoYXJlcy5iYXNpc3RlY2gubmV0Pg=="},"prevInTopic":1868,"nextInTopic":1873,"prevInTime":1869,"nextInTime":1871,"topicId":1868,"numMessagesInTopic":9,"msgSnippet":"... Igor just took a look at a recent crawl and found that state was 15% the size of the arcs captured. I just tried a crawl against the infiniteurl","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 91416 invoked from network); 23 May 2005 21:54:11 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m25.grp.scd.yahoo.com with QMQP; 23 May 2005 21:54:11 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (207.241.224.172)\n  by mta4.grp.scd.yahoo.com with SMTP; 23 May 2005 21:54:11 -0000\r\nReceived: (qmail 24108 invoked by uid 100); 23 May 2005 21:54:07 -0000\r\nReceived: from debord.archive.org (HELO ?207.241.238.140?) (stack@...@207.241.238.140)\n  by mail-dev.archive.org with SMTP; 23 May 2005 21:54:07 -0000\r\nMessage-ID: &lt;42924ED8.3080604@...&gt;\r\nDate: Mon, 23 May 2005 14:44:56 -0700\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.7.3) Gecko/20041007 Debian/1.7.3-5\r\nX-Accept-Language: en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;17041.63474.91772.902280@...&gt;\r\nIn-Reply-To: &lt;17041.63474.91772.902280@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=-59.0 required=7.0 tests=AWL,USER_IN_WHITELIST \n\tautolearn=no version=2.63\r\nX-eGroups-Msg-Info: 1:12:0\r\nFrom: stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] BDB, state, and disk usage, and other questions\r\nX-Yahoo-Group-Post: member; u=168599281\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\nTom Emerson wrote:\n\n&gt; I have a largish (2308 seeds, inferred SURT scope) crawl that has been\n&gt; running for 115 hours under 1.4.0. So far I&#39;ve discovered 9,870,579\n&gt; documents and crawled 3,326,501. This consumes approximately 17 GB on\n&gt; disk for the ARC files, and 34 GB on disk for the BDB state. It looks,\n&gt; from the ad hoc monitoring that I&#39;ve been doing on disk usage, that\n&gt; there is a roughly linear 2:1 ratio in state storage to ARC\n&gt; storage. Does anyone have a feel if this is the expected ration? We\n&gt; will be done many more larger crawls than this, and need to budget\n&gt; disk space appropriately. (Note that I&#39;m only crawling storing\n&gt; text/html, so I get good compression in the arcs (so far around 4:1).\n\nIgor just took a look at a recent crawl and found that state was 15% the \nsize of the arcs captured.\n\nI just tried a crawl against the infiniteurl application (infiniteurl is \na simple webapp that we use here for testing. It manufactures new URLs \nad infinitum returning simple uniform html pages all of same approximate \nsize).   I&#39;m seeing ratios of 50 to 1 -- 50 times the arc data saved is \nneeded for state.  My crawl scenario is highly artificial.\n\nSeems like it depends highly on the character of the crawl being run \n(Capturing HTML only Tom, you&#39;re throwing out alot of what usually \nbulks-up the arcs: images, pdfs, etc.).\n\n&gt;\n&gt; Also, while I have configured a maximum of 100 toe threads, at this\n&gt; point only 92 are active (i.e., the dashboard states &quot;91 of\n&gt; 92&quot;). About 10% of the seeds haven&#39;t even been processed yet: I take\n&gt; it this doesn&#39;t happen until the other queues have been completely\n&gt; exhausted?\n\n\nYou have hold-queues enabled? Then this is what I&#39;d expect (You might \nchange the &#39;balance-replenish-amount&#39; setting so its less than 3000 so \nother queues get rotated in quicker).\n\nIgor asks if the uncrawled seeds are showing in the seeds report -- are \nthey recognized as uncrawled (There&#39;s an issue where we recognize seeds \nonly if they have a scheme OR they look like a host name -- otherwise, \nthey&#39;re skipped).\n\n&gt;\n&gt; The threads report states that there are 92 in the pool, but lists\n&gt; status for 100. How can I find the 8 that aren&#39;t being used?\n&gt;\nWe ain&#39;t sure why it would report any less than 100 threads in the \npool.  Anything in heritrix_out.log?  Runtime/local errors? Send us over \nthe report so we can take a look.\n\nThanks Tom,\nSt.Ack\n\n&gt; TIA,\n&gt;\n&gt;     -tree\n&gt;\n&gt; -- \n&gt; Tom Emerson                                          Basis Technology \n&gt; Corp.\n&gt; Software Architect                                 \n&gt; http://www.basistech.com\n&gt;   &quot;Beware the lollipop of mediocrity: lick it once and you suck forever&quot;\n&gt;\n&gt; ------------------------------------------------------------------------\n&gt; *Yahoo! Groups Links*\n&gt;\n&gt;     * To visit your group on the web, go to:\n&gt;       http://groups.yahoo.com/group/archive-crawler/\n&gt;        \n&gt;     * To unsubscribe from this group, send an email to:\n&gt;       archive-crawler-unsubscribe@yahoogroups.com\n&gt;       &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;        \n&gt;     * Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;.\n&gt;\n&gt;\n\n\n"}}