{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"Michael Stack","from":"Michael Stack &lt;stack@...&gt;","replyTo":"LIST","senderId":"C-3pZI4r16LOjPLHOj23zfdIjMAV5lnfWljC_YLHc1a4nJmci20-95Evt3cK3svqn9jxkLcQPipT9BCjLdPcdZ-_Wc2pZm3w","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Heritrix - use...","postDate":"1086103390","msgId":500,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQwQkM5RjVFLjgwMzA4MDJAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDAwNjAwMWM0NDUzYSQ4NjIxZDM4MCQwMzAxYThjMEBNZXNhLmNvbT4=","referencesHeader":"PDAwNjAwMWM0NDUzYSQ4NjIxZDM4MCQwMzAxYThjMEBNZXNhLmNvbT4="},"prevInTopic":499,"nextInTopic":501,"prevInTime":499,"nextInTime":501,"topicId":455,"numMessagesInTopic":37,"msgSnippet":"... The template says info-url.  This is an url that someone can go to to learn more about you should they want to know who is crawling the site (The from","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 51256 invoked from network); 1 Jun 2004 15:30:43 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m13.grp.scd.yahoo.com with QMQP; 1 Jun 2004 15:30:43 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (209.237.232.202)\n  by mta1.grp.scd.yahoo.com with SMTP; 1 Jun 2004 15:30:43 -0000\r\nReceived: (qmail 18556 invoked by uid 100); 1 Jun 2004 15:22:23 -0000\r\nReceived: from b116-dyn-36.archive.org (HELO archive.org) (stack@...@209.237.240.36)\n  by mail-dev.archive.org with SMTP; 1 Jun 2004 15:22:23 -0000\r\nMessage-ID: &lt;40BC9F5E.8030802@...&gt;\r\nDate: Tue, 01 Jun 2004 08:23:10 -0700\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.6) Gecko/20040526 Debian/1.6-6\r\nX-Accept-Language: en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;006001c4453a$8621d380$0301a8c0@...&gt;\r\nIn-Reply-To: &lt;006001c4453a$8621d380$0301a8c0@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=0.4 required=6.0 tests=AWL autolearn=ham version=2.63\r\nX-eGroups-Remote-IP: 209.237.232.202\r\nFrom: Michael Stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] Heritrix - use...\r\nX-Yahoo-Group-Post: member; u=168599281\r\n\r\nbruce wrote:\n\n&gt;more information...\n&gt;\n&gt;the actual error i&#39;m getting is:\n&gt;\n&gt;20040529051254496    Simple    Could not launch job - Fatal\n&gt;InitializationException     Crawl order   Crawl report   Seeds report   Seed\n&gt;file   Logs   Journal   Delete\n&gt; A fatal InitializationException occured when loading job:\n&gt;You must set the User-Agent and From HTTP header values to acceptable\n&gt;strings.\n&gt; User-Agent: [software-name](+[info-url])[misc]\n&gt; From: [email-address]\n&gt;\n&gt;any ideas as to what i should be using ..\n&gt;\n&gt;i used &gt;&gt;&gt; os-heritrix/0.8.1 mozilla\n&gt;       &gt;&gt;&gt; bedouglas@...\n&gt;\n&gt;is there a sample of what i should be using, as well as the correct format\n&gt;for the input information...\n&gt;  \n&gt;\nThe template says info-url.  This is an url that someone can go to to \nlearn more about you should they want to know who is crawling the site \n(The &#39;from&#39; address is a contact in case they want to write you and ask \nyou why you are crawling their site).\n\nUse:\n\n    os-heritrix/0.8.1 (+http://YOUR.WEB.SITE)\n\nSt.Ack\n\n&gt;thanks,\n&gt;\n&gt;-bruce\n&gt;\n&gt;\n&gt;-----Original Message-----\n&gt;From: bruce [mailto:bedouglas@...]\n&gt;Sent: Friday, May 28, 2004 4:55 PM\n&gt;To: archive-crawler@yahoogroups.com\n&gt;Subject: RE: [archive-crawler] Heritrix - use...\n&gt;\n&gt;\n&gt;in regards to my last message, we&#39;re starting to climb through the docs for\n&gt;heritrix.. we don&#39;t initially see anything that jumps out at us as to how\n&gt;the app handles, or can be configured to handle parsing through\n&gt;dropdown/select menu structures within a given page...\n&gt;\n&gt;have we missed a section of the doc that discusses this, or is this logic\n&gt;we&#39;d have to add to the app ourselves..??\n&gt;\n&gt;\n&gt;\n&gt;-----Original Message-----\n&gt;From: Michael Stack [mailto:stack@...]\n&gt;Sent: Friday, May 28, 2004 7:38 AM\n&gt;To: archive-crawler@yahoogroups.com\n&gt;Cc: kris@...\n&gt;Subject: Re: [archive-crawler] Heritrix - use...\n&gt;\n&gt;\n&gt;bruce wrote:\n&gt;\n&gt;  \n&gt;\n&gt;&gt;Kristinn (and others..)\n&gt;&gt;\n&gt;&gt;Thanks for the responses to my questions. I&#39;m getting the feeling that this\n&gt;&gt;approach might me better/more efficient than simply writing a unique Perl\n&gt;&gt;script for each of the 100&#39;s of universities that i&#39;m considering. That\n&gt;&gt;said, i still have a few questions about setting up the app, and running a\n&gt;&gt;test. My primary issues would get into how complex the jave\n&gt;&gt;    \n&gt;&gt;\n&gt;code/environment\n&gt;  \n&gt;\n&gt;&gt;would be.\n&gt;&gt;\n&gt;&gt;Never coded in Java. Plenty of C/C++/etc... but minimal java experience...\n&gt;&gt;But it might be worth climbing the learning curve if this might work.\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;You could do as Kris suggests and write plugins for Heritrix having it\n&gt;make decisions on-the-fly about what to write to disk.  But I&#39;d advise\n&gt;that learning java is a significant undertaking.\n&gt;\n&gt;I&#39;d suggest you begin by figuring heritrix, learning how to configure it\n&gt;to do a targetted crawl, and spend your time initially on the parsing of\n&gt;the downloaded ARCs (Take a look at Tom&#39;s pretty libarc tool if c/c++ is\n&gt;what you&#39;re used to).  Taking this approach will help you better\n&gt;determine the mods you want to make to heritrix, if you need to make\n&gt;them at all.\n&gt;\n&gt;  \n&gt;\n&gt;&gt;Is there a phone number for you so I could have a short conversation\n&gt;&gt;regarding the Heritrix app??\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;We don&#39;t do phone support usually (smile).  Put your questions up here\n&gt;on the list.  Its better than phone support anyways (Witness the quality\n&gt;and variety of the responses you&#39;ve gotten to date).\n&gt;\n&gt;Yours,\n&gt;St.Ack\n&gt;\n&gt;  \n&gt;\n&gt;&gt;Thanks\n&gt;&gt;\n&gt;&gt;Bruce Douglas\n&gt;&gt;bedouglas@...\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;-----Original Message-----\n&gt;&gt;From: Kristinn Sigurdsson [mailto:kris@...]\n&gt;&gt;Sent: Friday, May 28, 2004 2:04 AM\n&gt;&gt;To: archive-crawler@yahoogroups.com\n&gt;&gt;Subject: RE: [archive-crawler] Heritrix - use...\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;&gt;&gt;-----Original Message-----\n&gt;&gt;&gt;From: bruce [mailto:bedouglas@...]\n&gt;&gt;&gt;Sent: 28. maï¿½ 2004 01:08\n&gt;&gt;&gt;To: &#39;archive-crawler@yahoogroups.com&#39;\n&gt;&gt;&gt;Subject: RE: [archive-crawler] Heritrix - use...\n&gt;&gt;&gt;\n&gt;&gt;&gt;hey...\n&gt;&gt;&gt;\n&gt;&gt;&gt;thanks for the response. my questions are pretty basic, so bear with me!\n&gt;&gt;&gt;\n&gt;&gt;&gt;1) is it possible to provide a list of domains/urls that the app can crawl\n&gt;&gt;&gt;through, thus creating a basic domain/pool of content. ie, is it possible\n&gt;&gt;&gt;for us to &quot;feed&quot; the urls of the various college registrar sites to the\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;app,\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;&gt;&gt;and have it then return/save the information to an internal file, or\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;series\n&gt;  \n&gt;\n&gt;&gt;&gt;of files.\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;Yes.\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;&gt;&gt;2) is it possible to configure the app to only return pages from a given\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;url\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;&gt;&gt;that have certain information/tags/elements, or is that better handled by\n&gt;&gt;&gt;the parser/reader function?\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;A custom module can be plugged into the processing chain that looks for\n&gt;&gt;    \n&gt;&gt;\n&gt;this\n&gt;  \n&gt;\n&gt;&gt;type of information. But it would then also require a custom writer module\n&gt;&gt;to take advantage of the information.\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;&gt;&gt;3) once we have the returned information, how difficult/easy is it to\n&gt;&gt;&gt;write/create a reader? if we are looking to parse multiple schools, would\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;it\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;&gt;&gt;make sense to write a separate reader for each school that would have been\n&gt;&gt;&gt;returned from the crawling app?\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;It occurs to me that you _might_ be best off not using the standard ARC\n&gt;&gt;writer that comes with Heritrix. Rather implement your own writer that\n&gt;&gt;examines the content and makes informed decisions about what to write to\n&gt;&gt;disk. That writer could then write the files to disk any way you like. In\n&gt;&gt;fact you could have it simply extract what data you are interested in and\n&gt;&gt;only write that piece of information. For information about writing custom\n&gt;&gt;modules refer to the developers manual on our website. It and the user\n&gt;&gt;manual are quite comprehensive and should give you a clear idea of\n&gt;&gt;Heritrix&#39;s potential.\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;&gt;&gt;4) are there reasonably well documented readers for us to review? it would\n&gt;&gt;&gt;help greatly to be able to run a crawling app, and then pass the reader\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;over\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;&gt;&gt;the returned information... this would allow a way to see how the overall\n&gt;&gt;&gt;apps actually function..\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;I&#39;m unsure of the status of existing readers. But if you opt for the above\n&gt;&gt;idea you wouldn&#39;t need to bother with ARC files.\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;&gt;&gt;another question...\n&gt;&gt;&gt;\n&gt;&gt;&gt;can the heritrix app be setup/configured to access sites that require a\n&gt;&gt;&gt;user/passwd in a manner similar to what i can do with a perl (LWP)\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;app...??\n&gt;  \n&gt;\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;Yes, credentials can be supplied for certain types of logins. This is\n&gt;&gt;covered in the user manual.\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;&gt;&gt;thanks for your time/patience...\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;No problem.\n&gt;&gt;\n&gt;&gt;Regards,\n&gt;&gt;Kristinn Sigurï¿½sson\n&gt;&gt;Software Engineer\n&gt;&gt;National and University Library of Iceland\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;&gt;&gt;bruce\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;\n&gt;&gt;Yahoo! Groups Sponsor\n&gt;&gt;ADVERTISEMENT\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;Yahoo! Groups Links\n&gt;&gt;\n&gt;&gt;To visit your group on the web, go to:\n&gt;&gt;http://groups.yahoo.com/group/archive-crawler/\n&gt;&gt;\n&gt;&gt;To unsubscribe from this group, send an email to:\n&gt;&gt;archive-crawler-unsubscribe@yahoogroups.com\n&gt;&gt;\n&gt;&gt;Your use of Yahoo! Groups is subject to the Yahoo! Terms of Service.\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;Yahoo! Groups Links\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;\n&gt;Yahoo! Groups Sponsor\n&gt;ADVERTISEMENT\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;Yahoo! Groups Links\n&gt;\n&gt;To visit your group on the web, go to:\n&gt;http://groups.yahoo.com/group/archive-crawler/\n&gt;\n&gt;To unsubscribe from this group, send an email to:\n&gt;archive-crawler-unsubscribe@yahoogroups.com\n&gt;\n&gt;Your use of Yahoo! Groups is subject to the Yahoo! Terms of Service.\n&gt;\n&gt;\n&gt;Yahoo! Groups Sponsor\n&gt;ADVERTISEMENT\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;Yahoo! Groups Links\n&gt;\n&gt;To visit your group on the web, go to:\n&gt;http://groups.yahoo.com/group/archive-crawler/\n&gt;\n&gt;To unsubscribe from this group, send an email to:\n&gt;archive-crawler-unsubscribe@yahoogroups.com\n&gt;\n&gt;Your use of Yahoo! Groups is subject to the Yahoo! Terms of Service.\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; \n&gt;Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n&gt; \n&gt;\n&gt;  \n&gt;\n\n\n"}}