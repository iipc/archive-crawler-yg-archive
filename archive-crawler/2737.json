{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137477665,"authorName":"Igor Ranitovic","from":"Igor Ranitovic &lt;igor@...&gt;","profile":"iranitovic","replyTo":"LIST","senderId":"2VrLhHYbstp8sYqHMfrkkrZtWQJ54U5WGvjq5Tm7xKAjPCx8HXedCqXZ5SmlfioQHw3hfmQEYuTsvbL3-ltQjyTxvNpDkVns","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Robots.txt parsing problem?","postDate":"1141841478","msgId":2737,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ0MEYxRTQ2LjgwMzAwMDJAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDQ0MEYxQkE3LjIwNTAyMDNAbWV0YWNhcnRhLmNvbT4=","referencesHeader":"PDQ0MEYxQkE3LjIwNTAyMDNAbWV0YWNhcnRhLmNvbT4="},"prevInTopic":2736,"nextInTopic":2738,"prevInTime":2736,"nextInTime":2738,"topicId":2736,"numMessagesInTopic":7,"msgSnippet":"Hi Karl, Heritrix rechecks robots.txt files every 24 hours by default. Did you change that value? It seems that this robots file has been recently modified and","rawEmail":"Return-Path: &lt;igor@...&gt;\r\nX-Sender: igor@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 46530 invoked from network); 8 Mar 2006 18:19:43 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m24.grp.scd.yahoo.com with QMQP; 8 Mar 2006 18:19:43 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (207.241.224.171)\n  by mta1.grp.scd.yahoo.com with SMTP; 8 Mar 2006 18:19:43 -0000\r\nReceived: (qmail 15002 invoked by uid 100); 8 Mar 2006 18:11:57 -0000\r\nReceived: from adsl-71-130-102-77.dsl.pltn13.pacbell.net (HELO ?192.168.1.199?) (igor@...@71.130.102.77)\n  by mail-dev.archive.org with SMTP; 8 Mar 2006 18:11:57 -0000\r\nMessage-ID: &lt;440F1E46.8030002@...&gt;\r\nDate: Wed, 08 Mar 2006 10:11:18 -0800\r\nUser-Agent: Thunderbird 1.5 (Windows/20051201)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: Keith Baker &lt;krbaker@...&gt;\r\nReferences: &lt;440F1BA7.2050203@...&gt;\r\nIn-Reply-To: &lt;440F1BA7.2050203@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=-96.4 required=7.0 tests=AWL,USER_IN_WHITELIST \n\tautolearn=no version=2.63\r\nX-eGroups-Msg-Info: 2:12:4:0\r\nFrom: Igor Ranitovic &lt;igor@...&gt;\r\nSubject: Re: [archive-crawler] Robots.txt parsing problem?\r\nX-Yahoo-Group-Post: member; u=137477665; y=zOlahj5utL4THaJbF6rcAscdTyPaRJiWqnfYzJbogK5BDUdh0g\r\nX-Yahoo-Profile: iranitovic\r\n\r\nHi Karl,\n\nHeritrix rechecks robots.txt files every 24 hours by default. Did you change that value?\n\nIt seems that this robots file has been recently modified and it is possible that 24 hours has not \nelapsed since the modification.\nIf that is the case, you can do several things: force fetch the http://uaelp.pennnet.com/robots.txt \nor change the value of robot-validity-duration-seconds.\n\nTake care,\ni.\n\n&gt; Hi,\n&gt; \n&gt; We got dinged again by using Heritrix in that a crawlee complained that \n&gt; we were ignoring their robots.txt file.  On the face of it, they look \n&gt; like they are correct in complaining:\n&gt; \n&gt; http://uaelp.pennnet.com/robots.txt\n&gt; ===================================\n&gt; \n&gt; # pennwell robots.txt\n&gt; # updated 3/6/06 by bwn\n&gt; \n&gt; User-agent: Googlebot\n&gt; Disallow: /Search/\n&gt; Disallow: /search/\n&gt; Disallow: /Userreg/\n&gt; Disallow: /userreg/\n&gt; Disallow: /Nav/\n&gt; Disallow: /nav/\n&gt; Disallow: /js\n&gt; Disallow: /JS\n&gt; Disallow: /whitepapers/wp_redirect.cfm\n&gt; Disallow: /*.js$\n&gt; \n&gt; User-agent: *\n&gt; Disallow: /Search/\n&gt; Disallow: /search/\n&gt; Disallow: /Userreg/\n&gt; Disallow: /userreg/\n&gt; Disallow: /Nav/\n&gt; Disallow: /nav/\n&gt; Disallow: /js\n&gt; Disallow: /JS\n&gt; Disallow: /whitepapers/wp_redirect.cfm\n&gt; \n&gt; \n&gt; heritrix crawl log portion\n&gt; ==========================\n&gt; \n&gt; 2006-03-08T16:11:41.295Z   200      17266 \n&gt; http://uaelp.pennnet.com/whitepapers/wp_redirect.cfm?id=305 LLL \n&gt; http://uaelp.pennnet.com/whitepapers/wp.cfm?id=305 text/html #075 \n&gt; 20060308161137362+1062 R5C73R3EPNNO4UYMWRPBTUJD3TWW32X7 2t\n\n&gt; \n&gt; According to our reading of the robots.txt spec, this URL should not \n&gt; have been crawled.  The only reason I can find for the failure may be \n&gt; that the last line is not terminated with a newline, but rather just an EOF.\n&gt; \n&gt; Any thoughts?\n&gt; \n&gt; Karl\n&gt; \n&gt; \n&gt;  \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n&gt;  \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n\n\n"}}