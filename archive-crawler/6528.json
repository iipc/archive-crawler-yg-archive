{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":254719850,"authorName":"steve@archive.org","from":"&quot;steve@...&quot; &lt;steve@...&gt;","profile":"stearcorg","replyTo":"LIST","senderId":"bO4BbFcZUgnI6hRPlwjHkoFfkc6asfntVO5Mbdyur6uGUS2rfwuKxzTmmFw2BqAsIULKfsRDpnR2DXXY412VIgxy32uZip6F_qV-jbJJ","spamInfo":{"isSpam":false,"reason":"3"},"subject":"Re: [archive-crawler] Heritrix v1 frontier and reconstruction files from ARC","postDate":"1274315902","msgId":6528,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRCRjQ4NDdFLjUwNzAzMDdAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGhzaDQ4Mis0ZDI3QGVHcm91cHMuY29tPg==","referencesHeader":"PGhzaDQ4Mis0ZDI3QGVHcm91cHMuY29tPg=="},"prevInTopic":6524,"nextInTopic":6543,"prevInTime":6527,"nextInTime":6529,"topicId":6524,"numMessagesInTopic":3,"msgSnippet":"hi Adam, some speculation on your frontier budget question; i see that you have hold-queues=true, perhaps your crawl has finished by reaching some global limit","rawEmail":"Return-Path: &lt;steve@...&gt;\r\nX-Sender: steve@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 8312 invoked from network); 20 May 2010 00:38:24 -0000\r\nX-Received: from unknown (98.137.34.44)\n  by m14.grp.re1.yahoo.com with QMQP; 20 May 2010 00:38:24 -0000\r\nX-Received: from unknown (HELO mail.archive.org) (207.241.231.239)\n  by mta1.grp.sp2.yahoo.com with SMTP; 20 May 2010 00:38:23 -0000\r\nX-Received: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id 403A729D35;\n\tWed, 19 May 2010 17:38:23 -0700 (PDT)\r\nX-Received: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id UmTGdmIzGvgd; Wed, 19 May 2010 17:38:22 -0700 (PDT)\r\nX-Received: from laptop-siznax.us.archive.org (laptop-siznax.us.archive.org [207.241.227.150])\n\tby mail.archive.org (Postfix) with ESMTPSA id 97CF529D2E;\n\tWed, 19 May 2010 17:38:22 -0700 (PDT)\r\nMessage-ID: &lt;4BF4847E.5070307@...&gt;\r\nDate: Wed, 19 May 2010 17:38:22 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.6; en-US; rv:1.9.1.9) Gecko/20100317 Thunderbird/3.0.4\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: goblin_cz &lt;adam.brokes@...&gt;\r\nReferences: &lt;hsh482+4d27@...&gt;\r\nIn-Reply-To: &lt;hsh482+4d27@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 2:3:4:0:0\r\nFrom: &quot;steve@...&quot; &lt;steve@...&gt;\r\nSubject: Re: [archive-crawler] Heritrix v1 frontier and reconstruction files\n from ARC\r\nX-Yahoo-Group-Post: member; u=254719850; y=Lpm4QNv8dj6_ATbQ9Ypp3jSS9fsArzC7lThs23UA7aOp\r\nX-Yahoo-Profile: stearcorg\r\n\r\nhi Adam,\n\nsome speculation on your frontier budget question; i see\nthat you have hold-queues=true, perhaps your crawl has\nfinished by reaching some global limit (e.g. max-time,\nmax-docs, etc.) leaving newly created but inactive queues\nunder budget, but having some downloaded by transclusion?\n5998 is suspiciously close to 2x balance-replenish-amount\nthough - as if the queue may have been active a couple of\ntimes before the crawl &quot;finished&quot;. i would try setting\nhold-queues=false, and see if those queues reach their\nbudget.\n\ni&#39;m not sure how best to recreate a site from your archive,\nbut have you considered crawling your own archive using\nMirrorWriterProcessor, or another crawler designed for\nmirror writing, like HTTrack? otherwise, a class using\nW/ARCReader to extract records and write them to the right\npaths directly from your W/ARCs might be the best start.\n\nhope that helps.\n\n/steve@...\n\n\nOn 5/13/10 8:01 AM, goblin_cz wrote:\n&gt;\n&gt;\n&gt; Hi,\n&gt;\n&gt; I am using heritrix 1.14.3 and the frontier budget functionality\n&gt; (described here:\n&gt; https://webarchive.jira.com/wiki/display/Heritrix/Frontier+queue+budgets\n&gt; &lt;https://webarchive.jira.com/wiki/display/Heritrix/Frontier+queue+budgets&gt;)\n&gt;\n&gt; I set budget limit to 20,000. UnitCost and SurtPrefixAssigment policy.\n&gt;\n&gt; Well, maybe this will be more clear:\n&gt;\n&gt; &lt;string name=&quot;queue-assignment-policy&quot;&gt;\n&gt; org.archive.crawler.frontier.SurtAuthorityQueueAssignmentPolicy\n&gt; &lt;/string&gt;\n&gt; &lt;string name=&quot;force-queue-assignment&quot;/&gt;\n&gt; &lt;boolean name=&quot;pause-at-start&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;pause-at-finish&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;source-tag-seeds&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;recovery-log-enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;hold-queues&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;integer name=&quot;balance-replenish-amount&quot;&gt;3000&lt;/integer&gt;\n&gt; &lt;integer name=&quot;error-penalty-amount&quot;&gt;100&lt;/integer&gt;\n&gt; &lt;long name=&quot;queue-total-budget&quot;&gt;20000&lt;/long&gt;\n&gt; &#8722;\n&gt; &lt;string name=&quot;cost-policy&quot;&gt;\n&gt; org.archive.crawler.frontier.UnitCostAssignmentPolicy\n&gt; &lt;/string&gt;\n&gt; &lt;long name=&quot;snooze-deactivate-ms&quot;&gt;300&lt;/long&gt;\n&gt;\n&gt; When the crawl has been paused I forced generation of final reports to\n&gt; disk. In such way I can import this data to excel sheet and analyze it.\n&gt; The most interesting is host-report.txt. And there I found that some of\n&gt; queues has less than the limit (e.g. 8500) downloaded and despite that\n&gt; has some urls in remaining column.\n&gt;\n&gt; for example:\n&gt; url: kvetena.cz\n&gt; downloaded: 5998\n&gt; remaining: 29084\n&gt;\n&gt; I am not sure how this could happen and how to reach limit of these sites.\n&gt;\n&gt; Second question.\n&gt;\n&gt; There have been risen requirement to extract data from one domain.\n&gt;\n&gt; Our case:\n&gt; - the provider that hosted domain lost their data\n&gt; - we have have two years crawls in our archive\n&gt; - we need to extract the data just before the crash and restore it\n&gt; exactly as it was on the server\n&gt;\n&gt; What is the best and fastest way to do that? I am asking because I am\n&gt; sure that this is not unusual case.\n&gt;\n&gt; Thanks a lot,\n&gt;\n&gt; best regards.\n&gt;\n&gt; Adam\n\n"}}