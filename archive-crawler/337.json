{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"dCFPHhrvU9YdBk_w_c4DCuIiZB-OwJ1CGBGT9z59AgjbiVWz2qVQ3wVF73pidfOpL_b5hv3Dh-fL_49Bv4_ZZVmQlrI8aCI","spamInfo":{"isSpam":false,"reason":"0"},"subject":"FYI/ plan for post-1.0 scope definition reworking","postDate":"1082755655","msgId":337,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQwODk4QTQ3LjIwMjAzMDVAYXJjaGl2ZS5vcmc+"},"prevInTopic":0,"nextInTopic":345,"prevInTime":336,"nextInTime":338,"topicId":337,"numMessagesInTopic":3,"msgSnippet":"We are planning a change in the way in which a crawl s scope -- its definition of what URIs are included and excluded -- is modelled and specified after the","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 17007 invoked from network); 23 Apr 2004 21:27:45 -0000\r\nReceived: from unknown (66.218.66.218)\n  by m13.grp.scd.yahoo.com with QMQP; 23 Apr 2004 21:27:45 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (209.237.232.202)\n  by mta3.grp.scd.yahoo.com with SMTP; 23 Apr 2004 21:27:45 -0000\r\nReceived: (qmail 23417 invoked by uid 100); 23 Apr 2004 21:21:56 -0000\r\nReceived: from b116-dyn-47.archive.org (HELO archive.org) (gojomo@...@209.237.240.47)\n  by mail-dev.archive.org with SMTP; 23 Apr 2004 21:21:56 -0000\r\nMessage-ID: &lt;40898A47.2020305@...&gt;\r\nDate: Fri, 23 Apr 2004 14:27:35 -0700\r\nUser-Agent: Mozilla Thunderbird 0.5 (X11/20040208)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nContent-Type: text/plain; charset=us-ascii; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=-0.0 required=6.0 tests=AWL autolearn=ham version=2.63\r\nX-eGroups-Remote-IP: 209.237.232.202\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: FYI/ plan for post-1.0 scope definition reworking\r\nX-Yahoo-Group-Post: member; u=137285340\r\nX-Yahoo-Profile: gojomo\r\n\r\nWe are planning a change in the way in which a crawl&#39;s scope --\nits definition of what URIs are included and excluded -- is\nmodelled and specified after the 1.0 Heritrix release. (That is\nto say, sometime in May or after.) The hope is to make alternate\nscope choices more understandable and flexible.\n\nThe new approach is somewhat like (and inspired by) HTTrack&#39;s\n&#39;scan rules&#39;/filters, Alexa&#39;s mask/ignore/void syntax for\nadjusting recurring crawls, or the Nutch &#39;regex-urlfilter&#39;\nfacility, but is a little more general than any of those.\n\nPRIOR APPROACH\n\nUp until now, our predefined Scope classes -- PathScope, HostScope,\nDomainScope, BroadScope -- all could be thought of as fitting a\nspecific pattern: A CandidateURI u is included if and only if:\n\n    ( ( focusFilter.accepts(u)\n        | transitiveFilter.accepts(u) )\n      && ! exclusionFilter.accepts(u) )\n\nMore generally, the &#39;focus&#39; filter was meant to rule things in by\nprima facia/regexp-pattern analysis; the &#39;transitive&#39; filter\nrule extra items in by dynamic path analysis (for example, offsite\nembedded images); and the &#39;exclusion&#39; filter rule things out\nby any number of chained exclusion rules.\n\nSo in a typical crawl, the &#39;focus&#39; filter drew from one of these\ncategories:\n\n    broad: accept all\n    domain: accept if on same &#39;domain&#39; (for some definition) as seeds\n    host: accept if on exact host as seeds\n    path: accept if on same host and a sahred path-prefix as seeds\n\nThe &#39;transitive&#39; filter was configured based on the various link-hops\nand embed-hops thresholds set by the operator.\n\nThe &#39;exclusion&#39; filter was in fact a compound chain of filters,\nOR&#39;ed together, such that any one of them could knock a URI out of\nconsideration.\n\nHowever, a number of aspects of this arrangement have caused problems:\n\n  * To truly understand what happens to an URI, you must\n    understand the above nested boolean-construct.\n  * Adding mixed focuses -- such as all of this one host, all of\n    this other domain, and then just these paths on this other host --\n    is not supported, nor easy to mix-in to the &#39;focus&#39; filter.\n  * Constructing and configuring the multiple filters required\n    many setup steps across several web UI pages.\n  * The reverse sense of the &#39;exclusion&#39; filters -- if URIs are\n    accepted by the filter, they are excluded from teh crawl -- proved\n    confusing, exacerbated by the fact that &#39;filter&#39; itself can\n    commonly mean either &#39;filter in&#39; or &#39;filter out&#39;.\n\nNEW APPROACH\n\nWe are planning a new standard Scope model that should be easier to\nunderstand when used for simple, common crawls, as well as better\naccomodate certain &#39;mixed&#39; focus requirements. This model retains the\nidea that at the highest level, the &#39;Scope&#39; is a swappable,\nself-contained component that is consulted for a yes/no judgement on\nwhether or not a particular candidate URI is &#39;in scope&#39; for a crawl.\n\nIn the common case, though, we will think of the Scope is thought of\nas a series of ScopeRules. Each ScopeRule contains a Matcher and a\nScopeAction. A Matcher can be thought of as a Filter ranamed for\nclarity: it returns true if its conditions are matched. A\nScopeAction is (for now) either INCLUDE or EXCLUDE.\n\nTo define a Scope, the operator configures an ordered series of\nScopeRules. A URI under consideration begins with the assumed\nstatus EXCLUDED, but then each rule is applied in turn to the\ncandidate URI. If the rule&#39;s Matcher matches, then the supplied\naction is applied to the URI&#39;s current include/exclude status,\npossibly changing that status. After all rules have been applied,\nif the URI&#39;s status is INCLUDED it is &quot;in scope&quot; and scheduled\nfor crawling; if its status is EXCLUDED it is discarded.\n\nThere are no branches, but much of what nested conditionals\ncan achieve is possible, in a form that should be be easier to\nfollow than arbitrary expressions.\n\nThe list of available Matchers would include things like:\n\n   sameDomainAsAnySeed()\n   sameDomainAsAnyUriInFile(&quot;filename&quot;)\n   pathExtensionOf(&quot;http://www.berkeley.edu/research/&quot;)\n   embeddedResourceWithinHops(3)\n   regexpMatch(&quot;.*cgi-bin.*&quot;)\n   pathSlashesGreaterThan(10)\n\n...covering everything our existing focus- and filter-\nbased classes do. By ordering exclude and include actions,\ncombinations that were awkward before -- or even impossible\ngiven the current interface -- become straightforward.\n\nFor example, a previous request that was hard for us to\naccomodate was the idea: &quot;crawl exactly these X hosts,\nand get offsite images if only on the same domains.&quot; That is,\ndon&#39;t wander off the exact hosts to follow links, or even\nget offsite images -- except when the offsite image shares\nthe same domain.\n\nOur relevant function-of-seeds tests -- host-based and\ndomain-based -- were exclusive of each other (at the &#39;focus&#39;\nlevel) and difficult to mix-in with path-based criteria\n(at the &#39;transitive&#39; level).\n\nAs a series of ScopeRules, this can be achieved as:\n\n   includeIf(sameHostAsAnySeed())\n   includeIf(embeddedResourceWithinHops(1))\n   excludeIf(not(sameDomainAsAnySeed())\n\nFurther refinements to this basic model are possible:\n\n(1) Allow rules to offer more actions than include/exclude,\n     such as an early exit from the rule chain. Then meeting\n     a certain test might mean &#39;exclude regardless of subsequent\n     rules&#39; or &#39;include regardless of subsequent rules&#39;.\n     (More speculative: let rules mark-up URIs in ways that\n     affect their future scoping, processing, or the handling\n     of other URIs discovered off them.) This sort of\n     refinement could allieviate the otherwise inefficient\n     calculation of ultimately irrelevant rules.\n\n(2) Segment the ScopeRules into 2 distinct chains: one\n     chain that is &quot;core&quot; or perhaps &quot;static&quot; rules, defining\n     the main focus of the crawl, and another chain which approves\n     related URIs dynamically. This would somewhat replicate\n     the intent of the &#39;focus&#39; vs. &#39;transitive&#39; split in the 1.0\n     scope model, and make possible a Scope which says, &quot;get\n     all this &#39;core&#39;, and then anything else within N link-hops\n     of any &#39;core&#39; items.&quot; (Current link-hop limits apply from\n     seeds, not from site boundaries.)\n\n(3) Allow a seedlist-annotation syntax to help create\n     mixed scopes. For example, each URI listed in a seed\n     file might be followed with a label -- &#39;group1&#39;,\n     &#39;group2&#39;, etc. This could then be used to refer back to\n     a URI set in Scope Rules -- sameHostAsSeeds(&quot;group1&quot;),\n     samePathAsSeeds(&quot;group2&quot;), etc.\n\n(4) As is suggested by the syntax for listing ScopeRules\n     above, they could be scripting code supplied by the\n     crawl operator, in Python, Javascript, or other scripting\n     langauges that we might embed in our Java app. Then\n     other optimizations and tests of arbitrary complexity\n     could be added as needed, as either one ScopeRule among\n     many or as the entire scope. Further, such scripts\n     could reuse and combine predefined Matcher functions.\n\nOur first steps to validate this approach can likely reuse\nthe existing multi-admin-page system for setting up filters\nto set up rules; as we acquire confidence in how it would\nbe used, we could integrate it all into the main settings\npage, or its own scope definition page. We could also offer\na &#39;testing page&#39; where you could feed URIs (plus specified\nother attributes) to the system and see what each rule does,\nand the final answer given.\n\nComments wanted! Remember this new plan won&#39;t be acted upon\nuntil some time in May at the earliest, so the 1.0 crawler\nwill continue to use the old approach.\n\n- Gordon\n\n\n"}}