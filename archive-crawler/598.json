{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr (@Internet Archive)","from":"&quot;Gordon Mohr (@Internet Archive)&quot; &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"JLEtj-R7RFtAiCuzqJySC0hl-Fe1ifDOUPNzVUK_tlVBZUnFm6vg1WnHBx2L44u6TyQHHdbeuqC6HSKXkQVkoweej4rXC7GGsxRjcVes0e-FnqDC8GB62LPslxyu","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Stupid crawl problems:  User-Agent and From","postDate":"1089282232","msgId":598,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQwRUQyMEI4LjcwMDA4MDhAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDEwODkyODEwNTcuMTkzOC43Ni5jYW1lbEBwYzc3MC5zYi5zdGF0c2JpYmxpb3Rla2V0LmRrPg==","referencesHeader":"PDEwODkyODEwNTcuMTkzOC43Ni5jYW1lbEBwYzc3MC5zYi5zdGF0c2JpYmxpb3Rla2V0LmRrPg=="},"prevInTopic":597,"nextInTopic":599,"prevInTime":597,"nextInTime":599,"topicId":595,"numMessagesInTopic":8,"msgSnippet":"You need the + in the User-Agent, exactly as the template shows, inside the parenthesis before the URL. We should probably relax and better document this;","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 8601 invoked from network); 8 Jul 2004 10:23:57 -0000\r\nReceived: from unknown (66.218.66.218)\n  by m13.grp.scd.yahoo.com with QMQP; 8 Jul 2004 10:23:57 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (209.237.232.202)\n  by mta3.grp.scd.yahoo.com with SMTP; 8 Jul 2004 10:23:57 -0000\r\nReceived: (qmail 26046 invoked by uid 100); 8 Jul 2004 10:15:12 -0000\r\nReceived: from adsl-63-196-1-42.dsl.snfc21.pacbell.net (HELO ?10.0.10.13?) (gojomo@...@63.196.1.42)\n  by mail-dev.archive.org with SMTP; 8 Jul 2004 10:15:12 -0000\r\nMessage-ID: &lt;40ED20B8.7000808@...&gt;\r\nDate: Thu, 08 Jul 2004 03:23:52 -0700\r\nUser-Agent: Mozilla Thunderbird 0.6 (X11/20040502)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;1089281057.1938.76.camel@...&gt;\r\nIn-Reply-To: &lt;1089281057.1938.76.camel@...&gt;\r\nContent-Type: text/plain; charset=us-ascii; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: ***\r\nX-Spam-Status: No, hits=3.3 required=6.0 tests=AWL,RCVD_IN_DYNABLOCK,\n\tRCVD_IN_NJABL,RCVD_IN_NJABL_PROXY,RCVD_IN_SORBS autolearn=no \n\tversion=2.63\r\nX-eGroups-Remote-IP: 209.237.232.202\r\nFrom: &quot;Gordon Mohr (@Internet Archive)&quot; &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Stupid crawl problems:  User-Agent and From\r\nX-Yahoo-Group-Post: member; u=137285340\r\nX-Yahoo-Profile: gojomo\r\n\r\nYou need the &#39;+&#39; in the User-Agent, exactly as the template shows, inside the\nparenthesis before the URL.\n\nWe should probably relax and better document this; it&#39;s been a point of\nconfusion for others as well.\n\n- Gordon @ IA\n\n\nLars Clausen wrote:\n&gt; I&#39;m trying to make a crawl to gather some articles about us today, but I\n&gt; can&#39;t get Heritrix 0.10.0 to accept my User-Agent and From fields.  Now\n&gt; I know other people have been running them, so it must work, but I see\n&gt; no clue abot what goes wrong.  The relevant part of the crawl order is\n&gt; \n&gt; &lt;map name=&quot;http-headers&quot;&gt;\n&gt; &lt;string name=&quot;user-agent&quot;&gt;linux-heritrix/0.10.0 (http://www.netarkivet.dk/)&lt;/string&gt;\n&gt; &lt;string name=&quot;from&quot;&gt;lc@...&lt;/string&gt;\n&gt; &lt;/map&gt;\n&gt; \n&gt; and the error message is\n&gt; \n&gt; A fatal InitializationException occured when loading job:\n&gt; You must set the User-Agent and From HTTP header values to acceptable strings. \n&gt;  User-Agent: [software-name](+[info-url])[misc]\n&gt;  From: [email-address]\n&gt; : org.archive.crawler.framework.exceptions.FatalConfigurationException: unacceptable user-agent or from\n&gt; \n&gt; I tried with http://www.netarkivet.dk or www.netarkivet.dk as URL.\n&gt; \n&gt; For future users, it would be nice if a) the little pop-up helps show an\n&gt; example of accepted style, and/or b) the error message showed what\n&gt; Heritrix got and found offending.\n&gt; \n&gt; -Lars\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt;  \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n&gt;  \n&gt; \n\n\n"}}