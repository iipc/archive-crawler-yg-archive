{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"TIHpNcucU6w5U7AUa-yiMmSOooNItvlrJH2rUFXIrvB2N_AA91DkRFRSmadY497EvU1OyGOJyG89AmR53fKlV1VKaVn2cwo","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] politeness issue / out of memory error","postDate":"1131394801","msgId":2333,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQzNkZCNkYxLjgwNDA2MDNAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDQzNkYxNDNDLjQwMDAwMDdAc3NsbWl0LnVuaWJvLml0Pg==","referencesHeader":"PDQzNkYxNDNDLjQwMDAwMDdAc3NsbWl0LnVuaWJvLml0Pg=="},"prevInTopic":2332,"nextInTopic":2335,"prevInTime":2332,"nextInTime":2334,"topicId":2319,"numMessagesInTopic":8,"msgSnippet":"... See this message -- we speculatively try INPUT values that look like path-segments, because they often are: ","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 93780 invoked from network); 7 Nov 2005 20:20:08 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m32.grp.scd.yahoo.com with QMQP; 7 Nov 2005 20:20:08 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (207.241.224.171)\n  by mta2.grp.scd.yahoo.com with SMTP; 7 Nov 2005 20:20:07 -0000\r\nReceived: (qmail 31642 invoked by uid 100); 7 Nov 2005 20:17:28 -0000\r\nReceived: from adsl-71-130-102-78.dsl.pltn13.pacbell.net (HELO ?192.168.1.10?) (gojomo@...@71.130.102.78)\n  by mail-dev.archive.org with SMTP; 7 Nov 2005 20:17:28 -0000\r\nMessage-ID: &lt;436FB6F1.8040603@...&gt;\r\nDate: Mon, 07 Nov 2005 12:20:01 -0800\r\nUser-Agent: Mozilla Thunderbird 1.0.6-1.1.fc3 (X11/20050720)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;436F143C.4000007@...&gt;\r\nIn-Reply-To: &lt;436F143C.4000007@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=-69.0 required=7.0 tests=AWL,USER_IN_WHITELIST \n\tautolearn=no version=2.63\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] politeness issue / out of memory error\r\nX-Yahoo-Group-Post: member; u=137285340; y=kUxxamyAFnEPFi9OCyXWhuB1dgWG-kHoL5oEFdd0vifE\r\nX-Yahoo-Profile: gojomo\r\n\r\nMarco Baroni wrote:\n&gt; Dear all,\n&gt; \n&gt; I have been running heritrix (1.4.0) for about 10 days, with about 10,000 \n&gt; seeds, broad scope, Tom Emerson&#39;s &quot;HTML only&quot; filters, 150 threads, and \n&gt; pretty much all other settings with default values.\n&gt; \n&gt; I have two problems.\n&gt; \n&gt; Problem one is that this morning I received the following e-mail. I \n&gt; remember that there was a thread about a similar problem a few months ago, \n&gt; but I am not able to locate it in the archives -- could somebody kindly \n&gt; point me to the relevant thread, or give me fresh advice if previous advice \n&gt; is not relevant?\n&gt; \n&gt; Your web page says to let you know if your web crawler doesn&#39;t behave\n&gt; well. I thought you would be interested to know that your web crawler\n&gt; generated 88 error404 messages in one day on one single page (\n&gt; http://water.usgs.gov/ogw/bgas/forms/course_evaluation.html). To the best\n&gt; of my knowledge, the page is fully functional, and the problem is in your\n&gt; how your web bot handled the form.\n\nSee this message -- we speculatively try INPUT values that &#39;look like&#39;\npath-segments, because they often are:\n\n   http://groups.yahoo.com/group/archive-crawler/message/2222\n\n(Though, on trying that URL, I only get a single spurious 404.)\n\n&gt; Second, this morning I also noticed an out-of-memory error, and the crawler \n&gt; was in pause mode. I sort of expected this, given the warnings re broad \n&gt; scope in the documentation, but I am wondering: is there any use in \n&gt; resuming the job (I crawled about half as much the data I would like to \n&gt; crawl), or will it get out of memory again soon anyway? Any other solution? \n&gt; (e.g., some setting I can change on the fly?)\n\nOccasionally you can resume from an out-of-memory (OOM) situation -- but\nusually, not. With the checkpointing feature now in HEAD, you can also\noften checkpoint the crawl, then quit & restart the crawler, and resume\nfrom the checkpoint for some additional crawling. But, depending on the\nreal cause of the OOM, you may be likely to hit another very soon.\n\nSome things that are interesting to know about any OOM...\n\n  - what was the exact exception reported (did it specify &#39;java heap space&#39;\n    and was there a stack trace)?\n\n    We&#39;ve seen a few weird but reproduceable OOMs on one dual-opteron machine\n    in Unix file ops even when heap space is plentiful... implying some other\n    resource (handles, native buffers, ?) is what&#39;s really depleted. More\n    reports would help determine what&#39;s going on; moving to another nearly\n    identical machine that may differ only by BIOS memory settings resolves\n    the problem.\n\n  - what is the thread/URI affected?\n\n    Occasionally, OOMs have been due to runaway memory-consumption bugs in a\n    particular module (sometimes 3rd-party) on worst-case input. These seem to\n    have a better-than-average chance of triggering the OOM in the real culprit\n    thread, rather than an innocent bystander. We&#39;ve fixed these on a\n    case-by-case basis, but new ones are always a risk.\n\n    Restarting a crawl (via the recovery log, checkpoint, or even just a\n    lucky resume-from-pause) from such an OOM has a better chance of\n    continuing for a long time.\n\n  - Do the last lines of progress-statistics.log before the OOM show\n    a packed heap? If so, it&#39;s likely that it is simply too many live\n    objects causing the OOM.\n\n  - What sort of queue-counts are shown in the &#39;reports&#39; UI page? Some\n    of the queue-holding structures still grow in heap usage with size\n    (the snoozed, inactive, ready, and retired lists), so &#39;large&#39; numbers\n    here are something that can eventually, understandably create an\n    OOM. (&#39;Large&#39; depending on your heap size.) We plan to do more to\n    cap the heap-consumption of these structures.\n\n- Gordon @ IA\n\n"}}