{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"Michael Stack","from":"Michael Stack &lt;stack@...&gt;","replyTo":"LIST","senderId":"76H24axT7t08WQ8wuIaR85raGsFlBS9vvNcGbF9T6yFMVhFKY7SSuzg-3QRICpDVdGtsU1zk3dMyzZ2uCtzHftPilln37D_0","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Large seed lists: some troubles","postDate":"1083287161","msgId":361,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQwOTFBNjc5LjUwODA4QGFyY2hpdmUub3JnPg==","inReplyToHeader":"PHMwOGY3ZDMyLjAwNEBsb2MuZ292Pg==","referencesHeader":"PHMwOGY3ZDMyLjAwNEBsb2MuZ292Pg=="},"prevInTopic":356,"nextInTopic":0,"prevInTime":360,"nextInTime":362,"topicId":353,"numMessagesInTopic":4,"msgSnippet":"Andrew: Both of the below issues are now fixed in HEAD. On the too many open files issue , we were leaking file descriptors. We also were using up file","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 97077 invoked from network); 30 Apr 2004 01:12:35 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m24.grp.scd.yahoo.com with QMQP; 30 Apr 2004 01:12:35 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (209.237.232.202)\n  by mta5.grp.scd.yahoo.com with SMTP; 30 Apr 2004 01:12:34 -0000\r\nReceived: (qmail 3874 invoked by uid 100); 30 Apr 2004 01:06:35 -0000\r\nReceived: from b116-dyn-60.archive.org (HELO archive.org) (stack@...@209.237.240.60)\n  by mail-dev.archive.org with SMTP; 30 Apr 2004 01:06:35 -0000\r\nMessage-ID: &lt;4091A679.50808@...&gt;\r\nDate: Thu, 29 Apr 2004 18:06:01 -0700\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.5) Gecko/20031107 Debian/1.5-3\r\nX-Accept-Language: en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;s08f7d32.004@...&gt;\r\nIn-Reply-To: &lt;s08f7d32.004@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=0.5 required=6.0 tests=AWL autolearn=ham version=2.63\r\nX-eGroups-Remote-IP: 209.237.232.202\r\nFrom: Michael Stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] Large seed lists: some troubles\r\nX-Yahoo-Group-Post: member; u=168599281\r\n\r\nAndrew:\n\nBoth of the below issues are now fixed in HEAD.\n\nOn the &#39;too many open files issue&#39;, we were leaking file descriptors.  \nWe also were using up file descriptors for a feature not yet implemented \n(I turned the facility off in meantime).  We&#39;re now at about two FDs per \nthread w/ a base cost of 100 FDs (JVM, logs, jars, etc.).   I&#39;ve added a \nnote to the FAQ on what to do if too many open files exceptions are seen \nin the logs.\n\nThanks again for the reports.\nSt.Ack\n\n\nAndrew Boyko wrote:\n\n&gt; I happen to have a seed list of nearly 1024 entries.  Not totally \n&gt; surprisingly, Heritrix behaves a little oddly with that many seeds.  \n&gt; First, crawls with either 0.6.0 or the latest CVS build fail because \n&gt; too many files are opened almost immediately, and then neither socket \n&gt; operations nor file logging are able to proceed.  A typical exception:\n&gt;  \n&gt;  java.io.FileNotFoundException: \n&gt; /crawl/heritrix/heritrix-0.6.0/jobs/crs-20040427190708335/disk/scratch/bphc.hrsa.gov.ff0 \n&gt; (Too many open files)\n&gt;         at java.io.FileOutputStream.open(Native Method)\n&gt;         at java.io.FileOutputStream.&lt;init&gt;(FileOutputStream.java:179)\n&gt;         at java.io.FileOutputStream.&lt;init&gt;(FileOutputStream.java:131)\n&gt;         at \n&gt; org.archive.io.FlipFileOutputStream.&lt;init&gt;(FlipFileOutputStream.java:69)\n&gt;         at \n&gt; org.archive.io.DiskBackedByteQueue.initializeStreams(DiskBackedByteQueue.java:67)\n&gt;         at org.archive.util.DiskQueue.&lt;init&gt;(DiskQueue.java:100)\n&gt;         at \n&gt; org.archive.util.DiskBackedQueue.&lt;init&gt;(DiskBackedQueue.java:59)\n&gt;         at org.archive.crawler.basic.KeyedQueue.&lt;init&gt;(KeyedQueue.java:76)\n&gt;         at \n&gt; org.archive.crawler.basic.Frontier.keyedQueueFor(Frontier.java:927)\n&gt;         at \n&gt; org.archive.crawler.basic.Frontier.scheduleForRetry(Frontier.java:1333)\n&gt;         at org.archive.crawler.basic.Frontier.finished(Frontier.java:676)\n&gt;         at \n&gt; org.archive.crawler.framework.ToeThread.processCrawlUri(ToeThread.java:200)\n&gt;         at org.archive.crawler.framework.ToeThread.run(ToeThread.java:124)\n&gt; You can get past that by allowing a larger number of open files for \n&gt; the process (which requires running Heritrix with root privilege), as in:\n&gt;    # (ulimit -n 4096; JAVA_OPTS=-Xmx320 bin/heritrix -p 9876)\n&gt;  \n&gt; Next up, using the current CVS build, a surprising number (like, \n&gt; ~70) of java.util.ConcurrentModificationExceptions occurred in the \n&gt; first moments of the crawl (and then intermittently throughout), all \n&gt; with the same stack trace.  An example:\n&gt;  \n&gt; 20040427194255925    -5      39804 #48 http://eia.doe.gov/ 124 \n&gt; text/html 3t\n&gt;  java.util.ConcurrentModificationException\n&gt;         at \n&gt; java.util.AbstractList$Itr.checkForComodification(AbstractList.java:448)\n&gt;         at java.util.AbstractList$Itr.next(AbstractList.java:419)\n&gt;         at \n&gt; org.archive.crawler.scope.HostScope.focusAccepts(HostScope.java:120)\n&gt;         at \n&gt; org.archive.crawler.framework.CrawlScope.innerAccepts(CrawlScope.java:198)\n&gt;         at org.archive.crawler.framework.Filter.accepts(Filter.java:94)\n&gt;         at \n&gt; org.archive.crawler.basic.Postselector.schedule(Postselector.java:200)\n&gt;         at \n&gt; org.archive.crawler.basic.Postselector.handleLinkCollection(Postselector.java:262)\n&gt;         at \n&gt; org.archive.crawler.basic.Postselector.innerProcess(Postselector.java:112)\n&gt;         at \n&gt; org.archive.crawler.framework.Processor.process(Processor.java:106)\n&gt;         at \n&gt; org.archive.crawler.framework.ToeThread.processCrawlUri(ToeThread.java:205)\n&gt;         at org.archive.crawler.framework.ToeThread.run(ToeThread.java:135)\n&gt; Looking at the code, it looks like the CrawlScope class hands out an \n&gt; iterator on the scope&#39;s seeds list; that iteration needs to \n&gt; synchronize on the list (per the note in  \n&gt; http://java.sun.com/j2se/1.4.2/docs/api/java/util/Collections.html#synchronizedCollection(java.util.Collection \n&gt; &lt;http://java.sun.com/j2se/1.4.2/docs/api/java/util/Collections.html#synchronizedCollection%28java.util.Collection&gt;) \n&gt; ), which I guess is going to take some refactoring.\n&gt;  \n&gt; Should it be relevant, the few changes made to the default \n&gt; configuration for this crawl, other than adding a pile of seeds, were:\n&gt; - HostScope\n&gt; - max-link-hops 1\n&gt; - total-bandwidth-usage-KB-sec 500\n&gt; Otherwise, the crawl for this large seed list seems to be proceeding \n&gt; apace.\n&gt;  \n&gt; Andy Boyko    aboy@... &lt;mailto:aboy@...&gt;\n&gt;  \n&gt;\n&gt; ------------------------------------------------------------------------\n&gt; *Yahoo! Groups Links*\n&gt;\n&gt;     * To visit your group on the web, go to:\n&gt;       http://groups.yahoo.com/group/archive-crawler/\n&gt;        \n&gt;     * To unsubscribe from this group, send an email to:\n&gt;       archive-crawler-unsubscribe@yahoogroups.com\n&gt;       &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;        \n&gt;     * Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;.\n&gt;\n&gt;\n\n\n\n"}}