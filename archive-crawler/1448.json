{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"stack","from":"stack &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"H6Xrfm8C54eOP-urQiYOifgYFr7NNb3x-Ik67St_ZZKdE-3_09tfrK4CGGr6V79Ho5bfA7BWacbqDD6h8CxhEg","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] something for consideration","postDate":"1106883783","msgId":1448,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQxRjlCNEM3LjUwMzA2MDdAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDYuMS4yLjAuMC4yMDA1MDEyNzEyNDMyMC4wNGI1MGFjMEAyMDYuMTYzLjEwMy40Pg==","referencesHeader":"PDYuMS4yLjAuMC4yMDA1MDEyNzEyNDMyMC4wNGI1MGFjMEAyMDYuMTYzLjEwMy40Pg=="},"prevInTopic":1447,"nextInTopic":1449,"prevInTime":1447,"nextInTime":1449,"topicId":1447,"numMessagesInTopic":4,"msgSnippet":"... We had a chat here and it makes sense that extractors should default to not run if links have already been extracted.  I ll patch the current extractors to","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 49819 invoked from network); 28 Jan 2005 03:50:29 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m22.grp.scd.yahoo.com with QMQP; 28 Jan 2005 03:50:29 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (207.241.224.172)\n  by mta2.grp.scd.yahoo.com with SMTP; 28 Jan 2005 03:50:29 -0000\r\nReceived: (qmail 29231 invoked by uid 100); 28 Jan 2005 03:34:52 -0000\r\nReceived: from debord.archive.org (HELO ?207.241.238.140?) (stack@...@207.241.238.140)\n  by mail-dev.archive.org with SMTP; 28 Jan 2005 03:34:52 -0000\r\nMessage-ID: &lt;41F9B4C7.5030607@...&gt;\r\nDate: Thu, 27 Jan 2005 19:43:03 -0800\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.7.3) Gecko/20041007 Debian/1.7.3-5\r\nX-Accept-Language: en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;6.1.2.0.0.20050127124320.04b50ac0@206.163.103.4&gt;\r\nIn-Reply-To: &lt;6.1.2.0.0.20050127124320.04b50ac0@206.163.103.4&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=0.7 required=6.5 tests=AWL autolearn=no version=2.63\r\nX-eGroups-Remote-IP: 207.241.224.172\r\nFrom: stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] something for consideration\r\nX-Yahoo-Group-Post: member; u=168599281\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\nDave Skinner wrote:\n\n&gt; This was not in my list of three but it is easier to send....\n&gt;\n&gt; ExtractorUniversal.java contains the following check\n&gt;\n&gt;   protected void innerProcess(CrawlURI curi) {\n&gt;          if(curi.hasBeenLinkExtracted()){\n&gt;              //Some other extractor already handled this one. We&#39;ll \n&gt; pass on it.\n&gt;              return;\n&gt;          }\n&gt;\n&gt; I think all the extractors should have the same or similar code.  \n&gt; Right now\n&gt; it is not easy to prevent a curi from having its links followed.  I cant\n&gt; find anywhere in the standard code where this is checked other than \n&gt; the one\n&gt; place in ExtractorUniversal.\n\nWe had a chat here and it makes sense that extractors should default to \nnot run if links have already been extracted.  I&#39;ll patch the current \nextractors to respect curi.hasBeenLinkExtracted tomorrow.\n\nBy the way, you might look at the \nCrawlURI#skipToProcessor(ProcessorChain) and \nCrawlURI#skipToProcessor(ProcessorChain, Processor) methods as a means \nof skipping processing (A ProcessorChain is a group of like-minded \nProcessors: e.g: The Extractors all sit in one ProcessorChain).  See how \nthe PreconditionEnforcer processor works for an example. \n\nAs is, its easy enough to jump to the end of processing but awkward \ntaking smaller jumps; say, aborting the current processing chain.  The \nCrawlController would need some work.  Currently the CrawlController has \nmethods to return the list of all ProcessorChains, the first \nProcessorChain and the last ProcessorChain only.   Processors could also \nhave an abortCurrentChain method and/or a method that returns the \nProcessorChain they belong to.\n\nSt.Ack\n\n&gt;\n&gt; An example of how this might be useful would be someone who is doing\n&gt; lexical analysis on documents as they are being fetched.  Depending upon\n&gt; the content of document, they might wish to discontinue following the \n&gt; thread.\n&gt;\n&gt;\n&gt; ------------------------------------------------------------------------\n&gt; *Yahoo! Groups Links*\n&gt;\n&gt;     * To visit your group on the web, go to:\n&gt;       http://groups.yahoo.com/group/archive-crawler/\n&gt;        \n&gt;     * To unsubscribe from this group, send an email to:\n&gt;       archive-crawler-unsubscribe@yahoogroups.com\n&gt;       &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;        \n&gt;     * Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;.\n&gt;\n&gt;\n\n\n"}}