{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":207498816,"authorName":"ogrenholm","from":"&quot;ogrenholm&quot; &lt;oskar.grenholm@...&gt;","profile":"ogrenholm","replyTo":"LIST","senderId":"JG3sFzyjFw-umYM-LgVxSgaZD02osBMk3dqCBwomiO66DGziF-LNw5C7sMF1sJOSMd8mf7IuNqhYo17t4ee775jB1Ow2Zy51hw","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Problem with some robots.txt files","postDate":"1113394934","msgId":1722,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGQzajJ0bSs5N2JyQGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":1723,"prevInTime":1721,"nextInTime":1723,"topicId":1722,"numMessagesInTopic":2,"msgSnippet":"Hi, I ve found that for some reason or another some webmasters want to allow robots to access scripts, but not with some certain parameters, i.e., in","rawEmail":"Return-Path: &lt;oskar.grenholm@...&gt;\r\nX-Sender: oskar.grenholm@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 49606 invoked from network); 13 Apr 2005 12:22:31 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m30.grp.scd.yahoo.com with QMQP; 13 Apr 2005 12:22:31 -0000\r\nReceived: from unknown (HELO n21a.bulk.scd.yahoo.com) (66.94.237.50)\n  by mta5.grp.scd.yahoo.com with SMTP; 13 Apr 2005 12:22:31 -0000\r\nDomainKey-Signature: \r\nReceived: from [66.218.66.58] by n21.bulk.scd.yahoo.com with NNFMP; 13 Apr 2005 12:22:15 -0000\r\nReceived: from [66.218.66.72] by mailer7.bulk.scd.yahoo.com with NNFMP; 13 Apr 2005 12:22:15 -0000\r\nDate: Wed, 13 Apr 2005 12:22:14 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;d3j2tm+97br@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Length: 986\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0\r\nFrom: &quot;ogrenholm&quot; &lt;oskar.grenholm@...&gt;\r\nSubject: Problem with some robots.txt files\r\nX-Yahoo-Group-Post: member; u=207498816\r\nX-Yahoo-Profile: ogrenholm\r\n\r\n\nHi,\nI&#39;ve found that for some reason or another some webmasters want to\nallow robots to access scripts, but not with some certain parameters,\ni.e., in robots.txt:  \nDisallow: /wiki/index.php?action=edit\n\nI&#39;m not sure if this is a allowed thing to specify in robots.txt, but\nnonetheless people tend to do so sometimes. \nThe problem then is that when Heritrix does a check whether to allow\ncrawling of a URL or not (in  RobotsExclusionPolicy.java) it does only\ncall the URI:s getPath() and therefore doesn&#39;t match it with the above\nmentioned robots.txt rule, and it will get crawled. Maybe this is what\nis supposed to happen, but if someone wants to apply the rule above, a\ncall to the URI:s getPathQuery() will fix this.\n\nIn other words change line 229 in RobotsExclusionPolicy.java\nfrom: String p = curi.getUURI().getPath();\nto: String p = curi.getUURI().getPathQuery();\n\nI have no idea what so ever though if this will cause some other\nhorrible problems that I haven&#39;t thought of.\n\n/OG\n\n\n\n\n"}}