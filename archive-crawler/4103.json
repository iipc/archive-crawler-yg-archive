{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":132996324,"authorName":"joehung302","from":"&quot;joehung302&quot; &lt;joe.hung@...&gt;","profile":"joehung302","replyTo":"LIST","senderId":"aLTBMf3HUonUT61JoJS23XkuZuaQ5FrDIbNcDaBjMJDkQaomS-Q5AgeH6BrX8syqBIpKGzmookVY5HD6bCrHv8sQQvf6GohwX0Nqnvms","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Distributed Crawling","postDate":"1176399886","msgId":4103,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGV2bHI2ZStuc2MyQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGV2Z2czNSttOGFwQGVHcm91cHMuY29tPg=="},"prevInTopic":4081,"nextInTopic":4106,"prevInTime":4102,"nextInTime":4104,"topicId":3834,"numMessagesInTopic":26,"msgSnippet":"This morning I was trying to pause a crawler and was not able to after a long time (20+ minutes?). I looked at the toethread report from the console and found","rawEmail":"Return-Path: &lt;joe.hung@...&gt;\r\nX-Sender: joe.hung@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 44437 invoked from network); 12 Apr 2007 17:47:15 -0000\r\nReceived: from unknown (66.218.66.72)\n  by m50.grp.scd.yahoo.com with QMQP; 12 Apr 2007 17:47:15 -0000\r\nReceived: from unknown (HELO n29.bullet.scd.yahoo.com) (66.94.237.22)\n  by mta14.grp.scd.yahoo.com with SMTP; 12 Apr 2007 17:47:15 -0000\r\nReceived: from [66.218.69.6] by n29.bullet.scd.yahoo.com with NNFMP; 12 Apr 2007 17:44:46 -0000\r\nReceived: from [66.218.66.73] by t6.bullet.scd.yahoo.com with NNFMP; 12 Apr 2007 17:44:46 -0000\r\nDate: Thu, 12 Apr 2007 17:44:46 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;evlr6e+nsc2@...&gt;\r\nIn-Reply-To: &lt;evgg35+m8ap@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;joehung302&quot; &lt;joe.hung@...&gt;\r\nSubject: Re: Distributed Crawling\r\nX-Yahoo-Group-Post: member; u=132996324; y=zeI23EX1WXwUrMP0D8e3Y0ccrmaWHPETmz1JhOuKE2cUWNHiiQ\r\nX-Yahoo-Profile: joehung302\r\n\r\nThis morning I was trying to pause a crawler and was not able to \nafter a l=\r\nong time (20+ minutes?). I looked at the toethread report \nfrom the console=\r\n and found the following trace.\n\nFrom past experience whenever I cannot pau=\r\nse a thread, usually there \nwas some sort of parsing loop on bad pages. But=\r\n this one is \nconcerning to me. I would think that the thread really should=\r\n stop. \nThe un-predicability of not being able to pause the crawl really \ni=\r\nmpact our ability to automate the checkpoint and diversion during a \nbig cr=\r\nawl.\n\nAnything info that you need for this problem?\n\n=3D=3D=3D=3D=3D=3D=3D=\r\n=3D=3D=3D=3D=3D=3D=3D=3D=3D\n   ToeThread #6\n[ToeThread #6: http://even42.cs=\r\n.ohiou.edu/robots.txt\n CrawlURI http://even42.cs.ohiou.edu/robots.txt LLLLL=\r\nLLLLLLLP \nhttp://even42.cs.ohiou.edu/~osterman/dpierce/    0 attempts\n    i=\r\nn processor: HTTP\n    ACTIVE for 19h2m28s490ms\n    step: ABOUT_TO_BEGIN_PRO=\r\nCESSOR for 19h2m28s490ms\n    java.net.SocketInputStream.socketRead0(Native =\r\nMethod)\n    java.net.SocketInputStream.read(SocketInputStream.java:129)\n   =\r\n java.io.BufferedInputStream.fill(BufferedInputStream.java:218)\n    java.io=\r\n.BufferedInputStream.read(BufferedInputStream.java:235)\n    org.archive.io.=\r\nRecordingInputStream.read\n(RecordingInputStream.java:100)\n    org.apache.co=\r\nmmons.httpclient.HttpParser.readRawLine\n(HttpParser.java:78)\n    org.apache=\r\n.commons.httpclient.HttpParser.readLine\n(HttpParser.java:106)\n    org.apach=\r\ne.commons.httpclient.HttpConnection.readLine\n(HttpConnection.java:1144)\n   =\r\n org.apache.commons.httpclient.HttpMethodBase.readStatusLine\n(HttpMethodBas=\r\ne.java:1852)\n    org.apache.commons.httpclient.HttpMethodBase.readResponse\n=\r\n(HttpMethodBase.java:1612)\n    org.apache.commons.httpclient.HttpMethodBase=\r\n.execute\n(HttpMethodBase.java:1002)\n    org.archive.httpclient.HttpRecorder=\r\nGetMethod.execute\n(HttpRecorderGetMethod.java:116)\n    org.apache.commons.h=\r\nttpclient.HttpMethodDirector.executeWithRetry\n(HttpMethodDirector.java:397)=\r\n\n    org.apache.commons.httpclient.HttpMethodDirector.executeMethod\n(HttpMe=\r\nthodDirector.java:170)\n    org.apache.commons.httpclient.HttpClient.execute=\r\nMethod\n(HttpClient.java:396)\n    org.apache.commons.httpclient.HttpClient.e=\r\nxecuteMethod\n(HttpClient.java:346)\n    org.archive.crawler.fetcher.FetchHTT=\r\nP.innerProcess\n(FetchHTTP.java:489)\n    org.archive.crawler.framework.Proce=\r\nssor.process\n(Processor.java:109)\n    org.archive.crawler.framework.ToeThre=\r\nad.processCrawlUri\n(ToeThread.java:302)\n    org.archive.crawler.framework.T=\r\noeThread.run(ToeThread.java:151)\n]\n\n\n\n"}}