{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":39397245,"authorName":"Eric","from":"Eric &lt;ej@...&gt;","profile":"mar1ow2003","replyTo":"LIST","senderId":"R4iMKA6l4eHyKLS0vLTLgeRuI6B3E8w0ZkTUWO5T8l7XW-bZ4Cg1cIr8TRWDpUceSJS8l8o2s7e1EDM","spamInfo":{"isSpam":false,"reason":"0"},"subject":"robots.txt from every directory?","postDate":"1152223909","msgId":3012,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDIwMDYwNzA2MjIxMTQ4LkdBMTE4NjNAZHV2ZWwuaXIuaWl0LmVkdT4="},"prevInTopic":0,"nextInTopic":3013,"prevInTime":3011,"nextInTime":3013,"topicId":3012,"numMessagesInTopic":3,"msgSnippet":"In examining my crawl logs, I find that heritrix is trying to download robots.txt from every directory I access on the server, i.e. ","rawEmail":"Return-Path: &lt;ej@...&gt;\r\nX-Sender: ej@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 40612 invoked from network); 6 Jul 2006 22:11:52 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m41.grp.scd.yahoo.com with QMQP; 6 Jul 2006 22:11:52 -0000\r\nReceived: from unknown (HELO duvel.ir.iit.edu) (216.47.134.15)\n  by mta1.grp.scd.yahoo.com with SMTP; 6 Jul 2006 22:11:52 -0000\r\nReceived: from ej by duvel.ir.iit.edu with local (Exim 4.54)\n\tid 1Fyc4b-0004Lq-2t\n\tfor archive-crawler@yahoogroups.com; Thu, 06 Jul 2006 17:11:49 -0500\r\nDate: Thu, 6 Jul 2006 17:11:49 -0500\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;20060706221148.GA11863@...&gt;\r\nMime-Version: 1.0\r\nContent-Type: text/plain; charset=us-ascii\r\nContent-Disposition: inline\r\nX-PGP-Key: http://ir.iit.edu/~ej/ericjensen.asc\r\nUser-Agent: Mutt/1.5.11\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: Eric &lt;ej@...&gt;\r\nSubject: robots.txt from every directory?\r\nX-Yahoo-Group-Post: member; u=39397245; y=go40RPp4_kNRlhxpHjAYox12lLBZVqRKUO5-liSUbRD4Qg5yUA\r\nX-Yahoo-Profile: mar1ow2003\r\n\r\nIn examining my crawl logs, I find that heritrix is trying to download\nrobots.txt from every directory I access on the server, i.e.\n\nhttp://www.somewhere.com/a/robots.txt\nhttp://www.somewhere.com/b/robots.txt\n\neven though it&#39;s able to fetch the root\nhttp://www.somewhere.com/robots.txt just fine (it&#39;s in the arcs)\n\nThis is a problem because some of my crawl has CGI&#39;s which use the\npath as their argument list, so I have many different &quot;directories&quot;\nthat are really just CGI parameters.  How can I turn this off?\n\nI tried changing\n\nPreconditionEnforcer.java:176\nString prereq = curi.getUURI().resolve(&quot;/robots.txt&quot;).toString();\n\nBut it doesn&#39;t seem to have done the trick.  \n\nThanks,\neric.\n\n-- \nhttp://ir.iit.edu/~ej\n\n"}}