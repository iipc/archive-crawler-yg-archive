{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"wN20mA-Hu2l9bQVvIKIaydTgt_TbrJ8mYWgAGH_ipBd5vrbyjPw00QDFCDnt_BPvRXep_6I6khikK0xMuxgsfwTyKHjkOdw","spamInfo":{"isSpam":false,"reason":"2"},"subject":"Re: [archive-crawler] How to define a good &#39;max-hop&#39;?","postDate":"1254118568","msgId":6056,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRBQzA1NEE4LjYwMzA4MDlAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGg5cDg5ZStvZmFyQGVHcm91cHMuY29tPg==","referencesHeader":"PGg5cDg5ZStvZmFyQGVHcm91cHMuY29tPg=="},"prevInTopic":6054,"nextInTopic":6057,"prevInTime":6055,"nextInTime":6057,"topicId":6054,"numMessagesInTopic":4,"msgSnippet":"... Which 5 do you get? What s an example of one that you think you should have gotten, but didn t? Note that a crawl with the default profile, starting with","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 2570 invoked from network); 28 Sep 2009 06:16:13 -0000\r\nX-Received: from unknown (98.137.34.45)\n  by m3.grp.sp2.yahoo.com with QMQP; 28 Sep 2009 06:16:13 -0000\r\nX-Received: from unknown (HELO mail.archive.org) (207.241.231.239)\n  by mta2.grp.sp2.yahoo.com with SMTP; 28 Sep 2009 06:16:13 -0000\r\nX-Received: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id 08BEE3575A\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Sun, 27 Sep 2009 23:17:18 -0700 (PDT)\r\nX-Received: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id 24H1RmuHoI6v for &lt;archive-crawler@yahoogroups.com&gt;;\n\tSun, 27 Sep 2009 23:17:17 -0700 (PDT)\r\nX-Received: from [10.0.13.17] (adsl-70-137-138-250.dsl.snfc21.sbcglobal.net [70.137.138.250])\n\tby mail.archive.org (Postfix) with ESMTPSA id 1AC6C35757\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Sun, 27 Sep 2009 23:17:15 -0700 (PDT)\r\nMessage-ID: &lt;4AC054A8.6030809@...&gt;\r\nDate: Sun, 27 Sep 2009 23:16:08 -0700\r\nUser-Agent: Thunderbird 2.0.0.23 (Windows/20090812)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;h9p89e+ofar@...&gt;\r\nIn-Reply-To: &lt;h9p89e+ofar@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 2:2:2:0:1\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] How to define a good &#39;max-hop&#39;?\r\nX-Yahoo-Group-Post: member; u=137285340; y=EPc9LYfKIpZaG7NJ5XMX4Gf2E9sC8FHabKWs_eDdcTBw\r\nX-Yahoo-Profile: gojomo\r\n\r\nshichuanwuhan@... wrote:\n&gt; Hi all,\n&gt; \n&gt;   Suppose I plan to crawl all professors&#39; homepages on the site: http://www.cs.umn.edu/people/faculty/index.php \n&gt; \n&gt;    To avoid redundant crawling, I set max-hop to 2 and max-path-segment to 15. However, I can only successfully crawl no more than 5 homepages(in the form of &#39;/~name/&#39;) according to crawl log. Could anyone tell me why?\n\nWhich 5 do you get?\n\nWhat&#39;s an example of one that you think you should have gotten, but didn&#39;t?\n\nNote that a crawl with the default profile, starting with just the seed \nURI &#39;http://www.cs.umn.edu/people/faculty/index.php&#39; will only visit \noutlink navigational URIs that begin \n&#39;http://www.cs.umn.edu/people/faculty/&#39;. (Those are the only URIs \n&#39;implied&#39; as in-scope by the seed. To get more, you&#39;d have to add more \nseeds or SURT-prefix scope-directives.)\n\nIt will not visit pages on &#39;www-users.cs.umn.edu&#39;, or even URIs on \n&#39;www.cs.umn.edu&#39; whose path-segment does not begin &#39;/people/faculty/&#39;.\n\n- Gordon @ IA\n\n\n&gt;    Following is my crawl order:\n&gt; \n&gt; 2-15 Admin 20090928022729 settings logs checkpoints state scratch 0 0 0 100 4096 65536 0 true seeds.txt true ACCEPT true d:&#92;&#92;result.txt false true 15 2 2 REJECT Custom .*(/|&#92;.html)$ Mozilla/5.0 (compatible; heritrix/@1.14.3@ +http://192.168.0.1) test@... classic false 5.0 30000 3000 300 30 900 1 0 0 org.archive.crawler.frontier.HostnameQueueAssignmentPolicy false false false true true 3000 100 -1 org.archive.crawler.frontier.UnitCostAssignmentPolicy 300000 50 org.archive.crawler.util.BdbUriUniqFilter false true false false false true 21600 86400 false true false true sha1 true 1200 20000 0 0 false true open ISO-8859-1 true sha1 true true true true false true true true true false true true true true true index.html %2E . true mirror 1023 255 false true LONG true true false true -1 true true false true true\n&gt; \n&gt; \n&gt; \n&gt; ------------------------------------\n&gt; \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n"}}