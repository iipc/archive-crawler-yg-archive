{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"Fej7lxFz8QUtgno0hSZIvm5oSBnjEAvwS3PXYOF2ezsAVSZjgl4PuHVNoE5xIQ5pxGuVlXoOv6CoWSr_oX2xavFVj9WCtHc","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] link-discovery/extraction","postDate":"1295999436","msgId":6986,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDREM0Y2MUNDLjEwMTAwMDBAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDY5NDc5NS4xODU3MS5xbUB3ZWI0MzEzNC5tYWlsLnNwMS55YWhvby5jb20+","referencesHeader":"PDY5NDc5NS4xODU3MS5xbUB3ZWI0MzEzNC5tYWlsLnNwMS55YWhvby5jb20+"},"prevInTopic":6985,"nextInTopic":0,"prevInTime":6985,"nextInTime":6987,"topicId":6985,"numMessagesInTopic":2,"msgSnippet":"I don t know how this could happen; unless you ve taken specific extra steps to reuse/reload state from previous crawls, they shouldn t affect future launches.","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 16134 invoked from network); 25 Jan 2011 23:50:37 -0000\r\nX-Received: from unknown (66.196.94.107)\n  by m17.grp.re1.yahoo.com with QMQP; 25 Jan 2011 23:50:37 -0000\r\nX-Received: from unknown (HELO relay01.pair.com) (209.68.5.15)\n  by mta3.grp.re1.yahoo.com with SMTP; 25 Jan 2011 23:50:37 -0000\r\nX-Received: (qmail 36036 invoked by uid 0); 25 Jan 2011 23:50:36 -0000\r\nX-Received: from 208.70.27.190 (HELO silverbook.local) (208.70.27.190)\n  by relay01.pair.com with SMTP; 25 Jan 2011 23:50:36 -0000\r\nX-pair-Authenticated: 208.70.27.190\r\nMessage-ID: &lt;4D3F61CC.1010000@...&gt;\r\nDate: Tue, 25 Jan 2011 15:50:36 -0800\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.6; en-US; rv:1.9.2.13) Gecko/20101207 Thunderbird/3.1.7\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: Pranay Pandey &lt;sspranay@...&gt;\r\nReferences: &lt;694795.18571.qm@...&gt;\r\nIn-Reply-To: &lt;694795.18571.qm@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] link-discovery/extraction\r\nX-Yahoo-Group-Post: member; u=137285340; y=9gBo2dAn6GziVHHrHwOybDnagWeLiB1XUzp9D6PUi6vi\r\nX-Yahoo-Profile: gojomo\r\n\r\nI don&#39;t know how this could happen; unless you&#39;ve taken specific extra \nsteps to reuse/reload state from previous crawls, they shouldn&#39;t affect \nfuture launches. (This is even the case given that in the H3 model, jobs \ncan be relaunched in the exact same place, using the same path for the \n&#39;state&#39; directory.)\n\nIf I understand your description correctly, a job was relaunched in \nplace a number of times, during the same launch of the JVM/Heritrix. For \na number of runs, each run behaved as expected. Then, another relaunch \n(or more) started behaving differently.\n\nI would study the logs for any unexplained errors, especially any logged \n&#39;alerts&#39; and the heritrix_out.log.\n\nAre you attempting to reuse any state from previous runs, for example \nvia the optional duplication-reduction processors, or by feeding \nnon-seed URIs to a crawl? Have there been any crawl-configuration \nchanges during the series of runs?\n\nDo you have frontier-recover logs from both a &#39;good&#39; and &#39;bad&#39; run for \ncomparison? (As a detailed log of frontier operations, it may help \npinpoint the URLs whose treatment is different, or if other \nerrors/retries are the real culprit.)\n\nI would not expect any other configuration changes on the machine (such \nas an Apache install/update) to have any relationship to the problem.\n\n- Gordon @ IA\n\nOn 1/25/11 8:12 AM, Pranay Pandey wrote:\n&gt; I noticed that the crawler (H-3.0.0) after staying up for few days and\n&gt; running fine on many jobs, stops to discover links on new jobs all of a\n&gt; sudden, one day.\n&gt; This is very rare though.\n&gt; My crawler was up for last 1 month, did a good job on a dozens of crawl\n&gt; jobs. But since last week it had been failing to discover and extract\n&gt; links &#39;L&#39; even on the previously nicely done jobs. Killed it and\n&gt; restarted, everything back to normal.\n&gt;\n&gt; Any possible explanation?\n&gt; Our system guys did some apache installation on the same machine couple\n&gt; of days back. Will that affect the already running crawler in anyway?\n&gt;\n&gt; Thanks!\n&gt; Pranay\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; \n\n"}}