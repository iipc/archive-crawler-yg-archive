{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"r7AEPnT5-9Pv0aVhGek6dkBL3iyKH7rUtUbKV8CFy0cnA9S2RAcDUvfM77l37tI8DQWm1mpBRgxFlHslnK7nd9Rb9rO8BFo","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] Auto Stopping Problem","postDate":"1290892044","msgId":6831,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRDRjE3MzBDLjQwMTA5MDJAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PEFBTkxrVGluRTNmcnBLNStvcz1pNGZhekM9MXRLVGZEaEN2a1pRU3hoLXpEMEBtYWlsLmdtYWlsLmNvbT4=","referencesHeader":"PGljNTRhZStucDVsQGVHcm91cHMuY29tPgk8NENFQUJGMjkuNDA0MDhAYXJjaGl2ZS5vcmc+CTxBQU5Ma1RpPURaWlhjZ2FLUGRHTW1DVWg0bVFvM25FMWgyNTAxYk9pVmNjVUNAbWFpbC5nbWFpbC5jb20+CTw0Q0VDNjVGMS4xMDUwMDAxQGFyY2hpdmUub3JnPgk8QUFOTGtUaWsxQnZueWVRQz1yc3YyTitndXBqYTBXOU4wZ2tCY184eGlGYkNyQG1haWwuZ21haWwuY29tPgk8NENFRDkzMTguNzAxMDcwOUBhcmNoaXZlLm9yZz4gPEFBTkxrVGluRTNmcnBLNStvcz1pNGZhekM9MXRLVGZEaEN2a1pRU3hoLXpEMEBtYWlsLmdtYWlsLmNvbT4="},"prevInTopic":6825,"nextInTopic":6833,"prevInTime":6830,"nextInTime":6832,"topicId":6809,"numMessagesInTopic":10,"msgSnippet":"I don t think there s anything left to troubleshoot. As I mentioned, all current versions of Heritrix assume they will be able to do DNS lookups of all crawled","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 94611 invoked from network); 27 Nov 2010 21:07:26 -0000\r\nX-Received: from unknown (98.137.34.46)\n  by m4.grp.sp2.yahoo.com with QMQP; 27 Nov 2010 21:07:26 -0000\r\nX-Received: from unknown (HELO relay01.pair.com) (209.68.5.15)\n  by mta3.grp.sp2.yahoo.com with SMTP; 27 Nov 2010 21:07:26 -0000\r\nX-Received: (qmail 18485 invoked by uid 0); 27 Nov 2010 21:07:24 -0000\r\nX-Received: from 70.112.224.182 (HELO silverbook.local) (70.112.224.182)\n  by relay01.pair.com with SMTP; 27 Nov 2010 21:07:24 -0000\r\nX-pair-Authenticated: 70.112.224.182\r\nMessage-ID: &lt;4CF1730C.4010902@...&gt;\r\nDate: Sat, 27 Nov 2010 13:07:24 -0800\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.6; en-US; rv:1.9.2.12) Gecko/20101027 Thunderbird/3.1.6\r\nMIME-Version: 1.0\r\nTo: Allen Sim &lt;allensim81@...&gt;\r\nCc: archive-crawler@yahoogroups.com\r\nReferences: &lt;ic54ae+np5l@...&gt;\t&lt;4CEABF29.40408@...&gt;\t&lt;AANLkTi=DZZXcgaKPdGMmCUh4mQo3nE1h2501bOiVccUC@...&gt;\t&lt;4CEC65F1.1050001@...&gt;\t&lt;AANLkTik1BvnyeQC=rsv2N+gupja0W9N0gkBc_8xiFbCr@...&gt;\t&lt;4CED9318.7010709@...&gt; &lt;AANLkTinE3frpK5+os=i4fazC=1tKTfDhCvkZQSxh-zD0@...&gt;\r\nIn-Reply-To: &lt;AANLkTinE3frpK5+os=i4fazC=1tKTfDhCvkZQSxh-zD0@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Auto Stopping Problem\r\nX-Yahoo-Group-Post: member; u=137285340; y=7yXyfQ9zRA4ivl7pNQImy681rNYl5szbBbVcceBEjgg5\r\nX-Yahoo-Profile: gojomo\r\n\r\nI don&#39;t think there&#39;s anything left to troubleshoot. As I mentioned, all \ncurrent versions of Heritrix assume they will be able to do DNS lookups \nof all crawled hosts from the crawling machine. (It would require \nchanging the Heritrix code to remove this assumption.)\n\nIt seems like your machine only allows DNS lookups of LAN websites. So \nthe trouble is fully diagnosed, and the easiest fix is to enable that \nmachine to do DNS lookups. No amount of proxy/authentication adjustments \nwill help.\n\n- Gordon @ IA\n\nOn 11/26/10 1:17 AM, Allen Sim wrote:\n&gt; Dear Gordon,\n&gt; I have checked through my proxy setting.. and i understand that Heritrix\n&gt; not support authenticated proxy access, so my proxy setting now allow\n&gt; unauthenticated the access, this is because I can browse any websites in\n&gt; this Web curator machine without key in any username and password and no\n&gt; authentication box is popping up! But the strange and weird thing is\n&gt; that when I use WCT to harvest the websites, only the LAN websites are\n&gt; successfully harvested, the external websites still have auto stopping\n&gt; problem . I have done the proxy setting in the WCT profile setting and\n&gt; as well at the script there. But the auto stopping still persist. I\n&gt; wonder what happen..\n&gt; Any idea to trobleshoot?\n&gt;\n&gt; Appreciate your guidance and help!\n&gt;\n&gt; Thanks in advance & looking forward to hear from you,\n&gt; Allen Wilson\n&gt;\n&gt;\n&gt;\n&gt; On Thu, Nov 25, 2010 at 6:35 AM, Gordon Mohr &lt;gojomo@...\n&gt; &lt;mailto:gojomo@...&gt;&gt; wrote:\n&gt;\n&gt;     Heritrix does not use wget.\n&gt;\n&gt;     You might be able to fix wget to use the same proxy as your\n&gt;     graphical brwoser, but as I mentioned, Heritrix expects to be able\n&gt;     to do DNS lookups itself. The machine&#39;s ability to do DNS lookups\n&gt;     will need to be remedied in order for Heritrix to work there.\n&gt;\n&gt;     - Gordon @ IA\n&gt;\n&gt;\n&gt;     On 11/24/10 1:30 AM, Allen Sim wrote:\n&gt;\n&gt;         Hi Gordon,\n&gt;         Glad to hear from you once again!\n&gt;         I got few queries here:\n&gt;         1. Is Heritrix and WCT using the wget?\n&gt;         2. Can I define my proxy server at /etc/wgetrc?\n&gt;         Please advice and looking forward to hear from you once again.\n&gt;         Thanks for you guidance and help. Really appreciate it!.\n&gt;         Regards,\n&gt;         Allen Wilson\n&gt;         On Wed, Nov 24, 2010 at 9:10 AM, Gordon Mohr &lt;gojomo@...\n&gt;         &lt;mailto:gojomo@...&gt;\n&gt;         &lt;mailto:gojomo@... &lt;mailto:gojomo@...&gt;&gt;&gt; wrote:\n&gt;\n&gt;             My guess is that your browser is set up to use an HTTP\n&gt;         proxy, and\n&gt;             that proxy is doing everything (including name lookups) for\n&gt;         the browser.\n&gt;\n&gt;             But, the machine itself can&#39;t do domain lookups. (Or\n&gt;         perhaps: can\n&gt;             only do a small number of internal/approved domain lookups.)\n&gt;         This\n&gt;             will need to be resolved in the machine&#39;s configuration for\n&gt;         Heritrix\n&gt;             to work.\n&gt;\n&gt;             Heritrix can direct HTTP requests through a configured proxy\n&gt;         -- but\n&gt;             expects to be able to do DNS lookups itself. It would take a\n&gt;         code\n&gt;             change to enable skipping DNS lookups when an HTTP proxy is\n&gt;         to be\n&gt;             used, and it would mean there would be no record of the\n&gt;         actual IP\n&gt;             address contacted (which would be a problem for our usual\n&gt;             archival-record use, though would make sense in other\n&gt;         applications).\n&gt;\n&gt;             - Gordon @ IA\n&gt;\n&gt;\n&gt;             On 11/23/10 1:08 AM, Allen Sim wrote:\n&gt;\n&gt;\n&gt;\n&gt;                 Dear Gordon,\n&gt;                 I am so glad to hear from you!\n&gt;                 Wow, Indeed you are very Sharp and you understood my\n&gt;         problem!\n&gt;                 I tried to type the following in my terminal and i got the\n&gt;                 following:\n&gt;                 [root@localhost ~]# wget http://www.swinburne.edu.my\n&gt;         &lt;http://www.swinburne.edu.my/&gt;\n&gt;                 --2010-11-23 17:04:43-- http://www.swinburne.edu.my/\n&gt;                 Resolving www.swinburne.edu.my... failed: Temporary\n&gt;         failure in name\n&gt;                 resolution.\n&gt;                 wget: unable to resolve host address\n&gt;         `www.swinburne.edu.my &lt;http://www.swinburne.edu.my&gt;\n&gt;         &lt;http://www.swinburne.edu.my/&gt;\n&gt;         &lt;http://www.swinburne.edu.my &lt;http://www.swinburne.edu.my/&gt;&gt;&#39;\n&gt;\n&gt;\n&gt;                 But the strange thing is that i can browse successfully\n&gt;         www.swinburne.edu.my &lt;http://www.swinburne.edu.my&gt;\n&gt;         &lt;http://www.swinburne.edu.my/&gt;\n&gt;         &lt;http://www.swinburne.edu.my &lt;http://www.swinburne.edu.my/&gt;&gt; at\n&gt;\n&gt;                 the machine&#39;s\n&gt;\n&gt;                 graphical browser.\n&gt;                 What&#39;s wrong with it? Is it because of my proxy setting\n&gt;         or my\n&gt;                 DNS setting.\n&gt;                 Please advice and looking forward to hear from you.\n&gt;                 Thanks for your guidance and advice,\n&gt;                 Allen WIlson\n&gt;\n&gt;                 On Tue, Nov 23, 2010 at 3:06 AM, Gordon Mohr\n&gt;         &lt;gojomo@... &lt;mailto:gojomo@...&gt;\n&gt;         &lt;mailto:gojomo@... &lt;mailto:gojomo@...&gt;&gt;\n&gt;         &lt;mailto:gojomo@... &lt;mailto:gojomo@...&gt;\n&gt;         &lt;mailto:gojomo@... &lt;mailto:gojomo@...&gt;&gt;&gt;&gt; wrote:\n&gt;\n&gt;                     The fact that the first error is a DNS failure, and that\n&gt;                 prevents\n&gt;                     further progress, suggests that the ability of the\n&gt;         crawler\n&gt;                 machine\n&gt;                     to do DNS lookups -- both from a command-line, and\n&gt;         from Java\n&gt;                 -- is\n&gt;                     the first thing to look at.\n&gt;\n&gt;                     On the crawling machine itself, can you visit\n&gt;         &lt;http://www.swinburne.edu.my/&gt; (from a command-line browser or tool\n&gt;                     like &#39;wget&#39;/&#39;curl&#39; if the machine doesn&#39;t have a\n&gt;         graphical\n&gt;                 browser)?\n&gt;\n&gt;                     There *might* be a little more detail on the DNS\n&gt;         error in the\n&gt;         &#39;local-errors.log&#39; in the crawl&#39;s logs directory as well.\n&gt;\n&gt;                     - Gordon @ IA\n&gt;\n&gt;\n&gt;                     On 11/18/10 10:09 PM, ssgtitanic wrote:\n&gt;\n&gt;                         Hi,\n&gt;                         Hi,\n&gt;                         I successfully downloaded and deployed WCT 1.5 and\n&gt;                 indeed it&#39;s a\n&gt;                         wonderful tool for harvesting!\n&gt;                         This morning I tried to harvest few websites.\n&gt;         The first two\n&gt;                         websites that I harvested were okay. As I\n&gt;         proceed to my\n&gt;                 third\n&gt;                         website, The Target Instances itself only run\n&gt;         for few\n&gt;                 seconds\n&gt;                         (00:00:18) then it automatically &#39;Stopping&#39; then\n&gt;         after few\n&gt;                         seconds it turned to &#39;harvested&#39; with 0 bytes data\n&gt;                 downloaded.I\n&gt;                         restart my server and Apache-tomcat, the problem\n&gt;         still\n&gt;                 persist.\n&gt;\n&gt;                           Following is the crwal.log logfile:\n&gt;                         2010-11-18T04:14:11.482Z    -1          -\n&gt;                         dns:www.swinburne.edu.my\n&gt;         &lt;http://www.swinburne.edu.my&gt; &lt;http://www.swinburne.edu.my/&gt;\n&gt;         &lt;http://www.swinburne.edu.my &lt;http://www.swinburne.edu.my/&gt;&gt; P\n&gt;\n&gt;\n&gt;         http://www.swinburne.edu.my/ text/dns #001\n&gt;                         20101118041409425+2055 - - 3t\n&gt;                         2010-11-18T04:14:11.786Z    -6          -\n&gt;         http://www.swinburne.edu.my/ - - no-type #002 - - - 2t\n&gt;                         Displaying: 100% of 239 B\n&gt;                         crawl report.txt:\n&gt;                         Crawl Name:\n&gt;                         Crawl Status: Finished\n&gt;                         Duration Time: 20s617ms\n&gt;                         Total Seeds Crawled: 0\n&gt;                         Total Seeds not Crawled: 1\n&gt;                         Total Hosts Crawled: -1\n&gt;                         Total Documents Crawled: 2\n&gt;                         Processed docs/sec: 0\n&gt;                         Bandwidth in Kbytes/sec: 0\n&gt;                         Total Raw Data Size in Bytes: 0 (0 B)\n&gt;                         Novel Bytes: 0 (0 B)\n&gt;                         Displaying: 100% of 271 B\n&gt;                         Frontier report.txt\n&gt;                         frontier empty\n&gt;                         Displaying: 100% of 15 B\n&gt;\n&gt;                         Can you please guide me. what&#39;s wrong with it?\n&gt;         Is it my\n&gt;                 setting?\n&gt;                         As I am refeering to Heritrix status code, I\n&gt;         found the\n&gt;                 following:\n&gt;                           -1 DNS lookup failed\n&gt;                           -6 Prerequisite domain-lookup failed,\n&gt;         precluding fetch\n&gt;                 attempt\n&gt;\n&gt;                         How am I going to fix it? Please help and advice.\n&gt;\n&gt;                         Looking forward to hear from you.\n&gt;\n&gt;                         Thanks in advance,\n&gt;                         Allen Wilson\n&gt;\n&gt;\n&gt;\n&gt;                         ------------------------------------\n&gt;\n&gt;                         Yahoo! Groups Links\n&gt;\n&gt;\n&gt;         &lt;mailto:archive-crawler-digest@yahoogroups.com\n&gt;         &lt;mailto:archive-crawler-digest@yahoogroups.com&gt;&gt;\n&gt;         &lt;mailto:archive-crawler-digest@yahoogroups.com\n&gt;         &lt;mailto:archive-crawler-digest@yahoogroups.com&gt;\n&gt;         &lt;mailto:archive-crawler-digest@yahoogroups.com\n&gt;         &lt;mailto:archive-crawler-digest@yahoogroups.com&gt;&gt;&gt;\n&gt;\n&gt;         archive-crawler-fullfeatured@yahoogroups.com\n&gt;         &lt;mailto:archive-crawler-fullfeatured@yahoogroups.com&gt;\n&gt;         &lt;mailto:archive-crawler-fullfeatured@yahoogroups.com\n&gt;         &lt;mailto:archive-crawler-fullfeatured@yahoogroups.com&gt;&gt;\n&gt;         &lt;mailto:archive-crawler-fullfeatured@yahoogroups.com\n&gt;         &lt;mailto:archive-crawler-fullfeatured@yahoogroups.com&gt;\n&gt;         &lt;mailto:archive-crawler-fullfeatured@yahoogroups.com\n&gt;         &lt;mailto:archive-crawler-fullfeatured@yahoogroups.com&gt;&gt;&gt;\n&gt;\n&gt;\n&gt;         &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com\n&gt;         &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com&gt;&gt;\n&gt;         &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com\n&gt;         &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com&gt;\n&gt;         &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com\n&gt;         &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com&gt;&gt;&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;                 \n&gt;\n&gt;\n&gt;\n\n"}}