{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"&quot;Gordon Mohr&quot; &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"pAhxvR22g5TlJ8H76cZDliFqYRukdhgOH2Q0mKoFSSdmU6JbNJ1-uPWyWf05gaKY1vorcw9oqs4vsYdyomYm8gptSPBZydqBJg","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Moving to long-lived, disk-based crawl state: &quot;Splinters&quot;","postDate":"1060887258","msgId":146,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDAwMWIwMWMzNjI5NSQ5YzBjNTk1MCQ0OGYwZWRkMUBXT1JLU1RBVElPTjIxPg=="},"prevInTopic":0,"nextInTopic":0,"prevInTime":145,"nextInTime":147,"topicId":146,"numMessagesInTopic":1,"msgSnippet":"A first rough proposal for moving the crawler to disk-based crawl-state to allow indefinite runs, in fixed RAM, as long as sufficient disk space is available: ","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 84928 invoked from network); 14 Aug 2003 18:55:28 -0000\r\nReceived: from unknown (66.218.66.218)\n  by m17.grp.scd.yahoo.com with QMQP; 14 Aug 2003 18:55:28 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (209.237.232.202)\n  by mta3.grp.scd.yahoo.com with SMTP; 14 Aug 2003 18:55:28 -0000\r\nReceived: (qmail 32275 invoked by uid 100); 14 Aug 2003 18:52:32 -0000\r\nReceived: from b116-dyn-72.archive.org (HELO WORKSTATION21) (gojomo@...@209.237.240.72)\n  by ia00524.archive.org with SMTP; 14 Aug 2003 18:52:32 -0000\r\nMessage-ID: &lt;001b01c36295$9c0c5950$48f0edd1@WORKSTATION21&gt;\r\nTo: &lt;archive-crawler@yahoogroups.com&gt;\r\nSubject: Moving to long-lived, disk-based crawl state: &quot;Splinters&quot;\r\nDate: Thu, 14 Aug 2003 11:54:18 -0700\r\nMIME-Version: 1.0\r\nContent-Type: text/plain;\n\tcharset=&quot;Windows-1252&quot;\r\nContent-Transfer-Encoding: 7bit\r\nX-Priority: 3\r\nX-MSMail-Priority: Normal\r\nX-Mailer: Microsoft Outlook Express 6.00.2800.1158\r\nX-MimeOLE: Produced By Microsoft MimeOLE V6.00.2800.1165\r\nX-Spam-Status: No, hits=0.0 required=6.0\n\ttests=none\n\tversion=2.55\r\nX-Spam-Level: \r\nX-Spam-Checker-Version: SpamAssassin 2.55 (1.174.2.19-2003-05-19-exp)\r\nFrom: &quot;Gordon Mohr&quot; &lt;gojomo@...&gt;\r\nX-Yahoo-Group-Post: member; u=137285340\r\nX-Yahoo-Profile: gojomo\r\n\r\nA first rough proposal for moving the crawler to disk-based crawl-state to\nallow indefinite runs, in fixed RAM, as long as sufficient disk space\nis available: \n\nEssentially, we need a paging mechanism for moving convenient\nand predictable work-units to and from disk as necessary. \n\nBut what is the right paging unit?\n\nI believe it is a partition of the entire URI-space about which all \nrelevant knowledge (visited URIs, discovered URIs, scheduled URIs, \nrankings, running statistics and appropriate policies, etc.) can be \nloaded in into working memory. Let&#39;s call this page unit in our\ncrawling context a &quot;splinter&quot;.\n\nA splinter would have a maximum memory size, such that with an allocated\nRAM footprint, a running crawler instance knows it can always have\n(at least) N splinters in memory. Ideally, N would be at least as\nbig as the number of worker ToeThreads.\n\nA splinter can be completely persisted to disk when necessary. When\nURIs are discovered which belong to an out-of-memory splinter, they\nare simply logged to a disk-based queue of work for that Splinter to \ndo next time it is loaded. (So, this log may often include multiple\nduplicates, even of URIs already visited. The &quot;URI-seen&quot; tests are \nall deferred until that Splinter is again under consideration;\nrandom-access of disk-based structures is avoided.)\n\nInitially, a 1-to-1 mapping of splinters to hostnames would be\nin effect. When a splinter grows too large, it would split. (Until\nthere are only a handful of sites left to crawl, it should never\nbe necessary to have 2 splinters devoted to the same host in \nmemory at once: politeness would usually disallow it, and in the\npotential cases where we&#39;d want to be grabbing multiple pages in\nparallel [eg BBC, CNN], a single splinter can still provide all the\nURIs to fetch.)\n\nWhile primarily, the records stored in splinters would include a\nfull URI and a collection of fields about its crawl-state (within\na fixed maximum size), when a URI is truly &quot;finished&quot; within the \nparameters of the crawl, it might be stripped down to a mere \nfingerprint and finished-flag, as it only exists to prevent revisits \nto the same place. \n\nVaried strategies for when to swap out an in-memory splinter and choose\na new disk-based splinter to work on are possible. Clearly, when a\nsplinter is nearing scheduled-URI exhaustion, or appears to be in\nan uninteresting boundless tail, that would be a cue to switch. More\nlikely, some set of thresholds would try to keep the top or average\n&quot;value&quot; of all splinters in rough alignment. Or, in the case of \nsite-first crawls, keep the top or average values of all splinters\ndedicated to the same host in rough alignment. \n\nIn the case of very broad crawls, as the crawl goes on for long time, \nmost URIs discovered will have already been visited. Most splinters\nwill be filled with more finished URIs than scheduled URIs -- and\nideally the compressed representation of finished URIs would still\nallow many scheduled URIs to be processed per splinter-swap. \n\nMapped to the current design, the URIStore would become a collection\nof active Splinters, plus the necessary indexes to find/choose new \nSplinters from disk when necessary. The caches of information about\nServers (host:port pairs) and Hosts (hosts) could become adjuncts to\ntheir associated splinters. \n\nPriority offsite fetches might be handled through a special, always\nin memory splinter -- with the actual splinter to which they are \nassigned being advised through the batching log approach. However,\neven redundant fetches of such resources may wind up being a small,\ntolerable cost, especially if there is a post-collection duplication-\nremoval process. \n\nThis approach should also checkpoint and distribute over multiple\nmachines well. \n\nQuestions? Comments? \n\n- Gordon\n\n"}}