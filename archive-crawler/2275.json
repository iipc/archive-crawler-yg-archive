{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"stack@archive.org","from":"&quot;stack@...&quot; &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"De1cWdYUbodZmxhxKP5aO4FuTd5GFgOvGxTGSbZo0vTgdiaTIdj5jk3KpIASv4G5_oWLqgno2L2GfUoai_RSKvooLoDofBhzx0T8XX6j","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] hi,the seed is not being crawled after dns/.txt file-please help","postDate":"1130163902","msgId":2275,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQzNUNFRUJFLjEwNzA3QGFyY2hpdmUub3JnPg==","inReplyToHeader":"PGRqYXB1YytjZW9qQGVHcm91cHMuY29tPg==","referencesHeader":"PGRqYXB1YytjZW9qQGVHcm91cHMuY29tPg=="},"prevInTopic":2266,"nextInTopic":0,"prevInTime":2274,"nextInTime":2276,"topicId":2266,"numMessagesInTopic":2,"msgSnippet":"... Don t apologize.  There is no inconvenience caused. Rather, pardon me. I missed this mail in my mailbox.  Now I see you have read the FAQ. Please ignore my","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 68289 invoked from network); 25 Oct 2005 04:26:03 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m27.grp.scd.yahoo.com with QMQP; 25 Oct 2005 04:26:03 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (207.241.224.171)\n  by mta6.grp.scd.yahoo.com with SMTP; 25 Oct 2005 04:26:03 -0000\r\nReceived: (qmail 15102 invoked by uid 100); 25 Oct 2005 04:22:59 -0000\r\nReceived: from adsl-216-103-208-88.dsl.snfc21.pacbell.net (HELO ?192.168.1.105?) (stack@...@216.103.208.88)\n  by mail-dev.archive.org with SMTP; 25 Oct 2005 04:22:59 -0000\r\nMessage-ID: &lt;435CEEBE.10707@...&gt;\r\nDate: Mon, 24 Oct 2005 07:25:02 -0700\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.7.5) Gecko/20050105 Debian/1.7.5-1\r\nX-Accept-Language: en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;djapuc+ceoj@...&gt;\r\nIn-Reply-To: &lt;djapuc+ceoj@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=-99.6 required=7.0 tests=DATE_IN_PAST_12_24,\n\tUSER_IN_WHITELIST autolearn=no version=2.63\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: &quot;stack@...&quot; &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] hi,the seed is not being crawled after dns/.txt\n file-please help\r\nX-Yahoo-Group-Post: member; u=168599281; y=ErgX7WvqlnWzTgXd33vpStkcHqH4YKUzwHwRvGscw5NUNvPw4v9YasUo\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\nswamikrish2001 wrote:\n\n&gt; Hi,\n&gt; I am extremely sorry for the inconvenience caused.\n\nDon&#39;t apologize.  There is no inconvenience caused. Rather, pardon me.  \nI missed this mail in my mailbox.  Now I see you have read the FAQ.  \nPlease ignore my mail from earlier today referring you back to the FAQ.\n\n From your mail, it looks like you have a few problems.  I try to \naddress the inline below.\n\n\n&gt; I read the windows faq and I am still not able run the crawler and\n&gt; download the documents (trying for the past 2 days)and I would really\n&gt; appreciate  help on this regard.\n&gt; When I set up the job with the user agent and url,even for open sites\n&gt; such wikepedia or slshdot the crwler downloads a single dns/txt file\n&gt; and stops crawling.\n\n&gt; I dont know where I had gone wrong:\n&gt;\n&gt; 1)i am using internet explorer,is there any specific settings for\n&gt; this ?,if so where should I change ?\n\nAre you asking if its ok to configure Heritrix using Internet Explorer?  \nIf so, the answer is yes.\n\n&gt;\n&gt; 2)The computer I am using goes through a proxy,i have set the proxy\n&gt; setting in Heritrix settings,but still not able crawl and download.\n\n&gt;\n&gt; 3)When going to an external site my connection in the internal network\n&gt; asks for a url and password,for the first time when opening the\n&gt; browser.Will this be the problem?but when I see the log files,i get the\n&gt; message the crawler has visited the page and from the page only got the\n&gt; txt file.So where else would be the problem?or have I got the whole\n&gt; concept wrong!\n\nCan you try from some location that does not require proxying Heritrix \njust to see if the proxy is your problem?\n\nIf you have to supply a login/password using your browser, then the \nproxy is likely an issue.  There is no mechanism in Heritrix for \nsupplying a proxy login/password.\n\n&gt;\n&gt; 4)For an earlier mail on this regard I was asked to check the faq\n&gt; file,but I had configured the batch file properly and my batch file is\n&gt; as follows:\n&gt; set HERITRIX_HOME=D:/heritrix\n\nYes.  Your batch file looks right.\n\n&gt;\n&gt; set CLASSPATH=%HERITRIX_HOME%/heritrix-1.4.0.jar;%\n&gt; HERITRIX_HOME%/lib/ant-1.6.2.jar;%HERITRIX_HOME%/lib/commons-cli-\n&gt; 1.0.jar;%HERITRIX_HOME%/lib/commons-codec-1.3.jar;%\n&gt; HERITRIX_HOME%/lib/commons-collections-3.1.jar;%\n&gt; HERITRIX_HOME%/lib/commons-httpclient-3.0-beta1.jar;%\n&gt; HERITRIX_HOME%/lib/commons-logging-1.0.4.jar;%\n&gt; HERITRIX_HOME%/lib/commons-net-1.1.0.jar;%HERITRIX_HOME%/lib/commons-\n&gt; pool-1.2.jar;%HERITRIX_HOME%/lib/concurrent-1.3.2.jar;%\n&gt; HERITRIX_HOME%/lib/dnsjava-1.6.2.jar;%HERITRIX_HOME%/lib/dsi-unimi-it-\n&gt; 0.9.1.jar;%HERITRIX_HOME%/lib/itext-1.2.0.jar;%\n&gt; HERITRIX_HOME%/lib/jasper-compiler-tomcat-4.1.30.jar;%\n&gt; HERITRIX_HOME%/lib/jasper-runtime-tomcat-4.1.30.jar;%\n&gt; HERITRIX_HOME%/lib/javaswf-CVS-SNAPSHOT-1.jar;%HERITRIX_HOME%/lib/je-\n&gt; 1.7.1-12115_11552-2.jar;%HERITRIX_HOME%/lib/jetty-4.2.23.jar;%\n&gt; HERITRIX_HOME%/lib/jmxri-1.2.1.jar;%HERITRIX_HOME%/lib/jmxtools-\n&gt; 1.2.1.jar;%HERITRIX_HOME%/lib/junit-3.8.1.jar;%HERITRIX_HOME%/lib/poi-\n&gt; 2.0-RC1-20031102.jar;%HERITRIX_HOME%/lib/poi-scratchpad-2.0-RC1-\n&gt; 20031102.jar;%HERITRIX_HOME%/lib/servlet-tomcat-4.1.30.jar\n&gt;\n&gt;\n&gt; java -Dheritrix.home=D:/heritrix -Djava.ext.dirs=D:/heritrix/lib -\n&gt; Xmx256m org.archive.crawler.Heritrix\n&gt;\n&gt;\n&gt;\n&gt; have made any mistake in the batch file configuration?\n\nAs long as all jars from lib are listed, it should be fine (Though its \nbeen reported that the resultant CLASSPATH is too long for windows).\n\n&gt;\n&gt; 5)When I run the batch file I get some warnings,are these the reasons\n&gt; behing the crawler not working?\n&gt; the messages on cmd.exe are as follows:\n&gt;\n&gt; 3:04:08.561 EVENT  Starting Jetty/4.2.23\n&gt; 3:04:08.952 WARN!! Delete existing temp dir C:&#92;DOCUME~1&#92;127924&#92;LOCALS~1\n&gt; &#92;Temp&#92;\n&gt; ty__8080__ for WebApplicationContext\n&gt; [/,jar:file:/D:/heritrix/webapps/admin.wa\n&gt; ]\n\nThis is fine.  Its just a message from the embedded jetty container \nsaying its deleting the unjarred heritrix admin made by a previous run \nof Heritrix.\n\n&gt; 3:04:09.296 EVENT  Started WebApplicationContext[/,Heritrix Console]\n&gt; 3:04:09.967 EVENT  Started SocketListener on 0.0.0.0:8080\n&gt; 3:04:09.967 EVENT  Started org.mortbay.jetty.Server@de6f34\n&gt; 0/21/2005 13:04:11 +0000 WARNING\n&gt; org.archive.crawler.settings.CrawlSettingsSA\n&gt; ndler$SimpleElementHandler endElement Unknown attribute &#39;10.237.3.28&#39;\n&gt; in &#39;fil\n&gt; D:/heritrix/conf/profiles/krish/order.xml&#39;, line: 129, column: 45\n&gt; 0/21/2005 13:04:11 +0000 WARNING\n&gt; org.archive.crawler.settings.CrawlSettingsSA\n&gt; ndler$SimpleElementHandler endElement Unknown attribute &#39;6050&#39;\n&gt; in &#39;file:/D:/h\n&gt; trix/conf/profiles/krish/order.xml&#39;, line: 130, column: 38\n&gt; 0/21/2005 13:04:12 +0000 WARNING\n\nLooks like you have incorrectly configured the crawler.  Look at the \ncontents of your order file on lines 129 and 130.\n\n&gt; org.archive.crawler.settings.CrawlSettingsSA\n&gt; ndler handleValueError This field must contain a valid URL leading to\n&gt; the web\n&gt; e of the person or organization responsible for this crawl.\n&gt; Attribute: &#39;http-headers:user-agent&#39;\n&gt; Value:     &#39;Mozilla/5.0 (compatible; heritrix/@VERSION@\n&gt; +www.wikepedia.org)&#39;\n&gt; File:      &#39;file:/D:/heritrix/jobs/default1-\n&gt; 20051020121523526/order.xml&#39;, lin\n&gt; 58, column: 105\n&gt; eritrix version: 1.4.0\n&gt;\n&gt; Is there anything I have to do with this?\n\nThe above is definetly a problem.  You must set the user-agent \nproperly.  Read the help text thats available under the &#39;?&#39; beside \nuser-agent in the settings screen.\n\nAre you not seeing alerts complaining that you have not set the \n&#39;user-agent&#39; properly? (Looks like you should have \n&#39;http://www.wikipedia.org&#39; rather than just www.wikipedia.org).\n\nBy the way, are you of the wikipedia organization, crawling on its \nbehalf?  If not, how do you have license to pose as wikipedia \norganization crawling?  The user-agent should describe your organization \n-- not the organization you are trying to crawl.  Please see the user \nmanual -- http://crawler.archive.org/articles/user_manual.html#settings \n-- sections 6.3.1.3.1 and 6.3.1.3.2.\n\n&gt;\n&gt;\n&gt; 5)I tried running heritrix for navigating html files created by me.\n&gt; The link of the file was  http://localhost:8080/first.html\n&gt;\nIs this page on same host as heritrix is running on?  Heritrix by \ndefault comes up on port 8080 (There is not page named &#39;first.html&#39; in \nheritrix -- hence the 404s below). \n\nI&#39;d suggest that you get heritrix crawling your localhost first, just so \nyou can see it in operation.  Can you put up a webserver on port 80 and \nhave Heritrix crawl &#39;http://localhost/&#39;?\n\n&gt; The crawl job came as finished but nothing downloaded!!\n&gt;\n&gt; The crawl log is as follows:\n&gt;\n&gt; 2005-10-21T05:28:38.706Z     1         46 dns:localhost P\n&gt; http://localhost:8080/first.html text/dns #001 20051021052838691+0 - -\n&gt; 2005-10-21T05:28:41.128Z   404          0\n&gt; http://localhost:8080/robots.txt P http://localhost:8080/first.html\n&gt; text/html #031 20051021052841113+0 3I42H3S6NNFQ2MSVX7XZKYAYSCX5QBYJ -\n&gt; 2005-10-21T05:28:43.144Z   404          0\n&gt; http://localhost:8080/first.html - - text/html #031 20051021052843128+0\n&gt; 3I42H3S6NNFQ2MSVX7XZKYAYSCX5QBYJ\n&gt;\n&gt; How did the robots.txt come in my page??\n\nWhen Heritrix goes about crawling a new site for the first time, it \nfetches prerequisites.  Currently these are the dns record for the new \nsite and the robots.txt, the file that contains the rules for robots \naccess.  It is not always present but -- unless explicitly configured \nnot to -- Heritrix will always attempt to fetch it (Above there is no \nrobots.txt so we got a 404).\n\n&gt;\n&gt;\n&gt; 6)Is there any other setting I have to set or enable to make the\n&gt; application work?\n\nChoose defaults, set an (open) seed, set (properly) the &#39;from&#39; and \n&#39;user-agent&#39; and that should be sufficent to get a basic crawl going.\n\nGood luck,\nSt.Ack\n\n&gt;\n&gt;\n&gt; Is the problem with regard to windows or browser or network and\n&gt; connection?\n&gt;\n&gt;\n&gt; Please help me on resolving the problem.\n&gt; -Krishna\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; SPONSORED LINKS\n&gt; Computer internet security \n&gt; &lt;http://groups.yahoo.com/gads?t=ms&k=Computer+internet+security&w1=Computer+internet+security&w2=Computer+internet+business&w3=Computer+internet+access&w4=Computer+internet+privacy+securities&w5=Computer+internet+help&w6=Computer+internet+connection&c=6&s=198&.sig=V04yaONvhRiZX9V-9vaMcA&gt; \n&gt; \tComputer internet business \n&gt; &lt;http://groups.yahoo.com/gads?t=ms&k=Computer+internet+business&w1=Computer+internet+security&w2=Computer+internet+business&w3=Computer+internet+access&w4=Computer+internet+privacy+securities&w5=Computer+internet+help&w6=Computer+internet+connection&c=6&s=198&.sig=QEM5QXY5E4yokvfp8I9OxA&gt; \n&gt; \tComputer internet access \n&gt; &lt;http://groups.yahoo.com/gads?t=ms&k=Computer+internet+access&w1=Computer+internet+security&w2=Computer+internet+business&w3=Computer+internet+access&w4=Computer+internet+privacy+securities&w5=Computer+internet+help&w6=Computer+internet+connection&c=6&s=198&.sig=GvFjo1UJpzPMTQeQeWH-9Q&gt; \n&gt;\n&gt; Computer internet privacy securities \n&gt; &lt;http://groups.yahoo.com/gads?t=ms&k=Computer+internet+privacy+securities&w1=Computer+internet+security&w2=Computer+internet+business&w3=Computer+internet+access&w4=Computer+internet+privacy+securities&w5=Computer+internet+help&w6=Computer+internet+connection&c=6&s=198&.sig=2cAxh4C_HeZYnGK5pWGQjg&gt; \n&gt; \tComputer internet help \n&gt; &lt;http://groups.yahoo.com/gads?t=ms&k=Computer+internet+help&w1=Computer+internet+security&w2=Computer+internet+business&w3=Computer+internet+access&w4=Computer+internet+privacy+securities&w5=Computer+internet+help&w6=Computer+internet+connection&c=6&s=198&.sig=XyuTAshDdmCMqHSTUW6r1Q&gt; \n&gt; \tComputer internet connection \n&gt; &lt;http://groups.yahoo.com/gads?t=ms&k=Computer+internet+connection&w1=Computer+internet+security&w2=Computer+internet+business&w3=Computer+internet+access&w4=Computer+internet+privacy+securities&w5=Computer+internet+help&w6=Computer+internet+connection&c=6&s=198&.sig=PWZ1Hrcj8Yl7bPjnNBOESg&gt; \n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------------------------------------------\n&gt; YAHOO! GROUPS LINKS\n&gt;\n&gt;     *  Visit your group &quot;archive-crawler\n&gt;       &lt;http://groups.yahoo.com/group/archive-crawler&gt;&quot; on the web.\n&gt;        \n&gt;     *  To unsubscribe from this group, send an email to:\n&gt;        archive-crawler-unsubscribe@yahoogroups.com\n&gt;       &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;        \n&gt;     *  Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;.\n&gt;\n&gt;\n&gt; ------------------------------------------------------------------------\n&gt;\n\n\n"}}