{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":251489418,"authorName":"goblin_cz","from":"&quot;goblin_cz&quot; &lt;adam.brokes@...&gt;","profile":"goblin_cz","replyTo":"LIST","senderId":"6SvC_dAMdrqBhzgJJWs8abJzF8zgpwQ41Xr2B8ulb1kIC49_VmhohiaWm0cC-g0NUZ4NUEthUp_ctF-kuQ0MRnexicibOBLTg5qv","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Logging Out Of Scope","postDate":"1190814814","msgId":4566,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZkZG84dSttdmM2QGVHcm91cHMuY29tPg==","inReplyToHeader":"PDQ2RkE0MjYzLjEwNDA5MDFAYXJjaGl2ZS5vcmc+"},"prevInTopic":4565,"nextInTopic":4576,"prevInTime":4565,"nextInTime":4567,"topicId":4564,"numMessagesInTopic":4,"msgSnippet":"Thanks a lot. It helps very much ;] Now I m logging into separate file and I ve set some filter (I m experimenting with index.html/htm/php/asp) But still I","rawEmail":"Return-Path: &lt;adam.brokes@...&gt;\r\nX-Sender: adam.brokes@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 43510 invoked from network); 26 Sep 2007 13:53:48 -0000\r\nReceived: from unknown (66.218.66.72)\n  by m50.grp.scd.yahoo.com with QMQP; 26 Sep 2007 13:53:48 -0000\r\nReceived: from unknown (HELO n19b.bullet.sp1.yahoo.com) (69.147.64.131)\n  by mta14.grp.scd.yahoo.com with SMTP; 26 Sep 2007 13:53:48 -0000\r\nReceived: from [216.252.122.218] by n19.bullet.sp1.yahoo.com with NNFMP; 26 Sep 2007 13:53:35 -0000\r\nReceived: from [66.218.69.5] by t3.bullet.sp1.yahoo.com with NNFMP; 26 Sep 2007 13:53:35 -0000\r\nReceived: from [66.218.66.91] by t5.bullet.scd.yahoo.com with NNFMP; 26 Sep 2007 13:53:35 -0000\r\nDate: Wed, 26 Sep 2007 13:53:34 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;fddo8u+mvc6@...&gt;\r\nIn-Reply-To: &lt;46FA4263.1040901@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;goblin_cz&quot; &lt;adam.brokes@...&gt;\r\nSubject: Re: Logging Out Of Scope\r\nX-Yahoo-Group-Post: member; u=251489418; y=9l5DA9KL-wZj-3SAzrzd420m4U2yUu0yEPCnG4-yG7Wtg0mC\r\nX-Yahoo-Profile: goblin_cz\r\n\r\nThanks a lot. It helps very much ;]\n\nNow I&#39;m logging into separate file and=\r\n I&#39;ve set some filter (I&#39;m\nexperimenting with index.html/htm/php/asp)\n\nBut =\r\nstill I can&#39;t set separate logging features as limit and count.\nI tried:\n\no=\r\nrg.archive.crawler.postprocessor.LinksScoper.level =3D INFO\norg.archive.cra=\r\nwler.postprocessor.LinksScoper.pattern =3D %g%u.log\norg.archive.crawler.pos=\r\ntprocessor.LinksScoper.limit =3D 50\norg.archive.crawler.postprocessor.Links=\r\nScoper.count =3D 100\n\nThanks a lot.\n\nAdam\n\n\n--- In archive-crawler@yahoogro=\r\nups.com, Igor Ranitovic &lt;igor@...&gt; wrote:\n&gt;\n&gt; Hi Adam,\n&gt; \n&gt; You can just un=\r\ncomment \n&gt; org.archive.crawler.postprocessor.LinksScoper.level =3D INFO\n&gt; i=\r\nn the heritrix.properties, and set LinksScoper&#39;s override-logger to \n&gt; true=\r\n to isolate LinksScoper logging. All out-of-scope links will be \n&gt; logged t=\r\no the org.archive.crawler.postprocessor.LinksScoper.log file \n&gt; within the =\r\n*logs* directory.  Be sure that all other logging \n&gt; characteristics in the=\r\n heritrix.properties are set to your needs.\n&gt; \n&gt; Keep in mind that this lis=\r\nt will probably grow very large with a lot of \n&gt; duplicate entires. If you =\r\nwant to reduce the logging output see \n&gt; scope-rejected-url-rules within Li=\r\nnksScoper. For example, you can add \n&gt; regex decide rule like ^.*&#92;.jpg$  an=\r\nd only URLs that that are \n&gt; out-of-scope and end with .jpg will be logged.=\r\n\n&gt; \n&gt; I hope this helps.\n&gt; \n&gt; Take care,\n&gt; i.\n&gt; \n&gt; \n&gt; \n&gt; goblin_cz wrote:\n&gt;=\r\n &gt; Hallo, I&#39;ve got a question..\n&gt; &gt; \n&gt; &gt; How to log every link that haven&#39;t=\r\n been downloaded in a crawl? The\n&gt; &gt; reason why is important too.\n&gt; &gt; I&#39;m d=\r\nownload only sites that ends with .cz, but we are developing a\n&gt; &gt; decide r=\r\nule, that can make a decision whether the page is useful for\n&gt; &gt; czech arch=\r\nive (based on some country settings, language recognition\n&gt; &gt; and so on). S=\r\no the plan is: make a crawl of whole czech domains (380k\n&gt; &gt; 2.level domain=\r\ns) and catch every link that is out of scope and than\n&gt; &gt; make crawl with t=\r\nhe czech decide rule with catched links as seeds.\n&gt; &gt; Another reasons loggi=\r\nng is useful too (deduplicator, quota enforcer,\n&gt; &gt; regexp,...)\n&gt; &gt; \n&gt; &gt; An=\r\nd is possible to override logger settings for LinkScoper? (count,\n&gt; &gt; file =\r\nlocation,..)\n&gt; &gt; \n&gt; &gt; Thanks a lot for answers,\n&gt; &gt; \n&gt; &gt; Adam\n&gt; &gt; \n&gt; &gt; \n&gt; &gt;=\r\n \n&gt; &gt;  \n&gt; &gt; Yahoo! Groups Links\n&gt; &gt; \n&gt; &gt; \n&gt; &gt;\n&gt;\n\n\n\n"}}