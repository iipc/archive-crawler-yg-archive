{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":145406984,"authorName":"Alex","from":"&quot;Alex&quot; &lt;a.beggs.ml@...&gt;","profile":"SUNYAl","replyTo":"LIST","senderId":"WSxc4OT-8U988YKc75aldDyF4XMZvfhoq7B-x74Qe-GXJMiHfg6WvM-mUKdjETYXBX774jTMG0uXuJDwWAaa-Jcv","spamInfo":{"isSpam":false,"reason":"12"},"subject":"RE: [archive-crawler] Recovering a Job","postDate":"1134491527","msgId":2422,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDAwMTYwMWM2MDAwMiRjNTUzNjdiMCQ3OTAxMTkwYUB4c2JpbnRlcm5hbC5jb20+","inReplyToHeader":"PDQzOUU0NTM5LjcwOTA5MDVAYXJjaGl2ZS5vcmc+"},"prevInTopic":2417,"nextInTopic":2423,"prevInTime":2421,"nextInTime":2423,"topicId":2368,"numMessagesInTopic":19,"msgSnippet":"Hi Stack, So are you suggesting using the CrawlController instead of a CrawlJobHandler in general?  I understand how it feels a little weird with the state","rawEmail":"Return-Path: &lt;a.beggs.ml@...&gt;\r\nX-Sender: a.beggs.ml@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 43121 invoked from network); 13 Dec 2005 16:26:23 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m25.grp.scd.yahoo.com with QMQP; 13 Dec 2005 16:26:23 -0000\r\nReceived: from unknown (HELO mx1.portjeff.net) (216.168.142.133)\n  by mta5.grp.scd.yahoo.com with SMTP; 13 Dec 2005 16:26:23 -0000\r\nReceived: from localhost (localhost [127.0.0.1])\n\tby mx1.portjeff.net (Postfix) with ESMTP id 46449719E8\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Tue, 13 Dec 2005 11:28:12 -0500 (EST)\r\nReceived: from mx1.portjeff.net ([127.0.0.1])\n by localhost (mx1.portjeff.net [127.0.0.1]) (amavisd-new, port 10024)\n with ESMTP id 10730-15 for &lt;archive-crawler@yahoogroups.com&gt;;\n Tue, 13 Dec 2005 11:28:09 -0500 (EST)\r\nReceived: from xsb.com (mail.portjeff.net [216.168.142.132])\n\tby mx1.portjeff.net (Postfix) with ESMTP id A5967718F9\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Tue, 13 Dec 2005 11:28:09 -0500 (EST)\r\nReceived: from xsbabeggs340 [129.49.16.170] by xsb.com with ESMTP\n  (SMTPD32-7.15) id A56684F0080; Tue, 13 Dec 2005 11:23:02 -0500\r\nTo: &lt;archive-crawler@yahoogroups.com&gt;\r\nDate: Tue, 13 Dec 2005 11:32:07 -0500\r\nMessage-ID: &lt;001601c60002$c55367b0$7901190a@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: text/plain;\n\tcharset=&quot;US-ASCII&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Priority: 3 (Normal)\r\nX-MSMail-Priority: Normal\r\nX-Mailer: Microsoft Outlook, Build 10.0.6626\r\nIn-Reply-To: &lt;439E4539.7090905@...&gt;\r\nX-MimeOLE: Produced By Microsoft MimeOLE V6.00.2900.2180\r\nImportance: Normal\r\nX-Virus-Scanned: amavisd-new at portjeff.net\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: &quot;Alex&quot; &lt;a.beggs.ml@...&gt;\r\nSubject: RE: [archive-crawler] Recovering a Job\r\nX-Yahoo-Group-Post: member; u=145406984; y=_KAO6qA6uYJfxTnnEwrEtMwpeDhUhYIZlSc2hGjXf4By\r\nX-Yahoo-Profile: SUNYAl\r\n\r\nHi Stack,\n\nSo are you suggesting using the CrawlController instead of a Cra=\r\nwlJobHandler\nin general?  I understand how it feels a little weird with the=\r\n state being\nmodified with the event queue.  If you could give me a little =\r\nbit more\ninsight on what you are suggesting.\n\nI agree with the logging, qui=\r\nck and dirty, added recently, locally.\n\nThanks,\nAlex\n\n&gt; On your classes:\n&gt; =\r\n\n&gt; Looks like you&#39;ve added to the crawlPaused method in your \n&gt; CrawlJobHan=\r\ndler override a check to see if a request to \n&gt; checkpoint has \n&gt; been set =\r\nand if so, you run checkpointing. Checkpointing runs, \n&gt; crawlCheckpoint is=\r\n called in your CJH override and you set \n&gt; &#39;shouldResume&#39; to true so that =\r\nwhen crawlPaused is called again after \n&gt; checkpointing has completed, you&#39;=\r\nre override invokes resume \n&gt; (I like your \n&gt; use of java.util.Timer).\n&gt; \n&gt;=\r\n One suggestion I&#39;d make is that changing/managing crawler \n&gt; state should =\r\n\n&gt; be done by the CrawlController rather than out of the state change \n&gt; me=\r\nthods in CJH (CrawlController is overrideable. See \n&gt; CrawlJob#setupForCraw=\r\nlStart where we override CC so we can remove \n&gt; registered MBeans).\n\n\n&gt; Wou=\r\nld also suggest using a java.util logger in place of calls to \n&gt; System.out=\r\n.err.\n&gt; \n&gt; Calling Heritrix#main is working fine for you?  Any reason you d=\r\non&#39;t \n&gt; want to do &#39;new Heritrix()&#39; only?  Did you try it?\n\n\n\n"}}