{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":334689939,"authorName":"Micah Wedemeyer","from":"Micah Wedemeyer &lt;mwedeme@...&gt;","replyTo":"LIST","senderId":"7HVD_rmqfT9Q0pIC8xQ-VetXEEK204rHMZen5WFeh3Q8P_iDBm-dJh7HEzYxI2pOCgTCH33tmFgv2I-HwlOUVQ6MRnsJpZ65610","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Running multiple concurrent CrawlJobs","postDate":"1200589851","msgId":4904,"canDelete":false,"contentTrasformed":false,"systemMessage":true,"headers":{"messageIdInHeader":"PDQ3OEY4QzFCLjMwMjA3MDJAZW1vcnkuZWR1Pg=="},"prevInTopic":0,"nextInTopic":0,"prevInTime":4903,"nextInTime":4905,"topicId":4904,"numMessagesInTopic":1,"msgSnippet":"Hi, I ve got heritrix embedded in another app, and I m currently using the CrawlJobHandler and CrawlJob classes to minimize the amount of setup I have to do. ","rawEmail":"Return-Path: &lt;mwedeme@...&gt;\r\nReceived: (qmail 75346 invoked from network); 17 Jan 2008 17:46:00 -0000\r\nReceived: from unknown (66.218.67.95)\n  by m53.grp.scd.yahoo.com with QMQP; 17 Jan 2008 17:46:00 -0000\r\nReceived: from unknown (HELO n25c.bullet.scd.yahoo.com) (66.218.67.216)\n  by mta16.grp.scd.yahoo.com with SMTP; 17 Jan 2008 17:46:00 -0000\r\nReceived: from [209.73.164.86] by n25.bullet.scd.yahoo.com with NNFMP; 17 Jan 2008 17:45:59 -0000\r\nReceived: from [66.218.66.81] by t8.bullet.scd.yahoo.com with NNFMP; 17 Jan 2008 17:45:59 -0000\r\nX-Sender: mwedeme@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 8173 invoked from network); 17 Jan 2008 17:10:55 -0000\r\nX-Received: from unknown (66.218.67.97)\n  by m45.grp.scd.yahoo.com with QMQP; 17 Jan 2008 17:10:55 -0000\r\nX-Received: from unknown (HELO mr3.cc.emory.edu) (170.140.52.92)\n  by mta18.grp.scd.yahoo.com with SMTP; 17 Jan 2008 17:10:55 -0000\r\nX-Received: from [170.140.210.152] (emoryfloatdmz.cc.emory.edu [170.140.52.254])\n\tby mr3.cc.emory.edu (8.13.1/8.13.1) with ESMTP id m0HHAp5F028951\n\t(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NO)\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Thu, 17 Jan 2008 12:10:51 -0500\r\nMessage-ID: &lt;478F8C1B.3020702@...&gt;\r\nDate: Thu, 17 Jan 2008 12:10:51 -0500\r\nUser-Agent: Icedove 1.5.0.14pre (X11/20071018)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nX-Enigmail-Version: 0.94.2.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Transfer-Encoding: 7bit\r\nX-emory.edu-MailScanner: Found to be clean\r\nX-emory.edu-MailScanner-From: mwedeme@...\r\nX-Spam-Status: No\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Micah Wedemeyer &lt;mwedeme@...&gt;\r\nSubject: Running multiple concurrent CrawlJobs\r\nX-Yahoo-Group-Post: member; u=334689939\r\nX-Yahoo-Newman-Property: groups-system\r\nX-eGroups-Approved-By: gojomo &lt;gojomo@...&gt; via web; 17 Jan 2008 17:45:59 -0000\r\n\r\nHi,\n\nI&#39;ve got heritrix embedded in another app, and I&#39;m currently using the\nCrawlJobHandler and CrawlJob classes to minimize the amount of setup I\nhave to do.\n\nHowever, I would like to run multiple crawls concurrently.  I don&#39;t need\na huge cluster, but I would like to be able to crawl several different\nseeds at once in different jobs.\n\nThere are a few possibilities that I&#39;ve come up with, and I&#39;d like the\nopinion of the more experienced heritrix community:\n\n1) Mutliple CrawlJobs\nIn my favorite case, I can just run multiple CrawlJobs simultaneously\nusing a CrawlJobHandler.  However, from the CrawlJobHandler javadocs,\nthis seems impossible (since there&#39;s only a single running job at one\ntime).  Am I missing something?\n\n2) Multiple CrawlJobHandlers\nI just recently thought of doing this, and it seems like it should be\nnearly as good as the first case.  I create multiple CrawlJobHandlers,\none for each job, and run them concurrently.  Is there anything that\nwould prevent this from working?\n\n3) Modify CrawlJob settings at run-time\nAssuming I can only run a single CrawlJob at any time, can I change its\nsettings at run-time?  In my particular case, someone can add a new seed\n(using my UI) and specify the maximum number of hops for that particular\nseed.  Then, I need to update the currently running CrawlJob to add the\nnew seed, and specify the new max hops _for only that seed and any links\nfound from it_\n\n4) Scrapping CrawlJobHandler and CrawlJob altogether\nI could probably puzzle my way through setting up a CrawlController,\nFrontier, Scoper, etc, and binding all the various pieces together like\nCrawlJob already does.  However, this would probably be fairly intensive\nand I don&#39;t want to go this route unless absolutely necessary.\n\nFor now, option 2 (multiple CrawlJobHandlers) seems like the best idea,\nbut I&#39;d still like to hear what thoughts people have.\n\nNote: I&#39;m using heritrix 1.12.1\n\nThanks,\nMicah Wedemeyer\nmwedeme@...\n\n"}}