{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":289645082,"authorName":"helloitsmaxine","from":"&quot;helloitsmaxine&quot; &lt;itsmaxine@...&gt;","profile":"helloitsmaxine","replyTo":"LIST","senderId":"sURXJnb4rmehwUyNU8CDvNfl-Wn_E1c4qwS1fs8NG5NkgDXrLf45zkB9Np0jO85cUjZMt-kAKeWmcjaMox3dllZUlnGqgVXd25GhSNU","spamInfo":{"isSpam":false,"reason":"6"},"subject":"settings to maximize number of unique domains crawled?","postDate":"1310594586","msgId":7206,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGl2bDRtcSsxc2NjQGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":7207,"prevInTime":7205,"nextInTime":7207,"topicId":7206,"numMessagesInTopic":5,"msgSnippet":"I m doing a crawl and interested in maximum the number of unique domains crawled, ie. I d rather crawl one page from each of 5 unique domains than have 10","rawEmail":"Return-Path: &lt;itsmaxine@...&gt;\r\nX-Sender: itsmaxine@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 61269 invoked from network); 13 Jul 2011 22:03:09 -0000\r\nX-Received: from unknown (98.137.34.45)\n  by m4.grp.sp2.yahoo.com with QMQP; 13 Jul 2011 22:03:09 -0000\r\nX-Received: from unknown (HELO ng15-ip2.bullet.mail.bf1.yahoo.com) (98.139.165.128)\n  by mta2.grp.sp2.yahoo.com with SMTP; 13 Jul 2011 22:03:09 -0000\r\nX-Received: from [98.139.164.124] by ng15.bullet.mail.bf1.yahoo.com with NNFMP; 13 Jul 2011 22:03:08 -0000\r\nX-Received: from [69.147.65.172] by tg5.bullet.mail.bf1.yahoo.com with NNFMP; 13 Jul 2011 22:03:08 -0000\r\nX-Received: from [98.137.34.119] by t14.bullet.mail.sp1.yahoo.com with NNFMP; 13 Jul 2011 22:03:08 -0000\r\nDate: Wed, 13 Jul 2011 22:03:06 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;ivl4mq+1scc@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;helloitsmaxine&quot; &lt;itsmaxine@...&gt;\r\nSubject: settings to maximize number of unique domains crawled?\r\nX-Yahoo-Group-Post: member; u=289645082; y=Ug1HbMFSFtXnMyVa-LIybcgQKXyg5REj0pEAfxhMX8A1FBgLEDm76gSkQD0iFoJbsc0pM_dzlx-OjpI\r\nX-Yahoo-Profile: helloitsmaxine\r\n\r\nI&#39;m doing a crawl and interested in maximum the number of unique domains cr=\r\nawled, ie. I&#39;d rather crawl one page from each of 5 unique domains than hav=\r\ne 10 pages from one domain. Right now it&#39;s weird because I have pretty stan=\r\ndard/default settings, ie. BroadScope and high max hops and such, but out o=\r\nf ~50gb I&#39;ve crawled, less than 1000 unique domains have been produced. I&#39;m=\r\n counting by counting the number of folders in the mirror folder (each of w=\r\nhich seems to represent the content from one unique domain), as I&#39;m using t=\r\nhe MirrorWriter. \n\nMy question is if anyone knows what the problem could be=\r\n and how to fix it? I was wondering if there were possible a maximum bytes =\r\nper domain limit to set (I know there&#39;s an overall max bytes but that would=\r\nn&#39;t seem to help) or some other settings that could help me get more domain=\r\ns per amount of space crawled?\n\nThanks for any help!\n\n\n"}}