{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"stack","from":"stack &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"5kNZC4ty6TmTcQH5EUX4hFRBSoIAlCMEnCn-fBRjLjE4Ppmpn7fZME9vXOBXk0gaBsTj92iZjiRJEh-x8VFIlQ","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] BdbUniqFilter vs BloomUniqFilter","postDate":"1136406624","msgId":2500,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQzQkMzMDYwLjUwNjAxMDRAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGRwZjVkNyt2c2gxQGVHcm91cHMuY29tPg==","referencesHeader":"PGRwZjVkNyt2c2gxQGVHcm91cHMuY29tPg=="},"prevInTopic":2490,"nextInTopic":2531,"prevInTime":2499,"nextInTime":2501,"topicId":2490,"numMessagesInTopic":4,"msgSnippet":"... Why? OOME?  Can you give crawler bigger heap?  Bloom filter by default uses ~500Megs [See note here: ","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 39560 invoked from network); 4 Jan 2006 20:35:37 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m32.grp.scd.yahoo.com with QMQP; 4 Jan 2006 20:35:37 -0000\r\nReceived: from unknown (HELO dns.duboce.net) (63.203.238.114)\n  by mta2.grp.scd.yahoo.com with SMTP; 4 Jan 2006 20:35:37 -0000\r\nReceived: from [192.168.1.105] ([192.168.1.105])\n\t(authenticated)\n\tby dns-eth1.duboce.net (8.10.2/8.10.2) with ESMTP id k04JO5N08265\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Wed, 4 Jan 2006 11:24:07 -0800\r\nMessage-ID: &lt;43BC3060.5060104@...&gt;\r\nDate: Wed, 04 Jan 2006 12:30:24 -0800\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; PPC Mac OS X Mach-O; en-US; rv:1.8) Gecko/20051218 SeaMonkey/1.0b\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;dpf5d7+vsh1@...&gt;\r\nIn-Reply-To: &lt;dpf5d7+vsh1@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 2:12:4:0\r\nFrom: stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] BdbUniqFilter vs BloomUniqFilter\r\nX-Yahoo-Group-Post: member; u=168599281; y=Hima69QJCAhN-e9Zug1e2Ud15nNdMbEf3LD4GrKLVn89FlPxzpMzMXhR\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\njoehung302 wrote:\n&gt; What is the difference?\n&gt;\n&gt; I have a proof crawler setup at 1500MB heap. It can never run Bloom\n&gt; filter for more than 1 day (maybe half a day). \nWhy? OOME?  Can you give crawler bigger heap?  Bloom filter by default \nuses ~500Megs [See note here: \nhttp://crawler.archive.org/xref/org/archive/crawler/util/BloomUriUniqFilter.html#56.  \nIts also possible to adjust BloomFilter size: See line 68 in the \nConstructor].  I believe we use heaps closer to 2Gigs running with \nBloomFilter already-seen.\n\n&gt; I&#39;ve tried several\n&gt; configurations and none of them runs for more a day.\n&gt;\n&gt; I then changed it to use BdbUniqFilter and now it&#39;s been running for\n&gt; 5+ days with 13M+ links downloaded and still going strong. The\n&gt; crawler is configured with CrawlMapping (in preparation for multi-\n&gt; machine crawl) setup with HostQueuePolicy.\n&gt;\n&gt; I know I&#39;m supposed to use Bloom filter for bigger crawls but can\n&gt; anyone explain to me that I should give bloom filter another try\n&gt; rather than stick with BdbUniqFilter? Assuming that my goal is to\n&gt; prove the 1500MB heap configuration can download more 30M links?\nLookups into a BdbUniqFilter, not surprisingly, start to slow \ndramatically as size of already-seen list grows above 20 or 30 million.  \nDownloading 30Million URLs, you might have an already-seen list of \nupwards of 3 or 4 times that, dependent on character of your crawl.\n\nBut perhaps the BdbUniqFilter is adequate to your purposes (Once you had \n30million urls queued, you might put in place a filter that prevented \nany new URLs being added to the Frontier/already-seen).\n&gt;\n&gt; I&#39;m running 1.5.0_05 32bit JVM on 1.6.0 heritrix.\nYou might also add details on the OS and hardware you&#39;re using Joe: What \nlinux, kernel, etc.  (Perhaps you did already?).  Could help giving you \nsupport.\n\nYours,\nSt.Ack\n&gt;\n&gt; cheers,\n&gt;\n&gt; -joe\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------------------------------------------\n&gt; YAHOO! GROUPS LINKS\n&gt;\n&gt;     *  Visit your group &quot;archive-crawler\n&gt;       &lt;http://groups.yahoo.com/group/archive-crawler&gt;&quot; on the web.\n&gt;        \n&gt;     *  To unsubscribe from this group, send an email to:\n&gt;        archive-crawler-unsubscribe@yahoogroups.com\n&gt;       &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;        \n&gt;     *  Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;.\n&gt;\n&gt;\n&gt; ------------------------------------------------------------------------\n&gt;\n\n\n"}}