{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":165458231,"authorName":"Bjarne Andersen","from":"Bjarne Andersen &lt;bja@...&gt;","profile":"bjarne_dk2000","replyTo":"LIST","senderId":"SDI6pi7WygNNuUFOFw5hW7sjWhMwij7cZNNHCE2ugELgChJBu3xZwr_VtOT9pdONc36El51t6J4mfGy71Jtidg3Uq4nG6khMfuaM2_nEcow","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Few questions","postDate":"1156142273","msgId":3197,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ0RTk1NEMxLjYwMzAyMDJAc3RhdHNiaWJsaW90ZWtldC5kaz4=","inReplyToHeader":"PGVjNHFjMCt0dnJ2QGVHcm91cHMuY29tPg==","referencesHeader":"PGVjNHFjMCt0dnJ2QGVHcm91cHMuY29tPg=="},"prevInTopic":3193,"nextInTopic":3199,"prevInTime":3196,"nextInTime":3198,"topicId":3193,"numMessagesInTopic":9,"msgSnippet":"The server max-successfull-fetches is for (as the setting-name says) only successfull fetches - that means that your crawl.log could have a lot of","rawEmail":"Return-Path: &lt;bja@...&gt;\r\nX-Sender: bja@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 26481 invoked from network); 21 Aug 2006 06:38:47 -0000\r\nReceived: from unknown (66.218.67.35)\n  by m21.grp.scd.yahoo.com with QMQP; 21 Aug 2006 06:38:47 -0000\r\nReceived: from unknown (HELO luna.statsbiblioteket.dk) (130.225.24.87)\n  by mta9.grp.scd.yahoo.com with SMTP; 21 Aug 2006 06:38:47 -0000\r\nReceived: from [172.18.251.249] (pc975.sb.statsbiblioteket.dk [172.18.251.249])\n by luna.statsbiblioteket.dk\n (iPlanet Messaging Server 5.2 HotFix 1.16 (built May 14 2003))\n with SMTP id &lt;0J4C00GWZ536K1@...&gt; for\n archive-crawler@yahoogroups.com; Mon, 21 Aug 2006 08:37:54 +0200 (MEST)\r\nDate: Mon, 21 Aug 2006 08:37:53 +0200\r\nIn-reply-to: &lt;ec4qc0+tvrv@...&gt;\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-id: &lt;44E954C1.6030202@...&gt;\r\nOrganization: Statsbiblioteket\r\nMIME-version: 1.0\r\nContent-type: multipart/mixed; boundary=&quot;Boundary_(ID_4iUVLOuQgjyDoRVif5lK8g)&quot;\r\nX-Accept-Language: en-us, en\r\nUser-Agent: Mozilla Thunderbird 1.0 (X11/20041206)\r\nReferences: &lt;ec4qc0+tvrv@...&gt;\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: Bjarne Andersen &lt;bja@...&gt;\r\nSubject: Re: [archive-crawler] Few questions\r\nX-Yahoo-Group-Post: member; u=165458231; y=shLOUfwY5Xrv7ATC2sATT5xPXy5jhDiYpC09_aBLWFM97mCzhXJypw\r\nX-Yahoo-Profile: bjarne_dk2000\r\n\r\n\r\n--Boundary_(ID_4iUVLOuQgjyDoRVif5lK8g)\r\nContent-type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-transfer-encoding: 8BIT\r\n\r\nThe &quot;server max-successfull-fetches&quot; is for (as the setting-name says) only successfull fetches - that means that your crawl.log could have \na lot of non-successfull fetches from the same servers. You might want to try &quot;server-max-fetch-responses&quot; which should stop just above \n5000. You should be aware that there could be several servers on on domain - each of those will be crawled until the quota is exceeded.\n\nAs far as I know all refuses should be logged in crawl.log - havn&#39;t tried the max-lenght-bytes though - but eg. the QuotaEnforcer logs with \nstatuscode -5003 and a comment (last field in the crawl.log lines) about which quota was exceeded.\n\nbest\nBjarne Andersen\n\ngoblin_cz wrote:\n&gt; \n&gt; \n&gt; Hallo,\n&gt; \n&gt; I have few questions.\n&gt; \n&gt; 1) When I have run crawl with QuotaEnforcer set on limit 5000 to\n&gt; server max-succesfull- fetches it downloaded more then 5600 from one\n&gt; dns record (domain). How this happened?\n&gt; \n&gt; 2) If I set max-length-bytes to 100MB, can I find in logs these\n&gt; refused files?\n&gt; \n&gt; 3) Another similiar question. Is it posible to hold in logs EVERY\n&gt; refused URL? (quota enforcer, refused by rules and so on)\n&gt; \n&gt; Thank you for your time and your excelent work!\n&gt; Brokes\n&gt; \n&gt; \n\n-- \nBjarne Andersen\nFunktionsansvarlig - Digitale Ressourcer\n\nSTATSBIBLIOTEKET\nUniversitetsparken\n8000 ï¿½rhus C\nTlf. 89462165 - Mobil 25662353\nCVR/SE 10100682 - EAN 5798000791084\nhttp://statsbiblioteket.dk\n\r\n--Boundary_(ID_4iUVLOuQgjyDoRVif5lK8g)\r\nContent-type: text/x-vcard; charset=utf-8; name=bja.vcf\r\nContent-disposition: attachment; filename=bja.vcf\r\n\r\n[ Attachment content not displayed ]\r\n--Boundary_(ID_4iUVLOuQgjyDoRVif5lK8g)--\r\n\n"}}