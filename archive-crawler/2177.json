{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":224113134,"authorName":"Dennis Hotson","from":"Dennis Hotson &lt;dwh@...&gt;","replyTo":"LIST","senderId":"lElaKrw257ljm9REmlFIu_OBFzOzaSazKW3WwIhI1C4JFldGlt8awmi6xjDfRtTPGjbtwkZv7j6lMZaovcKq_cITQOaxc-WM7Xo","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Incremental Crawling","postDate":"1126490871","msgId":2177,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDExMjY0OTA4NzEuNjQ2OS4xNC5jYW1lbEBkd2hwYy5tZHMucm1pdC5lZHUuYXU+"},"prevInTopic":0,"nextInTopic":2181,"prevInTime":2176,"nextInTime":2181,"topicId":2177,"numMessagesInTopic":8,"msgSnippet":"I m just wondering whether anyone has written a filter or module to do incremental crawling. What I mean is something that will do a HEAD request on pages and","rawEmail":"Return-Path: &lt;dwh@...&gt;\r\nX-Sender: dwh@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 91106 invoked from network); 12 Sep 2005 03:11:36 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m35.grp.scd.yahoo.com with QMQP; 12 Sep 2005 03:11:36 -0000\r\nReceived: from unknown (HELO its-mu-mail1.its.rmit.edu.au) (131.170.1.11)\n  by mta1.grp.scd.yahoo.com with SMTP; 12 Sep 2005 03:11:36 -0000\r\nReceived: from pan.mds.rmit.edu.au (pan.mds.rmit.edu.au [131.170.70.15])\n\tby its-mu-mail1.its.rmit.edu.au (8.13.1/8.13.1/mail1) with ESMTP id j8C27pOH024429\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Mon, 12 Sep 2005 12:07:51 +1000 (EST)\r\nReceived: from dwhpc.mds.rmit.edu.au (dwhpc.mds.rmit.edu.au [131.170.70.89])\n\tby pan.mds.rmit.edu.au (Postfix) with ESMTP id D40545016D;\n\tMon, 12 Sep 2005 12:07:46 +1000 (EST)\r\nTo: archive-crawler@yahoogroups.com\r\nContent-Type: text/plain\r\nDate: Mon, 12 Sep 2005 12:07:51 +1000\r\nMessage-Id: &lt;1126490871.6469.14.camel@...&gt;\r\nMime-Version: 1.0\r\nX-Mailer: Evolution 2.0.2 (2.0.2-3) \r\nContent-Transfer-Encoding: 7bit\r\nX-Scanned-By: MIMEDefang 2.44\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: Dennis Hotson &lt;dwh@...&gt;\r\nSubject: Incremental Crawling\r\nX-Yahoo-Group-Post: member; u=224113134\r\n\r\nI&#39;m just wondering whether anyone has written a filter or module to do\nincremental crawling.\nWhat I mean is something that will do a HEAD request on pages and then\nonly fetch the actual content if the page has been updated (newer last-\nmodified date or similar). This technique saves a lot of bandwidth and\ncan speed up crawling for sites that aren&#39;t updated very often.\n\nI&#39;ve written a proof of concept filter class that does this (well\nactually, it&#39;s not quite working yet). \n\nIf somebody else has already solved this problem it would save me a lot\nof effort. Thanks! :D\n\nCheers,\nDennis\n\n\n\n"}}