{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr (archive.org)","from":"&quot;Gordon Mohr (archive.org)&quot; &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"4A6Qpdp1kqPMM70vbTVu04PGQAayJakJOorhgnzYivrogUIMouOE2rac6db5Wqw_VnsBZgOv0UkvWbm3d50faxTeDsrcoUv8AUkt5TfTScMuSqld-IeF","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] QuotaEnforcer","postDate":"1136505860","msgId":2507,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQzQkRCNDA0LjMwOTA3MDZAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDQzQkMyQTA0LjMwMjAxMDdAYXJjaGl2ZS5vcmc+","referencesHeader":"PDYuMi41LjYuMC4yMDA2MDEwNDAzMjAyNy4wMWNhMGM3MEBkaWdpdGhpLmRlPiA8NDNCQzJBMDQuMzAyMDEwN0BhcmNoaXZlLm9yZz4="},"prevInTopic":2499,"nextInTopic":2826,"prevInTime":2506,"nextInTime":2508,"topicId":2492,"numMessagesInTopic":9,"msgSnippet":"... I would add to Stack s examples of things combined in the host count: other HTTP servers on nonstandard ports, such as http://example.com:8080 . All","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 31014 invoked from network); 6 Jan 2006 00:04:25 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m27.grp.scd.yahoo.com with QMQP; 6 Jan 2006 00:04:25 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (207.241.224.171)\n  by mta4.grp.scd.yahoo.com with SMTP; 6 Jan 2006 00:04:25 -0000\r\nReceived: (qmail 25839 invoked by uid 100); 5 Jan 2006 23:59:17 -0000\r\nReceived: from adsl-71-130-102-78.dsl.pltn13.pacbell.net (HELO ?192.168.1.10?) (gojomo@...@71.130.102.78)\n  by mail-dev.archive.org with SMTP; 5 Jan 2006 23:59:17 -0000\r\nMessage-ID: &lt;43BDB404.3090706@...&gt;\r\nDate: Thu, 05 Jan 2006 16:04:20 -0800\r\nUser-Agent: Mozilla Thunderbird 1.0.7-1.1.fc3 (X11/20050929)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;6.2.5.6.0.20060104032027.01ca0c70@...&gt; &lt;43BC2A04.3020107@...&gt;\r\nIn-Reply-To: &lt;43BC2A04.3020107@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=-80.9 required=7.0 tests=AWL,NORMAL_HTTP_TO_IP,\n\tUSER_IN_WHITELIST autolearn=no version=2.63\r\nX-eGroups-Msg-Info: 2:12:4:0\r\nFrom: &quot;Gordon Mohr (archive.org)&quot; &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] QuotaEnforcer\r\nX-Yahoo-Group-Post: member; u=137285340; y=zlKvpt-MzoRridSDVSt1_NKyQOlzGdH9Cs2UwKrmOZHY\r\nX-Yahoo-Profile: gojomo\r\n\r\nstack wrote:\n&gt; Thimo Eichstï¿½dt wrote:\n&gt; \n&gt;&gt;Hello,\n&gt;&gt;\n&gt;&gt;I want to restrict the number of fetched documents per webserver. I\n&gt;&gt;am using the QuotaEnforcer prefetch procesor.\n&gt;&gt;But I am unsure which directive should be configured,\n&gt;&gt;server-max-fetch-successes or host-max-fetch-successes ? Can anyone\n&gt;&gt;explain me the difference between them ?\n&gt; \n&gt; \n&gt; One makes counts on a &#39;CrawlHost&#39; \n&gt; [http://crawler.archive.org/xref/org/archive/crawler/datamodel/CrawlHost.html] \n&gt; basis.  The other on a &#39;CrawlServer&#39; \n&gt; [http://crawler.archive.org/xref/org/archive/crawler/datamodel/CrawlServer.html]  \n&gt; basis.  Coarsely, CrawlHost wraps a &#39;hostname&#39; whereas CrawlServer is a \n&gt; particular service on a CrawlHost.  Examples of CrawlServices on a \n&gt; CrawlHost would be http on port 80, secure http (https) on port 443, etc.\n&gt; \n&gt; If you want to count both http and https accesses against the same \n&gt; server quota, use host-max-fetch-successes.  If you want to count them \n&gt; distinctly, use server-max-fetch-successes.\n\nI would add to Stack&#39;s examples of things combined in the &#39;host&#39; count: other\nHTTP servers on nonstandard ports, such as &quot;http://example.com:8080&quot;.\nAll successful fetches against a single logical hostname -- whatever port,\nprotocol, etc. -- are tallied against the &#39;host-max-fetch-successes&#39; value.\nThe &#39;server&#39; version keeps separate tallies for each host:port combination.\n\nAnd to be clear: these operate on strictly the declared URI hostnames, not\nresolved IP addresses. So if &#39;http://example.com&#39;, &#39;http://example.net&#39;, and\n&#39;http://99.99.99.99&#39; all happen to be the same IP address, they still count\nas three different CrawlHosts. If your &#39;host-max-fetch-successes&#39; is 10,\nyou&#39;ll get up to 10 successful fetches from each.\n\n- Gordon @ IA\n\n"}}