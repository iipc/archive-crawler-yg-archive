{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":132996324,"authorName":"joehung302","from":"&quot;joehung302&quot; &lt;joe.hung@...&gt;","profile":"joehung302","replyTo":"LIST","senderId":"Capi2QImJaRoqNwTBrsi415HyTZhUYU062hE5PhooFV0FrU6M5d8yYbqWriY2dDRObghuQg5p4xI5JK-faclEfvvjyuovPOkNuJxn36z","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Large crawl experience (like, 500M links)","postDate":"1133835444","msgId":2391,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGRuMnNiaytmMmJvQGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":2402,"prevInTime":2390,"nextInTime":2392,"topicId":2391,"numMessagesInTopic":12,"msgSnippet":"Hi, Just wondering if anybody have used heritrix to do large crawling at the scale at around 500M links. I know I probably need to use mutliple instances and","rawEmail":"Return-Path: &lt;joe.hung@...&gt;\r\nX-Sender: joe.hung@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 4131 invoked from network); 6 Dec 2005 02:17:31 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m30.grp.scd.yahoo.com with QMQP; 6 Dec 2005 02:17:31 -0000\r\nReceived: from unknown (HELO n1a.bulk.scd.yahoo.com) (66.94.237.35)\n  by mta4.grp.scd.yahoo.com with SMTP; 6 Dec 2005 02:17:30 -0000\r\nComment: DomainKeys? See http://antispam.yahoo.com/domainkeys\r\nReceived: from [66.218.66.59] by n1.bullet.scd.yahoo.com with NNFMP; 06 Dec 2005 02:17:24 -0000\r\nReceived: from [66.218.66.89] by mailer8.bulk.scd.yahoo.com with NNFMP; 06 Dec 2005 02:17:24 -0000\r\nDate: Tue, 06 Dec 2005 02:17:24 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;dn2sbk+f2bo@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: &quot;joehung302&quot; &lt;joe.hung@...&gt;\r\nSubject: Large crawl experience (like, 500M links)\r\nX-Yahoo-Group-Post: member; u=132996324; y=mMqN-R2TQu2ZhFH30HevEWfbhwQaaiwcBO7ayp_acNOn_YZuMw\r\nX-Yahoo-Profile: joehung302\r\n\r\nHi,\n\nJust wondering if anybody have used heritrix to do large crawling at \n=\r\nthe scale at around 500M links. \n\nI know I probably need to use mutliple in=\r\nstances and split crawl \ntechnique mentioned in this forum. I plan to start=\r\n with URLs from the \ndmoz.org.\n\nAny help is greatly appreciated. \n\ncheers,\n=\r\n-joe\n\n\n\n\n"}}