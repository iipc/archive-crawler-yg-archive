{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"o2Hu2RtQn-yOnMxxXJ-XVSpabV0c4hGdrgGTew7G6yrAfu0hMCixHST6JExyFks24_dscWswEluWPveybxkKwG4wpGiVbNs","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] Auto Stopping Problem","postDate":"1290561009","msgId":6821,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRDRUM2NUYxLjEwNTAwMDFAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PEFBTkxrVGk9RFpaWGNnYUtQZEdNbUNVaDRtUW8zbkUxaDI1MDFiT2lWY2NVQ0BtYWlsLmdtYWlsLmNvbT4=","referencesHeader":"PGljNTRhZStucDVsQGVHcm91cHMuY29tPgk8NENFQUJGMjkuNDA0MDhAYXJjaGl2ZS5vcmc+IDxBQU5Ma1RpPURaWlhjZ2FLUGRHTW1DVWg0bVFvM25FMWgyNTAxYk9pVmNjVUNAbWFpbC5nbWFpbC5jb20+"},"prevInTopic":6820,"nextInTopic":6822,"prevInTime":6820,"nextInTime":6822,"topicId":6809,"numMessagesInTopic":10,"msgSnippet":"My guess is that your browser is set up to use an HTTP proxy, and that proxy is doing everything (including name lookups) for the browser. But, the machine","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 43461 invoked from network); 24 Nov 2010 01:10:14 -0000\r\nX-Received: from unknown (98.137.34.45)\n  by m3.grp.sp2.yahoo.com with QMQP; 24 Nov 2010 01:10:14 -0000\r\nX-Received: from unknown (HELO relay00.pair.com) (209.68.5.9)\n  by mta2.grp.sp2.yahoo.com with SMTP; 24 Nov 2010 01:10:13 -0000\r\nX-Received: (qmail 30564 invoked by uid 0); 24 Nov 2010 01:10:09 -0000\r\nX-Received: from 208.70.27.190 (HELO silverbook.local) (208.70.27.190)\n  by relay00.pair.com with SMTP; 24 Nov 2010 01:10:09 -0000\r\nX-pair-Authenticated: 208.70.27.190\r\nMessage-ID: &lt;4CEC65F1.1050001@...&gt;\r\nDate: Tue, 23 Nov 2010 17:10:09 -0800\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.6; en-US; rv:1.9.2.12) Gecko/20101027 Thunderbird/3.1.6\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: Allen Sim &lt;allensim81@...&gt;\r\nReferences: &lt;ic54ae+np5l@...&gt;\t&lt;4CEABF29.40408@...&gt; &lt;AANLkTi=DZZXcgaKPdGMmCUh4mQo3nE1h2501bOiVccUC@...&gt;\r\nIn-Reply-To: &lt;AANLkTi=DZZXcgaKPdGMmCUh4mQo3nE1h2501bOiVccUC@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Auto Stopping Problem\r\nX-Yahoo-Group-Post: member; u=137285340; y=uALoDznot9ej8baYZ9CItdSLZ0vQzRgU8wvKrzrKF5u4\r\nX-Yahoo-Profile: gojomo\r\n\r\nMy guess is that your browser is set up to use an HTTP proxy, and that \nproxy is doing everything (including name lookups) for the browser.\n\nBut, the machine itself can&#39;t do domain lookups. (Or perhaps: can only \ndo a small number of internal/approved domain lookups.) This will need \nto be resolved in the machine&#39;s configuration for Heritrix to work.\n\nHeritrix can direct HTTP requests through a configured proxy -- but \nexpects to be able to do DNS lookups itself. It would take a code change \nto enable skipping DNS lookups when an HTTP proxy is to be used, and it \nwould mean there would be no record of the actual IP address contacted \n(which would be a problem for our usual archival-record use, though \nwould make sense in other applications).\n\n- Gordon @ IA\n\nOn 11/23/10 1:08 AM, Allen Sim wrote:\n&gt;\n&gt;\n&gt; Dear Gordon,\n&gt; I am so glad to hear from you!\n&gt; Wow, Indeed you are very Sharp and you understood my problem!\n&gt; I tried to type the following in my terminal and i got the following:\n&gt; [root@localhost ~]# wget http://www.swinburne.edu.my\n&gt; --2010-11-23 17:04:43-- http://www.swinburne.edu.my/\n&gt; Resolving www.swinburne.edu.my... failed: Temporary failure in name\n&gt; resolution.\n&gt; wget: unable to resolve host address `www.swinburne.edu.my\n&gt; &lt;http://www.swinburne.edu.my&gt;&#39;\n&gt; But the strange thing is that i can browse successfully\n&gt; www.swinburne.edu.my &lt;http://www.swinburne.edu.my&gt; at the machine&#39;s\n&gt; graphical browser.\n&gt; What&#39;s wrong with it? Is it because of my proxy setting or my DNS setting.\n&gt; Please advice and looking forward to hear from you.\n&gt; Thanks for your guidance and advice,\n&gt; Allen WIlson\n&gt;\n&gt; On Tue, Nov 23, 2010 at 3:06 AM, Gordon Mohr &lt;gojomo@...\n&gt; &lt;mailto:gojomo@...&gt;&gt; wrote:\n&gt;\n&gt;     The fact that the first error is a DNS failure, and that prevents\n&gt;     further progress, suggests that the ability of the crawler machine\n&gt;     to do DNS lookups -- both from a command-line, and from Java -- is\n&gt;     the first thing to look at.\n&gt;\n&gt;     On the crawling machine itself, can you visit\n&gt;     &lt;http://www.swinburne.edu.my/&gt; (from a command-line browser or tool\n&gt;     like &#39;wget&#39;/&#39;curl&#39; if the machine doesn&#39;t have a graphical browser)?\n&gt;\n&gt;     There *might* be a little more detail on the DNS error in the\n&gt;     &#39;local-errors.log&#39; in the crawl&#39;s logs directory as well.\n&gt;\n&gt;     - Gordon @ IA\n&gt;\n&gt;\n&gt;     On 11/18/10 10:09 PM, ssgtitanic wrote:\n&gt;\n&gt;         Hi,\n&gt;         Hi,\n&gt;         I successfully downloaded and deployed WCT 1.5 and indeed it&#39;s a\n&gt;         wonderful tool for harvesting!\n&gt;         This morning I tried to harvest few websites. The first two\n&gt;         websites that I harvested were okay. As I proceed to my third\n&gt;         website, The Target Instances itself only run for few seconds\n&gt;         (00:00:18) then it automatically &#39;Stopping&#39; then after few\n&gt;         seconds it turned to &#39;harvested&#39; with 0 bytes data downloaded.I\n&gt;         restart my server and Apache-tomcat, the problem still persist.\n&gt;\n&gt;           Following is the crwal.log logfile:\n&gt;         2010-11-18T04:14:11.482Z    -1          -\n&gt;         dns:www.swinburne.edu.my &lt;http://www.swinburne.edu.my&gt; P\n&gt;         http://www.swinburne.edu.my/ text/dns #001\n&gt;         20101118041409425+2055 - - 3t\n&gt;         2010-11-18T04:14:11.786Z    -6          -\n&gt;         http://www.swinburne.edu.my/ - - no-type #002 - - - 2t\n&gt;         Displaying: 100% of 239 B\n&gt;         crawl report.txt:\n&gt;         Crawl Name:\n&gt;         Crawl Status: Finished\n&gt;         Duration Time: 20s617ms\n&gt;         Total Seeds Crawled: 0\n&gt;         Total Seeds not Crawled: 1\n&gt;         Total Hosts Crawled: -1\n&gt;         Total Documents Crawled: 2\n&gt;         Processed docs/sec: 0\n&gt;         Bandwidth in Kbytes/sec: 0\n&gt;         Total Raw Data Size in Bytes: 0 (0 B)\n&gt;         Novel Bytes: 0 (0 B)\n&gt;         Displaying: 100% of 271 B\n&gt;         Frontier report.txt\n&gt;         frontier empty\n&gt;         Displaying: 100% of 15 B\n&gt;\n&gt;         Can you please guide me. what&#39;s wrong with it? Is it my setting?\n&gt;         As I am refeering to Heritrix status code, I found the following:\n&gt;           -1 DNS lookup failed\n&gt;           -6 Prerequisite domain-lookup failed, precluding fetch attempt\n&gt;\n&gt;         How am I going to fix it? Please help and advice.\n&gt;\n&gt;         Looking forward to hear from you.\n&gt;\n&gt;         Thanks in advance,\n&gt;         Allen Wilson\n&gt;\n&gt;\n&gt;\n&gt;         ------------------------------------\n&gt;\n&gt;         Yahoo! Groups Links\n&gt;\n&gt;\n&gt;         archive-crawler-fullfeatured@yahoogroups.com\n&gt;         &lt;mailto:archive-crawler-fullfeatured@yahoogroups.com&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; \n\n"}}