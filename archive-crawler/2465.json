{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr (archive.org)","from":"&quot;Gordon Mohr (archive.org)&quot; &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"9dyAxZdtypaTC87RQuMwhEh5zDP0i97cRkpz6vz_s4N5O71DcblmILEgU7UsQvxQb7gy21-t327DYINx1cb6-Pdp_ug7oPGanXU7om0XdzKMl0ySTZ_B","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: Scope Qs Re: [archive-crawler] Re: Large crawl experience (like, 500M links)","postDate":"1135303941","msgId":2465,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQzQUI1RDA1LjkwMTA2MDdAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGRvZmtxNitpbnRoQGVHcm91cHMuY29tPg==","referencesHeader":"PGRvZmtxNitpbnRoQGVHcm91cHMuY29tPg=="},"prevInTopic":2463,"nextInTopic":2466,"prevInTime":2464,"nextInTime":2466,"topicId":2391,"numMessagesInTopic":12,"msgSnippet":"... Depends on the rest of the scope settings. Would these two URIs have been accepted by the scope before the importUris, if they had been discovered on a","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 55544 invoked from network); 23 Dec 2005 02:15:26 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m29.grp.scd.yahoo.com with QMQP; 23 Dec 2005 02:15:26 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (207.241.224.171)\n  by mta4.grp.scd.yahoo.com with SMTP; 23 Dec 2005 02:15:26 -0000\r\nReceived: (qmail 19330 invoked by uid 100); 23 Dec 2005 02:07:52 -0000\r\nReceived: from adsl-71-130-102-78.dsl.pltn13.pacbell.net (HELO ?192.168.1.10?) (gojomo@...@71.130.102.78)\n  by mail-dev.archive.org with SMTP; 23 Dec 2005 02:07:52 -0000\r\nMessage-ID: &lt;43AB5D05.9010607@...&gt;\r\nDate: Thu, 22 Dec 2005 18:12:21 -0800\r\nUser-Agent: Mozilla Thunderbird 1.0.7-1.1.fc3 (X11/20050929)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;dofkq6+inth@...&gt;\r\nIn-Reply-To: &lt;dofkq6+inth@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=-78.5 required=7.0 tests=AWL,USER_IN_WHITELIST \n\tautolearn=no version=2.63\r\nX-eGroups-Msg-Info: 2:12:4:0\r\nFrom: &quot;Gordon Mohr (archive.org)&quot; &lt;gojomo@...&gt;\r\nSubject: Re: Scope Qs Re: [archive-crawler] Re: Large crawl experience (like,\n 500M links)\r\nX-Yahoo-Group-Post: member; u=137285340; y=3zI1js0xvxcN8u2cv3MJ2ekvkJj3GRYk6nGM79fg0oPu\r\nX-Yahoo-Profile: gojomo\r\n\r\njoehung302 wrote:\n&gt;&gt;Every URI that is discovered by the Extractor processors gets \n&gt; \n&gt; queued up\n&gt; \n&gt;&gt;inside the originating URI as it continues its processing. \n&gt; \n&gt; \n&gt; How about new URIs discovered through the JMX importUris as non-seed?\n&gt; Let&#39;s say I JMX imported this link (http://members.aol.com/joe) as \n&gt; non-seed and this link gets crawled/extracted and the crawler get \n&gt; two new links\n&gt; \n&gt; http://members.aol.com/joe/kid1.html\n&gt; http://members.aol.com/joe/kid2.html\n&gt; \n&gt; Since http://members.aol.com/joe is not seed, would the crawler \n&gt; continue to download \n&gt; \n&gt; http://members.aol.com/joe/kid1.html\n&gt; http://members.aol.com/joe/kid2.html\n&gt; \n\nDepends on the rest of the scope settings. Would these two URIs\nhave been accepted by the scope before the importUris, if they\nhad been discovered on a crawled page? The fact that they were\ndiscovered on a URI that was imported makes no difference -- the\nsame rules will be applied at the LinksScoping step.\n\n&gt;&gt;If you are trying new scopes, the otherthing to look into is the\n&gt;&gt;DecidingScope. It &#39;unwraps&#39; some of the things bundled together in \n&gt; \n&gt; the\n&gt; \n&gt;&gt;classic scopes to be separate reorderable &#39;DecideRules&#39;, applied in\n&gt;&gt;sequence. As a result, you can gain even finer control over what&#39;s\n&gt;&gt;included and what isn&#39;t.\n&gt;&gt;\n&gt; \n&gt; \n&gt; Frankly I&#39;m willing to try anything that would leads me to a 500M \n&gt; links crawl. Right now it seems to me the most promising methods are \n&gt; split-crawl technique with SurtPrefixScope and moving uris around. \n&gt; I&#39;m hoping someone on this list can shed some light...\n\nYes, something using SURTs to split among multiple crawlers is your best\nbet given the current software. You may still want to have all the crawlers\nhave the same scope, but each only retain URIs of a portion of that scope,\nusing the CrawlMapper processor, as noted in the messages:\n\n  http://groups.yahoo.com/group/archive-crawler/message/2348\n  http://groups.yahoo.com/group/archive-crawler/message/2402\n\n- Gordon @ IA\n\n"}}