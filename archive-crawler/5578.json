{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"vCVy0hKHXfGuA1oGaxUipVD5lcU_FDbwM_Ja40xCg6nitdE01XcNymrdOkpI98apx18aWngMrE8GEvVJjmvY_cy2ncTfNYQ","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] TooManyOpenFiles with 1M seed and 300 ToeThreads","postDate":"1226965214","msgId":5578,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ5MjIwMERFLjgwMzAwMDNAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDQ5MUIxRDIwLjQwNzAzMDBAdW1icmljaC5uZXQ+","referencesHeader":"PDQ5MUIxRDIwLjQwNzAzMDBAdW1icmljaC5uZXQ+"},"prevInTopic":5574,"nextInTopic":5580,"prevInTime":5577,"nextInTime":5579,"topicId":5572,"numMessagesInTopic":5,"msgSnippet":"You previous message reported running several successful crawls that collected ~10M pages a day, starting from 1M seed URLs. What is different about the","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 53039 invoked from network); 17 Nov 2008 23:40:11 -0000\r\nX-Received: from unknown (66.218.67.97)\n  by m42.grp.scd.yahoo.com with QMQP; 17 Nov 2008 23:40:11 -0000\r\nX-Received: from unknown (HELO relay01.pair.com) (209.68.5.15)\n  by mta18.grp.scd.yahoo.com with SMTP; 17 Nov 2008 23:40:11 -0000\r\nX-Received: (qmail 10160 invoked from network); 17 Nov 2008 23:40:10 -0000\r\nX-Received: from 67.170.220.186 (HELO ?192.168.1.42?) (67.170.220.186)\n  by relay01.pair.com with SMTP; 17 Nov 2008 23:40:10 -0000\r\nX-pair-Authenticated: 67.170.220.186\r\nMessage-ID: &lt;492200DE.8030003@...&gt;\r\nDate: Mon, 17 Nov 2008 15:40:14 -0800\r\nUser-Agent: Thunderbird 2.0.0.17 (Windows/20080914)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;491B1D20.4070300@...&gt;\r\nIn-Reply-To: &lt;491B1D20.4070300@...&gt;\r\nContent-Type: text/plain; charset=UTF-8; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] TooManyOpenFiles with 1M seed and 300 ToeThreads\r\nX-Yahoo-Group-Post: member; u=137285340; y=pZrt2yE6qjq3nhpKJKrzsD9zEvLCZNNT6IVf1hy7wGjv\r\nX-Yahoo-Profile: gojomo\r\n\r\nYou previous message reported running several successful crawls that \ncollected ~10M pages a day, starting from 1M seed URLs.\n\nWhat is different about the machine or crawl configuration on this crawl \nthat dies after only 458 crawl.log entries, compared to the prior \nsuccesses? (Might there be some other runaway use of file handles on the \nsame machine?)\n\n- Gordon @ IA\n\nJuergen Umbrich wrote:\n&gt; Hi all,\n&gt; \n&gt; we had a TMOF-Excetpion while we tried to run a crawl with 300 \n&gt; ToeThreads, 1M seed URIs, and a\n&gt; #ulimit -l = 32768. (global sheet attached)\n&gt; The execption happens just at the beginning, when the URIs from the seed \n&gt; list were parsed and loaded and the crawler started.\n&gt; The crawl.log contains 458 entries, with 380 dns - lookups.\n&gt; All the other log files are empty.\n&gt; \n&gt; I think with a ulimit of 32768 this should not happen! Or am I wrong?\n&gt; \n&gt; Best juergen\n&gt; \n&gt; \n&gt; alerts.log:\n&gt; ------------------------------------------------------------------------------------------------------------------------\n&gt; \n&gt;  org.archive.modules.fetcher.FetchDNS storeDNSRecord\n&gt; SEVERE: Failed store of DNS Record for dns:breakers.typepad.com (in \n&gt; thread &#39;ToeThread #88: dns:breakers.typepad.com&#39;; in processor &#39;DNS&#39;)\n&gt; java.io.FileNotFoundException: \n&gt; /home/heritrix/heritrix-2.0.1/jobs/active-BenchmarkCrawl-20081026023802/scratch/tt88http.ris \n&gt; (Too many open files)\n&gt;     at java.io.FileOutputStream.open(Native Method)\n&gt;     at java.io.FileOutputStream.&lt;init&gt;(FileOutputStream.java:179)\n&gt;     at java.io.FileOutputStream.&lt;init&gt;(FileOutputStream.java:70)\n&gt;     at \n&gt; org.archive.io.RecordingOutputStream.open(RecordingOutputStream.java:207)\n&gt;     at \n&gt; org.archive.io.RecordingOutputStream.open(RecordingOutputStream.java:173)\n&gt;     at \n&gt; org.archive.io.RecordingInputStream.open(RecordingInputStream.java:92)\n&gt;     at org.archive.util.Recorder.inputWrap(Recorder.java:150)\n&gt;     at org.archive.modules.fetcher.FetchDNS.recordDNS(FetchDNS.java:270)\n&gt;     at \n&gt; org.archive.modules.fetcher.FetchDNS.storeDNSRecord(FetchDNS.java:215)\n&gt;     at org.archive.modules.fetcher.FetchDNS.innerProcess(FetchDNS.java:170)\n&gt;     at org.archive.modules.Processor.innerProcessResult(Processor.java:157)\n&gt;     at org.archive.modules.Processor.process(Processor.java:123)\n&gt;     at \n&gt; org.archive.crawler.framework.ToeThread.processCrawlUri(ToeThread.java:310)\n&gt;     at org.archive.crawler.framework.ToeThread.run(ToeThread.java:157)\n&gt; 26-Oct-2008 04:00:49 org.archive.modules.fetcher.FetchDNS storeDNSRecord\n&gt; SEVERE: Failed store of DNS Record for dns:depts.drew.edu (in thread \n&gt; &#39;ToeThread #88: dns:depts.drew.edu&#39;; in processor &#39;DNS&#39;)\n&gt; java.io.IOException: RIS already open for ToeThread #88: dns:depts.drew.edu\n&gt;     at \n&gt; org.archive.io.RecordingInputStream.open(RecordingInputStream.java:88)\n&gt;     at org.archive.util.Recorder.inputWrap(Recorder.java:150)\n&gt;     at org.archive.modules.fetcher.FetchDNS.recordDNS(FetchDNS.java:270)\n&gt;     at \n&gt; org.archive.modules.fetcher.FetchDNS.storeDNSRecord(FetchDNS.java:215)\n&gt;     at org.archive.modules.fetcher.FetchDNS.innerProcess(FetchDNS.java:170)\n&gt;     at org.archive.modules.Processor.innerProcessResult(Processor.java:157)\n&gt;     at org.archive.modules.Processor.process(Processor.java:123)\n&gt;     at \n&gt; org.archive.crawler.framework.ToeThread.processCrawlUri(ToeThread.java:310)\n&gt;     at org.archive.crawler.framework.ToeThread.run(ToeThread.java:157)\n\n"}}