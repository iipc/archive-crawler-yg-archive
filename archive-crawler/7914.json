{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":494554680,"authorName":"Travis Wellman","from":"Travis Wellman &lt;travis@...&gt;","replyTo":"LIST","senderId":"MOh_NIzOHTGAdgtM2TzQUJo1XThuw98tQWrpuwA8mDUpR1oUWf6KbWkwezAp0IAKggSGo1lq95ZZuySK6N--ZIyGDskzTNpxlf4","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Implementing crawlers","postDate":"1358279163","msgId":7914,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDIwMTMwMTE1MTE0NjAzLjQ0YjZlMDBiM2U4M2EwYWEyYzg2NTg0MEBhcmNoaXZlLm9yZz4=","inReplyToHeader":"PDEzNTgyNzI3MDIuMzM2MTguWWFob29NYWlsTmVvQHdlYjEyNTUwNi5tYWlsLm5lMS55YWhvby5jb20+","referencesHeader":"PDEzNTgyNzI3MDIuMzM2MTguWWFob29NYWlsTmVvQHdlYjEyNTUwNi5tYWlsLm5lMS55YWhvby5jb20+"},"prevInTopic":0,"nextInTopic":7915,"prevInTime":7913,"nextInTime":7915,"topicId":7912,"numMessagesInTopic":4,"msgSnippet":"Ali, Heritrix is built for archiving not data mining. That said, you may want to implement a DecideRule if you have a custom way to shape the scope of a crawl,","rawEmail":"Return-Path: &lt;travis@...&gt;\r\nX-Sender: travis@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 68079 invoked from network); 15 Jan 2013 19:46:08 -0000\r\nX-Received: from unknown (98.137.34.46)\n  by m10.grp.sp2.yahoo.com with QMQP; 15 Jan 2013 19:46:08 -0000\r\nX-Received: from unknown (HELO mail.archive.org) (207.241.224.6)\n  by mta3.grp.sp2.yahoo.com with SMTP; 15 Jan 2013 19:46:08 -0000\r\nX-Received: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id E4FD8684016E\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Tue, 15 Jan 2013 11:46:07 -0800 (PST)\r\nX-Received: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id v8Qvt7nTyNPa for &lt;archive-crawler@yahoogroups.com&gt;;\n\tTue, 15 Jan 2013 11:46:04 -0800 (PST)\r\nX-Received: from travis-ia-laptop (router300.sf.archive.org [208.70.27.190])\n\tby mail.archive.org (Postfix) with ESMTPSA id 2B3F76840256\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Tue, 15 Jan 2013 11:46:04 -0800 (PST)\r\nDate: Tue, 15 Jan 2013 11:46:03 -0800\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-Id: &lt;20130115114603.44b6e00b3e83a0aa2c865840@...&gt;\r\nIn-Reply-To: &lt;1358272702.33618.YahooMailNeo@...&gt;\r\nReferences: &lt;1358272702.33618.YahooMailNeo@...&gt;\r\nOrganization: Internet Archive\r\nX-Mailer: Sylpheed 3.2.0 (GTK+ 2.24.8; x86_64-redhat-linux-gnu)\r\nMime-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Transfer-Encoding: quoted-printable\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Travis Wellman &lt;travis@...&gt;\r\nSubject: Re: [archive-crawler] Implementing crawlers\r\nX-Yahoo-Group-Post: member; u=494554680\r\n\r\nAli,\n\nHeritrix is built for archiving not data mining. That said, you may w=\r\nant to implement a DecideRule if you have a custom way to shape the scope o=\r\nf a crawl, or a ContentExtractor if you have a custom way to discover URLs =\r\nfrom resources.\n\nI think, though, that you&#39;re probably more interested in w=\r\nhat to do with the web data in the warc files after the crawl is complete.\n=\r\n\nTravis\n\nOn Tue, 15 Jan 2013 09:58:22 -0800 (PST)\nAli Pesaranghader &lt;alipsg=\r\nh@...&gt; wrote:\n\n&gt; Hi friends,\n&gt; I&#39;m new in working with Heritrix. I ne=\r\ned some help and somebody guides me with some helpful suggestions about imp=\r\nlementing my crawlers based on some algorithms such is TD-IDF, Shark Search=\r\n, Fish Search and etc. I know how algorithms work=A0theoretically (on paper=\r\n), but I want to build them as a real crawler to gather pages in the Web (f=\r\nrom seed pages) and filter them and retrieved most related pages to a query=\r\n.\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;I will be thankful if you share your ideas with me about this.=\r\n\n&gt; Respectfully,\n&gt; Ali\n\n"}}