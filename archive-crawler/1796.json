{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr (Internet Archive)","from":"&quot;Gordon Mohr (Internet Archive)&quot; &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"TSWDJPeGnlOBgg1iAR4NfnWKI7YSen5oNqBKGO6dPBuY7StMAs-Moc2s8zFt2g65JbtAL4-wC3ZsoctGDKoORFVJ-kHVfbnjlYJdBJzj2fc1ScfJdEvDyL7G0ko","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Not possible to override &quot;max-document-download&quot;","postDate":"1115247468","msgId":1796,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQyNzk1MzZDLjcwODA4MDFAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGRmOWYxNGVlOS4xNGVlOWRmOWZAc3RhdHNiaWJsaW90ZWtldC5kaz4=","referencesHeader":"PGRmOWYxNGVlOS4xNGVlOWRmOWZAc3RhdHNiaWJsaW90ZWtldC5kaz4="},"prevInTopic":1795,"nextInTopic":1801,"prevInTime":1795,"nextInTime":1797,"topicId":1784,"numMessagesInTopic":8,"msgSnippet":"Excellent suggestion. Until these details get integrated into the User Manual, you can learn about these budgetting settings in the wiki: ","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 53751 invoked from network); 4 May 2005 22:57:53 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m22.grp.scd.yahoo.com with QMQP; 4 May 2005 22:57:53 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (207.241.224.172)\n  by mta2.grp.scd.yahoo.com with SMTP; 4 May 2005 22:57:53 -0000\r\nReceived: (qmail 22205 invoked by uid 100); 4 May 2005 22:57:49 -0000\r\nReceived: from b116-dyn-239.archive.org (HELO ?207.241.238.239?) (gojomo@...@207.241.238.239)\n  by mail-dev.archive.org with SMTP; 4 May 2005 22:57:49 -0000\r\nMessage-ID: &lt;4279536C.7080801@...&gt;\r\nDate: Wed, 04 May 2005 15:57:48 -0700\r\nUser-Agent: Mozilla Thunderbird 1.0 (X11/20041206)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;df9f14ee9.14ee9df9f@...&gt;\r\nIn-Reply-To: &lt;df9f14ee9.14ee9df9f@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=-61.3 required=7.0 tests=AWL,USER_IN_WHITELIST \n\tautolearn=no version=2.63\r\nX-eGroups-Msg-Info: 1:12:0\r\nFrom: &quot;Gordon Mohr (Internet Archive)&quot; &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Not possible to override &quot;max-document-download&quot;\r\nX-Yahoo-Group-Post: member; u=137285340\r\nX-Yahoo-Profile: gojomo\r\n\r\nExcellent suggestion. Until these details get integrated into the User Manual,\nyou can learn about these &quot;budgetting&quot; settings in the wiki:\n\n    http://crawler.archive.org/cgi-bin/wiki.pl?BudgetingFrontier\n\nIn particular, the &#39;queue-total-budget&#39; can be used almost like a\nper-host max-documents, but note the following:\n\n  - Budget amounts are deducted on each *try* from a queue -- that is,\n    item dequeued, even if it gets requeued -- rather than each success.\n  - Each dequeue only counts as &#39;1&#39; if you&#39;re using the UnitCostAssignmentPolicy.\n    Other policies may consider some dequeues more &#39;costly&#39;, such as\n    those that look like calendars or deep dynamic content.\n  - Even normal error-free operation involves some URLs being pulled\n    from their queue more than once, for example when an URL is considered\n    but then put off for the fetching of a prerquisite DNS or /robots.txt\n    resource.\n\nSo, even a UnitCostAssignmentPolicy and queue-total-budget of (for example)\n1000 won&#39;t lead to exactly 1000 resources collected -- the actual number\nwill be slightly lower, or much lower if there were many problems requiring\nretries.\n\n- Gordon @ IA\n\nbja@... wrote:\n&gt; *A someway similar behavior could be obtained by using the cost-policies to \n&gt; ensure download of a maximum of e.g. 2000 objects from each host at a time - \n&gt; this would not stop the crawler after 2000 documents per host but this ensures \n&gt; that each host is visited before going nuts (in crawler traps and other \n&gt; unpleasent things like that)*\n&gt; \n&gt; *best\n&gt; Bjarne Andersen*\n&gt; \n&gt; *----- Original Message -----*\n&gt; \n&gt; *From*: Kristinn Sigurdsson &lt;kris@...&gt;\n&gt; \n&gt; *Date*: Wednesday, May 4, 2005 5:22 pm\n&gt; \n&gt; *Subject*: RE: [archive-crawler] Not possible to override &quot;max-document-download&quot;\n&gt; \n&gt;  &gt; What Stack fails to mention is that the DomainSensitiveFrontier is\n&gt;  &gt; based on\n&gt;  &gt; the now deprecated HostQueuesFrontier.\n&gt;  &gt;\n&gt;  &gt; A possible workaround for you Soren, would be to create a\n&gt;  &gt; processor and a\n&gt;  &gt; filter that attaches to the scope.\n&gt;  &gt;\n&gt;  &gt; The processor would be somewhere after the fetch part of the\n&gt;  &gt; chain. It would\n&gt;  &gt; simply tally the number of URIs that pass through for each host.\n&gt;  &gt; It would\n&gt;  &gt; also provide static access to look-ups on any of these values.\n&gt;  &gt; Actually, the\n&gt;  &gt; StatisticsTracker does keep track of this at the moment, but you\n&gt;  &gt; cant access\n&gt;  &gt; the information in a useful fashion.\n&gt;  &gt;\n&gt;  &gt; The filter (which is going to be a part of the scope) would then\n&gt;  &gt; check with\n&gt;  &gt; this processor for each URI to see if its host has exceeded its\n&gt;  &gt; maximumvalue. The filters maximum value would be configurable and,\n&gt;  &gt; moreimportantly, overridable in the usual manner.\n&gt;  &gt;\n&gt;  &gt; Set the Preselector to recheck scope and once a host has exceeded\n&gt;  &gt; its max,\n&gt;  &gt; all other URIs belonging to it will be tossed.\n&gt;  &gt;\n&gt;  &gt; Any other (more elegant) solutions would require tinkering with the\n&gt;  &gt; BdbFrontier.\n&gt;  &gt;\n&gt;  &gt; - Kris\n&gt;  &gt;\n&gt;  &gt; -----Original Message-----\n&gt;  &gt; From: archive-crawler@yahoogroups.com\n&gt;  &gt; [archive-crawler@yahoogroups.com] On Behalf Of stack\n&gt;  &gt; Sent: 4. ma� 2005 15:06\n&gt;  &gt; To: archive-crawler@yahoogroups.com\n&gt;  &gt; Subject: Re: [archive-crawler] Not possible to override\n&gt;  &gt; &quot;max-document-download&quot;\n&gt;  &gt;\n&gt;  &gt;\n&gt;  &gt; svc@... wrote:\n&gt;  &gt;\n&gt;  &gt; &gt; It would be nice for us, if we could override the &quot;max-document-\n&gt;  &gt; download&quot;&gt; setting, i.e have it defined pr. domain\n&gt;  &gt; &gt; We are planning to crawl a bunch of domains in a single job, but\n&gt;  &gt; need to\n&gt;  &gt; &gt; set a limit to the number of objects crawled for each of the\n&gt;  &gt; domains.&gt;\n&gt;  &gt; &gt; This seems not to be possible in the current version of heritrix.\n&gt;  &gt; &gt; Maybe this could be implemented instead as a processor.\n&gt;  &gt; &gt; Suggestions are very welcome.\n&gt;  &gt;\n&gt;  &gt; Take a look at the DomainSensitiveFrontier (See\n&gt;  &gt; &#39;6.1.2.3. DomainSensitveFrontier&#39; in the User Manual\n&gt;  &gt; http://crawler.archive.org/articles/user_manual.html#modules).\n&gt;  &gt; This\n&gt;  &gt; frontier allows specification of maximum documents per domain\n&gt;  &gt; adding a\n&gt;  &gt; filter to a domain-specific override to prevent further downloads\n&gt;  &gt; once\n&gt;  &gt; the maximum has been reached. The DSF is based on Heritrix&#39;s\n&gt;  &gt; previous\n&gt;  &gt; default frontier, the HostQueuesFrontier so your crawls will not\n&gt;  &gt; be as\n&gt;  &gt; long lasting -- but perhaps it will be sufficent to your purposes\n&gt;  &gt; (I&#39;ve\n&gt;  &gt; added a feature request that we add this ability to the\n&gt;  &gt; BdbFrontier:\n&gt;  &gt; http://sourceforge.net/tracker/index.php?func=detail\n&gt;  &gt; &lt;http://sourceforge.net/tracker/index.php?func=detail&aid=1195298&group_id=7\n&gt;  &gt; 3833&atid=539102).&gt; &aid=1195298&group_id=73833&atid=539102).\n&gt;  &gt; St.Ack\n&gt;  &gt;\n&gt;  &gt; &gt;\n&gt;  &gt; &gt; regards\n&gt;  &gt; &gt; ------------------------------------------------------------\n&gt;  &gt; &gt; S�ren Vejrup Carlsen, DDA, Det Kongelige Bibliotek\n&gt;  &gt; &gt; tlf: (+45) 33 47 48 41\n&gt;  &gt; &gt; email: svc@...\n&gt;  &gt; &gt; email: svc@...\n&gt;  &gt; &gt; -------------------------------------------------------------\n&gt;  &gt; &gt; Non omnia possumus omnes\n&gt;  &gt; &gt; --- Macrobius, Saturnalia, VI, 1, 35 -------\n&gt;  &gt; &gt;\n&gt;  &gt; &gt;\n&gt;  &gt; &gt; -----------------------------------------------------------------\n&gt;  &gt; -------\n&gt;  &gt; &gt; *Yahoo! Groups Links*\n&gt;  &gt; &gt;\n&gt;  &gt; &gt; * To visit your group on the web, go to:\n&gt;  &gt; &gt; http://groups.yahoo.com/group/archive-crawler/\n&gt;  &gt; &gt;\n&gt;  &gt; &gt; * To unsubscribe from this group, send an email to:\n&gt;  &gt; &gt; archive-crawler-unsubscribe@yahoogroups.com\n&gt;  &gt; &gt;\n&gt;  &gt; &lt;&#39;)&quot; &gt;archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;  &gt; &gt;\n&gt;  &gt; &gt; * Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;  &gt; &gt; Service &lt;.&quot; target=&quot;l&quot;&gt;http://docs.yahoo.com/info/terms/&gt;.\n&gt;  &gt; &gt;\n&gt;  &gt; &gt;\n&gt;  &gt;\n&gt;  &gt;\n&gt;  &gt;\n&gt;  &gt; _____\n&gt;  &gt;\n&gt;  &gt; Yahoo! Groups Links\n&gt;  &gt;\n&gt;  &gt;\n&gt;  &gt; * To visit your group on the web, go to:\n&gt;  &gt; http://groups.yahoo.com/group/archive-crawler/\n&gt;  &gt;\n&gt;  &gt;\n&gt;  &gt; * To unsubscribe from this group, send an email to:\n&gt;  &gt; archive-crawler-unsubscribe@yahoogroups.com\n&gt;  &gt; &lt;&#39;)&quot; &gt;archive-crawler-\n&gt;  &gt; unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;  &gt;\n&gt;  &gt;\n&gt;  &gt; * Your use of Yahoo! Groups is subject to the Yahoo! Terms of Service\n&gt;  &gt; &lt;&quot; target=&quot;l&quot;&gt;http://docs.yahoo.com/info/terms/&gt; .\n&gt;  &gt;\n&gt;  &gt;\n&gt;  &gt;\n&gt; --------------------------------------------------------------------------------\n&gt; *Yahoo! Groups Links*\n&gt; \n&gt;     * To visit your group on the web, go to:\n&gt;       http://groups.yahoo.com/group/archive-crawler/\n&gt;        \n&gt;     * To unsubscribe from this group, send an email to:\n&gt;       archive-crawler-unsubscribe@yahoogroups.com\n&gt;       &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;        \n&gt;     * Your use of Yahoo! Groups is subject to the Yahoo! Terms of Service\n&gt;       &lt;http://docs.yahoo.com/info/terms/&gt;. \n&gt; \n&gt; \n\n\n"}}