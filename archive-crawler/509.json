{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":172190008,"authorName":"Andy Boyko","from":"Andy Boyko &lt;aboy@...&gt;","profile":"andyboyko","replyTo":"LIST","senderId":"QyoqOaHxkE1b7O_LOfet9ettVBkmRBiQ3l5ehZ3gyX7UEfLEJxVtzb4b01t4OzjXbRfoe3oEpLhTgiIzHgrcKQ","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Inserting information to MYSQL during crawl","postDate":"1086372360","msgId":509,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQwQzBCQTA4LjIwMTA1MDZAbG9jLmdvdj4=","inReplyToHeader":"PGM5cTQ2dStqNzBzQGVHcm91cHMuY29tPg==","referencesHeader":"PGM5cTQ2dStqNzBzQGVHcm91cHMuY29tPg=="},"prevInTopic":508,"nextInTopic":514,"prevInTime":508,"nextInTime":510,"topicId":507,"numMessagesInTopic":19,"msgSnippet":"... Are you interested in that specifically to get away from ARC, or more simply because you re interested in being able to issue queries on the crawl results","rawEmail":"Return-Path: &lt;aboy@...&gt;\r\nX-Sender: aboy@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 31599 invoked from network); 4 Jun 2004 18:06:13 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m17.grp.scd.yahoo.com with QMQP; 4 Jun 2004 18:06:13 -0000\r\nReceived: from unknown (HELO sun8.loc.gov) (140.147.249.48)\n  by mta5.grp.scd.yahoo.com with SMTP; 4 Jun 2004 18:06:12 -0000\r\nReceived: from [140.147.131.81] (amerprt1.loc.gov [140.147.131.81])\n\tby sun8.loc.gov  with ESMTP id i54I60VT011705\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Fri, 4 Jun 2004 14:06:00 -0400 (EDT)\r\nMessage-ID: &lt;40C0BA08.2010506@...&gt;\r\nDate: Fri, 04 Jun 2004 14:06:00 -0400\r\nUser-Agent: Mozilla Thunderbird 0.6 (Windows/20040502)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;c9q46u+j70s@...&gt;\r\nIn-Reply-To: &lt;c9q46u+j70s@...&gt;\r\nContent-Type: text/plain; charset=us-ascii; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Remote-IP: 140.147.249.48\r\nFrom: Andy Boyko &lt;aboy@...&gt;\r\nSubject: Re: [archive-crawler] Inserting information to MYSQL during crawl\r\nX-Yahoo-Group-Post: member; u=172190008\r\nX-Yahoo-Profile: andyboyko\r\n\r\nAhnu Nahki wrote:\n&gt; Instead of writing to an arc file, Id like to create a method that\n&gt; takes the URI info, Content, headers, ect into a MYSQL database. Does\n&gt; anyone have any suggestion on how to do this , where I should look to\n&gt; place my methods?\n\nAre you interested in that specifically to get away from ARC, or more \nsimply because you&#39;re interested in being able to issue queries on the \ncrawl results in interesting/relational ways?  I ask because we&#39;re \nlooking into a slightly different approach - rather than building the \ndatabase logic into Heritrix, treating the DB import as a \npost-processing step on the crawl output (ARC files & logs) once the \ncrawl is complete.  I believe Tom Emerson has also talked about \npopulating a DB from ARC files in future versions of his libarc library.\n\nBy keeping the content in ARCs, you get the ability to leverage the \ngrowing number of tools for dealing with the format coming from this \ncommunity, and if the post-processing approach can work for you, code \nfor populating a DB may be forthcoming from a couple of sources in the \nnear future.\n\nCan you describe in more detail what you&#39;re envisioning with your \nplanned DB crawl storage?\n\nRegards,\nAndy Boyko    aboy@...     Library of Congress\n\n"}}