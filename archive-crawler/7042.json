{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":475161324,"authorName":"Dhake, Pankaj","from":"&quot;Dhake, Pankaj&quot; &lt;pdhake@...&gt;","replyTo":"LIST","senderId":"ouDbzaFZn5ny1f6hdDeRlMf-f7cTuz0YeVPKqDhsVCaZfuupLDJu-czM-UV2UbZ4ZZjA3bF5JtDOS5EJl03sCkoYxr5tQ1LQBzQ","spamInfo":{"isSpam":false,"reason":"12"},"subject":"[archive-crawler] Heritrix WriterProcessor","postDate":"1298883363","msgId":7042,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDlDQzhENkU0ODA0RTIzNEE4MjdEMTc4MkFFM0RCNzc4MkRFRTNCOENGNkBFWC1NQUlMLUhZRDEtMS5hbnQuYW1hem9uLmNvbT4="},"prevInTopic":7037,"nextInTopic":7045,"prevInTime":7041,"nextInTime":7043,"topicId":7016,"numMessagesInTopic":8,"msgSnippet":"Hi, Thanks for your reply. Could not yet get the solution to this problem. ... My writer is the first in the DispositionChain Processors which consists of 3","rawEmail":"Return-Path: &lt;pdhake@...&gt;\r\nX-Sender: pdhake@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 54008 invoked from network); 28 Feb 2011 08:56:33 -0000\r\nX-Received: from unknown (98.137.34.46)\n  by m7.grp.sp2.yahoo.com with QMQP; 28 Feb 2011 08:56:33 -0000\r\nX-Received: from unknown (HELO smtp-fw-4101.amazon.com) (72.21.198.25)\n  by mta3.grp.sp2.yahoo.com with SMTP; 28 Feb 2011 08:56:33 -0000\r\nX-IronPort-AV: E=Sophos;i=&quot;4.62,238,1297036800&quot;; \n   d=&quot;scan&#39;208&quot;;a=&quot;368536861&quot;\r\nX-Received: from smtp-in-1104.vdc.amazon.com ([10.140.10.25])\n  by smtp-border-fw-out-4101.iad4.amazon.com with ESMTP/TLS/DHE-RSA-AES256-SHA; 28 Feb 2011 08:56:32 +0000\r\nX-Received: from ex-hub-12011.ant.amazon.com (ex-hub-12011.ant.amazon.com [10.32.49.104])\n\tby smtp-in-1104.vdc.amazon.com (8.13.8/8.13.8) with ESMTP id p1S8uNkE001840\n\t(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=FAIL)\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Mon, 28 Feb 2011 08:56:32 GMT\r\nX-Received: from ex-cas-hyd1-1.ant.amazon.com (10.43.31.64) by\n ex-hub-12011.ant.amazon.com (10.32.49.104) with Microsoft SMTP Server (TLS)\n id 8.2.254.0; Mon, 28 Feb 2011 08:56:08 +0000\r\nX-Received: from ex-mail-hyd1-1.ant.amazon.com ([fe80::556:4cdd:76c1:d940]) by\n ex-cas-hyd1-1.ant.amazon.com ([fe80::e497:35d3:f367:9a0%11]) with mapi; Mon,\n 28 Feb 2011 14:26:06 +0530\r\nTo: &quot;archive-crawler@yahoogroups.com&quot; &lt;archive-crawler@yahoogroups.com&gt;\r\nDate: Mon, 28 Feb 2011 14:26:03 +0530\r\nThread-Topic: [archive-crawler] Heritrix WriterProcessor\r\nThread-Index: AcvS5bnACQzddzLtQi+HjFs3f79dWQCBwYkQAI3rhOA=\r\nMessage-ID: &lt;9CC8D6E4804E234A827D1782AE3DB7782DEE3B8CF6@...&gt;\r\nAccept-Language: en-US\r\nContent-Language: en-US\r\nX-MS-Has-Attach: \r\nX-MS-TNEF-Correlator: \r\nacceptlanguage: en-US\r\nContent-Type: text/plain; charset=&quot;us-ascii&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nMIME-Version: 1.0\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;Dhake, Pankaj&quot; &lt;pdhake@...&gt;\r\nSubject: [archive-crawler] Heritrix WriterProcessor\r\nX-Yahoo-Group-Post: member; u=475161324\r\n\r\n\nHi,\nThanks for your reply. Could not yet get the solution to this problem.=\r\n\n\n&gt;Where is your writer relative to other Processors? Does it do anything \n=\r\n&gt;other that p[en the URL and write its contents?\n\nMy writer is the first in=\r\n the DispositionChain Processors which consists of 3 processors, S3WriterPr=\r\nocessor, CandidatesProcessor, DispositionProcessor.\nNo my writer does nothi=\r\nng other than take the URL stirng and write its contents.\n\n&gt;Do you have ano=\r\nther standard writer present, as well? (When you remove \n&gt;your writer, do y=\r\nou put back the standard writer, or run with no writers?)\nIs I have the sta=\r\nndard ARCWriterProcessor and when I put it back then no errors are produced=\r\n.\n\n\n&gt;Have you done any other reordering/insertion of Processors compared to=\r\n \n&gt;the example default configuration?\nNO I have not done any reordering but=\r\n only replaced the ARCWriterProcessor by my S3WriterProcessor.\n\n&gt;This is un=\r\nclear. If all the seeds succeed, then all the DNS and \n&gt;robots.txt for thos=\r\ne same hosts must have succeeded.\n&gt;If some other (non-seed-host) robots.txt=\r\n succeed, then the DNS for that \n&gt;same host must have succeeded.\n&gt;I would t=\r\nry a very small number of seeds and watch exactly which (and \n&gt;how many) UR=\r\nIs of other types, and on other hosts, succeed.\nFor the seeds both the robo=\r\nts.txt and dns do succeed and it also works for most other URL.\nI get aroun=\r\nd 5 dns errors, which I had mentioned, while about 60 success.\nTo debug thi=\r\ns error, I did output the URI strings from the S3WriterProcessor file. Howe=\r\nver the uris for which the DNS error is reported are not in this output and=\r\n hence may be not passed to my S3WriterProcessor. Just wondering could this=\r\n be because the same URI is extracted from two different files and then pas=\r\nsed on to the FetchDNS Processor more than once, which gives the error beca=\r\nuse the ReplayInputStream is alredy opened for that URI?\n\n&gt;&gt; Are you using =\r\nthe Heritrix 3.0 original release as your base, or more\n&gt;&gt; recent code from=\r\n the project SVN/dev-builds?\nI am using the original release as the base.\n\n=\r\n\nThanking you,\nPankaj.\n\n\n-----Original Message-----\nFrom: Gordon Mohr [mail=\r\nto:gojomo@...] \nSent: Wednesday, February 23, 2011 4:41 AM\nTo: arch=\r\nive-crawler@yahoogroups.com\nCc: Dhake, Pankaj\nSubject: Re: [archive-crawler=\r\n] Heritrix WriterProcessor\n\nOn 2/21/11 11:57 PM, Dhake, Pankaj wrote:\n&gt; Tha=\r\nnks for your reply.\n&gt;\n&gt;  &gt;There&#39;s no &#39;openstream()&#39; method on CrawlURI; can=\r\n you be more specific\n&gt;  &gt;about what you&#39;re doing?\n&gt;\n&gt; I am using the opens=\r\ntream() available with the java.net.URL class. On\n&gt; the CrawlURI I use the =\r\ngetURI() method to get a String. Then I form a\n&gt; URL using the String obtai=\r\nned and then use the openstream() function on\n&gt; this URL to get an inputstr=\r\neam.\n\nThen you are actually fetching the URL twice! Once in our FetchHTTP \n=\r\nmodule (which does not use the java.net.URL class, because it does not \noff=\r\ner enough control and raw access) and then again in your writer.\n\n&gt; The onl=\r\ny thing I am currently doing in my WriterProcessor is to use the\n&gt; above pr=\r\nocedure to get an inputstream which then is used to write to the\n&gt; local fi=\r\nles. I am not making use of ReplayInputStream, but the errors do\n&gt; disappea=\r\nr on removing my writer so am confused!!\n&gt;\n&gt;  &gt;If you remove your writer, a=\r\nnd just do a short test crawl without\n&gt;  &gt;writing anything, do the above er=\r\nrors go away?\n&gt;\n&gt; When I remove my writer then the errors do go away.\n\nWher=\r\ne is your writer relative to other Processors? Does it do anything \nother t=\r\nhat p[en the URL and write its contents?\n\nDo you have another standard writ=\r\ner present, as well? (When you remove \nyour writer, do you put back the sta=\r\nndard writer, or run with no writers?)\n\nHave you done any other reordering/=\r\ninsertion of Processors compared to \nthe example default configuration?\n\nI =\r\ndon&#39;t yet see a pattern or have a good theory as to what is happening, \nbut=\r\n on the chance that we&#39;re not cleaning things up properly in the case \nwher=\r\ne custom additions are used instead of usual classes, I&#39;d really \nlike to f=\r\nigure out exactly what&#39;s triggering the problem.\n\n&gt;  &gt;Are the errors always=\r\n on DNS URIs, as in your example above, or all URI\n&gt;  &gt;types?\n&gt;\n&gt; Yes the e=\r\nrrors are only on DNS URIs.\n&gt;\n&gt;  &gt;Is it exactly your seeds + the robots.txt=\r\n URIs that succeed, then\n&gt;  &gt;no other URIs? (So, exactly 2 times the number=\r\n of seeds are shown as\n&gt;  &gt;fetch successes?)\n&gt;\n&gt; The seeds are the only one=\r\n&#39;s that succeed. However the robots.txt do\n&gt; succeed for some other URIs.\n\n=\r\nThis is unclear. If all the seeds succeed, then all the DNS and \nrobots.txt=\r\n for those same hosts must have succeeded.\n\nIf some other (non-seed-host) r=\r\nobots.txt succeed, then the DNS for that \nsame host must have succeeded.\n\nI=\r\n would try a very small number of seeds and watch exactly which (and \nhow m=\r\nany) URIs of other types, and on other hosts, succeed.\n\nAlso, still wonderi=\r\nng:\n\n&gt;&gt; Are you using the Heritrix 3.0 original release as your base, or mo=\r\nre\n&gt;&gt; recent code from the project SVN/dev-builds?\n\n\n- Gordon @ IA\n\n\n\n&gt; Tha=\r\nnking You,\n&gt;\n&gt; Pankaj.\n&gt;\n&gt; *From:*archive-crawler@yahoogroups.com\n&gt; [mailto=\r\n:archive-crawler@yahoogroups.com] *On Behalf Of *Gordon Mohr\n&gt; *Sent:* Tues=\r\nday, February 22, 2011 12:34 PM\n&gt; *To:* archive-crawler@yahoogroups.com\n&gt; *=\r\nCc:* Dhake, Pankaj\n&gt; *Subject:* Re: [archive-crawler] Heritrix WriterProces=\r\nsor\n&gt;\n&gt; On 2/21/11 9:56 PM, Dhake, Pankaj wrote:\n&gt;  &gt; Hi all, I have wriitt=\r\nen a WriterProcessor which serves my needs to\n&gt;  &gt; replace the ARCWriterPro=\r\ncessor for Heritrix 3.0. However, when I run\n&gt;  &gt; Heritrix 3.0 with my Writ=\r\nerProcessor then it correctly downloads the\n&gt;  &gt; contents of the seeds I su=\r\npply and also the robots.txt files. However\n&gt;  &gt; it does not download the c=\r\nontents for the URLs generated after the\n&gt;  &gt; seed. The log file gives the =\r\nfollowing message for all URLs generated\n&gt;  &gt; after the seeds:\n&gt;  &gt;\n&gt;  &gt; 20=\r\n11-02-21 11:07:44.708 SEVERE thread-14\n&gt; org.archive.modules.fetcher.FetchD=\r\nNS.storeDNSRecord() Failed store of\n&gt; DNS Record for dns:search.yahoo.com\n&gt;=\r\n  &gt; java.io.IOException: RIS already open for ToeThread #15:\n&gt; dns:search.y=\r\nahoo.com\n&gt;  &gt; at org.archive.io.RecordingInputStream.open(RecordingInputStr=\r\neam.java:84)\n&gt;  &gt; at org.archive.util.Recorder.inputWrap(Recorder.java:144)=\r\n\n&gt;  &gt; at org.archive.modules.fetcher.FetchDNS.recordDNS(FetchDNS.java:271)\n=\r\n&gt;  &gt; at org.archive.modules.fetcher.FetchDNS.storeDNSRecord(FetchDNS.java:2=\r\n16)\n&gt;  &gt; at org.archive.modules.fetcher.FetchDNS.innerProcess(FetchDNS.java=\r\n:171)\n&gt;  &gt; at org.archive.modules.Processor.innerProcessResult(Processor.ja=\r\nva:177)\n&gt;  &gt; at org.archive.modules.Processor.process(Processor.java:144)\n&gt;=\r\n  &gt; at org.archive.modules.ProcessorChain.process(ProcessorChain.java:131)\n=\r\n&gt;  &gt; at org.archive.crawler.framework.ToeThread.run(ToeThread.java:146)\n&gt;  =\r\n&gt;\n&gt;  &gt; It says that RIS is already open. However in my code I have not made=\r\n\n&gt;  &gt; use of the ReplayInputStream at all and am just making use of the\n&gt;  =\r\n&gt; CrawlURI and then using the openstream() function to download the\n&gt;  &gt; co=\r\nntents. I am not quite clear about the tasks that are done in\n&gt;  &gt; innerpro=\r\ncess() function of the ARCWriterProcessor. So am not able to\n&gt;  &gt; find the =\r\nbug in my code.\n&gt;\n&gt; There&#39;s no &#39;openstream()&#39; method on CrawlURI; can you b=\r\ne more specific\n&gt; about what you&#39;re doing?\n&gt;\n&gt; (If you&#39;re getting the data =\r\nfrom a fetch for analysis/writing, then you\n&gt; are in some way or another op=\r\nening an InputStream or ReplayCharSequence\n&gt; from the Recorder data, and it=\r\n needs to be cleanly closed in any\n&gt; eventuality.)\n&gt;\n&gt; If you remove your w=\r\nriter, and just do a short test crawl without\n&gt; writing anything, do the ab=\r\nove errors go away?\n&gt;\n&gt; Are the errors always on DNS URIs, as in your examp=\r\nle above, or all URI\n&gt; types? Is it exactly your seeds + the robots.txt URI=\r\ns that succeed, then\n&gt; no other URIs? (So, exactly 2 times the number of se=\r\neds are shown as\n&gt; fetch successes?)\n&gt;\n&gt; Are you using the Heritrix 3.0 ori=\r\nginal release as your base, or more\n&gt; recent code from the project SVN/dev-=\r\nbuilds?\n&gt;\n&gt; - Gordon @ IA\n&gt;\n&gt;\n&gt;\n&gt; \n\n"}}