{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":145267558,"authorName":"Sajib Dasgupta","from":"&quot;Sajib Dasgupta&quot; &lt;sajib44new@...&gt;","profile":"sajib44new","replyTo":"LIST","senderId":"30j68N7X6QENsHdCp2C0VIu6lB3rHYqLiTgD8nUTMpD9wWxNcnRq-Rs2b5ueHF2L83XPp3z9T-ZKpye-DmbPxrK21BnaAkdKiM8dCbrM","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Regular Expression Problem","postDate":"1208412984","msgId":5127,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZ1NnB2bytsZG43QGVHcm91cHMuY29tPg==","inReplyToHeader":"PDQ4MDY5NTg4LjkwMTAxMDlAYXJjaGl2ZS5vcmc+"},"prevInTopic":5126,"nextInTopic":5128,"prevInTime":5126,"nextInTime":5128,"topicId":5125,"numMessagesInTopic":4,"msgSnippet":"Thanks a ton. I thought, every crawler starts from the seed. Anyway, I guess, for Heritrix, they crawl the robots.txt before they crawl the seeds, and hence,","rawEmail":"Return-Path: &lt;sajib44new@...&gt;\r\nX-Sender: sajib44new@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 24279 invoked from network); 17 Apr 2008 06:16:25 -0000\r\nX-Received: from unknown (66.218.67.94)\n  by m45.grp.scd.yahoo.com with QMQP; 17 Apr 2008 06:16:25 -0000\r\nX-Received: from unknown (HELO n25c.bullet.scd.yahoo.com) (66.218.67.216)\n  by mta15.grp.scd.yahoo.com with SMTP; 17 Apr 2008 06:16:25 -0000\r\nX-Received: from [66.218.69.1] by n25.bullet.scd.yahoo.com with NNFMP; 17 Apr 2008 06:16:25 -0000\r\nX-Received: from [66.218.66.81] by t1.bullet.scd.yahoo.com with NNFMP; 17 Apr 2008 06:16:25 -0000\r\nDate: Thu, 17 Apr 2008 06:16:24 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;fu6pvo+ldn7@...&gt;\r\nIn-Reply-To: &lt;48069588.9010109@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Sajib Dasgupta&quot; &lt;sajib44new@...&gt;\r\nSubject: Re: Regular Expression Problem\r\nX-Yahoo-Group-Post: member; u=145267558; y=q9idoGc23_n6dbc01u6KFsHAt1sWgrJ9m0kdE65pVL1A3HabeA\r\nX-Yahoo-Profile: sajib44new\r\n\r\nThanks a ton.\nI thought, every crawler starts from the seed. Anyway, I gues=\r\ns, for \nHeritrix, they crawl the robots.txt before they crawl the seeds, an=\r\nd \nhence, they need prerequisite crawling.\n\nBottom line:\nAlways use \n\n&quot;org.=\r\narchive.crawler.deciderules.PrerequisiteAcceptDecideRule&quot;\n\nat the end of cr=\r\nawl-order decide rule.\n\n\nSajib\n\n\n--- In archive-crawler@yahoogroups.com, Go=\r\nrdon Mohr &lt;gojomo@...&gt; \nwrote:\n&gt;\n&gt; Sajib Dasgupta wrote:\n&gt; &gt; Hi,\n&gt; &gt; I am u=\r\nsing heritrix-1.14.0-RC1 on Windows.\n&gt; &gt; I can&#39;t add the regular expression=\r\n with the characters like \n(&#39;/&#39;, &#39;~&#39; \n&gt; &gt; etc.) \n&gt; &gt; \n&gt; &gt; My goal is very s=\r\nimple:\n&gt; &gt; =3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=\r\n=3D=3D=3D=3D=3D\n&gt; &gt; I want to crawl either the seed or deeper webpages with=\r\n certain \n&gt; &gt; pattern (.*program.*). \n&gt; &gt; Given the seed of http://www.hlt.=\r\nutdallas.edu/~sajib/, I have \nadded \n&gt; &gt; the following rules in the crawl-o=\r\nrder scope:\n&gt; &gt; \n&gt; &gt;   Reject By Default \norg.archive.crawler.deciderules.R=\r\nejectDecideRule\n&gt; &gt;   Accept If \norg.archive.crawler.deciderules.MatchesReg=\r\nExpDecideRule \n&gt; &gt;                  [Here, I have added the seed as regular=\r\n \nexpression]\n&gt; &gt;   Accept If \norg.archive.crawler.deciderules.MatchesRegEx=\r\npDecideRule \n&gt; &gt;                  [Here, I have added .*program.* as regula=\r\nr \nexpression]\n&gt; \n&gt; You have no rules here to accept the necessary prerequi=\r\nsite URLs \n&gt; Heritrix needs to visit before even visiting your seed. So you=\r\n \nshould \n&gt; add at least a PrerequisiteAcceptDecideRule at the end.\n&gt; \n&gt; St=\r\nill, while your seed would then match the 2nd rule&#39;s regex \n(exactly), \n&gt; I=\r\n don&#39;t see any outlinks on your seed page that have &#39;program&#39; in \nthem. \n&gt; =\r\nSo nothing else would be crawled.\n&gt; \n&gt; Maybe you want to crawl everything &#39;=\r\nunder&#39; (an extension of) \n&gt; http://www.hlt.utdallas.edu/~sajib/ ? In which =\r\ncase make that \nsecond \n&gt; rule a SurtPrefixedDecideRule, with ACCEPT as the=\r\n decision, and \nhave it \n&gt; use the seeds to get the initial acceptable pref=\r\nixes.\n&gt; \n&gt; That will get your seed, plus any other material it discovers at=\r\n \nURLs \n&gt; starting http://www.hlt.utdallas.edu/~sajib/ -- and any &#39;program&#39;=\r\n \nURLs \n&gt; if you leave in your third rule.\n&gt; \n&gt; I highly recommend people d=\r\nesigning their own scopes start with \nthe \n&gt; default and craft it to add/re=\r\nmove other URLs, rather than build \nup from \n&gt; scratch.\n&gt; \n&gt; - Gordon @ IA\n=\r\n&gt; \n&gt; &gt; \n&gt; &gt; I also tried with\n&gt; &gt;   Reject By Default \norg.archive.crawler.=\r\ndeciderules.RejectDecideRule\n&gt; &gt;   Accept If \norg.archive.crawler.deciderul=\r\nes.MatchesRegExpDecideRule \n&gt; &gt;                  [Here, I have added .*prog=\r\nram.* as regular \nexpression]\n&gt; &gt;   Accept If org.archive.crawler.deciderul=\r\nes.SeedAcceptDecideRule\n&gt; &gt; \n&gt; &gt; None of those seems to work. \n&gt; &gt; I thing =\r\nif anyone suggests how to write the regular expression \nin \n&gt; &gt; Heritrix, t=\r\nhat would be just great.\n&gt; &gt; \n&gt; &gt; Thanks,\n&gt; &gt; Sajib\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; ---------=\r\n---------------------------\n&gt; &gt; \n&gt; &gt; Yahoo! Groups Links\n&gt; &gt; \n&gt; &gt; \n&gt; &gt;\n&gt;\n\n\n=\r\n\n"}}