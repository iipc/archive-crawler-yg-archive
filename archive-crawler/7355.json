{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"wKAp_twcoHwaegtEXuS7LY1rW6WQL3XN6XiVumvlaLvRBMevye7GPWZzulHfIRFt-pXKmwcAns5uC-pF-e68r8OGn9BqoUQ","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] H3 - distributed crawling and memory/cpu utilization","postDate":"1318659831","msgId":7355,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRFOTkyNkY3LjgwMDAwMDlAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDRFOThFQTdELjEwODA4MDZAYXJjaGl2ZS5vcmc+","referencesHeader":"PGo3NHMzNCtldWVnQGVHcm91cHMuY29tPiA8NEU5OEVBN0QuMTA4MDgwNkBhcmNoaXZlLm9yZz4="},"prevInTopic":7353,"nextInTopic":7372,"prevInTime":7354,"nextInTime":7356,"topicId":7351,"numMessagesInTopic":7,"msgSnippet":"A few comments interspersed below: ... Yes, to really understand why a crawl might seem stuck, some key things to check are: - the logs, especially the","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 1485 invoked from network); 15 Oct 2011 06:23:58 -0000\r\nX-Received: from unknown (98.137.35.160)\n  by m15.grp.sp2.yahoo.com with QMQP; 15 Oct 2011 06:23:58 -0000\r\nX-Received: from unknown (HELO relay02.pair.com) (209.68.5.16)\n  by mta4.grp.sp2.yahoo.com with SMTP; 15 Oct 2011 06:23:57 -0000\r\nX-Received: (qmail 63071 invoked by uid 0); 15 Oct 2011 06:23:52 -0000\r\nX-Received: from 76.218.213.38 (HELO silverbook.local) (76.218.213.38)\n  by relay02.pair.com with SMTP; 15 Oct 2011 06:23:52 -0000\r\nX-pair-Authenticated: 76.218.213.38\r\nMessage-ID: &lt;4E9926F7.8000009@...&gt;\r\nDate: Fri, 14 Oct 2011 23:23:51 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:7.0.1) Gecko/20110929 Thunderbird/7.0.1\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: david_pane1 &lt;dpane@...&gt;\r\nReferences: &lt;j74s34+eueg@...&gt; &lt;4E98EA7D.1080806@...&gt;\r\nIn-Reply-To: &lt;4E98EA7D.1080806@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] H3 - distributed crawling and memory/cpu utilization\r\nX-Yahoo-Group-Post: member; u=137285340; y=H2ND34m3lm9evTw7QxyFT5kFYAxzIJI76NNt1e2ZhuMo\r\nX-Yahoo-Profile: gojomo\r\n\r\nA few comments interspersed below:\n\nOn 10/14/11 7:05 PM, Noah Levitt wrote:\n&gt;&gt; Increasing the maxToeThreads to a higher value than 1200 causes the\n&gt;&gt; java application to fall to minimal to no cpu usage and the web\n&gt;&gt; interface to be unresponsive.  Does anyone know why this is\n&gt;&gt; happening?\n&gt;\n&gt; Don&#39;t know without looking more closely at the logs and state of the\n&gt; java process when that happens. But 1200 threads for an 11000M heap\n&gt; seems like a lot, maybe too many depending on the rest of your\n&gt; config.\n\nYes, to really understand why a crawl might seem stuck, some key things \nto check are:\n\n- the logs, especially the heritrix_out.log\n- thread status, via either the web UI threads report or Java tools like \n&#39;jstack&#39; (or sending SIGQUIT JVM process)\n\nBut, the rules-of-thumb for memory usage Noah lists are our best \nestimates of memory needs, and by those rules of thumb (5-10MB per \ntoethread, 60% default to BDB, some other space for other structures) \nyour crawl would tend to exceed 11000MB of heap, by at least a little \nand possibly a lot.\n\nThere shouldn&#39;t be anything inherently wrong with 1200 threads (given \nsufficient CPU and RAM), nor with heaps 11GB+. But for comparison, in my \nrecollection, the largest number of threads used in crawls at the \nInternet Archive has been 400 (or maybe 600), and the largest assigned \nheap about 6.5-7GB. There may have been other crawls at IA or elsewhere \nI haven&#39;t heard of, but you are in some lesser-understood territory with \nthese settings.\n\nAnother concern I hear from Java projects which regularly use &gt;4GB or \n &gt;8GB heaps is occasional multiple-minute-long global-GC cycles. Such \npauses generally won&#39;t harm a crawl -- perhaps a remote server will drop \nthe connection, triggering an extra retry of that URL. My understanding \nis that the latest or experimental/optional garbage-collector options \nmay do better with giant heaps -- it&#39;s something to keep in mind and \nperhaps experiment with on such a large heap crawl.\n\n&gt;&gt; 2) One of the 2 crawlers stopped crawling due to a congestion ratio\n&gt;&gt; of infinity.  What are some ways to overcome this? What can I do to\n&gt;&gt; avoid it happening in the future?\n&gt;\n&gt; I don&#39;t know. Not clear what you mean by &quot;stopped&quot; exactly for one\n&gt; thing. If it happens again, maybe gather more information from\n&gt; heritrix_out.log, toe thread report, frontier report, top, iostat,\n&gt; jstack, etc.\n\nA congestion ration of &#39;infinity&#39; just means no threads are active; that \nvalue won&#39;t cause any problems. As Noah notes, understanding what is \nmeant by &#39;stopped&#39; requires more log/process/system analysis.\n\n&gt;&gt; 3) In\n&gt;&gt; http://tech.groups.yahoo.com/group/archive-crawler/message/3846\n&gt;&gt; Gordon stated:\n&gt;&gt;\n&gt;&gt; &quot;... HashCrawlMapper looks at the queue key of a URI -- here, the\n&gt;&gt; SURT authority part, because of the above choice -- and decides if\n&gt;&gt; a URI is handled by the current crawler or one of its siblings. If\n&gt;&gt; mapped to a sibling, the URI is dumped to a log rather than crawled\n&gt;&gt; locally. Depending on the character of your crawl, you may want to\n&gt;&gt; feed these logs to the other crawlers occasionally or it may be OK\n&gt;&gt; to ignore them. ... &quot;\n&gt;&gt;\n&gt;&gt; How does one feed the diverted URIs/logs to a sibling crawler?\n&gt;\n&gt; A coworker kindly put up this page yesterday:\n&gt; https://webarchive.jira.com/wiki/display/Heritrix/Multiple+Machine+Crawling\n&gt;\n&gt;which says, &quot;Crawl operators must set up a process where the the URIs\n&gt; contained in .divert files are copied from each crawler to their\n&gt; assigned crawlers and queued into the active crawl (putting the\n&gt; .divert file in the actions directory as a .include should be\n&gt; sufficient).&quot;\n\nActually, the &#39;.divert&#39; format and the (recovery-log-like) formats \naccepted by the action directory are not equivalent and interchangeable. \n(They probably should be.) So, the process outside the crawler will need \nto massage the diversion logs a bit to make them action-directory ready.\n\nAlso, an &#39;.include&#39; URI list just tells a crawler to consider those URIs \n&#39;already included&#39;. That is, it actually *prevents* those URIs from \nbeing enqueued, from that point onward. Instead, use the &#39;.schedule&#39; \nsuffix to indicate that the URIs in the file should be presented to the \nfrontier, and thus possibly enqueued (if not previously seen).\n\nI&#39;ve corrected the wiki page to indicate a format-conversion and \n&#39;.schedule&#39; file is more appropriate.\n\n- Gordon\n\n"}}