{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"Michael Stack","from":"Michael Stack &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"kkxvn-2tyM68P7W0iaCZ0L-FHjopOiuaY35cMXpl9cu3PmOuxOd146HYN04iKX1pW5XZcXBZ_-SAzdL08OIZctULG2dy7fPW","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Re: Reduce Politeness / Increase Download Rate","postDate":"1149779107","msgId":2930,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ0ODgzQ0EzLjkwMzAwMDNAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGU2ODA3aituaDBhQGVHcm91cHMuY29tPg==","referencesHeader":"PGU2ODA3aituaDBhQGVHcm91cHMuY29tPg=="},"prevInTopic":2927,"nextInTopic":2933,"prevInTime":2929,"nextInTime":2931,"topicId":2923,"numMessagesInTopic":5,"msgSnippet":"... For the special case where you own both ends -- crawler and server -- one thing to try would be writing your own QueueAssignmentPolicy: ","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 46152 invoked from network); 8 Jun 2006 15:04:32 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m14.grp.scd.yahoo.com with QMQP; 8 Jun 2006 15:04:31 -0000\r\nReceived: from unknown (HELO dns.duboce.net) (63.203.238.114)\n  by mta1.grp.scd.yahoo.com with SMTP; 8 Jun 2006 15:04:08 -0000\r\nReceived: from [192.168.1.105] ([192.168.1.105])\n\tby dns-eth1.duboce.net (8.10.2/8.10.2) with ESMTP id k58Dnpv10746;\n\tThu, 8 Jun 2006 06:49:51 -0700\r\nMessage-ID: &lt;44883CA3.9030003@...&gt;\r\nDate: Thu, 08 Jun 2006 08:05:07 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; PPC Mac OS X Mach-O; en-US; rv:1.8.0.1) Gecko/20060127 SeaMonkey/1.0\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;e6807j+nh0a@...&gt;\r\nIn-Reply-To: &lt;e6807j+nh0a@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: Michael Stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] Re: Reduce Politeness / Increase Download Rate\r\nX-Yahoo-Group-Post: member; u=168599281; y=KD5oh8tXjRvN5R5wSf77cdvWK9Xv-9ua8jC8_0Nsu8pI4I4fdINYzdBe\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\njcr2102 wrote:\n&gt;\n&gt;\n&gt; How difficult would it be for me to modify the BDB frontier that ships\n&gt; with Heritrix, such that it will support multiple simultaneous\n&gt; connections to the same host?\n&gt;\n\n\n\n\n\n\n\n\nFor the special case where you own both ends -- crawler and server -- \none thing to try would be writing your own QueueAssignmentPolicy: \nhttp://crawler.archive.org/apidocs/org/archive/crawler/frontier/QueueAssignmentPolicy.html.  \nThe QueueAssignmentPolicy looks at passed URL -- i.e. CandidateURI -- \nand makes a ruling on the queue the URL belongs to.\n\nUsually queue assignment is based on URL domain -- \nSurtAuthorityQueueAssignmentPolicy -- or IP (IPQueueAssignmentPolicy).\n\nAn alternate policy is the BucketQueueAssignmentPolicy: \nhttp://crawler.archive.org/xref/org/archive/crawler/frontier/BucketQueueAssignmentPolicy.html.  \nIt was written by Christian Kohlschuetter.  It has hardcoded number of \nqueues -- 1021 -- and then does a hash on the IP to figure which of the \nqueues/buckets the URL belongs in.  You could make your own version of \nthis policy -- one that hashed the URL itself so you have 1021 queues \nbut in your case, the URLs are all of the same host.\n\nUsing such a policy, you should be able to set hundreds of threads \nrunning against the one server.  Perhaps first start with 2 or 3 threads \nand see how your server holds up.  To make Heritrix see your new policy, \nyou&#39;ll have to add it to the list here: \nhttp://crawler.archive.org/xref/org/archive/crawler/frontier/AbstractFrontier.html#264 \n(We should move this list out to a config. file).\n\nLet us know if it works for you.\nSt.Ack\n\n"}}