{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":361563137,"authorName":"Adam Broke≈°","from":"=?UTF-8?B?QWRhbSBCcm9rZcWh?= &lt;adam.brokes@...&gt;","profile":"goblin_cz","replyTo":"LIST","senderId":"Zqn48v5LvplspEPjZzTw9VQzLL9JkshVtkp7x0v7G4iLGIcIYB3aPLrGOg1E1IQo20FamWOO2EJYEx5a3uwH05GLMRcMuPGQSsttZpqBcvlJHGjYfmu3HpydUQ","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Heritrix does not obey robots.txt rules on particular site","postDate":"1303392508","msgId":7122,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEJBTkxrVGlucUorK3hOY2l3X0UwVD1rQWlGODltYWt4N1RnQG1haWwuZ21haWwuY29tPg==","inReplyToHeader":"PDREQTY1NzIzLjgwNDAxMDdAYXJjaGl2ZS5vcmc+","referencesHeader":"PEJBTkxrVGlrWj1LWmRGdWg3Y3VYLWJuTXdleXpfdmhZZlBnQG1haWwuZ21haWwuY29tPgk8NERBNjI4Q0MuNjA3MDMwNEBhcmNoaXZlLm9yZz4JPDREQTY1NzIzLjgwNDAxMDdAYXJjaGl2ZS5vcmc+"},"prevInTopic":7106,"nextInTopic":0,"prevInTime":7121,"nextInTime":7123,"topicId":7100,"numMessagesInTopic":4,"msgSnippet":"Hi guys, thank you both for explanation. From my experience, webmasters often think the google robots.txt policy as the standard. Maybe the heritrix should","rawEmail":"Return-Path: &lt;adam.brokes@...&gt;\r\nX-Sender: adam.brokes@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 79471 invoked from network); 21 Apr 2011 13:28:29 -0000\r\nX-Received: from unknown (98.137.34.45)\n  by m4.grp.sp2.yahoo.com with QMQP; 21 Apr 2011 13:28:29 -0000\r\nX-Received: from unknown (HELO mail-vx0-f173.google.com) (209.85.220.173)\n  by mta2.grp.sp2.yahoo.com with SMTP; 21 Apr 2011 13:28:29 -0000\r\nX-Received: by vxb41 with SMTP id 41so1586606vxb.32\n        for &lt;archive-crawler@yahoogroups.com&gt;; Thu, 21 Apr 2011 06:28:28 -0700 (PDT)\r\nMIME-Version: 1.0\r\nX-Received: by 10.52.99.194 with SMTP id es2mr4684571vdb.216.1303392508237; Thu,\n 21 Apr 2011 06:28:28 -0700 (PDT)\r\nX-Received: by 10.52.163.201 with HTTP; Thu, 21 Apr 2011 06:28:28 -0700 (PDT)\r\nIn-Reply-To: &lt;4DA65723.8040107@...&gt;\r\nReferences: &lt;BANLkTikZ=KZdFuh7cuX-bnMweyz_vhYfPg@...&gt;\n\t&lt;4DA628CC.6070304@...&gt;\n\t&lt;4DA65723.8040107@...&gt;\r\nDate: Thu, 21 Apr 2011 15:28:28 +0200\r\nX-Google-Sender-Auth: jDHYTRv6XDc7fl5HPr1qGGqct0w\r\nMessage-ID: &lt;BANLkTinqJ++xNciw_E0T=kAiF89makx7Tg@...&gt;\r\nTo: Gordon Mohr &lt;gojomo@...&gt;\r\nCc: archive-crawler &lt;archive-crawler@yahoogroups.com&gt;, Noah Levitt &lt;nlevitt@...&gt;\r\nContent-Type: text/plain; charset=UTF-8\r\nContent-Transfer-Encoding: quoted-printable\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nX-eGroups-From: =?UTF-8?B?QWRhbSBCcm9rZcWh?= &lt;adam@...&gt;\r\nFrom: =?UTF-8?B?QWRhbSBCcm9rZcWh?= &lt;adam.brokes@...&gt;\r\nSubject: Re: [archive-crawler] Heritrix does not obey robots.txt rules on\n particular site\r\nX-Yahoo-Group-Post: member; u=361563137; y=sr4hiE6s7aYnUsadwtY1dX-9bWsaoCKYkFrC6CbDQKM-hNIW\r\nX-Yahoo-Profile: goblin_cz\r\n\r\nHi guys,\n\nthank you both for explanation. From my experience, webmasters of=\r\nten\nthink the google robots.txt policy as the standard. Maybe the heritrix\n=\r\nshould handle this situation.\n\nBest regards,\n\nAdam\n--\nAdam Broke=C5=A1\nhttp=\r\n://www.brokes.net\nadam@...\n\n\n\nOn Thu, Apr 14, 2011 at 4:08 AM, Gordo=\r\nn Mohr &lt;gojomo@...&gt; wrote:\n&gt; However, note that with respect to the=\r\n original formulation of the &#39;Allow&#39;\n&gt; directive, the example site really d=\r\noes allow everything.\n&gt;\n&gt; See section 3.2.3 of:\n&gt;\n&gt; http://www.robotstxt.or=\r\ng/norobots-rfc.txt\n&gt;\n&gt; &quot;To evaluate if access to a URL is allowed, a robot =\r\nmust attempt to match\n&gt; the paths in Allow and Disallow lines against the U=\r\nRL, in the order they\n&gt; occur in the record. The first match found is used.=\r\n&quot;\n&gt;\n&gt; Although our code varies from that spec for certain rule orderings, i=\r\nn this\n&gt; particular case, we&#39;re having the same effect.\n&gt;\n&gt; Also, by any of=\r\n the interpretations, a site never really needs an &quot;Allow: /&quot;\n&gt; directive. =\r\nIn the &quot;first match found&quot; interpretation, it simply serves to\n&gt; disable al=\r\nl later rules of any type by matching all URL paths. (Just\n&gt; deleting the &quot;=\r\nAllow: /&quot; and all later rules would have the same effect,\n&gt; which probably =\r\nisn&#39;t what&#39;s really wanted.) And with the Google/Bing\n&gt; interpretation, the=\r\n &quot;Allow: /&quot; will be overruled by all other longer\n&gt; directives (since &#39;/&#39; i=\r\ns the shortest-possible path, and &#39;allow&#39; is already\n&gt; the default for no-o=\r\nther-matching-rules). It could always be omitted with no\n&gt; change of behavi=\r\nor.\n&gt;\n&gt; Still, I think Heritrix should match the Google/Bing behavior, beca=\r\nuse\n&gt; that&#39;s what webmasters generally come to expect, no matter what the w=\r\nritten\n&gt; specs say, so we&#39;ll fix this. In the meantime, a tip to the webmas=\r\nter that\n&gt; their &quot;Allow: /&quot; rule only confuses Heritrix, and has no effects=\r\n elsewhere,\n&gt; may provide some interim relief.\n&gt;\n&gt; - Gordon @ IA\n&gt;\n&gt; On 4/1=\r\n3/11 3:50 PM, Noah Levitt wrote:\n&gt;&gt;\n&gt;&gt; Hello Adam,\n&gt;&gt;\n&gt;&gt; I think you&#39;re rig=\r\nht, this is a bug. In heritrix, an Allow directive\n&gt;&gt; always overrides a Di=\r\nsallow. Quoting RobotsDirectives.java:\n&gt;&gt;\n&gt;&gt; =C2=A0 =C2=A0 =C2=A0public boo=\r\nlean allows(String path) {\n&gt;&gt; =C2=A0 =C2=A0 =C2=A0 =C2=A0 =C2=A0if(disallow=\r\ns.containsPrefixOf(path)) {\n&gt;&gt; =C2=A0 =C2=A0 =C2=A0 =C2=A0 =C2=A0 =C2=A0 =\r\n=C2=A0return allows.containsPrefixOf(path);\n&gt;&gt; =C2=A0 =C2=A0 =C2=A0 =C2=A0 =\r\n=C2=A0}\n&gt;&gt; =C2=A0 =C2=A0 =C2=A0 =C2=A0 =C2=A0return true;\n&gt;&gt; =C2=A0 =C2=A0 =\r\n=C2=A0}\n&gt;&gt;\n&gt;&gt; However,\n&gt;&gt; https://secure.wikimedia.org/wikipedia/en/wiki/Ro=\r\nbots_exclusion_standard\n&gt;&gt; says, &quot;While by standard implementation the firs=\r\nt matching robots.txt\n&gt;&gt; pattern always wins, Google&#39;s implementation diffe=\r\nrs in that Allow patterns\n&gt;&gt; with equal or more characters in the directive=\r\n path win over a matching\n&gt;&gt; Disallow pattern.[6] Bing uses the Allow or Di=\r\nsallow directive which is the\n&gt;&gt; most specific.[7]&quot;\n&gt;&gt;\n&gt;&gt; It seems logical =\r\nthat the most specific matching rule, Allow or Disallow,\n&gt;&gt; should be the o=\r\nne that applies.\n&gt;&gt; =C2=A0Filedhttps://webarchive.jira.com/browse/HER-1880\n=\r\n&gt;&gt;\n&gt;&gt; Noah\n&gt;&gt;\n&gt;&gt; On 2011-04-13 02:42 , Adam Broke=C5=A1 wrote:\n&gt;&gt;&gt;\n&gt;&gt;&gt; Hi a=\r\nll,\n&gt;&gt;&gt;\n&gt;&gt;&gt; in our broad crawl I came across strange issue with robots.txt.=\r\n\n&gt;&gt;&gt;\n&gt;&gt;&gt; The website http://www.jezise.cz is using robots.txt which contain=\r\ns:\n&gt;&gt;&gt;\n&gt;&gt;&gt; User-agent: *\n&gt;&gt;&gt; Allow: /\n&gt;&gt;&gt; Disallow: /bible21/\n&gt;&gt;&gt; Disallow:=\r\n /downloads/\n&gt;&gt;&gt; Disallow: /stats/\n&gt;&gt;&gt; Sitemap: http://nasledovnici.jezise.=\r\nnet/sitemap.xml\n&gt;&gt;&gt; Sitemap: http://nasledovnici.jezise.net/ucebnice/sitema=\r\np.xml\n&gt;&gt;&gt;\n&gt;&gt;&gt; Even though the Heritrix is set to classic robot honouring po=\r\nlicy, it\n&gt;&gt;&gt; crawls content inside the forbidden directories as can be seen=\r\n from\n&gt;&gt;&gt; the log:\n&gt;&gt;&gt;\n&gt;&gt;&gt; 2011-04-13T09:15:52.303Z =C2=A0 200 =C2=A0 =C2=\r\n=A0 =C2=A0 =C2=A0663\n&gt;&gt;&gt; http://www.jezise.cz/stats/track.php?mode=3Djs E h=\r\nttp://www.jezise.cz/\n&gt;&gt;&gt; text/javascript #195 20110413091552265+37\n&gt;&gt;&gt; sha1=\r\n:MBPGHNW6I7Z4GXREMWZVLPVVP27NYK6Q - - -\n&gt;&gt;&gt;\n&gt;&gt;&gt; I could not figure out why =\r\nis this happening and how it can be solved.\n&gt;&gt;&gt; Is it possible that this is=\r\n some bug?\n&gt;&gt;&gt;\n&gt;&gt;&gt; I am using Heritrix 1.15.5 on Linux and order.xml is in =\r\nattachment.\n&gt;&gt;&gt;\n&gt;&gt;&gt; Thank you.\n&gt;&gt;&gt;\n&gt;&gt;&gt; Kind regards,\n&gt;&gt;&gt; Adam\n&gt;&gt;&gt; --\n&gt;&gt;&gt; Ad=\r\nam Broke=C5=A1\n&gt;&gt;&gt; http://www.brokes.net\n&gt;&gt;&gt; adam@...\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; --=\r\n----------------------------------\n&gt;&gt;&gt;\n&gt;&gt;&gt; Yahoo! Groups Links\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n=\r\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; ------------------------------------\n&gt;&gt;\n&gt;&gt; Yahoo! Groups Links\n&gt;&gt;\n=\r\n&gt;&gt;\n&gt;&gt;\n&gt;\n\n"}}