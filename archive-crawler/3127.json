{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"Michael Stack","from":"Michael Stack &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"X30hM3BtKvPI6U75N7AOtsuxzrt7EmWIiHMe78SXtPCQOYaKyJre1uWoCn7VTsQ3pARS3rqh0jMQxnwPOPENXJ3yUXe1GeWu","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Re: Parallelizing crawler","postDate":"1154029894","msgId":3127,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ0QzkxOTQ2LjIwNzA2MDBAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGVhYjBxOCtkczJzQGVHcm91cHMuY29tPg==","referencesHeader":"PGVhYjBxOCtkczJzQGVHcm91cHMuY29tPg=="},"prevInTopic":3125,"nextInTopic":3128,"prevInTime":3126,"nextInTime":3128,"topicId":3043,"numMessagesInTopic":16,"msgSnippet":"... Sorry.  What do you mean by chores in the above? ... If we add a (JMX?) facility that allowed one crawler to ask the next crawler along the unit-circle","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 40244 invoked from network); 27 Jul 2006 19:51:44 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m38.grp.scd.yahoo.com with QMQP; 27 Jul 2006 19:51:44 -0000\r\nReceived: from unknown (HELO dns.duboce.net) (63.203.238.114)\n  by mta4.grp.scd.yahoo.com with SMTP; 27 Jul 2006 19:51:43 -0000\r\nReceived: from [192.168.1.106] ([192.168.1.106])\n\t(authenticated)\n\tby dns-eth1.duboce.net (8.10.2/8.10.2) with ESMTP id k6RIYrT13135;\n\tThu, 27 Jul 2006 11:34:53 -0700\r\nMessage-ID: &lt;44C91946.2070600@...&gt;\r\nDate: Thu, 27 Jul 2006 12:51:34 -0700\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686 (x86_64); en-US; rv:1.8.0.4) Gecko/20060516 SeaMonkey/1.0.2\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;eab0q8+ds2s@...&gt;\r\nIn-Reply-To: &lt;eab0q8+ds2s@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: Michael Stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] Re: Parallelizing crawler\r\nX-Yahoo-Group-Post: member; u=168599281; y=Cjz7RCmHYmjW50vDK8VDqWZyy-0zDZ6l9LqmMFqo_BJymYBW3V0KwXMf\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\nmolzbh wrote:\n&gt;\n&gt; Hi\n&gt;\n&gt; We recently started plying around with the distributed architecture, I\n&gt; employed a Peer system, similar to how Sharad described. I am however\n&gt; favoring plain RMI over JMX on RMI connectors, I might even have to\n&gt; cut down some more chores to cut down on a node load.\n&gt;\n\n\n\n\n\n\n\n\n\nSorry.  What do you mean by &#39;chores&#39; in the above?\n\n\n&gt;\n&gt; A node heartbeat mechanism is maintained to keep the Hash functions\n&gt; synced across the nodes and to maintain the global noe information,\n&gt; however, this is a new problem : In dynamic setup when the number of\n&gt; agents leave/join, how does one ensure DeDuplication. The Already Seen\n&gt; list from the frontiers is not shared, as a result a new node might\n&gt; refetch a URL already fetched by another node. (It is sometimes not\n&gt; easy to visualize how? I can feed in more details). Any ideas on that\n&gt; front.\n&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf we add a (JMX?) facility that allowed one crawler to ask the next \ncrawler along the unit-circle if it had already-seen an URL, or a set of \nURLs, then it should be possible to implement the Page Recovery protocol \noutlined in 6.1.1. of the Ubicrawler paper \n[http://vigna.dsi.unimi.it/ftp/papers/UbiCrawler.pdf].  Pros: A \ndistributed already-seen db.  Later in the ubicrawler paper, it argues \nthat its hard to avoid a degree of duplication in the case of transient \nnode failures (See 6 Performance Evaluation, Overlap).  You might \nconsider this a &#39;Con&#39;. \n\nA central already-seen that all crawlers queried would avoid duplicates \nbut would be hard to scale.\n\nDo you foresee lots of churn in the number of crawling agents? \n\nSt.Ack\n\n\n\n\n\n&gt;\n&gt; I guess we might have to scale to 4-5 boxes to fetch the billion+\n&gt; mark, and hence this is an issue of concern.\n&gt;\n&gt; regards,\n&gt; Anmol\n&gt;\n&gt; --- In archive-crawler@yahoogroups.com \n&gt; &lt;mailto:archive-crawler%40yahoogroups.com&gt;, Michael Stack &lt;stack@...&gt; \n&gt; wrote:\n&gt; &gt;\n&gt; &gt; Sharad Agarwal wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; stack@... &lt;mailto:stack%40archive.org&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; &gt;Sharad Agarwal wrote:\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; ...\n&gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt; &gt; &gt;+ Did you use the ubicrawler ConsistentHashFunction\n&gt; implementation that\n&gt; &gt; &gt; &gt;is in Heritrix in the dsi.unimi.it jar or did you use something else?\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; yes. the same one.\n&gt; &gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; Be warned we recently removed the colt jar from Heritrix. We longer\n&gt; &gt; needed it. IIRC, its needed by CHF. Let us know and can add it back.\n&gt; &gt;\n&gt; &gt; Thanks for the update.\n&gt; &gt; St.Ack\n&gt; &gt;\n&gt;\n&gt;  \n\n\n"}}