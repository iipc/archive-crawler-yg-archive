{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":165458231,"authorName":"Bjarne Andersen","from":"Bjarne Andersen &lt;bja@...&gt;","profile":"bjarne_dk2000","replyTo":"LIST","senderId":"L6mrNXa9---1JgdrlSq_qi0QgBjdoFr516VAWLBmLBtxTTI8eUVNoLQ6Cpp_veaH3D1uzjbNbb3ZDEsrw1Xm5EOgrCcJXywm_8gRkEnRx88","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] JMX importUri not causing more crawling","postDate":"1118294587","msgId":1932,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQyQTdEMjNCLjQwMzA4MDVAc3RhdHNiaWJsaW90ZWtldC5kaz4=","inReplyToHeader":"PDQyQTdCQjBDLjUwODA3MDRAYXJjaGl2ZS5vcmc+","referencesHeader":"PDlkMWU0NTI1MDUwNjA4MTgwMTE5NDBmNTY2QG1haWwuZ21haWwuY29tPiA8NDJBN0JCMEMuNTA4MDcwNEBhcmNoaXZlLm9yZz4="},"prevInTopic":1931,"nextInTopic":1933,"prevInTime":1931,"nextInTime":1933,"topicId":1930,"numMessagesInTopic":7,"msgSnippet":"Sounds like Matt needs a new JMX call: importURIandIncludeInScope(...) to be able to import URI s just as if they had been in seeds.txt ? Is it possible to add","rawEmail":"Return-Path: &lt;bja@...&gt;\r\nX-Sender: bja@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 17342 invoked from network); 9 Jun 2005 05:23:10 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m30.grp.scd.yahoo.com with QMQP; 9 Jun 2005 05:23:10 -0000\r\nReceived: from unknown (HELO luna.statsbiblioteket.dk) (130.225.24.87)\n  by mta6.grp.scd.yahoo.com with SMTP; 9 Jun 2005 05:23:09 -0000\r\nReceived: from [130.225.25.67] (pc975.sb.statsbiblioteket.dk [130.225.25.67])\n by luna.statsbiblioteket.dk\n (iPlanet Messaging Server 5.2 HotFix 1.16 (built May 14 2003))\n with ESMTP id &lt;0IHS00I87XMJYF@...&gt; for\n archive-crawler@yahoogroups.com; Thu, 09 Jun 2005 07:23:07 +0200 (MEST)\r\nDate: Thu, 09 Jun 2005 07:23:07 +0200\r\nIn-reply-to: &lt;42A7BB0C.5080704@...&gt;\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-id: &lt;42A7D23B.4030805@...&gt;\r\nOrganization: Statsbiblioteket\r\nMIME-version: 1.0\r\nContent-type: multipart/mixed; boundary=&quot;Boundary_(ID_AxXVyYEcEs5HDIy2oNXEqw)&quot;\r\nX-Accept-Language: en-us, en\r\nUser-Agent: Mozilla Thunderbird 1.0 (X11/20041206)\r\nReferences: &lt;9d1e452505060818011940f566@...&gt;\n &lt;42A7BB0C.5080704@...&gt;\r\nX-eGroups-Msg-Info: 1:12:0\r\nFrom: Bjarne Andersen &lt;bja@...&gt;\r\nSubject: Re: [archive-crawler] JMX importUri not causing more crawling\r\nX-Yahoo-Group-Post: member; u=165458231; y=X81dVquZ3NxcIiUot7zhF2BISnwXTqtKM5NO8m_PnVDYPE9FpMqpRw\r\nX-Yahoo-Profile: bjarne_dk2000\r\n\r\n\r\n--Boundary_(ID_AxXVyYEcEs5HDIy2oNXEqw)\r\nContent-type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-transfer-encoding: 8BIT\r\n\r\nSounds like Matt needs a new JMX call: importURIandIncludeInScope(...)\nto be able to import URI&#39;s just as if they had been in seeds.txt ?\n\nIs it possible to add URI&#39;s as SURT&#39;s only (as in seeds.txt / SURT-scope) ?\n\nbest\nBjarne Andersen\n\nstack wrote:\n&gt; Matt Ittigson wrote:\n&gt; \n&gt;  &gt; I&#39;m using the importURI JMX call to add sites to a running job.  I&#39;ve\n&gt;  &gt; wrapped the cmdline-jmxclient in a perl script which depending on the\n&gt;  &gt; level of activity, adds more URL&#39;s to the job.  The problem is, the\n&gt;  &gt; threads don&#39;t seem to actually crawl the newly added URL&#39;s.  I&#39;m using\n&gt;  &gt; the BdbFrontier and PathScrope.  I&#39;m limiting the host-based queue&#39;s\n&gt;  &gt; to 200 URL&#39;s, and the Frontier queue&#39;s are all exhausted.  But I&#39;m\n&gt;  &gt; setting the forceFetch to true and I&#39;d be very surprised if every\n&gt;  &gt; single newly added URL would sort into an existing exhausted queue.\n&gt; \n&gt; And for sure the added URLs are in scope?  (You can enable logging of\n&gt; all rejected on the Postselector -- or if you&#39;re using a recent HEAD, on\n&gt; LinksScoper).\n&gt; \n&gt; What if you add URLs that have already been crawled (See the\n&gt; crawl.log).   If  you add these w/ forceFetch, are they not being crawled?\n&gt; \n&gt; Try adding URLs as for-sure in-scope seeds.  Do these get crawled?\n&gt; \n&gt; Let me know.  This needs to be working for us in short order so if\n&gt; you&#39;re having problems, I&#39;m interested.\n&gt; \n&gt; Thanks for writing the list.\n&gt; St.Ack\n&gt; \n&gt;  &gt;\n&gt;  &gt; Is there something I can do or someway to reconfigure the crawler so\n&gt;  &gt; that I can add URL&#39;s to a running job and have them crawled?\n&gt;  &gt;\n&gt;  &gt; Thanks in advance.\n&gt;  &gt;\n&gt;  &gt; -matt\n&gt;  &gt;\n&gt;  &gt; ------------------------------------------------------------------------\n&gt;  &gt; *Yahoo! Groups Links*\n&gt;  &gt;\n&gt;  &gt;     * To visit your group on the web, go to:\n&gt;  &gt;       http://groups.yahoo.com/group/archive-crawler/\n&gt;  &gt;       \n&gt;  &gt;     * To unsubscribe from this group, send an email to:\n&gt;  &gt;       archive-crawler-unsubscribe@yahoogroups.com\n&gt;  &gt;       \n&gt; &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;  &gt;       \n&gt;  &gt;     * Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;  &gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;.\n&gt;  &gt;\n&gt;  &gt;\n&gt; \n&gt; \n&gt; ------------------------------------------------------------------------\n&gt; *Yahoo! Groups Links*\n&gt; \n&gt;     * To visit your group on the web, go to:\n&gt;       http://groups.yahoo.com/group/archive-crawler/\n&gt;        \n&gt;     * To unsubscribe from this group, send an email to:\n&gt;       archive-crawler-unsubscribe@yahoogroups.com\n&gt;       &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;        \n&gt;     * Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;. \n&gt; \n&gt; \n\n-- \nBjarne Andersen\nIT-udvikler\n\nSTATSBIBLIOTEKET\nUniversitetsparken\n8000 ï¿½rhus C\nTlf. 89462165 - Mobil 28713889\nCVR/SE 10100682 - EAN 5798000791084\nhttp://statsbiblioteket.dk\n\r\n--Boundary_(ID_AxXVyYEcEs5HDIy2oNXEqw)\r\nContent-type: text/x-vcard; charset=utf-8; name=bja.vcf\r\nContent-disposition: attachment; filename=bja.vcf\r\n\r\n[ Attachment content not displayed ]\r\n--Boundary_(ID_AxXVyYEcEs5HDIy2oNXEqw)--\r\n\n"}}