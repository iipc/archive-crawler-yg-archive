{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"&quot;Gordon Mohr&quot; &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"-y-nU1HPpLxkG2S30UMkxKg0tu4X7QktdtEPYOZzn1F7onOUMp0VjfHfXzAyuzlw7A1O1q-G1RYOs-YAGdnDkTy-xaWhDl0EkA","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: Web crawler work ??","postDate":"1045872475","msgId":12,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDAwZGMwMWMyZGEwNyQ2NmVlMTM2MCQzYWViZWRkMUBnb2pvdmFpbz4=","referencesHeader":"PDM3ZWQwMWMyZDczNCQ0ZjQ0NjliMCRkNTAwYThjMEBSZWRkeUdCPiA8MDM4MDAxYzJkN2I2JDJjMTIxZjAwJDNhZWJlZGQxQGdvam92YWlvPiA8M2ZlMDAxYzJkOWM3JGU1OGE0YTgwJGQ1MDBhOGMwQFJlZGR5R0I+"},"prevInTopic":0,"nextInTopic":13,"prevInTime":11,"nextInTime":13,"topicId":12,"numMessagesInTopic":6,"msgSnippet":"[CC ing to archive-crawler@yahoogroups.com] ... This looks like a good first cut. I m still working to improve my understanding of the best way to use the","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (EGP: mail-8_2_3_4); 22 Feb 2003 00:17:28 -0000\r\nReceived: (qmail 44443 invoked from network); 22 Feb 2003 00:17:28 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m7.grp.scd.yahoo.com with QMQP; 22 Feb 2003 00:17:28 -0000\r\nReceived: from unknown (HELO mail.archive.org) (209.237.232.3)\n  by mta2.grp.scd.yahoo.com with SMTP; 22 Feb 2003 00:17:28 -0000\r\nReceived: from gojovaio (dynamic-44.archive.org [209.237.235.44])\n\tby mail.archive.org (8.10.2/8.10.2) with SMTP id h1LNdnm14025;\n\tFri, 21 Feb 2003 15:39:49 -0800\r\nMessage-ID: &lt;00dc01c2da07$66ee1360$3aebedd1@gojovaio&gt;\r\nTo: &quot;G.B.Reddy&quot; &lt;reddy@...&gt;\r\nCc: &quot;Raymie Stata&quot; &lt;raymie@...&gt;, &lt;wcr-team@...&gt;,\n   &lt;archive-crawler@yahoogroups.com&gt;\r\nReferences: &lt;37ed01c2d734$4f4469b0$d500a8c0@ReddyGB&gt; &lt;038001c2d7b6$2c121f00$3aebedd1@gojovaio&gt; &lt;3fe001c2d9c7$e58a4a80$d500a8c0@ReddyGB&gt;\r\nSubject: Re: Web crawler work ??\r\nDate: Fri, 21 Feb 2003 16:07:55 -0800\r\nMIME-Version: 1.0\r\nContent-Type: text/plain;\n\tcharset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: 7bit\r\nX-Priority: 3\r\nX-MSMail-Priority: Normal\r\nX-Mailer: Microsoft Outlook Express 6.00.2720.3000\r\nX-MimeOLE: Produced By Microsoft MimeOLE V6.00.2600.0000\r\nFrom: &quot;Gordon Mohr&quot; &lt;gojomo@...&gt;\r\nX-Yahoo-Group-Post: member; u=137285340\r\nX-Yahoo-Profile: gojomo\r\n\r\n[CC&#39;ing to archive-crawler@yahoogroups.com]\n\nReddy writes:\n\n&gt; On the first cut do we need to look at implementing an asynchronous DNS\n&gt; lookup mechanism. If we are not, then it is going to be two stages, viz.\n&gt; DNSCacheHandlingStage and ResolvingStage, that can be employed using the\n&gt; blocking DNS lookup calls in Java. The first stage, DNSCacheHandlingStage,\n&gt; would check if the entry is available in the cache. If available, he would\n&gt; set the resolved address in the CrawlURI object and enqueue it to the\n&gt; appropriate next stage. If the cache doesn&#39;t contain the entry, then he\n&gt; would pass the request to the Resolving stage which would call the\n&gt; InetAddress.getByName blocking method to resolve it. The getByName result\n&gt; would be set in the CrawlURI object as before and enqueued into the\n&gt; appropriate next stage. In addition to this, the Resolving stage will\n&gt; enqueue another event into the DNSCacheHandlingStage to enable him update\n&gt; his cache. So, the DNSCacheHandlingStage would be handling two types of\n&gt; events, one is the lookup events and the other is the update cache events.\n&gt; \n&gt; One problem here is that the InetAddress class does not expose its cache\n&gt; variables to its users. Even we cannot check if the cache has an entry\n&gt; before calling the getByName method. So, we should be disabling the java\n&gt; cache ( using the policy file ) and implementing our own caching mechanism.\n&gt; ( The DNSCacheHandlingStage would have to additionally do the job of\n&gt; throwing away the expired entries in the cache also.)\n&gt; \n&gt; Let me know your comments on this.\n\nThis looks like a good first cut. I&#39;m still working to improve my \nunderstanding of the best way to use the staged style, mostly by\nlooking at their HTTP and HTTP Server (Haboob) code. \n\nIt seems that they&#39;ve tended to use a single Stage object to do \nmany different steps/aspects of one process, by switching on the\ntype of QueueElement received. \n\nSo for example their seda.sandStorm.seda.apps.Haboob.http.HttpRecv \naccepts events of types....\n\n  - httpConnection\n  - httpRequest\n  - SinkClosedEvent\n  - timerEvent\n\nAnd their seda.sandStorm.lib.http.httpServer accepts events of\ntypes...\n\n  - ATcpInPacket\n  - ATcpConnection\n  - aSocketErrorEvent\n  - SinkDrainedEvent\n  - SinkCloggedEvent\n  - SinkClosedEvent\n  - ATcpListenSuccessEvent\n\nThey also use Sinks that are not associated with stages; rather,\nthey interface to unstaged components which nonetheless result in \nan eventual event to some supplied answer Sink. See for example\nseda.sandStorm.lib.http.httpConnection.\n\nSo perhaps as a matter of grouping related tasks, the same Stage object \nshould be re-entered over the course of a lookup, with different triggering \nevents. For example, you might want to reenter a single DNSResolvingStage\nover the course of cache lookup, lookup-initiation, result-receiving (or\ntimeout), etc. I&#39;m not sure; use your judgement as to how many stages are \nreally needed.\n\n&gt; P.S : We found some openly available async dns client APIs in C language.\n\nThat could be useful as a model. (I doubt we&#39;d want to call out to C\nfor this simple step, though -- and if we nailed down a truly async Java \nDNS facility, a lot of open source projects would probably be quite happy.)\n\nAlso: I heard back from Patrick Eaton about SEDA-style async HTTP client\ncode... he has a rough implementation for simple usage, and he knows of \nanother one at Berkeley which goes deeper into HTTP/1.1 conformance and\noptimal performance. I&#39;ve asked him to forward whatever additional code\nor details he can.\n\n- Gordon\n\n\n\n"}}