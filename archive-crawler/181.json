{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"AEpt-YUueU8JjjA3J-uSHkKy4vQ0M9fjmQ6NqfY339yd_VPD-mL7NGOVIVghl05zHKbIFa9fmjxAFQHDPXbJlslzgpyAZGY","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Crawl of 907 danish seeds","postDate":"1069721406","msgId":181,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDNGQzJBNzNFLjkwMjAyMDZAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDIwMDMxMTI0MTMzMjE5LjEzMDMyLnFtYWlsQHdlYjI1MjA4Lm1haWwudWtsLnlhaG9vLmNvbT4=","referencesHeader":"PDIwMDMxMTI0MTMzMjE5LjEzMDMyLnFtYWlsQHdlYjI1MjA4Lm1haWwudWtsLnlhaG9vLmNvbT4="},"prevInTopic":180,"nextInTopic":182,"prevInTime":180,"nextInTime":182,"topicId":180,"numMessagesInTopic":4,"msgSnippet":"Thanks for this report; these are curious results, and we ll want to track down every place where an expected URI/resource was missed. Was the code grabbed","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 14298 invoked from network); 25 Nov 2003 00:50:09 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m20.grp.scd.yahoo.com with QMQP; 25 Nov 2003 00:50:09 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (209.237.232.202)\n  by mta2.grp.scd.yahoo.com with SMTP; 25 Nov 2003 00:50:07 -0000\r\nReceived: (qmail 11410 invoked by uid 100); 25 Nov 2003 00:50:04 -0000\r\nReceived: from b116-dyn-43.archive.org (HELO archive.org) (gojomo@...@209.237.240.43)\n  by ia00524.archive.org with SMTP; 25 Nov 2003 00:50:04 -0000\r\nMessage-ID: &lt;3FC2A73E.9020206@...&gt;\r\nDate: Mon, 24 Nov 2003 16:50:06 -0800\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.5) Gecko/20031014 Thunderbird/0.3\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nSubject: Re: [archive-crawler] Crawl of 907 danish seeds\r\nReferences: &lt;20031124133219.13032.qmail@...&gt;\r\nIn-Reply-To: &lt;20031124133219.13032.qmail@...&gt;\r\nContent-Type: text/plain; charset=windows-1252; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nX-Spam-Status: No, hits=-5.4 required=6.0\n\ttests=AWL,BAYES_10,EMAIL_ATTRIBUTION,IN_REP_TO,REFERENCES,\n\t      REPLY_WITH_QUOTES,USER_AGENT_MOZILLA_UA\n\tversion=2.55\r\nX-Spam-Level: \r\nX-Spam-Checker-Version: SpamAssassin 2.55 (1.174.2.19-2003-05-19-exp)\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nX-Yahoo-Group-Post: member; u=137285340\r\nX-Yahoo-Profile: gojomo\r\n\r\nThanks for this report; these are curious results, and we&#39;ll\nwant to track down every place where an expected URI/resource was\nmissed.\n\nWas the code grabbed from CVS and built just prior to the run?\n(We are still making significant destabilizing changes regularly.)\n\nWhat configuration options were used? (Can you forward your crawl-order\nfile?) What command-line was used to launch the crawler?\n\nWithout listing all the seeds, can you say whether they were always\nsite roots (http://www.site.org) or sometimes other entry pages\n(http://www.site.org/subsection/)?\n\nSteen Christensen wrote:\n &gt; Total number of seed URLï¿½s: 907\n &gt;\n &gt; Harvest start: 11.11.2003-17\n &gt; Harverst end: 14.11.2003-12\n &gt;\n &gt; Harvest time: 67 hours\n &gt;\n &gt; Total amount of data harvested: 4 GB (compressed), 14 GB (uncompressed)\n\nHow many total resources were successfully collected?\n\nDid the crawler run out of pages to crawl, or hit an error or user-abort?\n\nThe current version of Heritrix will still eventually hit, and be\nstopped, by memory-footprint limits.\n\nHow soon these limits are hit depend on the available memory, diversity\nof URIs crawled, and whether you&#39;ve enabled the experimental disk-based\nstructure for tracking &quot;alreadyIncluded&quot; items. (This is currently done\nin code, in the Frontier class initialization method.)\n\nUsing the in-memory only implementation (MemLongFPSet), on a 2GB crawl\nmachine, we recently ran a crawl of ~250 sites which gathered 4.8 million\nURIs over 3 days before hitting implementation problems.\n\nHowever, in order to run that long, we had to disable the ExtractorDOC\nand ExtractorPDF processors (which have unresolved memory-overuse bugs)\nand set the expiration of IP and robots info to 3 days (because the\nrefetching of this info after it expires is currently unreliable).\n\n &gt; Coverage analysis:\n &gt;\n &gt; 367 (40% of the 907) seed URLs were investigated more closely.\n &gt; 265 of these were valid sites that should be harvested.\n &gt; 101 (38%) were completely missed by the harvester.\n\nThis is the most surprising result; any URI listed in the seeds\nshould definitely be visited by the crawler. Were there errors\nevident in the logs for the seed sites missed?\n\n(I would check the crawl.log first. If a negative error code is\nassociated with the URI of interest, you have to look up its\nmeaning in the FetchStatusCodes class -- at least until we\nmove to better, more symbolic/mnemonic error codes. Barring any\nuseful info there, you can also check the runtime-errors.log\nand the local-errors.log to see if unexpected errors thwarted\nnormal processing.)\n\n &gt; Observed problems:\n &gt;\n &gt; Relative image URLs seem not to be stored\n &gt;\n &gt; Example:\n &gt; &lt;img src=&quot;../Images/logo.gif&quot; alt=&quot;Logo&quot;&gt;\n\nI will look into this further. Keep in mind that when you find\nspecific, reproduceable bugs, you may enter them directly into\nthe project bug-tracking system at:\n\n    https://sourceforge.net/tracker/?func=browse&group_id=73833&atid=539099\n\n &gt; Complex framesets:\n &gt;\n &gt; Example:\n &gt;\n &gt;                       http://www.centrumdemokraterne.dk\n &gt; &lt;http://www.centrumdemokraterne.dk/&gt; (center frame not crawled)\n &gt; http://www.chilinet.dk &lt;http://www.chilinet.dk/&gt;\n\nI suspect this might be other problems (perhaps evident in\nthe logs) affecting the given frame URIs, rather than a problem\nwith frameset parsing, but I will investigate further.\n\n\n &gt; A large number of city-sites using the same framework were not harvested:\n &gt;\n &gt;                       http://www.bynet.dk &lt;http://www.bynet.dk/&gt;\n &gt;                       http://esbjerg.bynet.dk/\n\nWere there errors in the logs explaining why the seed/roots\nfailed?\n\n &gt; Explicit port definitions seem to confuse Heritrix\n &gt;\n &gt;                       http://dk.yahoo.com:80 &lt;http://dk.yahoo.com/&gt;\n\nDo you mean sites were collected twice, or not at all with\nsome error?\n\n &gt; PDF files seem not to be stored correctly (Word files are OK.).\n\nBefore a bug in the ReplayInputStream was fixed on November 17, all\ncontent byte values &gt; 127 were being corrupted when sent to\nARC files.\n\n- Gordon\n\n\n\n\n"}}