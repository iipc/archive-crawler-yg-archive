{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":211021528,"authorName":"waisovsky","from":"&quot;waisovsky&quot; &lt;miro786@...&gt;","profile":"waisovsky","replyTo":"LIST","senderId":"tqqhyxp7UTaoDREcfxzqAqOMu2p6cLAu77jOOB9QuEfHv_iEBSDKWgvt9NeVm-14oxE5wCSd_oHzbd1bEbXGSU0qggxx0w","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Scalability in Heritrix","postDate":"1204187490","msgId":5012,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZxNXJoMisycHN0QGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":5013,"prevInTime":5011,"nextInTime":5013,"topicId":5012,"numMessagesInTopic":2,"msgSnippet":"Hi i was wondering if Heritrix is scalable. I suppose it surely is as it s used so widely. My problem was however that I ran a crawl on a site but t took","rawEmail":"Return-Path: &lt;miro786@...&gt;\r\nX-Sender: miro786@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 53240 invoked from network); 28 Feb 2008 08:31:30 -0000\r\nX-Received: from unknown (66.218.67.95)\n  by m43.grp.scd.yahoo.com with QMQP; 28 Feb 2008 08:31:30 -0000\r\nX-Received: from unknown (HELO n31a.bullet.sp1.yahoo.com) (209.131.38.208)\n  by mta16.grp.scd.yahoo.com with SMTP; 28 Feb 2008 08:31:30 -0000\r\nX-Received: from [216.252.122.219] by n31.bullet.sp1.yahoo.com with NNFMP; 28 Feb 2008 08:31:30 -0000\r\nX-Received: from [209.73.164.83] by t4.bullet.sp1.yahoo.com with NNFMP; 28 Feb 2008 08:31:30 -0000\r\nX-Received: from [66.218.66.90] by t7.bullet.scd.yahoo.com with NNFMP; 28 Feb 2008 08:31:30 -0000\r\nDate: Thu, 28 Feb 2008 08:31:30 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;fq5rh2+2pst@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;waisovsky&quot; &lt;miro786@...&gt;\r\nSubject: Scalability in Heritrix\r\nX-Yahoo-Group-Post: member; u=211021528; y=s-eR9BEteqNQqwA2l8_QQNUejSLjGhq34jrUQs1Sy7pp-g\r\nX-Yahoo-Profile: waisovsky\r\n\r\nHi\n\ni was wondering if Heritrix is scalable. I suppose it surely is as\nit&#39;s=\r\n used so widely. My problem was however that I ran a crawl on a\nsite but t =\r\ntook really long time-or showed at least &quot;150 days left&quot;\nand it was still g=\r\nrowing. Then I thought it might be job configuration\nproblem.\n\nI am therefo=\r\nre going to briefly describe what i want to crawl:\nsite name: www.xyz.com\np=\r\nages of interest: \n- www.xyz.com/members.* (i.e. prefixed with www.xyz.com/=\r\nmembers)\n- www.xyz.com/journal.*\n- www.xyz.com/location.*\n\n-----seed file:-=\r\n---------------------\nhttp://www.xyz.com/members\n+http://(com,xyz,www,)/jou=\r\nrnal\n+http://(com,xyz,www,)/memebers\n+http://(com,xyz,www,)/location\n------=\r\n-------------------------------\n\nSo the idea was to crawl this site and whe=\r\nnever I find a url which\nmatch those mentioned, scrape the information cont=\r\nained in that page\n(by a writer processor).\n\nMy problem was however after 2=\r\n weeks, that there were no space left\nfrom 20 GB and it showed really long =\r\ntime to complete the crawl.\n\nWhat do you gys think, is that a problem of jo=\r\nb/profile configuartion?\n\nbtw, here is the order.xml:\n\n\n&lt;?xml version=3D&quot;1.=\r\n0&quot; encoding=3D&quot;UTF-8&quot;?&gt;&lt;crawl-order\nxmlns:xsi=3D&quot;http://www.w3.org/2001/XML=\r\nSchema-instance&quot;\nxsi:noNamespaceSchemaLocation=3D&quot;heritrix_settings.xsd&quot;&gt;\n =\r\n &lt;meta&gt;\n    &lt;name&gt;XYZ&lt;/name&gt;\n    &lt;description&gt;XYZ&lt;/description&gt;\n    &lt;operat=\r\nor&gt;Admin&lt;/operator&gt;\n    &lt;organization/&gt;\n    &lt;audience/&gt;\n    &lt;date&gt;200801291=\r\n05458&lt;/date&gt;\n  &lt;/meta&gt;\n  &lt;controller&gt;\n    &lt;string name=3D&quot;settings-director=\r\ny&quot;&gt;settings&lt;/string&gt;\n    &lt;string name=3D&quot;disk-path&quot;/&gt;\n    &lt;string name=3D&quot;l=\r\nogs-path&quot;&gt;logs&lt;/string&gt;\n    &lt;string name=3D&quot;checkpoints-path&quot;&gt;checkpoints&lt;/=\r\nstring&gt;\n    &lt;string name=3D&quot;state-path&quot;&gt;state&lt;/string&gt;\n    &lt;string name=3D&quot;=\r\nscratch-path&quot;&gt;scratch&lt;/string&gt;\n    &lt;long name=3D&quot;max-bytes-download&quot;&gt;0&lt;/lon=\r\ng&gt;\n    &lt;long name=3D&quot;max-document-download&quot;&gt;0&lt;/long&gt;\n    &lt;long name=3D&quot;max-=\r\ntime-sec&quot;&gt;0&lt;/long&gt;\n    &lt;integer name=3D&quot;max-toe-threads&quot;&gt;100&lt;/integer&gt;\n    =\r\n&lt;integer name=3D&quot;recorder-out-buffer-bytes&quot;&gt;4096&lt;/integer&gt;\n    &lt;integer nam=\r\ne=3D&quot;recorder-in-buffer-bytes&quot;&gt;65536&lt;/integer&gt;\n    &lt;integer name=3D&quot;bdb-cac=\r\nhe-percent&quot;&gt;0&lt;/integer&gt;\n    &lt;newObject name=3D&quot;scope&quot;\nclass=3D&quot;org.archive.=\r\ncrawler.deciderules.DecidingScope&quot;&gt;\n      &lt;boolean name=3D&quot;enabled&quot;&gt;true&lt;/b=\r\noolean&gt;\n      &lt;string name=3D&quot;seedsfile&quot;&gt;seeds.txt&lt;/string&gt;\n      &lt;boolean =\r\nname=3D&quot;reread-seeds-on-config&quot;&gt;true&lt;/boolean&gt;\n      &lt;newObject name=3D&quot;dec=\r\nide-rules&quot;\nclass=3D&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n  =\r\n      &lt;map name=3D&quot;rules&quot;&gt;\n          &lt;newObject name=3D&quot;regexMatch&quot;\nclass=\r\n=3D&quot;org.archive.crawler.deciderules.MatchesRegExpDecideRule&quot;&gt;\n            &lt;=\r\nstring name=3D&quot;decision&quot;&gt;ACCEPT&lt;/string&gt;\n            &lt;string name=3D&quot;regexp=\r\n&quot;&gt;.*xyz.com.*&lt;/string&gt;\n          &lt;/newObject&gt;\n          &lt;newObject name=3D&quot;=\r\nSurt&quot;\nclass=3D&quot;org.archive.crawler.deciderules.SurtPrefixedDecideRule&quot;&gt;\n   =\r\n         &lt;string name=3D&quot;decision&quot;&gt;ACCEPT&lt;/string&gt;\n            &lt;string name=\r\n=3D&quot;surts-source-file&quot;/&gt;\n            &lt;boolean name=3D&quot;seeds-as-surt-prefixe=\r\ns&quot;&gt;true&lt;/boolean&gt;\n            &lt;string name=3D&quot;surts-dump-file&quot;/&gt;\n          =\r\n  &lt;boolean name=3D&quot;also-check-via&quot;&gt;false&lt;/boolean&gt;\n            &lt;boolean nam=\r\ne=3D&quot;rebuild-on-reconfig&quot;&gt;true&lt;/boolean&gt;\n          &lt;/newObject&gt;\n        &lt;/m=\r\nap&gt;\n      &lt;/newObject&gt;\n    &lt;/newObject&gt;\n    &lt;map name=3D&quot;http-headers&quot;&gt;\n   =\r\n   &lt;string name=3D&quot;user-agent&quot;&gt;Mozilla/5.0 (compatible;\nheritrix/1.12.1+htt=\r\np://www.www.com)&lt;/string&gt;\n      &lt;string name=3D&quot;from&quot;&gt;some@...&lt;/strin=\r\ng&gt;\n    &lt;/map&gt;\n    &lt;newObject name=3D&quot;robots-honoring-policy&quot;\nclass=3D&quot;org.a=\r\nrchive.crawler.datamodel.RobotsHonoringPolicy&quot;&gt;\n      &lt;string name=3D&quot;type&quot;=\r\n&gt;ignore&lt;/string&gt;\n      &lt;boolean name=3D&quot;masquerade&quot;&gt;false&lt;/boolean&gt;\n      &lt;=\r\ntext name=3D&quot;custom-robots&quot;/&gt;\n      &lt;stringList name=3D&quot;user-agents&quot;&gt;\n     =\r\n &lt;/stringList&gt;\n    &lt;/newObject&gt;\n    &lt;newObject name=3D&quot;frontier&quot;\nclass=3D&quot;o=\r\nrg.archive.crawler.frontier.BdbFrontier&quot;&gt;\n      &lt;float name=3D&quot;delay-factor=\r\n&quot;&gt;4.0&lt;/float&gt;\n      &lt;integer name=3D&quot;max-delay-ms&quot;&gt;20000&lt;/integer&gt;\n      &lt;i=\r\nnteger name=3D&quot;min-delay-ms&quot;&gt;2000&lt;/integer&gt;\n      &lt;integer name=3D&quot;max-retr=\r\nies&quot;&gt;30&lt;/integer&gt;\n      &lt;long name=3D&quot;retry-delay-seconds&quot;&gt;900&lt;/long&gt;\n     =\r\n &lt;integer name=3D&quot;preference-embed-hops&quot;&gt;1&lt;/integer&gt;\n      &lt;integer name=3D=\r\n&quot;total-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n      &lt;integer name=3D&quot;max-per-h=\r\nost-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n      &lt;string\nname=3D&quot;queue-assignm=\r\nent-policy&quot;&gt;org.archive.crawler.frontier.HostnameQueueAssignmentPolicy&lt;/str=\r\ning&gt;\n      &lt;string name=3D&quot;force-queue-assignment&quot;/&gt;\n      &lt;boolean name=3D=\r\n&quot;pause-at-start&quot;&gt;false&lt;/boolean&gt;\n      &lt;boolean name=3D&quot;pause-at-finish&quot;&gt;fa=\r\nlse&lt;/boolean&gt;\n      &lt;boolean name=3D&quot;source-tag-seeds&quot;&gt;false&lt;/boolean&gt;\n    =\r\n  &lt;boolean name=3D&quot;recovery-log-enabled&quot;&gt;true&lt;/boolean&gt;\n      &lt;boolean name=\r\n=3D&quot;hold-queues&quot;&gt;true&lt;/boolean&gt;\n      &lt;integer name=3D&quot;balance-replenish-am=\r\nount&quot;&gt;3000&lt;/integer&gt;\n      &lt;integer name=3D&quot;error-penalty-amount&quot;&gt;100&lt;/inte=\r\nger&gt;\n      &lt;long name=3D&quot;queue-total-budget&quot;&gt;-1&lt;/long&gt;\n      &lt;string\nname=\r\n=3D&quot;cost-policy&quot;&gt;org.archive.crawler.frontier.UnitCostAssignmentPolicy&lt;/str=\r\ning&gt;\n      &lt;long name=3D&quot;snooze-deactivate-ms&quot;&gt;300000&lt;/long&gt;\n      &lt;integer=\r\n name=3D&quot;target-ready-backlog&quot;&gt;50&lt;/integer&gt;\n      &lt;string\nname=3D&quot;uri-inclu=\r\nded-structure&quot;&gt;org.archive.crawler.util.BdbUriUniqFilter&lt;/string&gt;\n    &lt;/new=\r\nObject&gt;\n    &lt;map name=3D&quot;uri-canonicalization-rules&quot;&gt;\n      &lt;newObject name=\r\n=3D&quot;lc&quot;\nclass=3D&quot;org.archive.crawler.url.canonicalize.LowercaseRule&quot;&gt;\n     =\r\n   &lt;boolean name=3D&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n      &lt;/newObject&gt;\n      &lt;newOb=\r\nject name=3D&quot;WWW&quot;\nclass=3D&quot;org.archive.crawler.url.canonicalize.StripWWWRul=\r\ne&quot;&gt;\n        &lt;boolean name=3D&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n      &lt;/newObject&gt;\n   =\r\n &lt;/map&gt;\n    &lt;map name=3D&quot;pre-fetch-processors&quot;&gt;\n      &lt;newObject name=3D&quot;Pr=\r\neselector&quot;\nclass=3D&quot;org.archive.crawler.prefetch.Preselector&quot;&gt;\n        &lt;boo=\r\nlean name=3D&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n        &lt;newObject name=3D&quot;Preselector=\r\n#decide-rules&quot;\nclass=3D&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;=\r\n&gt;\n          &lt;map name=3D&quot;rules&quot;&gt;\n          &lt;/map&gt;\n        &lt;/newObject&gt;\n    =\r\n    &lt;boolean name=3D&quot;override-logger&quot;&gt;false&lt;/boolean&gt;\n        &lt;boolean name=\r\n=3D&quot;recheck-scope&quot;&gt;false&lt;/boolean&gt;\n        &lt;boolean name=3D&quot;block-all&quot;&gt;fals=\r\ne&lt;/boolean&gt;\n        &lt;string name=3D&quot;block-by-regexp&quot;/&gt;\n        &lt;string name=\r\n=3D&quot;allow-by-regexp&quot;&gt;.*xyz.*&lt;/string&gt;\n      &lt;/newObject&gt;\n      &lt;newObject n=\r\name=3D&quot;Preprocessor&quot;\nclass=3D&quot;org.archive.crawler.prefetch.PreconditionEnfo=\r\nrcer&quot;&gt;\n        &lt;boolean name=3D&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n        &lt;newObject =\r\nname=3D&quot;Preprocessor#decide-rules&quot;\nclass=3D&quot;org.archive.crawler.deciderules=\r\n.DecideRuleSequence&quot;&gt;\n          &lt;map name=3D&quot;rules&quot;&gt;\n          &lt;/map&gt;\n     =\r\n   &lt;/newObject&gt;\n        &lt;integer name=3D&quot;ip-validity-duration-seconds&quot;&gt;2160=\r\n0&lt;/integer&gt;\n        &lt;integer name=3D&quot;robot-validity-duration-seconds&quot;&gt;86400=\r\n&lt;/integer&gt;\n        &lt;boolean name=3D&quot;calculate-robots-only&quot;&gt;false&lt;/boolean&gt;\n=\r\n      &lt;/newObject&gt;\n    &lt;/map&gt;\n    &lt;map name=3D&quot;fetch-processors&quot;&gt;\n      &lt;ne=\r\nwObject name=3D&quot;HTTP&quot;\nclass=3D&quot;org.archive.crawler.fetcher.FetchHTTP&quot;&gt;\n    =\r\n    &lt;boolean name=3D&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n        &lt;newObject name=3D&quot;HTT=\r\nP#decide-rules&quot;\nclass=3D&quot;org.archive.crawler.deciderules.DecideRuleSequence=\r\n&quot;&gt;\n          &lt;map name=3D&quot;rules&quot;&gt;\n            &lt;newObject name=3D&quot;regex&quot;\ncla=\r\nss=3D&quot;org.archive.crawler.deciderules.MatchesRegExpDecideRule&quot;&gt;\n           =\r\n   &lt;string name=3D&quot;decision&quot;&gt;ACCEPT&lt;/string&gt;\n              &lt;string name=3D&quot;=\r\nregexp&quot;&gt;.*xyz.*&lt;/string&gt;\n            &lt;/newObject&gt;\n          &lt;/map&gt;\n        =\r\n&lt;/newObject&gt;\n        &lt;newObject name=3D&quot;midfetch-decide-rules&quot;\nclass=3D&quot;org=\r\n.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n          &lt;map name=3D&quot;ru=\r\nles&quot;&gt;\n          &lt;/map&gt;\n        &lt;/newObject&gt;\n        &lt;integer name=3D&quot;timeou=\r\nt-seconds&quot;&gt;1200&lt;/integer&gt;\n        &lt;integer name=3D&quot;sotimeout-ms&quot;&gt;20000&lt;/int=\r\neger&gt;\n        &lt;integer name=3D&quot;fetch-bandwidth&quot;&gt;0&lt;/integer&gt;\n        &lt;long n=\r\name=3D&quot;max-length-bytes&quot;&gt;0&lt;/long&gt;\n        &lt;boolean name=3D&quot;ignore-cookies&quot;&gt;=\r\nfalse&lt;/boolean&gt;\n        &lt;boolean name=3D&quot;use-bdb-for-cookies&quot;&gt;true&lt;/boolean=\r\n&gt;\n        &lt;string name=3D&quot;load-cookies-from-file&quot;/&gt;\n        &lt;string name=3D=\r\n&quot;save-cookies-to-file&quot;/&gt;\n        &lt;string name=3D&quot;trust-level&quot;&gt;open&lt;/string&gt;=\r\n\n        &lt;stringList name=3D&quot;accept-headers&quot;&gt;\n        &lt;/stringList&gt;\n       =\r\n &lt;string name=3D&quot;http-proxy-host&quot;/&gt;\n        &lt;string name=3D&quot;http-proxy-port=\r\n&quot;/&gt;\n        &lt;string name=3D&quot;default-encoding&quot;&gt;ISO-8859-1&lt;/string&gt;\n        &lt;=\r\nboolean name=3D&quot;digest-content&quot;&gt;true&lt;/boolean&gt;\n        &lt;string name=3D&quot;dige=\r\nst-algorithm&quot;&gt;sha1&lt;/string&gt;\n        &lt;boolean name=3D&quot;send-if-modified-since=\r\n&quot;&gt;true&lt;/boolean&gt;\n        &lt;boolean name=3D&quot;send-if-none-match&quot;&gt;true&lt;/boolean=\r\n&gt;\n        &lt;boolean name=3D&quot;send-connection-close&quot;&gt;true&lt;/boolean&gt;\n        &lt;b=\r\noolean name=3D&quot;send-referer&quot;&gt;true&lt;/boolean&gt;\n        &lt;boolean name=3D&quot;send-r=\r\nange&quot;&gt;false&lt;/boolean&gt;\n        &lt;string name=3D&quot;bind-address&quot;/&gt;\n      &lt;/newOb=\r\nject&gt;\n      &lt;newObject name=3D&quot;DNS&quot; class=3D&quot;org.archive.crawler.fetcher.Fe=\r\ntchDNS&quot;&gt;\n        &lt;boolean name=3D&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n        &lt;newObjec=\r\nt name=3D&quot;DNS#decide-rules&quot;\nclass=3D&quot;org.archive.crawler.deciderules.Decide=\r\nRuleSequence&quot;&gt;\n          &lt;map name=3D&quot;rules&quot;&gt;\n          &lt;/map&gt;\n        &lt;/ne=\r\nwObject&gt;\n        &lt;boolean name=3D&quot;accept-non-dns-resolves&quot;&gt;false&lt;/boolean&gt;\n=\r\n        &lt;boolean name=3D&quot;digest-content&quot;&gt;true&lt;/boolean&gt;\n        &lt;string nam=\r\ne=3D&quot;digest-algorithm&quot;&gt;sha1&lt;/string&gt;\n      &lt;/newObject&gt;\n    &lt;/map&gt;\n    &lt;map=\r\n name=3D&quot;extract-processors&quot;&gt;\n      &lt;newObject name=3D&quot;ExtractorHTML&quot;\nclass=\r\n=3D&quot;org.archive.crawler.extractor.ExtractorHTML&quot;&gt;\n        &lt;boolean name=3D&quot;=\r\nenabled&quot;&gt;true&lt;/boolean&gt;\n        &lt;newObject name=3D&quot;ExtractorHTML#decide-rul=\r\nes&quot;\nclass=3D&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n         =\r\n &lt;map name=3D&quot;rules&quot;&gt;\n          &lt;/map&gt;\n        &lt;/newObject&gt;\n        &lt;boolea=\r\nn name=3D&quot;extract-javascript&quot;&gt;true&lt;/boolean&gt;\n        &lt;boolean name=3D&quot;treat=\r\n-frames-as-embed-links&quot;&gt;true&lt;/boolean&gt;\n        &lt;boolean name=3D&quot;ignore-form=\r\n-action-urls&quot;&gt;false&lt;/boolean&gt;\n        &lt;boolean name=3D&quot;overly-eager-link-de=\r\ntection&quot;&gt;true&lt;/boolean&gt;\n        &lt;boolean name=3D&quot;ignore-unexpected-html&quot;&gt;tr=\r\nue&lt;/boolean&gt;\n      &lt;/newObject&gt;\n    &lt;/map&gt;\n    &lt;map name=3D&quot;write-processor=\r\ns&quot;&gt;\n\t&lt;!- this is an ad-hoc writer for this crawl-&gt;\n      &lt;newObject name=3D=\r\n&quot;Sql&quot; class=3D&quot;org.archive.crawler.writer.sqlWriter&quot;&gt;\n        &lt;boolean name=\r\n=3D&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n        &lt;newObject name=3D&quot;Sql#decide-rules&quot;\ncl=\r\nass=3D&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n          &lt;map =\r\nname=3D&quot;rules&quot;&gt;\n          &lt;/map&gt;\n        &lt;/newObject&gt;\n      &lt;/newObject&gt;\n  =\r\n  &lt;/map&gt;\n    &lt;map name=3D&quot;post-processors&quot;&gt;\n      &lt;newObject name=3D&quot;Update=\r\nr&quot;\nclass=3D&quot;org.archive.crawler.postprocessor.CrawlStateUpdater&quot;&gt;\n        &lt;=\r\nboolean name=3D&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n        &lt;newObject name=3D&quot;Updater#=\r\ndecide-rules&quot;\nclass=3D&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;=\r\n\n          &lt;map name=3D&quot;rules&quot;&gt;\n          &lt;/map&gt;\n        &lt;/newObject&gt;\n     =\r\n &lt;/newObject&gt;\n      &lt;newObject name=3D&quot;LinksScoper&quot;\nclass=3D&quot;org.archive.cr=\r\nawler.postprocessor.LinksScoper&quot;&gt;\n        &lt;boolean name=3D&quot;enabled&quot;&gt;true&lt;/b=\r\noolean&gt;\n        &lt;newObject name=3D&quot;LinksScoper#decide-rules&quot;\nclass=3D&quot;org.a=\r\nrchive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n          &lt;map name=3D&quot;rule=\r\ns&quot;&gt;\n          &lt;/map&gt;\n        &lt;/newObject&gt;\n        &lt;boolean name=3D&quot;override=\r\n-logger&quot;&gt;false&lt;/boolean&gt;\n        &lt;boolean name=3D&quot;seed-redirects-new-seed&quot;&gt;=\r\ntrue&lt;/boolean&gt;\n        &lt;integer name=3D&quot;preference-depth-hops&quot;&gt;-1&lt;/integer&gt;=\r\n\n        &lt;newObject name=3D&quot;scope-rejected-url-rules&quot;\nclass=3D&quot;org.archive.=\r\ncrawler.deciderules.DecideRuleSequence&quot;&gt;\n          &lt;map name=3D&quot;rules&quot;&gt;\n   =\r\n       &lt;/map&gt;\n        &lt;/newObject&gt;\n      &lt;/newObject&gt;\n      &lt;newObject name=\r\n=3D&quot;FrontierScheduler&quot;\nclass=3D&quot;org.archive.crawler.postprocessor.FrontierS=\r\ncheduler&quot;&gt;\n        &lt;boolean name=3D&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n        &lt;newObj=\r\nect name=3D&quot;FrontierScheduler#decide-rules&quot;\nclass=3D&quot;org.archive.crawler.de=\r\nciderules.DecideRuleSequence&quot;&gt;\n          &lt;map name=3D&quot;rules&quot;&gt;\n          &lt;/m=\r\nap&gt;\n        &lt;/newObject&gt;\n      &lt;/newObject&gt;\n    &lt;/map&gt;\n    &lt;map name=3D&quot;log=\r\ngers&quot;&gt;\n    &lt;/map&gt;\n    &lt;string name=3D&quot;recover-path&quot;&gt;...&#92;logs&#92;recover.gz&lt;/st=\r\nring&gt;\n    &lt;boolean name=3D&quot;checkpoint-copy-bdbje-logs&quot;&gt;true&lt;/boolean&gt;\n    &lt;=\r\nboolean name=3D&quot;recover-retain-failures&quot;&gt;false&lt;/boolean&gt;\n    &lt;newObject nam=\r\ne=3D&quot;credential-store&quot;\nclass=3D&quot;org.archive.crawler.datamodel.CredentialSto=\r\nre&quot;&gt;\n      &lt;map name=3D&quot;credentials&quot;&gt;\n      &lt;/map&gt;\n    &lt;/newObject&gt;\n  &lt;/con=\r\ntroller&gt;\n&lt;/crawl-order&gt;\n\n\n\n"}}