{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":91078969,"authorName":"Jigar Patel","from":"&quot;Jigar Patel&quot; &lt;jigar_bca@...&gt;","profile":"jigar_bca","replyTo":"LIST","senderId":"5k6iH__pcXDp37w1h7aD34bSEWkspmmxSCBudgtWBC_iGMFts0UGD-STNDFM2_G8pOcvTODNZXwTjsikhpqpwet7z1wgENgmbzE","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Distributed Crawling","postDate":"1182861292","msgId":4361,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGY1cjE1YytlaW41QGVHcm91cHMuY29tPg==","inReplyToHeader":"PDQ1RTM0NzkzLjkwODA1MDRAYXJjaGl2ZS5vcmc+"},"prevInTopic":4229,"nextInTopic":4364,"prevInTime":4360,"nextInTime":4362,"topicId":3834,"numMessagesInTopic":26,"msgSnippet":"Presently I am running two heritrix instances on the same machine on different port... I am using decidingScope and inside it I apply SurtPrefixRule I added","rawEmail":"Return-Path: &lt;jigar_bca@...&gt;\r\nX-Sender: jigar_bca@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 68113 invoked from network); 26 Jun 2007 12:35:17 -0000\r\nReceived: from unknown (66.218.66.68)\n  by m43.grp.scd.yahoo.com with QMQP; 26 Jun 2007 12:35:17 -0000\r\nReceived: from unknown (HELO n31.bullet.scd.yahoo.com) (66.94.237.25)\n  by mta11.grp.scd.yahoo.com with SMTP; 26 Jun 2007 12:35:16 -0000\r\nReceived: from [209.73.164.86] by n31.bullet.scd.yahoo.com with NNFMP; 26 Jun 2007 12:34:52 -0000\r\nReceived: from [66.218.66.83] by t8.bullet.scd.yahoo.com with NNFMP; 26 Jun 2007 12:34:52 -0000\r\nDate: Tue, 26 Jun 2007 12:34:52 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;f5r15c+ein5@...&gt;\r\nIn-Reply-To: &lt;45E34793.9080504@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;Jigar Patel&quot; &lt;jigar_bca@...&gt;\r\nSubject: Re: Distributed Crawling\r\nX-Yahoo-Group-Post: member; u=91078969; y=iGOLJM5XKQSIAZnH36lUb4RGZmuPxXVa2HM0TCI9WuNXLxKR\r\nX-Yahoo-Profile: jigar_bca\r\n\r\n\nPresently I am running two heritrix instances on the same machine on \ndiff=\r\nerent port...\n\nI am using decidingScope and inside it I apply SurtPrefixRul=\r\ne\nI added HashCrawlMapper at two places as you suggested\nI made same config=\r\nuration setting and seed file at each place.\n\nBut as I run my job it gives =\r\nme following error in seed file and \nnothing was crawled.\n\nHeritrix(-5002)-=\r\nBlocked by custom prefetch processor \n\nPlease let me know why I am getting =\r\nsuch error...\n\nIs anything missing ?\n\nRegards,\n\nJigar Patel\n\n--- In archive=\r\n-crawler@yahoogroups.com, Gordon Mohr &lt;gojomo@...&gt; \nwrote:\n&gt;\n&gt; nt_bdr wrote=\r\n:\n&gt; &gt; Can Heretrix 1.10.2 be used as a distributed crawler?\n&gt; \n&gt; In a crude=\r\n fashion, yes. It is more manual and less dynamic than we \n&gt; would like, bu=\r\nt at IA we&#39;ve run crawls over up to 6 machines (&gt;600 \n&gt; million URLs visite=\r\nd), and know of work elsewhere over up to 8 \nmachines \n&gt; (&gt;1 billion URLs f=\r\netched).\n&gt; \n&gt; For background see some previous threads including:\n&gt; \n&gt;    h=\r\nttp://tech.groups.yahoo.com/group/archive-crawler/message/2909\n&gt;    http://=\r\ntech.groups.yahoo.com/group/archive-crawler/message/3060\n&gt; \n&gt; Roughly how w=\r\ne do it:\n&gt; \n&gt;   - Use BloomFilterUriUniqFilter with its defaults -- which d=\r\nevotes \n&gt; about 500MB to this structure and keeps the false-positive \n(mist=\r\nakenly \n&gt; believed to have been previously-scheduled) rate under 1-in-4-\nmi=\r\nllion up \n&gt; through 125 million URIs discovered.\n&gt; \n&gt;   - Use 3-6 crawlers =\r\n(constant number per crawl), each with ~1.8GB+ \nheap\n&gt; \n&gt;   - Use SurtAutho=\r\nrityAssignmentPolicy, so URIs are grouped in \nqueues \n&gt; named by the revers=\r\ned-host (com,example,) rather than usual host \n&gt; (example.com)\n&gt; \n&gt;   - Ins=\r\nert HashCrawlMapper processors at 2 places in the processor \nchain:\n&gt; \n&gt;   =\r\n  * Once, immediately before the PreconditionEnforcer. This one \nhas \n&gt; &#39;ch=\r\neck-uri&#39; true but &#39;check-outlinks&#39; false. (It diverts any \nscheduled \n&gt; URI=\r\ns that should be handled by other crawlers -- chiefly seeds.)\n&gt;     * Again=\r\n, immediately before the FrontierScheduler. This one has \n&gt; &#39;check-uri&#39; fal=\r\nse and &#39;check-outlinks&#39; true. (It diverts any \ndiscovered \n&gt; outlinks befor=\r\ne they are scheduled.)\n&gt; \n&gt;     Both HashCrawlMappers should have the same =\r\n&#39;local-name&#39; (a \nnumber 0 \n&gt; to n-1, where n is the nubmer of crawlers in u=\r\nse) per machine, and \nall \n&gt; machines should have the same &#39;crawler-count&#39; =\r\n(number of crawlers, \nn).\n&gt; \n&gt;     HashCrawlMapper looks at the queue key o=\r\nf a URI -- here, the \nSURT \n&gt; authority part, because of the above choice -=\r\n- and decides if a URI \nis \n&gt; handled by the current crawler or one of its =\r\nsiblings. If mapped to \na \n&gt; sibling, the URI is dumped to a log rather tha=\r\nn crawled locally. \n&gt; Depending on the character of your crawl, you may wan=\r\nt to feed \nthese \n&gt; logs to the other crawlers occasionally or it may be OK=\r\n to ignore \nthem.\n&gt; \n&gt;     The &#39;reduce-prefix-pattern&#39; may be used to trim =\r\nthe queue key \nbefore \n&gt; mapping -- used to ensure that all subdomains of e=\r\nxample.com are \ntreated \n&gt; the same as example.com for mapping purposes. Th=\r\ne first match of \nthis \n&gt; pattern, if present, is what is used for mapping =\r\npurposes. A small \n&gt; example would be:\n&gt; \n&gt;     ^((&#92;w&#92;w&#92;w,&#92;w*)|[&#92;w,]{9})\n&gt; =\r\n\n&gt;     For 3-letter domains (com, org, net), this uses everything \nthrough =\r\n\n&gt; the 2nd-level domain for mapping purposes. For everything else, it \nuses=\r\n \n&gt; the first 9 characters. You could imagine more complicated patterns \nth=\r\nat \n&gt; take into account other TLDs. (For example, some 2-letter TLDs, \nlike=\r\n \n&gt; &#39;fr&#39;, assign 2nd-level domains; others, like &#39;uk&#39;, assign 3rd-level \n&gt; =\r\ndomains.)\n&gt; \n&gt;    - All crawlers are launched with the same configuration, =\r\n\nincluding \n&gt; the same seeds, but otherwise do not (themselves) communicate=\r\n. \nSeeds \n&gt; that don&#39;t belong on any one crawler are dropped out by the ear=\r\nly \n&gt; HashCrawlMapper. Discovered outlinks logs that need to be cross-fed \n=\r\nare \n&gt; done so by an external process/scripts.\n&gt; \n&gt; - Gordon @ IA\n&gt;\n\n\n\n"}}