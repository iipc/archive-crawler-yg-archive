{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"stack","from":"stack &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"X0S7CxekPebLSYYiVQX2pA6kHDlT-ABwRhRLXAUlopubM8CNGrrN0gbZsnkd30NnwsfMRSc1hw_C459mOyHGWw","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Heritrix dies after a few URLs when started from within program","postDate":"1111454381","msgId":1681,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQyM0Y3MkFELjkwMjA3MDNAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDExMTE0MjM3NjQuMzk1NS4zMS5jYW1lbEBwYzk3Ny5zYi5zdGF0c2JpYmxpb3Rla2V0LmRrPg==","referencesHeader":"PDExMTE0MjM3NjQuMzk1NS4zMS5jYW1lbEBwYzk3Ny5zYi5zdGF0c2JpYmxpb3Rla2V0LmRrPg=="},"prevInTopic":1680,"nextInTopic":1700,"prevInTime":1680,"nextInTime":1682,"topicId":1680,"numMessagesInTopic":5,"msgSnippet":"... Looks to me as though any thread that sends a notifyAll -- for example, when the crawler unpauses to start up crawling in HostQueuesFrontier -- will cause","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 71553 invoked from network); 22 Mar 2005 01:28:54 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m30.grp.scd.yahoo.com with QMQP; 22 Mar 2005 01:28:54 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (207.241.224.172)\n  by mta6.grp.scd.yahoo.com with SMTP; 22 Mar 2005 01:28:54 -0000\r\nReceived: (qmail 19131 invoked by uid 100); 22 Mar 2005 01:11:04 -0000\r\nReceived: from debord.archive.org (HELO ?207.241.238.140?) (stack@...@207.241.238.140)\n  by mail-dev.archive.org with SMTP; 22 Mar 2005 01:11:04 -0000\r\nMessage-ID: &lt;423F72AD.9020703@...&gt;\r\nDate: Mon, 21 Mar 2005 17:19:41 -0800\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.7.3) Gecko/20041007 Debian/1.7.3-5\r\nX-Accept-Language: en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;1111423764.3955.31.camel@...&gt;\r\nIn-Reply-To: &lt;1111423764.3955.31.camel@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: *\r\nX-Spam-Status: No, hits=1.0 required=6.0 tests=AWL,CLICK_BELOW,HTML_30_40,\n\tHTML_MESSAGE autolearn=no version=2.63\r\nX-eGroups-Msg-Info: 1:12:0\r\nFrom: stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] Heritrix dies after a few URLs when started\n from within program\r\nX-Yahoo-Group-Post: member; u=168599281\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\nLars Clausen wrote:\n\n&gt; Hi!\n&gt;\n&gt; ...What kinds of events\n&gt; could cause Heritrix to suddenly give up the spirit like that?\n&gt;\n....\n\n&gt;         synchronized (this) {\n&gt;             try {\n&gt;                 wait(); // wait for the crawl to finish\n&gt;             } catch (InterruptedException e) {\n&gt;                 throw new IOFailure(&quot;Heritrix process interrupted&quot;,e);\n&gt;             }\n&gt;         }\n&gt;         logger.fine(&quot;Ending crawl..&quot;);\n&gt;     }\n\nLooks to me as though any thread that sends a notifyAll -- for example, \nwhen the crawler unpauses to start up crawling in HostQueuesFrontier -- \nwill cause your program to exit.  Perhaps add a check that its actually \ntime to exit.\n\nI tried your order w/ the below class and it crawled fine (I added a new \nparam to &#39;Heritrix#doOneCrawl&#39; -- effectively same as your doOneCrawl \nmethod -- so its now possible to pass in a listener and notice when the \ncrawl is done).\n\nHope this helps,\nSt.Ack\n\npublic class Embedded {\n    private static boolean exit = false;\n    public static void main(String[] args)\n    throws IOException, InvalidAttributeValueException,\n    InitializationException, InterruptedException {\n        Heritrix h = new Heritrix();\n        h.doOneCrawl(&quot;/tmp/order.xml&quot;, new CrawlStatusListener() {\n            public void crawlStarted(String message) {\n            }\n\n            public void crawlEnding(String sExitMessage) {\n            }\n\n            public void crawlEnded(String sExitMessage) {\n                Embedded.exit = true;\n            }\n\n            public void crawlPausing(String statusMessage) {\n            }\n\n            public void crawlPaused(String statusMessage) {\n            }\n\n            public void crawlResuming(String statusMessage) {\n            }}\n        );\n       \n        while(Embedded.exit) {\n            Thread.currentThread().wait();\n        }\n    }\n}\n\n \n\n&gt;\n&gt;\n&gt; *Yahoo! Groups Sponsor*\n&gt; ADVERTISEMENT\n&gt; click here \n&gt; &lt;http://us.ard.yahoo.com/SIG=129t52ltp/M=298184.6191685.7192823.3001176/D=groups/S=1705004924:HM/EXP=1111510168/A=2593423/R=0/SIG=11el9gslf/*http://www.netflix.com/Default?mqso=60190075&gt; \n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------------------------------------------\n&gt; *Yahoo! Groups Links*\n&gt;\n&gt;     * To visit your group on the web, go to:\n&gt;       http://groups.yahoo.com/group/archive-crawler/\n&gt;        \n&gt;     * To unsubscribe from this group, send an email to:\n&gt;       archive-crawler-unsubscribe@yahoogroups.com\n&gt;       &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;        \n&gt;     * Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;.\n&gt;\n&gt;\n&gt;------------------------------------------------------------------------\n&gt;\n&gt;&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&gt;\n&gt;&lt;crawl-order xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;heritrix_settings.xsd&quot;&gt;\n&gt;  &lt;meta&gt;\n&gt;    &lt;name&gt;Simple&lt;/name&gt;\n&gt;    &lt;description&gt;Profile: Simple crawl&lt;/description&gt;\n&gt;    &lt;operator&gt;Admin&lt;/operator&gt;\n&gt;    &lt;organization/&gt;\n&gt;    &lt;audience/&gt;\n&gt;    &lt;date&gt;20040409202922&lt;/date&gt;\n&gt;  &lt;/meta&gt;\n&gt;  &lt;controller&gt;\n&gt;    &lt;string name=&quot;settings-directory&quot;&gt;settings&lt;/string&gt;\n&gt;    &lt;string name=&quot;disk-path&quot;&gt;/tmp/releasetest-run/./data/42_1111422206116&lt;/string&gt;\n&gt;    &lt;string name=&quot;scratch-path&quot;&gt;scratch&lt;/string&gt;\n&gt;    &lt;string name=&quot;state-path&quot;&gt;state&lt;/string&gt;\n&gt;    &lt;string name=&quot;logs-path&quot;&gt;logs&lt;/string&gt;\n&gt;    &lt;string name=&quot;checkpoints-path&quot;&gt;checkpoints&lt;/string&gt;\n&gt;    &lt;integer name=&quot;max-toe-threads&quot;&gt;50&lt;/integer&gt;\n&gt;    &lt;long name=&quot;max-bytes-download&quot;&gt;0&lt;/long&gt;\n&gt;    &lt;long name=&quot;max-document-download&quot;&gt;0&lt;/long&gt;\n&gt;    &lt;long name=&quot;max-time-sec&quot;&gt;0&lt;/long&gt;\n&gt;    &lt;newObject name=&quot;scope&quot; class=&quot;org.archive.crawler.scope.DomainScope&quot;&gt;\n&gt;      &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;      &lt;string name=&quot;seedsfile&quot;&gt;/tmp/releasetest-run/./data/42_1111422206116/seeds.txt&lt;/string&gt;\n&gt;      &lt;integer name=&quot;max-link-hops&quot;&gt;25&lt;/integer&gt;\n&gt;      &lt;integer name=&quot;max-trans-hops&quot;&gt;5&lt;/integer&gt;\n&gt;      &lt;newObject name=&quot;exclude-filter&quot; class=&quot;org.archive.crawler.filter.OrFilter&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;boolean name=&quot;if-matches-return&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;&gt;\n&gt;          &lt;newObject name=&quot;pathdepth&quot; class=&quot;org.archive.crawler.filter.PathDepthFilter&quot;&gt;\n&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;            &lt;integer name=&quot;max-path-depth&quot;&gt;20&lt;/integer&gt;\n&gt;            &lt;boolean name=&quot;path-less-or-equal-return&quot;&gt;false&lt;/boolean&gt;\n&gt;          &lt;/newObject&gt;\n&gt;          &lt;newObject name=&quot;pathologicalpath&quot; class=&quot;org.archive.crawler.filter.PathologicalPathFilter&quot;&gt;\n&gt;            &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;            &lt;integer name=&quot;repetitions&quot;&gt;3&lt;/integer&gt;\n&gt;          &lt;/newObject&gt;\n&gt;        &lt;/map&gt;\n&gt;      &lt;/newObject&gt;\n&gt;      &lt;newObject name=&quot;additionalScopeFocus&quot; class=&quot;org.archive.crawler.filter.FilePatternFilter&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;boolean name=&quot;if-match-return&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;string name=&quot;use-default-patterns&quot;&gt;All&lt;/string&gt;\n&gt;        &lt;string name=&quot;regexp&quot;/&gt;\n&gt;      &lt;/newObject&gt;\n&gt;      &lt;newObject name=&quot;transitiveFilter&quot; class=&quot;org.archive.crawler.filter.TransclusionFilter&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;integer name=&quot;max-speculative-hops&quot;&gt;1&lt;/integer&gt;\n&gt;        &lt;integer name=&quot;max-referral-hops&quot;&gt;-1&lt;/integer&gt;\n&gt;        &lt;integer name=&quot;max-embed-hops&quot;&gt;-1&lt;/integer&gt;\n&gt;      &lt;/newObject&gt;\n&gt;    &lt;/newObject&gt;\n&gt;    &lt;map name=&quot;http-headers&quot;&gt;\n&gt;      &lt;string name=&quot;user-agent&quot;&gt;Mozilla/5.0 (compatible; heritrix/1.2.0 +http://www.netarkivet.dk)&lt;/string&gt;\n&gt;      &lt;string name=&quot;from&quot;&gt;netarkivet@...&lt;/string&gt;\n&gt;    &lt;/map&gt;\n&gt;    &lt;newObject name=&quot;robots-honoring-policy&quot; class=&quot;org.archive.crawler.datamodel.RobotsHonoringPolicy&quot;&gt;\n&gt;      &lt;string name=&quot;type&quot;&gt;classic&lt;/string&gt;\n&gt;      &lt;boolean name=&quot;masquerade&quot;&gt;false&lt;/boolean&gt;\n&gt;      &lt;text name=&quot;custom-robots&quot;/&gt;\n&gt;      &lt;stringList name=&quot;user-agents&quot;/&gt;\n&gt;    &lt;/newObject&gt;\n&gt;    &lt;newObject name=&quot;frontier&quot; class=&quot;org.archive.crawler.frontier.HostQueuesFrontier&quot;&gt;\n&gt;      &lt;float name=&quot;delay-factor&quot;&gt;5.0&lt;/float&gt;\n&gt;      &lt;integer name=&quot;max-delay-ms&quot;&gt;5000&lt;/integer&gt;\n&gt;      &lt;integer name=&quot;min-delay-ms&quot;&gt;500&lt;/integer&gt;\n&gt;      &lt;integer name=&quot;max-retries&quot;&gt;30&lt;/integer&gt;\n&gt;      &lt;long name=&quot;retry-delay-seconds&quot;&gt;900&lt;/long&gt;\n&gt;      &lt;integer name=&quot;total-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt;      &lt;integer name=&quot;max-per-host-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt;    &lt;/newObject&gt;\n&gt;    &lt;map name=&quot;uri-canonicalization-rules&quot;&gt;\n&gt;      &lt;newObject name=&quot;Lowercase&quot; class=&quot;org.archive.crawler.url.canonicalize.LowercaseRule&quot;/&gt;\n&gt;      &lt;newObject name=&quot;Userinfo&quot; class=&quot;org.archive.crawler.url.canonicalize.StripUserinfoRule&quot;/&gt;\n&gt;      &lt;newObject name=&quot;WWW&quot; class=&quot;org.archive.crawler.url.canonicalize.StripWWWRule&quot;/&gt;\n&gt;      &lt;newObject name=&quot;SessionIDs&quot; class=&quot;org.archive.crawler.url.canonicalize.StripSessionIDs&quot;/&gt;\n&gt;      &lt;newObject name=&quot;QueryStrPrefix&quot; class=&quot;org.archive.crawler.url.canonicalize.FixupQueryStr&quot;/&gt;\n&gt;    &lt;/map&gt;\n&gt;    &lt;map name=&quot;pre-fetch-processors&quot;&gt;\n&gt;      &lt;newObject name=&quot;Preselector&quot; class=&quot;org.archive.crawler.prefetch.Preselector&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;/&gt;\n&gt;        &lt;boolean name=&quot;recheck-scope&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;boolean name=&quot;block-all&quot;&gt;false&lt;/boolean&gt;\n&gt;        &lt;string name=&quot;block-by-regexp&quot;/&gt;\n&gt;      &lt;/newObject&gt;\n&gt;      &lt;newObject name=&quot;Preprocessor&quot; class=&quot;org.archive.crawler.prefetch.PreconditionEnforcer&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;/&gt;\n&gt;        &lt;integer name=&quot;ip-validity-duration-seconds&quot;&gt;21600&lt;/integer&gt;\n&gt;        &lt;integer name=&quot;robot-validity-duration-seconds&quot;&gt;86400&lt;/integer&gt;\n&gt;      &lt;/newObject&gt;\n&gt;    &lt;/map&gt;\n&gt;    &lt;map name=&quot;fetch-processors&quot;&gt;\n&gt;      &lt;newObject name=&quot;DNS&quot; class=&quot;org.archive.crawler.fetcher.FetchDNS&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;/&gt;\n&gt;      &lt;/newObject&gt;\n&gt;      &lt;newObject name=&quot;HTTP&quot; class=&quot;org.archive.crawler.fetcher.FetchHTTP&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;/&gt;\n&gt;        &lt;integer name=&quot;timeout-seconds&quot;&gt;1200&lt;/integer&gt;\n&gt;        &lt;integer name=&quot;sotimeout-ms&quot;&gt;20000&lt;/integer&gt;\n&gt;        &lt;long name=&quot;max-length-bytes&quot;&gt;0&lt;/long&gt;\n&gt;        &lt;string name=&quot;load-cookies-from-file&quot;/&gt;\n&gt;        &lt;string name=&quot;save-cookies-to-file&quot;/&gt;\n&gt;        &lt;string name=&quot;trust-level&quot;&gt;open&lt;/string&gt;\n&gt;      &lt;/newObject&gt;\n&gt;    &lt;/map&gt;\n&gt;    &lt;map name=&quot;extract-processors&quot;&gt;\n&gt;      &lt;newObject name=&quot;ExtractorHTTP&quot; class=&quot;org.archive.crawler.extractor.ExtractorHTTP&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;/&gt;\n&gt;      &lt;/newObject&gt;\n&gt;      &lt;newObject name=&quot;ExtractorHTML&quot; class=&quot;org.archive.crawler.extractor.ExtractorHTML&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;/&gt;\n&gt;      &lt;/newObject&gt;\n&gt;      &lt;newObject name=&quot;ExtractorCSS&quot; class=&quot;org.archive.crawler.extractor.ExtractorCSS&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;/&gt;\n&gt;      &lt;/newObject&gt;\n&gt;      &lt;newObject name=&quot;ExtractorJS&quot; class=&quot;org.archive.crawler.extractor.ExtractorJS&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;/&gt;\n&gt;      &lt;/newObject&gt;\n&gt;      &lt;newObject name=&quot;ExtractorSWF&quot; class=&quot;org.archive.crawler.extractor.ExtractorSWF&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;/&gt;\n&gt;      &lt;/newObject&gt;\n&gt;    &lt;/map&gt;\n&gt;    &lt;map name=&quot;write-processors&quot;&gt;\n&gt;      &lt;newObject name=&quot;Archiver&quot; class=&quot;org.archive.crawler.writer.ARCWriterProcessor&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;/&gt;\n&gt;        &lt;boolean name=&quot;compress&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;string name=&quot;prefix&quot;&gt;1111422206314&lt;/string&gt;\n&gt;        &lt;string name=&quot;suffix&quot;&gt;${HOSTNAME}&lt;/string&gt;\n&gt;        &lt;integer name=&quot;max-size-bytes&quot;&gt;100000000&lt;/integer&gt;\n&gt;        &lt;string name=&quot;path&quot;&gt;arcs&lt;/string&gt;\n&gt;        &lt;integer name=&quot;pool-max-active&quot;&gt;5&lt;/integer&gt;\n&gt;        &lt;integer name=&quot;pool-max-wait&quot;&gt;300000&lt;/integer&gt;\n&gt;      &lt;/newObject&gt;\n&gt;    &lt;/map&gt;\n&gt;    &lt;map name=&quot;post-processors&quot;&gt;\n&gt;      &lt;newObject name=&quot;Updater&quot; class=&quot;org.archive.crawler.postprocessor.CrawlStateUpdater&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;/&gt;\n&gt;      &lt;/newObject&gt;\n&gt;      &lt;newObject name=&quot;Postselector&quot; class=&quot;org.archive.crawler.postprocessor.Postselector&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;filters&quot;/&gt;\n&gt;        &lt;boolean name=&quot;seed-redirects-new-seed&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;boolean name=&quot;override-logger&quot;&gt;false&lt;/boolean&gt;\n&gt;        &lt;map name=&quot;scope-rejected-uri-log-filters&quot;/&gt;\n&gt;      &lt;/newObject&gt;\n&gt;    &lt;/map&gt;\n&gt;    &lt;map name=&quot;loggers&quot;&gt;\n&gt;      &lt;newObject name=&quot;crawl-statistics&quot; class=&quot;org.archive.crawler.admin.StatisticsTracker&quot;&gt;\n&gt;        &lt;integer name=&quot;interval-seconds&quot;&gt;20&lt;/integer&gt;\n&gt;      &lt;/newObject&gt;\n&gt;    &lt;/map&gt;\n&gt;    &lt;string name=&quot;recover-path&quot;/&gt;\n&gt;    &lt;newObject name=&quot;credential-store&quot; class=&quot;org.archive.crawler.datamodel.CredentialStore&quot;&gt;\n&gt;      &lt;map name=&quot;credentials&quot;/&gt;\n&gt;    &lt;/newObject&gt;\n&gt;  &lt;/controller&gt;\n&gt;&lt;/crawl-order&gt;\n&gt;  \n&gt;\n&gt;------------------------------------------------------------------------\n&gt;\n&gt;http://www.netarkivet.dk/\n&gt;http://www.netarkivet.dk/website/testsite/index.html\n&gt;  \n&gt;\n&gt;------------------------------------------------------------------------\n&gt;\n&gt;Mar 21, 2005 5:23:26 PM dk.netarkivet.distribute.JMSConnection send\n&gt;FINE: Sent message:DoOneCrawl \n&gt;Message ID HCC0\n&gt;Origin (reply To): HarvestScheduler_client_pc977_sb_statsbiblioteket_dk_38141\n&gt;Destination (To): harvester1\n&gt;IsOk: true\n&gt;Error message: \n&gt;\n&gt;Job:dk.netarkivet.harvestdefinition.Job@cdedfd\n&gt;;\n&gt;Mar 21, 2005 5:23:26 PM dk.netarkivet.harvestscheduler.HarvestScheduler run\n&gt;FINER: Job 0 send to harvest server:harvester1\n&gt;Please press enter when the harvesting is done and files are uploaded\n&gt;Mar 21, 2005 5:23:26 PM org.archive.crawler.url.Canonicalizer canonicalize\n&gt;INFO: http://www.netarkivet.dk/ =&gt; http://netarkivet.dk/\n&gt;Mar 21, 2005 5:23:26 PM org.archive.crawler.url.Canonicalizer canonicalize\n&gt;INFO: http://www.netarkivet.dk/website/testsite/index.html =&gt; http://netarkivet.dk/website/testsite/index.html\n&gt;Mar 21, 2005 5:23:26 PM org.archive.crawler.framework.ProcessorChain &lt;init&gt;\n&gt;INFO: Processor: Preselector --&gt; org.archive.crawler.prefetch.Preselector\n&gt;Mar 21, 2005 5:23:26 PM org.archive.crawler.framework.ProcessorChain &lt;init&gt;\n&gt;INFO: Processor: Preprocessor --&gt; org.archive.crawler.prefetch.PreconditionEnforcer\n&gt;Mar 21, 2005 5:23:26 PM org.archive.crawler.framework.ProcessorChain &lt;init&gt;\n&gt;INFO: Processor: DNS --&gt; org.archive.crawler.fetcher.FetchDNS\n&gt;Mar 21, 2005 5:23:26 PM org.archive.crawler.framework.ProcessorChain &lt;init&gt;\n&gt;INFO: Processor: HTTP --&gt; org.archive.crawler.fetcher.FetchHTTP\n&gt;Mar 21, 2005 5:23:26 PM org.archive.crawler.framework.ProcessorChain &lt;init&gt;\n&gt;INFO: Processor: ExtractorHTTP --&gt; org.archive.crawler.extractor.ExtractorHTTP\n&gt;Mar 21, 2005 5:23:26 PM org.archive.crawler.framework.ProcessorChain &lt;init&gt;\n&gt;INFO: Processor: ExtractorHTML --&gt; org.archive.crawler.extractor.ExtractorHTML\n&gt;Mar 21, 2005 5:23:26 PM org.archive.crawler.framework.ProcessorChain &lt;init&gt;\n&gt;INFO: Processor: ExtractorCSS --&gt; org.archive.crawler.extractor.ExtractorCSS\n&gt;Mar 21, 2005 5:23:26 PM org.archive.crawler.framework.ProcessorChain &lt;init&gt;\n&gt;INFO: Processor: ExtractorJS --&gt; org.archive.crawler.extractor.ExtractorJS\n&gt;Mar 21, 2005 5:23:26 PM org.archive.crawler.framework.ProcessorChain &lt;init&gt;\n&gt;INFO: Processor: ExtractorSWF --&gt; org.archive.crawler.extractor.ExtractorSWF\n&gt;Mar 21, 2005 5:23:26 PM org.archive.crawler.framework.ProcessorChain &lt;init&gt;\n&gt;INFO: Processor: Archiver --&gt; org.archive.crawler.writer.ARCWriterProcessor\n&gt;Mar 21, 2005 5:23:26 PM org.archive.crawler.framework.ProcessorChain &lt;init&gt;\n&gt;INFO: Processor: Updater --&gt; org.archive.crawler.postprocessor.CrawlStateUpdater\n&gt;Mar 21, 2005 5:23:26 PM org.archive.crawler.framework.ProcessorChain &lt;init&gt;\n&gt;INFO: Processor: Postselector --&gt; org.archive.crawler.postprocessor.Postselector\n&gt;Mar 21, 2005 5:23:27 PM dk.netarkivet.harvestcontroller.HeritrixLauncher doOneCrawl\n&gt;FINE: Starting crawl..\n&gt;Mar 21, 2005 5:23:27 PM org.archive.crawler.framework.CrawlController requestCrawlStart\n&gt;INFO: Starting crawl.\n&gt;Mar 21, 2005 5:23:27 PM org.archive.crawler.url.Canonicalizer canonicalize\n&gt;INFO: dns:www.netarkivet.dk =&gt; dns:www.netarkivet.dk\n&gt;Mar 21, 2005 5:23:27 PM org.archive.io.arc.ARCWriter createARCFile\n&gt;INFO: Opened /tmp/releasetest-run/./data/42_1111422206116/arcs/1111422206314-20050321162327-00000-pc977.sb.statsbiblioteket.dk.arc.gz.open\n&gt;Mar 21, 2005 5:23:28 PM org.archive.crawler.url.Canonicalizer canonicalize\n&gt;INFO: http://www.netarkivet.dk/robots.txt =&gt; http://netarkivet.dk/robots.txt\n&gt;Mar 21, 2005 5:23:28 PM org.archive.crawler.fetcher.FetchHTTP innerProcess\n&gt;INFO: GET http://www.netarkivet.dk/robots.txt 404 0 text/html; charset=iso-8859-1\n&gt;Mar 21, 2005 5:23:29 PM org.archive.crawler.fetcher.FetchHTTP innerProcess\n&gt;INFO: GET http://www.netarkivet.dk/ 200 0 text/html\n&gt;Mar 21, 2005 5:23:29 PM org.archive.crawler.fetcher.FetchHTTP innerProcess\n&gt;INFO: GET http://www.netarkivet.dk/website/testsite/index.html 200 0 text/html\n&gt;Mar 21, 2005 5:23:30 PM org.archive.crawler.framework.CrawlController beginCrawlStop\n&gt;INFO: Starting beginCrawlStop()...\n&gt;Mar 21, 2005 5:23:30 PM dk.netarkivet.harvestcontroller.HeritrixLauncher$SimpleCrawlStatusListener crawlEnding\n&gt;FINE: Crawl ending: Finished\n&gt;Mar 21, 2005 5:23:30 PM org.archive.io.arc.ARCWriter close\n&gt;INFO: Closed /tmp/releasetest-run/./data/42_1111422206116/arcs/1111422206314-20050321162327-00000-pc977.sb.statsbiblioteket.dk.arc.gz, size 788\n&gt;Mar 21, 2005 5:23:30 PM org.archive.crawler.framework.CrawlController beginCrawlStop\n&gt;INFO: Finished beginCrawlStop().\n&gt;Mar 21, 2005 5:23:30 PM org.archive.crawler.framework.CrawlController completeStop\n&gt;INFO: Entered complete stop.\n&gt;Mar 21, 2005 5:23:30 PM org.archive.crawler.admin.StatisticsTracker crawlEnded\n&gt;INFO: Entered crawlEnded\n&gt;Mar 21, 2005 5:23:30 PM org.archive.crawler.admin.StatisticsTracker writeReport\n&gt;INFO: /tmp/releasetest-run/./data/42_1111422206116/hosts-report.txt\n&gt;Mar 21, 2005 5:23:30 PM org.archive.crawler.admin.StatisticsTracker writeReport\n&gt;INFO: /tmp/releasetest-run/./data/42_1111422206116/mimetype-report.txt\n&gt;Mar 21, 2005 5:23:30 PM org.archive.crawler.admin.StatisticsTracker writeReport\n&gt;INFO: /tmp/releasetest-run/./data/42_1111422206116/responsecode-report.txt\n&gt;Mar 21, 2005 5:23:30 PM org.archive.crawler.admin.StatisticsTracker writeReport\n&gt;INFO: /tmp/releasetest-run/./data/42_1111422206116/seeds-report.txt\n&gt;Mar 21, 2005 5:23:30 PM org.archive.crawler.admin.StatisticsTracker writeReport\n&gt;INFO: /tmp/releasetest-run/./data/42_1111422206116/crawl-report.txt\n&gt;Mar 21, 2005 5:23:30 PM org.archive.crawler.admin.StatisticsTracker writeReport\n&gt;INFO: /tmp/releasetest-run/./data/42_1111422206116/processors-report.txt\n&gt;Mar 21, 2005 5:23:30 PM org.archive.crawler.admin.StatisticsTracker writeReport\n&gt;INFO: /tmp/releasetest-run/./data/42_1111422206116/crawl-manifest.txt\n&gt;Mar 21, 2005 5:23:30 PM org.archive.crawler.admin.StatisticsTracker crawlEnded\n&gt;INFO: Leaving crawlEnded\n&gt;Mar 21, 2005 5:23:30 PM org.archive.crawler.framework.CrawlController completeStop\n&gt;INFO: Sent crawlEnded to org.archive.crawler.admin.StatisticsTracker@21447f\n&gt;Mar 21, 2005 5:23:30 PM dk.netarkivet.harvestcontroller.HeritrixLauncher$SimpleCrawlStatusListener crawlEnded\n&gt;FINE: Crawl ended: Finished\n&gt;Mar 21, 2005 5:23:30 PM org.archive.crawler.framework.CrawlController completeStop\n&gt;INFO: Sent crawlEnded to dk.netarkivet.harvestcontroller.HeritrixLauncher$SimpleCrawlStatusListener@182a70\n&gt;Mar 21, 2005 5:23:30 PM org.archive.crawler.framework.CrawlController completeStop\n&gt;INFO: Sent crawlEnded to org.archive.crawler.writer.ARCWriterProcessor@8a2023\n&gt;Mar 21, 2005 5:23:30 PM dk.netarkivet.harvestcontroller.HeritrixLauncher doOneCrawl\n&gt;FINE: Ending crawl..\n&gt;  \n&gt;\n\n\n"}}