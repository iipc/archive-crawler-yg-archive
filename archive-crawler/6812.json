{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"D8tObE3SVg1Ttnkeyml-wcrwz7ylIRMyq2CtlNZff8K7Djc_z1876mYbwTtoZsqR3s3NatyBsHyVia2JOWkfn_rgQgnMVV8","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Auto Stopping Problem","postDate":"1290452777","msgId":6812,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRDRUFCRjI5LjQwNDA4QGFyY2hpdmUub3JnPg==","inReplyToHeader":"PGljNTRhZStucDVsQGVHcm91cHMuY29tPg==","referencesHeader":"PGljNTRhZStucDVsQGVHcm91cHMuY29tPg=="},"prevInTopic":6809,"nextInTopic":6820,"prevInTime":6811,"nextInTime":6813,"topicId":6809,"numMessagesInTopic":10,"msgSnippet":"The fact that the first error is a DNS failure, and that prevents further progress, suggests that the ability of the crawler machine to do DNS lookups -- both","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 69475 invoked from network); 22 Nov 2010 19:06:21 -0000\r\nX-Received: from unknown (66.196.94.105)\n  by m11.grp.re1.yahoo.com with QMQP; 22 Nov 2010 19:06:21 -0000\r\nX-Received: from unknown (HELO relay01.pair.com) (209.68.5.15)\n  by mta1.grp.re1.yahoo.com with SMTP; 22 Nov 2010 19:06:21 -0000\r\nX-Received: (qmail 33563 invoked by uid 0); 22 Nov 2010 19:06:19 -0000\r\nX-Received: from 67.188.34.83 (HELO silverbook.local) (67.188.34.83)\n  by relay01.pair.com with SMTP; 22 Nov 2010 19:06:19 -0000\r\nX-pair-Authenticated: 67.188.34.83\r\nMessage-ID: &lt;4CEABF29.40408@...&gt;\r\nDate: Mon, 22 Nov 2010 11:06:17 -0800\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.6; en-US; rv:1.9.2.12) Gecko/20101027 Thunderbird/3.1.6\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: ssgtitanic &lt;allensim81@...&gt;\r\nReferences: &lt;ic54ae+np5l@...&gt;\r\nIn-Reply-To: &lt;ic54ae+np5l@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Auto Stopping Problem\r\nX-Yahoo-Group-Post: member; u=137285340; y=1gLD_3lMqDujOqQCV_9qI8QrFelfc6ptTmhXEMfhAc2r\r\nX-Yahoo-Profile: gojomo\r\n\r\nThe fact that the first error is a DNS failure, and that prevents \nfurther progress, suggests that the ability of the crawler machine to do \nDNS lookups -- both from a command-line, and from Java -- is the first \nthing to look at.\n\nOn the crawling machine itself, can you visit \n&lt;http://www.swinburne.edu.my/&gt; (from a command-line browser or tool like \n&#39;wget&#39;/&#39;curl&#39; if the machine doesn&#39;t have a graphical browser)?\n\nThere *might* be a little more detail on the DNS error in the \n&#39;local-errors.log&#39; in the crawl&#39;s logs directory as well.\n\n- Gordon @ IA\n\nOn 11/18/10 10:09 PM, ssgtitanic wrote:\n&gt; Hi,\n&gt; Hi,\n&gt; I successfully downloaded and deployed WCT 1.5 and indeed it&#39;s a wonderful tool for harvesting!\n&gt; This morning I tried to harvest few websites. The first two websites that I harvested were okay. As I proceed to my third website, The Target Instances itself only run for few seconds (00:00:18) then it automatically &#39;Stopping&#39; then after few seconds it turned to &#39;harvested&#39; with 0 bytes data downloaded.I restart my server and Apache-tomcat, the problem still persist.\n&gt;\n&gt;   Following is the crwal.log logfile:\n&gt; 2010-11-18T04:14:11.482Z    -1          - dns:www.swinburne.edu.my P http://www.swinburne.edu.my/ text/dns #001 20101118041409425+2055 - - 3t\n&gt; 2010-11-18T04:14:11.786Z    -6          - http://www.swinburne.edu.my/ - - no-type #002 - - - 2t\n&gt; Displaying: 100% of 239 B\n&gt; crawl report.txt:\n&gt; Crawl Name:\n&gt; Crawl Status: Finished\n&gt; Duration Time: 20s617ms\n&gt; Total Seeds Crawled: 0\n&gt; Total Seeds not Crawled: 1\n&gt; Total Hosts Crawled: -1\n&gt; Total Documents Crawled: 2\n&gt; Processed docs/sec: 0\n&gt; Bandwidth in Kbytes/sec: 0\n&gt; Total Raw Data Size in Bytes: 0 (0 B)\n&gt; Novel Bytes: 0 (0 B)\n&gt; Displaying: 100% of 271 B\n&gt; Frontier report.txt\n&gt; frontier empty\n&gt; Displaying: 100% of 15 B\n&gt;\n&gt; Can you please guide me. what&#39;s wrong with it? Is it my setting?\n&gt; As I am refeering to Heritrix status code, I found the following:\n&gt;   -1 DNS lookup failed\n&gt;   -6 Prerequisite domain-lookup failed, precluding fetch attempt\n&gt;\n&gt; How am I going to fix it? Please help and advice.\n&gt;\n&gt; Looking forward to hear from you.\n&gt;\n&gt; Thanks in advance,\n&gt; Allen Wilson\n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------\n&gt;\n&gt; Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n\n"}}