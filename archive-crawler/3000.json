{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":39397245,"authorName":"mar1ow2003","from":"&quot;mar1ow2003&quot; &lt;ej@...&gt;","profile":"mar1ow2003","replyTo":"LIST","senderId":"dWaffxAGUdNscDXfZ-4zo5Dzl2cCgVTzTdjWHpVgNxGJF45wsihJWyb1Dsp-ytKfi_THTyEI1U5SUps_sE6e_D5mtA","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Breadth-first assignment priorities?","postDate":"1151898521","msgId":3000,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGU4YTQycCtjODhwQGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":3007,"prevInTime":2999,"nextInTime":3001,"topicId":3000,"numMessagesInTopic":4,"msgSnippet":"I need to perform a somewhat unusual crawl in which I have many seeds (100 s of thousands) all from the same host, and only want to extract pages under a","rawEmail":"Return-Path: &lt;ej@...&gt;\r\nX-Sender: ej@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 37431 invoked from network); 3 Jul 2006 03:48:45 -0000\r\nReceived: from unknown (66.218.67.36)\n  by m30.grp.scd.yahoo.com with QMQP; 3 Jul 2006 03:48:45 -0000\r\nReceived: from unknown (HELO n8b.bullet.sc5.yahoo.com) (66.163.187.175)\n  by mta10.grp.scd.yahoo.com with SMTP; 3 Jul 2006 03:48:44 -0000\r\nReceived: from [66.163.187.121] by n8.bullet.sc5.yahoo.com with NNFMP; 03 Jul 2006 03:48:44 -0000\r\nReceived: from [66.218.69.1] by t2.bullet.sc5.yahoo.com with NNFMP; 03 Jul 2006 03:48:44 -0000\r\nReceived: from [66.218.66.73] by t1.bullet.scd.yahoo.com with NNFMP; 03 Jul 2006 03:48:44 -0000\r\nDate: Mon, 03 Jul 2006 03:48:41 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;e8a42p+c88p@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;mar1ow2003&quot; &lt;ej@...&gt;\r\nSubject: Breadth-first assignment priorities?\r\nX-Yahoo-Group-Post: member; u=39397245; y=5CrC7jSbVnBqs6aVcrv9rdLXtOifTe-E3-AXAeOQdHHMQ_WkUQ\r\nX-Yahoo-Profile: mar1ow2003\r\n\r\nI need to perform a somewhat unusual crawl in which I have many seeds\n(100&#39;=\r\ns of thousands) all from the same host, and only want to extract\npages unde=\r\nr a couple directories from that host.  However, I want to\nbe able to crawl=\r\n all the pages discovered from a seed before moving on\nto the next seed.  H=\r\now can I make those discovered pages move up the\nqueue in front of the seed=\r\ns?\n\nThanks,\neric.\n\n\n\n\n\n"}}