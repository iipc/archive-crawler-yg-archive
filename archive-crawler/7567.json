{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":264138474,"authorName":"Kenji Nagahashi","from":"Kenji Nagahashi &lt;knagahashi@...&gt;","profile":"kenznag","replyTo":"LIST","senderId":"2_c2RNJmv_Bgz38HeHWqIw8CMCNOqA5RdBMr58nzJZBw8g73WjcPZHK6qmdrLR3xdO5-UJj8Gqik7wAKddX8MPil5UZrFosqcMAVNZE","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Re: questions before we restart the crawl","postDate":"1327306330","msgId":7567,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRGMUQxNjVBLjgwNzA1MDFAZ21haWwuY29tPg==","inReplyToHeader":"PDRGMUE1MzIyLjEwMjA1MDFAY3MuY211LmVkdT4=","referencesHeader":"PDRGMTU5NEQwLjIwOTA4MDhAY3MuY211LmVkdT4gPDRGMTVCQjNBLjUwMzA2QGFyY2hpdmUub3JnPiA8NEYxOUIzOTEuMTA3MDQwMUBjcy5jbXUuZWR1PiA8NEYxQTA0QkMuNjAxMDQwMkBjcy5jbXUuZWR1PiA8NEYxQTRCOUMuNTA5MDAwN0BhcmNoaXZlLm9yZz4gPDRGMUE1MzIyLjEwMjA1MDFAY3MuY211LmVkdT4="},"prevInTopic":7566,"nextInTopic":7568,"prevInTime":7566,"nextInTime":7568,"topicId":7527,"numMessagesInTopic":27,"msgSnippet":"Hi, May be a bit off-topic, but 25M/day with 5 machine is average 58/s per machine. Since I know Heritrix-3 can crawl at this speed with just 100 ToeThreads, I","rawEmail":"Return-Path: &lt;knagahashi@...&gt;\r\nX-Sender: knagahashi@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 92891 invoked from network); 23 Jan 2012 08:12:15 -0000\r\nX-Received: from unknown (98.137.34.46)\n  by m1.grp.sp2.yahoo.com with QMQP; 23 Jan 2012 08:12:15 -0000\r\nX-Received: from unknown (HELO mail-iy0-f170.google.com) (209.85.210.170)\n  by mta3.grp.sp2.yahoo.com with SMTP; 23 Jan 2012 08:12:15 -0000\r\nX-Received: by iaoo28 with SMTP id o28so4813940iao.15\n        for &lt;archive-crawler@yahoogroups.com&gt;; Mon, 23 Jan 2012 00:12:14 -0800 (PST)\r\nX-Received: by 10.50.170.73 with SMTP id ak9mr4269516igc.3.1327306333309;\n        Mon, 23 Jan 2012 00:12:13 -0800 (PST)\r\nReturn-Path: &lt;knagahashi@...&gt;\r\nX-Received: from kenji-mbp.local (adsl-71-135-163-49.dsl.pltn13.pacbell.net. [71.135.163.49])\n        by mx.google.com with ESMTPS id r18sm44413939ibh.4.2012.01.23.00.12.10\n        (version=TLSv1/SSLv3 cipher=OTHER);\n        Mon, 23 Jan 2012 00:12:12 -0800 (PST)\r\nMessage-ID: &lt;4F1D165A.8070501@...&gt;\r\nDate: Mon, 23 Jan 2012 00:12:10 -0800\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:9.0) Gecko/20111222 Thunderbird/9.0.1\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;4F1594D0.2090808@...&gt; &lt;4F15BB3A.50306@...&gt; &lt;4F19B391.1070401@...&gt; &lt;4F1A04BC.6010402@...&gt; &lt;4F1A4B9C.5090007@...&gt; &lt;4F1A5322.1020501@...&gt;\r\nIn-Reply-To: &lt;4F1A5322.1020501@...&gt;\r\nContent-Type: text/plain; charset=windows-1252; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Kenji Nagahashi &lt;knagahashi@...&gt;\r\nSubject: Re: [archive-crawler] Re: questions before we restart the crawl\r\nX-Yahoo-Group-Post: member; u=264138474; y=2lvaSodHCcJJoky-d86ByGBLTey503BI0YtLqnqJfo62XQ\r\nX-Yahoo-Profile: kenznag\r\n\r\nHi,\n\nMay be a bit off-topic, but 25M/day with 5 machine is average 58/s per \nmachine. Since I know Heritrix-3 can crawl at this speed with just 100 \nToeThreads, I wonder if most of your 1200 ToeThreads are idle.\n\nWhile why you don&#39;t get much higher speed with 1200 threads is a big \nquestion, it may make sense to cut down the number of ToeThreads if \nyou&#39;re okay with current crawl speed. Less threads will make H3 less \nsusceptible to memory problems... Just a thought.\n\n--Kenji\n\n(1/20/12 9:54 PM), David Pane wrote:\n&gt; Gordon,\n&gt;\n&gt; Thank you for your response. And I am sorry for the overwhelming amount\n&gt; of information...I think I am a little overwhelmed.... and feeling the\n&gt; pressure.\n&gt;\n&gt; 1) Our Bloom filter configuration:\n&gt;\n&gt; &lt;bean id=&quot;uriUniqFilter&quot;\n&gt; class=&quot;org.archive.crawler.util.BloomUriUniqFilter&quot;&gt;\n&gt; &lt;property name=&quot;bloomFilter&quot;&gt;\n&gt; &lt;bean class=&quot;org.archive.util.BloomFilter64bit&quot;&gt;\n&gt; &lt;constructor-arg value=&quot;400000000&quot;/&gt;\n&gt; &lt;constructor-arg value=&quot;30&quot;/&gt;\n&gt; &lt;/bean&gt;\n&gt; &lt;/property&gt;\n&gt; &lt;/bean&gt;\n&gt;\n&gt; 2) We are writing the crawl data to a NAS configured with RAID 6. We did\n&gt; see some problems with disk errors on the NAS earlier in the crawl (late\n&gt; Dec ). I recently found this out. We were/are running in a degraded\n&gt; raid state - a few of the disks have been replaced and the RAID is being\n&gt; rebuilt. We didn&#39;t see any block device errors in the logs on the NAS\n&gt; so the write failures we saw are probably not related to the rebuild. We\n&gt; did see some network hiccups (no outright failures) in the logs.\n&gt; So, this may be the culprit for some of the\n&gt;\n&gt; 3) Yes, we have been cross-feeding URIs.\n&gt;\n&gt; --David\n&gt;\n&gt; On 1/21/12 12:22 AM, Gordon Mohr wrote:\n&gt;  &gt; You&#39;ve provided an overwhelming amount of information and we may be\n&gt;  &gt; dealing with multiple issues, some of which have roots going back\n&gt;  &gt; earlier than the diagnostic data we now have available.\n&gt;  &gt;\n&gt;  &gt; A few key points of emphasis:\n&gt;  &gt;\n&gt;  &gt; - we&#39;ve not run crawls with 1200 threads before, or on hardware\n&gt;  &gt; similar to yours, so our experience is only vaguely suggestive\n&gt;  &gt;\n&gt;  &gt; - it&#39;s not the lower thread counts that are the real source of\n&gt;  &gt; concern; you can even adjust the number of threads mid-crawl. It&#39;s\n&gt;  &gt; that the error that killed the threads almost certainly left a queue\n&gt;  &gt; in a &#39;phantom&#39; state where no progress would be made crawling its\n&gt;  &gt; URIs, each time it happened, on each resume leading to the current state.\n&gt;  &gt;\n&gt;  &gt; - without having understood and fixed whatever software or system\n&gt;  &gt; problems caused the earliest/most-foundational errors in your crawl,\n&gt;  &gt; it&#39;s impossible to say how likely they are to recur.\n&gt;  &gt;\n&gt;  &gt; With that in mind, I&#39;ll try to provide quick answers to your other\n&gt;  &gt; questions...\n&gt;  &gt;\n&gt;  &gt; On 1/20/12 4:20 PM, David Pane wrote:\n&gt;  &gt;&gt;\n&gt;  &gt;&gt; We have collected about 550 million pages along with the images and\n&gt;  &gt;&gt; supporting documents on our 5 instance crawl that was started Dec. 23rd.\n&gt;  &gt;&gt; Although we are please with the amount of data we captured to date, we\n&gt;  &gt;&gt; are very concerned about the state of the Heritrix instances. If fact,\n&gt;  &gt;&gt; we aren&#39;t very confident that the instances will last until the end of\n&gt;  &gt;&gt; February. We are now running on a total of over 500 less threads than\n&gt;  &gt;&gt; the configured 1200 threads/instance.\n&gt;  &gt;&gt;\n&gt;  &gt;&gt; 0 - not running right now.\n&gt;  &gt;&gt; 1 - running on 1198 ( 2 less)\n&gt;  &gt;&gt; 2 - running on 931 (269 less)\n&gt;  &gt;&gt; 3 - running on 987 (213 less)\n&gt;  &gt;&gt; 4 - running on 1170 (30 less)\n&gt;  &gt;&gt;\n&gt;  &gt;&gt; Since we are seriously considering throwing away this past month&#39;s work\n&gt;  &gt;&gt; and starting over, we would like to pick your brain on some strategies\n&gt;  &gt;&gt; that will help us avoid getting into this situation again. We were\n&gt;  &gt;&gt; hoping to be done crawling by the end of February so this restart will\n&gt;  &gt;&gt; put us behind schedule.\n&gt;  &gt;&gt;\n&gt;  &gt;&gt; 1) Can we continue from here but with &quot;clean&quot; Heritrix instances?\n&gt;  &gt;&gt;\n&gt;  &gt;&gt; Is there a way that we can continue from the this point forward, but\n&gt;  &gt;&gt; start with Heritrix instances that will not be corrupt due to sever\n&gt;  &gt;&gt; error? (e.g. using the\n&gt;  &gt;&gt; https://webarchive.jira.com/wiki/display/Heritrix/Crawl+Recovery\n&gt; &lt;https://webarchive.jira.com/wiki/display/Heritrix/Crawl+Recovery&gt; ) If\n&gt;  &gt;&gt; so, would you recommend doing this? You mentioned that this could be\n&gt;  &gt;&gt; time consuming. Each of our instances has downloaded around 170M URIs,\n&gt;  &gt;&gt; they have over 700M queued URIs, what is your time estimate for\n&gt;  &gt;&gt; something this large?\n&gt;  &gt;&gt;\n&gt;  &gt;&gt; We are willing to sacrifice a few days to get our crawler to a clean\n&gt;  &gt;&gt; state again so we can crawl for another 30 days at the pace we have been\n&gt;  &gt;&gt; crawling.\n&gt;  &gt;\n&gt;  &gt; You can do a big &#39;frontier-recover&#39; log replay to avoid recrawling the\n&gt;  &gt; same URIs, and approximate the earlier queue state. Splitting/filters\n&gt;  &gt; the logs manually beforehand as alluded to in the wiki page can speed\n&gt;  &gt; this process somewhat... but given the size of all your log-segments\n&gt;  &gt; that log grooming beforehand is itself likely to be a lengthy process.\n&gt;  &gt;\n&gt;  &gt; I don&#39;t think we&#39;ve ever done it with logs of 170M crawled / 870M\n&gt;  &gt; discovered before, nor on any hardware comparable to yours. So it&#39;s\n&gt;  &gt; impossible to project its duration in your environment. It&#39;s taken 2-3\n&gt;  &gt; days for us on smaller crawls, slower hardware.\n&gt;  &gt;\n&gt;  &gt; An added complication is that this older frontier-recover-log replay\n&gt;  &gt; technique happens in its own thread separate from the checkpointing\n&gt;  &gt; process, so it is not, itself, accurately checkpointed during the long\n&gt;  &gt; reload process.\n&gt;  &gt;\n&gt;  &gt; At nearly 1B discovered URIs per node, even if you are using the\n&gt;  &gt; alternate BloomUriUniqFilter, if you are using it at its default size\n&gt;  &gt; (~500MB) it will now be heavily saturated and thus returning many\n&gt;  &gt; false-positives causing truly unique URIs to be rejected as\n&gt;  &gt; duplicates. (If you&#39;re using a significantly larger filter, you may\n&gt;  &gt; not yet be at a high false-positive rate: you&#39;d have to do the bloom\n&gt;  &gt; filter math. If you&#39;re still using BdbUriUniqFilter, you&#39;re way way\n&gt;  &gt; past the point where its disk seeks have usually made it too slow for\n&gt;  &gt; our purposes.)\n&gt;  &gt;\n&gt;  &gt;&gt; 2) What can be done to avoid corrupting the Heritrix instances?\n&gt;  &gt;&gt;\n&gt;  &gt;&gt; - What kind of strategies might we take to keep the crawl error free?\n&gt;  &gt;&gt;\n&gt;  &gt;&gt; - Do you think the SEVER errors that we have seen are deterministic or\n&gt;  &gt;&gt; random (e.g., triggered by occasional flaky network conditions, disks,\n&gt;  &gt;&gt; race conditions, or whatever)?\n&gt;  &gt;\n&gt;  &gt; Hard to say. The main thing I could suggest is watch very closely and\n&gt;  &gt; when a SEVERE error occurs, prioritize diagnosing and resolving the\n&gt;  &gt; cause while the info is fresh.\n&gt;  &gt;\n&gt;  &gt;&gt; - Do you believe that we can reliably backup to the previous checkpoint\n&gt;  &gt;&gt; if we watch the logs and stop as soon as we see the first SEVER error?\n&gt;  &gt;&gt; If we do this, do you speculate that the same SEVER will occur again?\n&gt;  &gt;\n&gt;  &gt; Resuming from the latest checkpoint before an error believed to\n&gt;  &gt; corrupt the on-disk state will be the best strategy.\n&gt;  &gt;\n&gt;  &gt; If we never figure out the real cause, but run the same software on\n&gt;  &gt; the same machine, yes, I expect the same problem will recur!\n&gt;  &gt;\n&gt;  &gt;&gt; - Is there any reason why a Heritrix instance that is run while binded\n&gt;  &gt;&gt; to one ip address can&#39;t be resumed binded to a different ip address?\n&gt;  &gt;\n&gt;  &gt; Only the web UI to my knowledge binds to a chosen address, and it is\n&gt;  &gt; common to have it bind to all. I don&#39;t expect the outbound requests\n&gt;  &gt; would be hurt by a machine changing its IP address while the crawl was\n&gt;  &gt; running, but I would run a test to be sure if that was an important,\n&gt;  &gt; expected transition.\n&gt;  &gt;\n&gt;  &gt;&gt; 3) Should we configure the crawler with more instances and switch\n&gt;  &gt;&gt; between them?\n&gt;  &gt;&gt;\n&gt;  &gt;&gt; We have seen that we can run a single instance to 100M pages +\n&gt;  &gt;&gt; supporting images and documents. Perhaps this means that we need 10 or\n&gt;  &gt;&gt; more instances instead of 5. That raises the possibility of running 2\n&gt;  &gt;&gt; instances per machine. If we could run 2, or even 4, instances on a\n&gt;  &gt;&gt; single machine, they would each run half as long.\n&gt;  &gt;\n&gt;  &gt; I don&#39;t think the problems as reported are specifically due to one\n&gt;  &gt; node&#39;s progress growing beyond a certain size, but it might be the\n&gt;  &gt; case that giant instances are more likely to suffer from, and harder\n&gt;  &gt; to recover from, single glitches (eg a single disk error). On the\n&gt;  &gt; other hand, many instances introduce more redundant overhead costs\n&gt;  &gt; (certain data structures, cross-feeding URIs if you&#39;re doing that, etc.).\n&gt;  &gt;\n&gt;  &gt;&gt; - Can you suggest a way to start/stop instances from a script so we can\n&gt;  &gt;&gt; change between instances automatically?\n&gt;  &gt;\n&gt;  &gt; Not a mode I&#39;ve thought much about.\n&gt;  &gt;\n&gt;  &gt;&gt; - Have you seen frequent starting / stopping of instances introduce\n&gt;  &gt;&gt; instability?\n&gt;  &gt;\n&gt;  &gt; No... but it might make you notice latent issues sooner.\n&gt;  &gt;\n&gt;  &gt;&gt; 4) Crawl slows but restarting seems to improve the speed again.\n&gt;  &gt;&gt;\n&gt;  &gt;&gt; We noticed that the all of our instances would initially run at a fast\n&gt;  &gt;&gt; pace. We would collect an average of 25M + pages/day for 2-3 days and\n&gt;  &gt;&gt; then the crawl would slow down to 10M pages/day over the next few days.\n&gt;  &gt;&gt; (these numbers are totals of all 5 instances combined). When we\n&gt;  &gt;&gt; restarted the instances, the average pages would improve back to 25M +\n&gt;  &gt;&gt; pages/day. The total crawled numbers (TiB) also reflected the slow down.\n&gt;  &gt;&gt;\n&gt;  &gt;&gt; - Is this something that others have experienced as well?\n&gt;  &gt;\n&gt;  &gt; I don&#39;t recall hearing other reports of speed boosts after\n&gt;  &gt; checkpoint-resumes but others may have more experience.\n&gt;  &gt;\n&gt;  &gt;&gt; 5) We are capturing tweets from twitter, harvesting the urls and want to\n&gt;  &gt;&gt; crawl those urls within 1 day of receiving the tweet. Can you recommend\n&gt;  &gt;&gt; a strategy for doing this with the 5 instances we are running?\n&gt;  &gt;&gt;\n&gt;  &gt;&gt; - Do we need to run a separate crawler dedicated to this? If so, can you\n&gt;  &gt;&gt; suggest a way to crawl out from the tweeted urls but when we get\n&gt;  &gt;&gt; additional urls from the tweets, quickly change focus to these urls\n&gt;  &gt;&gt; instead of the ones branching out. When adding urls as seeds, can you\n&gt;  &gt;&gt; set a high priority to crawl those before the discovered urls? Do you\n&gt;  &gt;&gt; recommend maybe setting up a specific crawl for these urls and then only\n&gt;  &gt;&gt; crawl a few hopes from the seeds - injecting the urls from the tweets as\n&gt;  &gt;&gt; seeds?\n&gt;  &gt;\n&gt;  &gt; Dedicating a special script or crawler to URIs that come from such a\n&gt;  &gt; constrained source (Twitter feeds), or that need to be crawled in a\n&gt;  &gt; special timeframe, or according to other special limits (fewer hops),\n&gt;  &gt; could make sense.\n&gt;  &gt;\n&gt;  &gt; It would take some customization of the queueing-policy or\n&gt;  &gt; &#39;precedence&#39; features of Heritrix to allow URIs added mid-crawl to be\n&gt;  &gt; prioritized above those already discovered and queued. The most simple\n&gt;  &gt; possible customization might be a UriPrecedencePolicy that takes all\n&gt;  &gt; zero-hop URIs (which all seeds and most direct-fed URIs would be) and\n&gt;  &gt; gives them a higher precedence (lower precedence number) than all\n&gt;  &gt; other URIs.\n&gt;  &gt;\n&gt;  &gt;&gt; 6) I think the answer is no for this question, but I will ask it anyway.\n&gt;  &gt;&gt; If you have a Heritrix instance that is configured for 1200 threads on\n&gt;  &gt;&gt; one machine, can you recover from a checkpoint from that 1200 thread\n&gt;  &gt;&gt; configuration on a different machine with an Heritrix instance that is\n&gt;  &gt;&gt; configured for less threads (e.g. the default 25 threads)?\n&gt;  &gt;\n&gt;  &gt; Yes - there&#39;s no need to keep the thread count the same after a\n&gt;  &gt; resume. None of the checkpoint structures (or usual disk structures)\n&gt;  &gt; are based on the number of worker threads (&#39;ToeThreads&#39;)... as\n&gt;  &gt; mentioned above you can even vary the number of threads in a running\n&gt;  &gt; crawl.\n&gt;  &gt;\n&gt;  &gt; - Gordon\n&gt;  &gt;\n&gt;\n&gt; \n\n\n"}}