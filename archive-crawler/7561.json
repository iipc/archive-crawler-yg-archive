{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":500983475,"authorName":"David Pane","from":"David Pane &lt;dpane@...&gt;","profile":"david_pane1","replyTo":"LIST","senderId":"JsoM77TwxcMJxhKigo6KtVvG-mr9uyrnXXpHqo8KiNoEZNKRK_tLIMbHj8eCKgI9gXLeKiusAxor6zzLuRErysirKHc","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: Configuring ContentLengthDecideRule","postDate":"1327123754","msgId":7561,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRGMUE0RDJBLjQwNTAzMDVAY3MuY211LmVkdT4=","inReplyToHeader":"PDRGMUE0NEFBLjEwNTAxMDVAYXJjaGl2ZS5vcmc+","referencesHeader":"PDRGMTYzQ0E1LjkwMTAwMDRAY3MuY211LmVkdT4gPDRGMThCQzA4LjYwODA0MDlAYXJjaGl2ZS5vcmc+IDw0RjFBMDlDRi4yMDIwNTA0QGNzLmNtdS5lZHU+IDw0RjFBNDRBQS4xMDUwMTA1QGFyY2hpdmUub3JnPg=="},"prevInTopic":7559,"nextInTopic":7563,"prevInTime":7560,"nextInTime":7562,"topicId":7530,"numMessagesInTopic":9,"msgSnippet":"Thanks Gordon. In regards to why we would want to add additional seeds during the crawl: We are planning on adding additional URLs that we harvest from twitter","rawEmail":"Return-Path: &lt;dpane@...&gt;\r\nX-Sender: dpane@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 47142 invoked from network); 21 Jan 2012 05:29:22 -0000\r\nX-Received: from unknown (98.137.34.44)\n  by m7.grp.sp2.yahoo.com with QMQP; 21 Jan 2012 05:29:22 -0000\r\nX-Received: from unknown (HELO smtp.andrew.cmu.edu) (128.2.11.61)\n  by mta1.grp.sp2.yahoo.com with SMTP; 21 Jan 2012 05:29:22 -0000\r\nX-Received: from iMac.local (c-24-131-240-160.hsd1.pa.comcast.net [24.131.240.160])\n\t(user=dpane mech=PLAIN (0 bits))\n\tby smtp.andrew.cmu.edu (8.14.4/8.14.4) with ESMTP id q0L5TEXj012311\n\t(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NOT);\n\tSat, 21 Jan 2012 00:29:14 -0500\r\nMessage-ID: &lt;4F1A4D2A.4050305@...&gt;\r\nDate: Sat, 21 Jan 2012 00:29:14 -0500\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:9.0) Gecko/20111222 Thunderbird/9.0.1\r\nMIME-Version: 1.0\r\nTo: Gordon Mohr &lt;gojomo@...&gt;\r\nCc: archive-crawler@yahoogroups.com, Noah Levitt &lt;nlevitt@...&gt;\r\nReferences: &lt;4F163CA5.9010004@...&gt; &lt;4F18BC08.6080409@...&gt; &lt;4F1A09CF.2020504@...&gt; &lt;4F1A44AA.1050105@...&gt;\r\nIn-Reply-To: &lt;4F1A44AA.1050105@...&gt;\r\nContent-Type: text/plain; charset=windows-1252; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-PMX-Version: 5.5.9.388399, Antispam-Engine: 2.7.2.376379, Antispam-Data: 2011.3.18.170322\r\nX-SMTP-Spam-Clean: 8% (\n BODY_SIZE_6000_6999 0, BODY_SIZE_7000_LESS 0, RDNS_BROADBAND 0, RDNS_GENERIC_POOLED 0, RDNS_POOLED 0, RDNS_SUSP 0, RDNS_SUSP_GENERIC 0, RDNS_SUSP_SPECIFIC 0, __BOUNCE_CHALLENGE_SUBJ 0, __BOUNCE_NDR_SUBJ_EXEMPT 0, __CANPHARM_UNSUB 0, __CT 0, __CTE 0, __CT_TEXT_PLAIN 0, __HAS_MSGID 0, __MIME_TEXT_ONLY 0, __MIME_VERSION 0, __MOZILLA_MSGID 0, __RDNS_BROADBAND_5 0, __RDNS_POOLED_11 0, __SANE_MSGID 0, __TO_MALFORMED_2 0, __URI_NO_MAILTO 0, __URI_NO_PATH 0, __URI_NO_WWW 0, __USER_AGENT 0)\r\nX-SMTP-Spam-Score: 8%\r\nX-Scanned-By: MIMEDefang 2.60 on 128.2.11.61\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: David Pane &lt;dpane@...&gt;\r\nSubject: Re: Configuring ContentLengthDecideRule\r\nX-Yahoo-Group-Post: member; u=500983475; y=Q1-DbsX-AbgI9y-_72iS8eL4UJnK7Mx5rxtBSph5lXdLvjKeEBz9uA\r\nX-Yahoo-Profile: david_pane1\r\n\r\nThanks Gordon.\n\nIn regards to why we would want to add additional seeds during the crawl:\n\nWe are planning on adding additional URLs that we harvest from twitter \ntweets (we are downloading a set of tweets  directly from twitter not \nthrough Heritrix).  We want the final crawl data to definitely include \nthese URLs.  We were planning on adding these URLS as seeds.  It appears \nthat we could be adding as many as 3 million of these URLs as new seeds \neach day.  So, I am trying to figure out a workaround so that we will \nnot have to continually add the accumulation of these new seeds  each \ntime we need to restart Heritrix.\n\n--David\n\nOn 1/20/12 11:52 PM, Gordon Mohr wrote:\n&gt; On 1/20/12 4:41 PM, David Pane wrote:\n&gt;&gt;&gt; Only SURT-prefixes coming from an explicitly configured &#39;surtsSource&#39;\n&gt;&gt;&gt; are restored after a checkpoint-resume. Note that this file is just\n&gt;&gt;&gt; literal SURTs, not the +/- syntax that can be used in seeds files.\n&gt;&gt;&gt;\n&gt;&gt;&gt; This bug is now in the tracking system as:\n&gt;&gt;&gt;\n&gt;&gt;&gt; https://webarchive.jira.com/browse/HER-1985\n&gt;&gt;&gt;\n&gt;&gt;&gt; Until it&#39;s fixed, possible workaround would include:\n&gt;&gt;&gt;\n&gt;&gt;&gt; (1) Always configuring SurtPrefixedDecideRules to use a surtsSource, \n&gt;&gt;&gt; and\n&gt;&gt;&gt; making sure that surtsSource is kept up-to-date as the canonical \n&gt;&gt;&gt; list of\n&gt;&gt;&gt; prefixes to rule-in (for an +/ACCEPT rule) or rule-out (for a -/REJECT\n&gt;&gt;&gt; rule), before any resumes.\n&gt;&gt;&gt;\n&gt;&gt; (a) If add the additional opt-out sites to my &quot;opt-out_blacklist.surt&quot;\n&gt;&gt; file as a &quot;+&quot; entry (for rule below). Can I use this rule for the new\n&gt;&gt; seeds but use a &quot;-&quot; entry?\n&gt;&gt;\n&gt;&gt; &lt;!-- ...but REJECT those from a configurable (initially empty) set of\n&gt;&gt; REJECT SURTs... --&gt;\n&gt;&gt; &lt;bean \n&gt;&gt; class=&quot;org.archive.modules.deciderules.surt.SurtPrefixedDecideRule&quot;&gt;\n&gt;&gt; &lt;property name=&quot;decision&quot; value=&quot;REJECT&quot;/&gt;\n&gt;&gt; &lt;property name=&quot;seedsAsSurtPrefixes&quot; value=&quot;false&quot;/&gt;\n&gt;&gt; &lt;property name=&quot;surtsDumpFile&quot; \n&gt;&gt; value=&quot;${launchId}/negative-surts.dump&quot; /&gt;\n&gt;&gt; &lt;property name=&quot;surtsSource&quot;&gt;\n&gt;&gt; &lt;bean class=&quot;org.archive.spring.ConfigFile&quot;&gt;\n&gt;&gt; &lt;!-- DAP opt out path here --&gt;\n&gt;&gt; &lt;property name=&quot;path&quot;\n&gt;&gt; value=&quot;/bos/tmp15/heritrix_crawl/jobs03/2011-12-23/opt-out_blacklist.surt&quot; \n&gt;&gt;\n&gt;&gt; /&gt;\n&gt;&gt; &lt;/bean&gt;\n&gt;&gt; &lt;/property&gt;\n&gt;&gt; &lt;/bean&gt;\n&gt;\n&gt; A &#39;seed&#39; is generally a URI you want to crawl, so you would not \n&gt; usually add a seed (in any way) to a REJECT rule, unless it&#39;s a matter \n&gt; of changing your mind about how it (and URIs that are implied \n&gt; extensions of it) should be treated.\n&gt;\n&gt; Looking over the code, I see that:\n&gt;\n&gt; - when lines are announced from a textual &#39;.seeds&#39; source, the &#39;+&#39; or \n&gt; &#39;-&#39; can affect which of different SurtPrefixedDecideRules notice that \n&gt; line, but in either case, if the line is noticed, it is *added* to \n&gt; that rule&#39;s set of SURT-prefixes\n&gt;\n&gt; - when lines are being processed from a static textual &#39;surtsSource&#39; \n&gt; (either inline ConfigString or disk ConfigFile), only &#39;+&#39; directives \n&gt; are noticed, and the following prefix (or hostname/URI that can be \n&gt; coerced to a prefix) is added to the rule&#39;s set of prefixes\n&gt;\n&gt; This is a bit confusing, but it means the exact same list of &quot;things \n&gt; to block&quot; would be prefixed with &#39;-&#39; if dropped in via a mixed \n&gt; seeds/directives &quot;.seeds&quot; file, but should be naked hosts/URIs (no \n&gt; directive) or preceded with a &#39;+&#39; (if a formal SURT) if supplied as a \n&gt; &#39;surtsSource&#39;.\n&gt;\n&gt; (I&#39;m not sure what exactly your question meant but that covers the \n&gt; different possibilities.)\n&gt;\n&gt;&gt;&gt; (2) After a checkpoint resume, while crawl is still paused, re-present\n&gt;&gt;&gt; all previously &#39;done&#39; files (including original seed-set/directives) to\n&gt;&gt;&gt; &#39;action&#39; directory for re-learning.\n&gt;&gt;&gt;\n&gt;&gt;\n&gt;&gt; Our initial seed list was 10M seeds. Do I need to include this in the\n&gt;&gt; action directory after every restart?\n&gt;\n&gt; If your crawl depends on learning a giant acceptable-sites SURT list \n&gt; from the seeds, and you are choosing this (2) workaround, then yes. \n&gt; But most broad crawls *don&#39;t* learn an acceptable set of sites from \n&gt; their seed list, so if that&#39;s the case for your crawl, then *no*, \n&gt; there&#39;s no need to re-present the seeds each time.\n&gt;\n&gt; - Gordon\n&gt;\n&gt;&gt;&gt; On 1/17/12 7:29 PM, David Pane wrote:\n&gt;&gt;&gt;&gt; I am using Heritrix 3.1.1. After some analysis of the average size of\n&gt;&gt;&gt;&gt; documents that we have been crawling, I would like to configure the\n&gt;&gt;&gt;&gt; crawler (mid-crawl) to begin only downloading documents under a \n&gt;&gt;&gt;&gt; certail\n&gt;&gt;&gt;&gt; size threshold. I am considering a size limit of 3-5MB.\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; I understand that maxLengthBytes in the Http fetcher module can be\n&gt;&gt;&gt;&gt; configure with the maximum length in bytes to fetch. The document, if\n&gt;&gt;&gt;&gt; larger than this, is truncated at this threshold. It seems the\n&gt;&gt;&gt;&gt; ContentLengthDecideRule is more attractive because it can be \n&gt;&gt;&gt;&gt; configured\n&gt;&gt;&gt;&gt; to avoid downloading documents that are larger than a certain \n&gt;&gt;&gt;&gt; threshold.\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; I searched for an example of the syntax to configure this decide \n&gt;&gt;&gt;&gt; rule to\n&gt;&gt;&gt;&gt; no avail. Can someone help me with this? Can I put this someplace near\n&gt;&gt;&gt;&gt; the Transclusion decide rule in the crawler-beans.cxml.\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Is there an easy way for a Heritrix user to find the correct syntax \n&gt;&gt;&gt;&gt; and\n&gt;&gt;&gt;&gt; options for these options? The default crawler-beans.cxml is useful \n&gt;&gt;&gt;&gt; for\n&gt;&gt;&gt;&gt; many options, but I have found it difficult to understand how to \n&gt;&gt;&gt;&gt; include\n&gt;&gt;&gt;&gt; items that are not already in this file.\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Due to our server&#39;s network going down tomorrow morning, I will be\n&gt;&gt;&gt;&gt; pausing our 5 instances of Heritrix. I am considering shutting down \n&gt;&gt;&gt;&gt; the\n&gt;&gt;&gt;&gt; crawlers completely and resuming them from the last checkpoint. Will\n&gt;&gt;&gt;&gt; changes in the crawler-beans.cxml take effect when doing this\n&gt;&gt;&gt;&gt; (i.e. configuring the ContentLengthDecideRule)?\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Additionally, I have been dropping additional bla.seeds files into the\n&gt;&gt;&gt;&gt; action directory when someone asks us to avoid their site. Am I \n&gt;&gt;&gt;&gt; correct\n&gt;&gt;&gt;&gt; that the checkpoint will preserve these opt-out domains?\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;\n\n"}}