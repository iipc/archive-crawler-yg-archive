{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"taV_swixTZfbw90COxmgZxbY4nygiV1wafYlUoqU-zKBI82EWGd1-KfnXUAVFiuD5KKmICWt_qCNHAZxPbmKDnr7D01vgwA","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] Re: H3 and custom HDFSWriterProcessor : questions about checkpoint and terminate","postDate":"1265880957","msgId":6380,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRCNzNDRjdELjUwMjA5MDNAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGhrOWp2ZythZW0yQGVHcm91cHMuY29tPg==","referencesHeader":"PGhrOWp2ZythZW0yQGVHcm91cHMuY29tPg=="},"prevInTopic":6372,"nextInTopic":0,"prevInTime":6379,"nextInTime":6381,"topicId":6345,"numMessagesInTopic":9,"msgSnippet":"... When I try to visit , I get a page not found error. You get a page? What URL are you visiting? ... ","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 20077 invoked from network); 11 Feb 2010 09:36:00 -0000\r\nX-Received: from unknown (98.137.34.44)\n  by m10.grp.re1.yahoo.com with QMQP; 11 Feb 2010 09:36:00 -0000\r\nX-Received: from unknown (HELO relay00.pair.com) (209.68.5.9)\n  by mta1.grp.sp2.yahoo.com with SMTP; 11 Feb 2010 09:36:00 -0000\r\nX-Received: (qmail 87675 invoked from network); 11 Feb 2010 09:35:58 -0000\r\nX-Received: from 70.137.148.203 (HELO ?192.168.23.128?) (70.137.148.203)\n  by relay00.pair.com with SMTP; 11 Feb 2010 09:35:58 -0000\r\nX-pair-Authenticated: 70.137.148.203\r\nMessage-ID: &lt;4B73CF7D.5020903@...&gt;\r\nDate: Thu, 11 Feb 2010 01:35:57 -0800\r\nUser-Agent: Thunderbird 2.0.0.23 (Windows/20090812)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: bertrand.dechoux@...\r\nReferences: &lt;hk9jvg+aem2@...&gt;\r\nIn-Reply-To: &lt;hk9jvg+aem2@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Re: H3 and custom HDFSWriterProcessor : questions\n about checkpoint and terminate\r\nX-Yahoo-Group-Post: member; u=137285340; y=U7tzzSQPh7Z8hv5ULca74QQ9BbvMiq7pdOm6CORtzqtd\r\nX-Yahoo-Profile: gojomo\r\n\r\nbertrand.dechoux wrote:\n&gt; Hi,\n&gt; \n&gt; I have indeed noticed that HDFSWriterProcessor is an outside contribution. About the broken link, I am not sure which one you are talking about. The one at http://crawler.archive.org/ works fine (with a redirection, granted).\n\nWhen I try to visit &lt;http://www.zvents.com/labs/hdfs_writer_processor&gt;, \nI get a &#39;page not found&#39; error. You get a page? What URL are you visiting?\n\n&gt; Like I said, I have no issue with the checkpointing. (The base classes from H3 do everything fine). However, the terminate action did not work.\n&gt; \n&gt; My previous guess was correct (about the toe being blocked by the outputStream) so I hacked my way out. Basically, my subclass of CrawlController sends a special event before cleaning the toe-pool and my writerProcessor closes the pool when receiving the event.\n&gt; \n&gt; I have nothing to commit really to H3 but I would recommend using more events : inside the frontier, the controller or both. An event before calling interrupt on all the toes was really helpful in my case.\n\nWithout an example stack of the problem -- or the HDFSWriterProcessor \ncode, which I don&#39;t have a copy of in either its original form or your \nH3 modifications -- there&#39;s nothing we can do to try to ameliorate this \nissue.\n\nThe HDFSWriterProcessor or other parts of your custom configuration \nmight not have been respecting existing crawl lifecycle events properly; \nI can&#39;t yet see a path in normal operation where the frontier will reach \nfinished state -- triggering the only relevant thread-interrupt, via \nToePool.cleanup() from CrawlController.completeStop() -- while a \nprocessor could still be in mid-operation.\n\n- Gordon @ IA\n\n&gt; Bertrand\n&gt; \n&gt;  \n&gt; \n&gt; --- In archive-crawler@yahoogroups.com, Gordon Mohr &lt;gojomo@...&gt; wrote:\n&gt;&gt; The HDFSWriterProcessor is an outside contribution, and in fact it \n&gt;&gt; appears the link from our news page to download it is broken. (Do you \n&gt;&gt; have a working link?)\n&gt;&gt;\n&gt;&gt; We don&#39;t currently use it but I&#39;d like to help make sure it can be \n&gt;&gt; ported to H3 and work with checkpointing.\n&gt;&gt;\n&gt;&gt; Seeing the whole stack might help narrow down the source of the error.\n&gt;&gt;\n&gt;&gt; Am I correct in assuming that you have no errors when terminating a \n&gt;&gt; crawl that hasn&#39;t been checkpointed?\n&gt;&gt;\n&gt;&gt; - Gordon @ IA\n&gt;&gt;\n&gt;&gt; bertrand.dechoux wrote:\n&gt;&gt;&gt; Hi,\n&gt;&gt;&gt;\n&gt;&gt;&gt; I am using the version 3 of heritrix and the latest version of hadoop (0.20). I have adapted the HDFSWriterProcessor with regard to the changes done in Heritrix 3. And I also have modified the information written in hadoop but that&#39;s a side story.\n&gt;&gt;&gt;\n&gt;&gt;&gt; When I create a checkpoint, everything &quot;works fine&quot; i.e. the buffer(s) -if any- are flushed and the file(s) closed. But when I terminate the crawl job, I get a java.io.InterruptedIOException inside the DFSClient class (an hadoop class).\n&gt;&gt;&gt;\n&gt;&gt;&gt; My &quot;educated guess&quot; would be that a few toes (threads) are waiting on the outputStream and that they are interupted when the frontier cleans the toes.\n&gt;&gt;&gt;\n&gt;&gt;&gt; Is that something you have already experienced? How would you fix it? Has anyone tried the original HDFSWriterProcessor and experienced the same error?\n&gt;&gt;&gt;\n&gt;&gt;&gt; Thanks in advance\n&gt;&gt;&gt;\n&gt;&gt;&gt; Bertrand\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; ------------------------------------\n&gt;&gt;&gt;\n&gt;&gt;&gt; Yahoo! Groups Links\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; ------------------------------------\n&gt; \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n"}}