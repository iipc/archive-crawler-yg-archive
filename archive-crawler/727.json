{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":193794848,"authorName":"nhckbdk","from":"&quot;nhckbdk&quot; &lt;nhckbdk@...&gt;","profile":"nhckbdk","replyTo":"LIST","senderId":"UysozV_jNc4bZfcxvfQ1aHilQUKRbMyIaMA7cswyFXe_GwDq5Ubd7EgnBMybo7G2nQMJuR_D6qxfkZtSalab5xDfzIc","spamInfo":{"isSpam":false,"reason":"0"},"subject":"ARC reading","postDate":"1091192939","msgId":727,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGNlZGg5YitsdDBtQGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":728,"prevInTime":726,"nextInTime":728,"topicId":727,"numMessagesInTopic":11,"msgSnippet":"Hi, I produced the following as an internal note for netarchive.dk, but it s probably of interest to some of the people on this list, so here goes...comments","rawEmail":"Return-Path: &lt;nhckbdk@...&gt;\r\nX-Sender: nhckbdk@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 48031 invoked from network); 30 Jul 2004 13:09:13 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m23.grp.scd.yahoo.com with QMQP; 30 Jul 2004 13:09:13 -0000\r\nReceived: from unknown (HELO n25.grp.scd.yahoo.com) (66.218.66.81)\n  by mta2.grp.scd.yahoo.com with SMTP; 30 Jul 2004 13:09:13 -0000\r\nReceived: from [66.218.67.184] by n25.grp.scd.yahoo.com with NNFMP; 30 Jul 2004 13:09:00 -0000\r\nDate: Fri, 30 Jul 2004 13:08:59 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;cedh9b+lt0m@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Length: 6450\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-eGroups-Remote-IP: 66.218.66.81\r\nFrom: &quot;nhckbdk&quot; &lt;nhckbdk@...&gt;\r\nSubject: ARC reading\r\nX-Yahoo-Group-Post: member; u=193794848\r\nX-Yahoo-Profile: nhckbdk\r\n\r\nHi,\n\nI produced the following as an internal note for netarchive.dk,\nbut it&#39;s probably of interest to some of the people on this list,\nso here goes...comments are welcome.\n\nNotes on a new/alternative version of dk.netarkivet.ArcUtils\n------------------------------------------------\nNiels H. Christensen, netarchive.dk.\nJuly 30th 2004.\n------------------------------------------------\n\nAt the moment, we know of two distinct Java packages that\nhandle the ARC and CDX file formats from Internet Archive\n(and Alexa):\n  - our own dk.netarkivet.ArcUtils, available as open source\n    from our website www.netarchive.dk, and\n  - the package org.archive.io.arc from Internet Archive.\n    This package is part of the open source web harvester Heritrix,\n    which is also open source and available from crawler.archive.org.\nThese two packages were developed simultaneously in Denmark and the \nU.S.\nWe shall refer to these packages as DK and the IA package \nrespectively.\n\n\nOverall functionalities and properties\n--------------------------------------\n\nBoth packages extend the basic functionality of reading and writing \nARC files\nwith a number of features. The DK package contains classes that\nmimic the Alexa tools &quot;binsearch&quot; and &quot;getpage&quot; as well as a class\nfor creating CDX indexes from ARC or DAT files. The IA package \nsupports\npools of ARC writers and sockets for receiving data to be written to \nARC files.\nThe IA package also supports the rather proprietary arc.gz format of\nconcatenated, gzipped ARC records, which the DK package does not.\n\nThe DK package is a closed entity consisting of 6 classes.\nOur dk.netarkivet.proxyviewer relies on classes from the DK package.\nThe IA package is an integrated part of the larger-scale Heritrix \nsoftware base.\n\n\nComparison of ARC reader classes\n--------------------------------\n\nIn the IA package, ARC files are read using the ARCReader class.\nAn ARCReader is constructed from a .arc or a .arc.gz file using \nARCReaderFactory.\nThe ARCReader supports two major styles of access:\n  - lookup of a given stored object using the get(long) method, and\n  - traversing an entire file using the iterator() method.\nEach object is represented by an ARCRecord. The ARCRecord class \nextends\nthe InputStream interface and the stored object is read through the\nassociated methods. Metadata stored in the ARC header can be retrieved\nby the getMetaData() method, which returns an ARCRecordMetaData.\nThe latter is a class of immutable objects that supports get-methods\nfor each header field. The return types are Strings and longs.\n\nIn the DK package, ARC files are read using the ARCInputStream class.\nObjects of this class are usually constructed from a File and an \noffset.\nSuch an object corresponds very closely to an ARCRecord, the \ndifferences being:\n  - The get-methods are implemented directly in the class and all\n    return Strings.\n  - ARCInputStream features a handy readAll() method returning a byte\n[]\n    with the complete object.\nThe reading seems to be better optimized in the IA package\n(though we haven&#39;t tried to measure the difference in performance).\nTraversing an entire file is not directly supported in the DK package,\nbut the ExtractCDX class implements a traversal for its own purposes.\n\n\nARC writer classes\n------------------\n\nBoth packages have class for writing ARC files but we have not made a \nclose\ncomparison of these yet.\n\n\nVision\n------\n\nWe would like to see at some point of time a package that combines\nthe best features of both the DK and the IA package. Ideally this \npackage should:\n  - Be a small, closed enitity.\n  - Be able to mimic the most important Alexa tools.\n  - Support both .arc and .arc.gz.\n  - Provide efficient and convenient access to a single object\n    given a file and an offset.\n  - Provide efficient and convenient traversal of archives.\n  - Provide convenient writing of ARC (and .arc.gz) files.\n    (Large-scale efficient writing may be left out - this is more of\n     a harvester issue).\n\n\nFirst step\n----------\n\nAs a first step, we are developing a version of the DK package\nthat still provides all functionalities of the package but builds on \ntop\nof the IA package. The replacement for ARCInputStream is called\nShareableARCRecord and should have the following public members:\n\npublic class ShareableARCRecord{\n    public ShareableARCRecord(ARCRecord record,File file);\n    public File getFile();\n    public ARCRecordMetaData getMetaData();\n    public byte[] readAll() throws IOException;\n    public InputStream getObjectAsInputStream() throws IOException;\n}\n\nThe File is just the name of the file in which the record was found.\nThis is useful for indexing information.\nAs the class name indicates, the two latter methods may be called\nany number of times without &quot;interference&quot;.\n\nIn order to support CDX extraction we need to extend the package\nwith more explicit support for batch jobs (i.e. &quot;convenient ARC file \ntraversal).\nThis should be implemented through a class with the following public \nmembers:\n\npublic class ARCBatchData {\n\tpublic static ARCBatchData fromArcs(File[] arcFiles);\n\tpublic ARCReadingException[] run(ARCBatchJob job);\n\tpublic ARCReadingException[] run(ARCBatchJob[] jobs);\n}\n\nThe class will do its best to read past any &quot;damages&quot; of the given\nARC files and process as many records as it can find. Problems \nencountered\non the way (e.g. EOF within a record) are encoded in the \nARCReadingException\nclass. In particular, the following code prints out an error report\nfor the ARC file &quot;foo.arc&quot;:\n\n\nFile[] myFile = {new File(&quot;foo.arc&quot;)};\nARCBatchData batcher = ARCBatchData.fromArcs(myFile);\nARCBatchJob[] noJobs = {};\nARCReadingException[] report = batcher.run(noJobs);\nfor(int i=0; i&lt;report.length; i++)\n  System.out.println(report[i]);\n\nThe &quot;ARCBatchJob&quot; is defined as\n\npublic interface ARCBatchJob {\n\tpublic void initialize();\n\tpublic void process(ShareableARCRecord sar);\n\tpublic void finish();\n}\n\nThe ExtractCDX class can then build on top of a batch job with these \npublic \nmembers:\n\npublic class ExtractCDXJob implements ARCBatchJob {\n   /**\n     * @param fields the encoding of wanted fields, e.g. &quot;Aebmngv&quot;\n     * @param output the Stream to which the index is written\n     * @param fullpath indicates whether file names should be written \nwith\n     *                 full directory paths or &quot;flat&quot;.\n     */\n   public ExtractCDXJob(String[] fields,PrintStream output,boolean \nfullPath){\n   /* + all ARCBatchJob methods */\n}\n\n\n\n\n"}}