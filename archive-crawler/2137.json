{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":226767221,"authorName":"Matt Ittigson","from":"Matt Ittigson &lt;cydatamatt@...&gt;","replyTo":"LIST","senderId":"qnYcZMCbFgIl0Cfkk4_dBKD7NCixEEPml7-f31bhweNwOaoYG1b-1YQhK5qX82QC9YO_oHJw1bjdcTF1ZUre8tZySlEBj9puIozj","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Best approach to 7M seeds","postDate":"1124743663","msgId":2137,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDlkMWU0NTI1MDUwODIyMTM0NzcyNmNkY2RkQG1haWwuZ21haWwuY29tPg==","inReplyToHeader":"PDQzMDM4NTI3LjgwMjAxMDFAYXJjaGl2ZS5vcmc+","referencesHeader":"PDlkMWU0NTI1MDUwODE3MTAyMzQ4Y2Q2MmE4QG1haWwuZ21haWwuY29tPgkgPDQzMDM4NTI3LjgwMjAxMDFAYXJjaGl2ZS5vcmc+"},"prevInTopic":2117,"nextInTopic":2150,"prevInTime":2136,"nextInTime":2138,"topicId":2116,"numMessagesInTopic":25,"msgSnippet":"... Can you point me in the right direction on this one (in case I want to look into taking a stab at it)?  What s the problem with so many seeds?  Why does","rawEmail":"Return-Path: &lt;cydatamatt@...&gt;\r\nX-Sender: cydatamatt@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 7245 invoked from network); 22 Aug 2005 20:47:47 -0000\r\nReceived: from unknown (66.218.66.218)\n  by m24.grp.scd.yahoo.com with QMQP; 22 Aug 2005 20:47:47 -0000\r\nReceived: from unknown (HELO zproxy.gmail.com) (64.233.162.207)\n  by mta3.grp.scd.yahoo.com with SMTP; 22 Aug 2005 20:47:47 -0000\r\nReceived: by zproxy.gmail.com with SMTP id l1so30534nzf\n        for &lt;archive-crawler@yahoogroups.com&gt;; Mon, 22 Aug 2005 13:47:43 -0700 (PDT)\r\nReceived: by 10.36.5.16 with SMTP id 16mr4471193nze;\n        Mon, 22 Aug 2005 13:47:43 -0700 (PDT)\r\nReceived: by 10.36.55.19 with HTTP; Mon, 22 Aug 2005 13:47:43 -0700 (PDT)\r\nMessage-ID: &lt;9d1e45250508221347726cdcdd@...&gt;\r\nDate: Mon, 22 Aug 2005 15:47:43 -0500\r\nTo: archive-crawler@yahoogroups.com\r\nIn-Reply-To: &lt;43038527.8020101@...&gt;\r\nMime-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Transfer-Encoding: quoted-printable\r\nContent-Disposition: inline\r\nReferences: &lt;9d1e4525050817102348cd62a8@...&gt;\n\t &lt;43038527.8020101@...&gt;\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: Matt Ittigson &lt;cydatamatt@...&gt;\r\nSubject: Re: [archive-crawler] Best approach to 7M seeds\r\nX-Yahoo-Group-Post: member; u=226767221\r\n\r\nOn 8/17/05, stack &lt;stack@...&gt; wrote:\n&gt; Matt Ittigson wrote:\n&gt; \n&gt; &gt; =\r\nI have 7 million seeds I&#39;d like to spider.  What&#39;s the best approach?\n&gt; \n&gt; =\r\nHandling big lists of seeds -- in the millions -- needs work on our part\n&gt; =\r\n(We have an RFE: &#39;[944987] Support case where millions of seeds&#39; to\n&gt; addre=\r\nss this issue).  Its caused us trouble in the past usually in the\n&gt; form of=\r\n OOME soon after startup.\n\nCan you point me in the right direction on this =\r\none (in case I want to\nlook into taking a stab at it)?  What&#39;s the problem =\r\nwith so many\nseeds?  Why does the memory use continue to rise with more see=\r\nds?\n\n[...]\n\n&gt; &gt; Just hoping to get some feedback from the Heritrix pros abo=\r\nut whether\n&gt; &gt; I&#39;m taking the right approach to solving my problem.  My fir=\r\nst goal is\n&gt; &gt; to spider all 7 million seeds.  The second goal would be to =\r\ndo some\n&gt; &gt; spidering of on-domain pages linked to by those seeds (to disco=\r\nver\n&gt; &gt; possible new seeds).\n&gt; &gt;\n&gt; Your approach sounds fine to me (Gordon =\r\nand Igor might have further\n&gt; suggestions). You might keep the list up to d=\r\nate with your crawls&#39; progress.\n\nI can get to around 650k seeds before even=\r\n the machine with 4G of RAM\nruns out.  Also, the speed isn&#39;t great as more =\r\nseeds are added (that\ncould be any number of factors).\n\n-matt\n\n"}}