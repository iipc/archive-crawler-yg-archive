{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"VBh9wNmT3JGITR16k7kW4evkEq3LfGePEJpOVmuHxQyePg-qnqDdBe3qCLTeuMvDliKUiWc8Ez-S2mAM5jWOVpIyltVxqc4","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] collect only the seed","postDate":"1242071201","msgId":5832,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRBMDg4MEExLjYwNDA4MDlAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PEE0OURDNzgwLUVBNUEtNEYzNy05QzBDLUI3MzkwNUYwNzk2MEBhdG9tb3RpYy5jb20+","referencesHeader":"PGd0cXRsYitvNjNwQGVHcm91cHMuY29tPiA8QTQ5REM3ODAtRUE1QS00RjM3LTlDMEMtQjczOTA1RjA3OTYwQGF0b21vdGljLmNvbT4="},"prevInTopic":5831,"nextInTopic":5833,"prevInTime":5831,"nextInTime":5833,"topicId":5824,"numMessagesInTopic":7,"msgSnippet":"To crawl just the seed page and its inline resources itself -- and not continue crawling other pages -- you can set the max-hops value in the ","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 63979 invoked from network); 11 May 2009 19:47:42 -0000\r\nX-Received: from unknown (69.147.108.201)\n  by m2.grp.sp2.yahoo.com with QMQP; 11 May 2009 19:47:42 -0000\r\nX-Received: from unknown (HELO relay01.pair.com) (209.68.5.15)\n  by mta2.grp.re1.yahoo.com with SMTP; 11 May 2009 19:47:42 -0000\r\nX-Received: (qmail 56319 invoked from network); 11 May 2009 19:46:41 -0000\r\nX-Received: from 67.170.223.242 (HELO ?192.168.1.103?) (67.170.223.242)\n  by relay01.pair.com with SMTP; 11 May 2009 19:46:41 -0000\r\nX-pair-Authenticated: 67.170.223.242\r\nMessage-ID: &lt;4A0880A1.6040809@...&gt;\r\nDate: Mon, 11 May 2009 12:46:41 -0700\r\nUser-Agent: Thunderbird 2.0.0.21 (Windows/20090302)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;gtqtlb+o63p@...&gt; &lt;A49DC780-EA5A-4F37-9C0C-B73905F07960@...&gt;\r\nIn-Reply-To: &lt;A49DC780-EA5A-4F37-9C0C-B73905F07960@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] collect only the seed\r\nX-Yahoo-Group-Post: member; u=137285340; y=gOfrEtGujd1y1sQZ0LMaTL72tOz8mlMch359L0M9hKuW\r\nX-Yahoo-Profile: gojomo\r\n\r\nTo crawl just the seed page and its inline resources itself -- and not \ncontinue crawling other pages -- you can set the &#39;max-hops&#39; value in the \nTooManyHopsDecideRule to 0. Everything not a seed (which by definition \nhas no hop-distance from your starting points) will then be REJECTed.\n\nNote that this assumes that like the default configuration, there are \nstill later rules which then ACCEPT transcluded inline resources (like \nimages, scripts, etc.) or prerequisites.\n\n- Gordon @ IA\n\nraffaele messuti wrote:\n&gt; On May 6, 2009, at 4:46 AM, enigmacodes wrote:\n&gt;&gt; How can I tweak heritrix to crawl only within a seed?\n&gt;&gt; E.g. if my seed is www.espn.com, I would like to retrieve/download  \n&gt;&gt; only links within espn.com. I understand Heritrix by default will  \n&gt;&gt; persue all links it finds (including external ones).\n&gt;&gt;\n&gt; \n&gt; i&#39;ve the same question.\n&gt; i&#39;ve a bunch of url, resolved with handle.net\n&gt; \n&gt; how do i configure heritrix2 to follow redirection from hdl\n&gt; and then crawl only the single page (with images)?\n&gt; \n&gt; please, could you post a complete sheet example?\n&gt; \n&gt; thank you\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; --\n&gt; raffaele@...\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; ------------------------------------\n&gt; \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n"}}