{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"Z716vv1NLyIKjC0XFQosmS-XyENsEerBG08eZ6O95FT_o7iEFQJ7k0CwIVSRVsyvER5KEFBqcpkGjOPx0yJVVM8hneZx2Eg","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] user agent","postDate":"1176141655","msgId":4068,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ2MUE3RjU3LjcwODA4QGFyY2hpdmUub3JnPg==","inReplyToHeader":"PDQ2MUE3MzQxLjIwMzA1MDhAYXJjaGl2ZS5vcmc+","referencesHeader":"PDVhMWMzNGFhMDcwNDA5MDg0MXM0M2QzNDhjN2o5NmUzYzMxMjI1NjE5NWRiQG1haWwuZ21haWwuY29tPiA8NDYxQTczNDEuMjAzMDUwOEBhcmNoaXZlLm9yZz4="},"prevInTopic":4067,"nextInTopic":4069,"prevInTime":4067,"nextInTime":4069,"topicId":4066,"numMessagesInTopic":6,"msgSnippet":"Though we grab exactly what follows the User-Agent directive in a robots.txt file, note that it is not the case this has to exactly match your configured","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 8034 invoked from network); 9 Apr 2007 18:02:56 -0000\r\nReceived: from unknown (66.218.67.35)\n  by m43.grp.scd.yahoo.com with QMQP; 9 Apr 2007 18:02:56 -0000\r\nReceived: from unknown (HELO relay01.pair.com) (209.68.5.15)\n  by mta9.grp.scd.yahoo.com with SMTP; 9 Apr 2007 18:02:56 -0000\r\nReceived: (qmail 33461 invoked from network); 9 Apr 2007 18:00:44 -0000\r\nReceived: from 67.180.63.26 (HELO ?192.168.1.103?) (67.180.63.26)\n  by relay01.pair.com with SMTP; 9 Apr 2007 18:00:44 -0000\r\nX-pair-Authenticated: 67.180.63.26\r\nMessage-ID: &lt;461A7F57.70808@...&gt;\r\nDate: Mon, 09 Apr 2007 11:00:55 -0700\r\nUser-Agent: Thunderbird 1.5.0.10 (Windows/20070221)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;5a1c34aa0704090841s43d348c7j96e3c312256195db@...&gt; &lt;461A7341.2030508@...&gt;\r\nIn-Reply-To: &lt;461A7341.2030508@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] user agent\r\nX-Yahoo-Group-Post: member; u=137285340; y=9sanU2StcZFOpraVh5LKpkpthChVADg0EqdLMGHm-Rf4\r\nX-Yahoo-Profile: gojomo\r\n\r\nThough we grab exactly what follows the User-Agent directive in a \nrobots.txt file, note that it is not the case this has to exactly match \nyour configured crawler user-agent.\n\nThe original robots standard says of the the &#39;User-Agent&#39; field \n(&lt;http://www.robotstxt.org/wc/norobots.html#format&gt;):\n\n&quot;The robot should be liberal in interpreting this field. A case \ninsensitive substring match of the name without version information is \nrecommended.&quot;\n\nHeritrix follows this recommendation: if the value in the robots.txt \n&#39;user-agent&#39; is found as a case-insensitive substring in the \ncrawler-configured user-agent, that ruleset is considered to apply.\n\nSo in the &#39;bot1&#39; example, the &#39;bot1&#39; ruleset will apply to a crawler \nwith UA &quot;Mozilla/5.0 (compatible; bot1 +http://myUrl)&quot;.\n\nTwo important notes would be:\n- no attempt is made to strip &#39;version information&#39; from the \nrobots.txt-specified string -- in general, it&#39;s not included by \nrobots.txt authors\n- only the first matching ruleset is applied. So if for example your \ncrawler-configured UA is &quot;superbot&quot;, and the robots.txt includes both \nrulesets for &quot;superbot&quot; and &quot;bot&quot;, the first to appear is applied (even \nthough both are substrings of your configured UA).\n\nThe wildcard &#39;*&#39; user-agent ruleset is only applied if no other rulesets \napply.\n\nHope this helps,\n\n- Gordon @ IA\n\nMichael Stack wrote:\n&gt; Looks like Heritrix is doing exact matches of string that follows \n&gt; &#39;User-agent: &#39; in robots.txt.  See \n&gt; http://crawler.archive.org/xref/org/archive/crawler/datamodel/Robotstxt.html#38 \n&gt; for where we do the parse and then here, \n&gt; http://crawler.archive.org/xref/org/archive/crawler/datamodel/RobotsExclusionPolicy.html#147, \n&gt; for the check of whats disallowed.\n&gt;\n&gt; St.Ack\n&gt; \n&gt; \n&gt; Andrea Goethals wrote:\n&gt;&gt; Hello,\n&gt;&gt;\n&gt;&gt; Does heritrix do any &quot;liberal-reading&quot; of robots.txt files when\n&gt;&gt; determining if a user agent specified in it is referring to it or does\n&gt;&gt; it take the user agent we configure for it as is?\n&gt;&gt;\n&gt;&gt; For example, if a robots.txt file says\n&gt;&gt; User-agent: bot1\n&gt;&gt;\n&gt;&gt; and we configure our user agent as:\n&gt;&gt; Mozilla/5.0 (compatible; bot1 +http://myUrl)\n&gt;&gt; will the crawler interpret the bot1 user-agent specified in the file\n&gt;&gt; as referring to it?\n&gt;&gt;\n&gt;&gt; Or do we need to specify our user agent like:\n&gt;&gt; bot1 (+http://myUrl)\n&gt;&gt;\n&gt;&gt; thanks,\n&gt;&gt; Andrea\n&gt;&gt;\n&gt;&gt;  \n&gt; \n&gt; \n&gt; \n&gt;  \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n"}}