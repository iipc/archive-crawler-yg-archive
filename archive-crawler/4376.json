{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":307548477,"authorName":"badswalu","from":"&quot;badswalu&quot; &lt;badswalu@...&gt;","profile":"badswalu","replyTo":"LIST","senderId":"fkgcTB9sG2L4OrHDtOgPnTrjqORt8eLJy7KLO3kXxv7t2JLdgwO5VH9OHu0QeQXefUpT6Y3t_VFTtY9_dfTnM_WGdtcOUw","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Questions running multiple crawler&#39;s","postDate":"1182974487","msgId":4376,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGY1dWZtbisyMWQ2QGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":4388,"prevInTime":4375,"nextInTime":4377,"topicId":4376,"numMessagesInTopic":2,"msgSnippet":"I want to start several heritrix crawlers, each in their own JVM running on different JMX ports and web GUI ports. I have noticed that if there are any","rawEmail":"Return-Path: &lt;badswalu@...&gt;\r\nX-Sender: badswalu@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 73902 invoked from network); 27 Jun 2007 20:02:22 -0000\r\nReceived: from unknown (66.218.67.36)\n  by m46.grp.scd.yahoo.com with QMQP; 27 Jun 2007 20:02:22 -0000\r\nReceived: from unknown (HELO n27c.bullet.scd.yahoo.com) (66.218.67.220)\n  by mta10.grp.scd.yahoo.com with SMTP; 27 Jun 2007 20:02:22 -0000\r\nReceived: from [66.218.69.3] by n27.bullet.scd.yahoo.com with NNFMP; 27 Jun 2007 20:01:28 -0000\r\nReceived: from [66.218.66.76] by t3.bullet.scd.yahoo.com with NNFMP; 27 Jun 2007 20:01:28 -0000\r\nDate: Wed, 27 Jun 2007 20:01:27 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;f5ufmn+21d6@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;badswalu&quot; &lt;badswalu@...&gt;\r\nSubject: Questions running multiple crawler&#39;s\r\nX-Yahoo-Group-Post: member; u=307548477; y=L2QE3Ue_Px352pBCDjEtIkl8HBtjAX188MLohwm_WgLgoU4\r\nX-Yahoo-Profile: badswalu\r\n\r\nI want to start several heritrix crawlers, each in their own JVM\nrunning on=\r\n different JMX ports and web GUI ports. I have noticed that\nif there are an=\r\ny uncrawled jobs in the jobs folder, that each Heritrix\ncrawler I start wil=\r\nl have those jobs pending (i am starting each\ncrawler from the same source =\r\nlocation).\n    Is there a way to run several Heritrix crawlers (each in the=\r\nir own\nJVM) on the same machine, without them sharing jobs?  i.e., Could ea=\r\nch\ncrawler have it&#39;s own &#39;jobs&#39; folder? How could that be set up? Would I\nh=\r\nave to create several different copies of the Heritrix executible?\n\n\nI am a=\r\nlso trying to monitor or &quot;watch&quot; a crawler, and would like to do\nso from a =\r\njava application. I am most interested in knowing when the\ncrawler being wa=\r\ntched is done crawling (isCrawling=3Dfalse) so I can\nschedule another job w=\r\nith it. I would be monitoring from the same\nmachine the crawler is on, and =\r\nwould like to monitor more than one\ncrawler, each in it&#39;s own JVM. \n    Is =\r\nthere a good way to do this? Is there a way my application\ncould receive a =\r\nnotification from the crawler when it is done, or do I\nhave to manually pol=\r\ne the crawler waiting for isCrawling=3Dfalse?\n\nMy last question has to do w=\r\nith the number of URL&#39;s submitted as\nSeeds.  How many seeds are too many fo=\r\nr one job? How many seeds\ncan/will heritrix try to crawl simultainously fro=\r\nm one job?\n\nThank you,\n-badswalu\n\n\n"}}