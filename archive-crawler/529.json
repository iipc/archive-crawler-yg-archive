{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137477665,"authorName":"Igor Ranitovic","from":"Igor Ranitovic &lt;igor@...&gt;","profile":"iranitovic","replyTo":"LIST","senderId":"5WHhtJbnOcXbQdix7qVg4v_SqNDhDy8fe7R8vbbJjnRNX9JkM5MEa6-wNT0_7NAXju98vTqb2SOrVPZTRTb7P8I9CfouKNpx","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Out-of-the-box defaults?","postDate":"1086912225","msgId":529,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQwQzhGNkUxLjkwOUBhcmNoaXZlLm9yZz4=","inReplyToHeader":"PDQwQzhEN0ZBLjUwNTAyQGxvYy5nb3Y+","referencesHeader":"PDQwQzhEN0ZBLjUwNTAyQGxvYy5nb3Y+"},"prevInTopic":528,"nextInTopic":550,"prevInTime":528,"nextInTime":530,"topicId":528,"numMessagesInTopic":4,"msgSnippet":"... Sure. Maybe we should adopt IBM s JVM approach where default size of the heap is a half of a system s physical memory. ... We should have HTTP, HTML, CSS,","rawEmail":"Return-Path: &lt;igor@...&gt;\r\nX-Sender: igor@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 39002 invoked from network); 11 Jun 2004 00:04:47 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m14.grp.scd.yahoo.com with QMQP; 11 Jun 2004 00:04:47 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (209.237.232.202)\n  by mta5.grp.scd.yahoo.com with SMTP; 11 Jun 2004 00:04:47 -0000\r\nReceived: (qmail 20988 invoked by uid 100); 10 Jun 2004 23:56:09 -0000\r\nReceived: from b116-dyn-56.archive.org (HELO archive.org) (igor@...@209.237.240.56)\n  by mail-dev.archive.org with SMTP; 10 Jun 2004 23:56:09 -0000\r\nMessage-ID: &lt;40C8F6E1.909@...&gt;\r\nDate: Thu, 10 Jun 2004 17:03:45 -0700\r\nUser-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.0; en-US; rv:1.6b) Gecko/20031205 Thunderbird/0.4\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;40C8D7FA.50502@...&gt;\r\nIn-Reply-To: &lt;40C8D7FA.50502@...&gt;\r\nContent-Type: text/plain; charset=us-ascii; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=0.1 required=6.0 tests=AWL autolearn=ham version=2.63\r\nX-eGroups-Remote-IP: 209.237.232.202\r\nFrom: Igor Ranitovic &lt;igor@...&gt;\r\nSubject: Re: [archive-crawler] Out-of-the-box defaults?\r\nX-Yahoo-Group-Post: member; u=137477665\r\nX-Yahoo-Profile: iranitovic\r\n\r\n&gt; - Invocation: it seems pretty clear that crawls are safest with some \n&gt; memory headroom.  Can the bin/heritrix script default JAVA_OPTS to \n&gt; &quot;-Xmx256m&quot; if it&#39;s not otherwise set?\n\nSure. Maybe we should adopt IBM&#39;s JVM approach where default size of the heap is a half of a \nsystem&#39;s physical memory.\n\n&gt; - Extractors: how experimental are the non-enabled variants?  I recall \n&gt; that in February, we were encouraged to use HTML2 and CSS, but that some \n&gt; leaked memory (PDF?  DOC?  SWF?).  Is it safe to change the defaults to, \n&gt; at the least, include CSS?  Of the potentially leaky ones, SWF seems the \n&gt; most compelling for enabling by default.\n\nWe should have HTTP, HTML, CSS, JS and SWF be defualt extractors.\nWe changed SWF extractor to use memory more efficiently and I have not have memory problems with it \nsince.\nPDF and DOC extractors are still problematic. I have been working on a new, more memory efficient \nPDF extractor but is not ready yet. DOC parsing is a problem since DOCs cannot be parsed by treating \nthem as randomly accesable streams. Beacause of this it is necessary to load entire DOCs into memory \nin order to parse them.\nHTML2 extractor(horrible name btw) is making two passes on javascript code. One pass examains all \nstrings in javascript code and second pass parses javascript code as html. HTML extractor is making \nonly the fisrt pass. I believe that HTML extracotr got better and that there is no need of HTML2 \nanymore.\nI will have to do some comparison to confirm this.\n\n&gt; - Filters: If I understand the &quot;recheck-scope&quot; setting on the \n&gt; preselector, it needs to be set for scope changes during the crawl to be \n&gt; detected and honored.  Assuming it doesn&#39;t affect performance too much, \n&gt; can it default to on?\n\nI have no preferences on this one. Though, it seems right as is.\n\n&gt; Is it worthwhile to enable by default either PathDepth or \n&gt; PathologicalPath filters, presumably with generous but non-infinite values?\n\nI agree. I usually set PathDepth to 20 and PathologicalPath to max of 3 repetitions of a pattern.\n\n&gt; - Politeness: I know per-host bandwidth usage got moved to the &quot;expert&quot; \n&gt; section, but it might be good to default the per-host cap to something \n&gt; maybe T1-like (thus, perhaps 150KBps or so) to avoid pummelling sites \n&gt; with large files, when crawling from a large pipe.  (Is the per-host cap \n&gt; like the total-bandwidth cap, in that it doesn&#39;t actually constrain \n&gt; instantaneous traffic, only the average?)\n\nI am not sure if need to do this. It seems that default values of dynamic politeness will \nsignificantly delay request to sites with large files when crawling from a large pipe.\nDuring fetching we just might be OK by relying on TCP&#39;s congestion control and not worry about \nsolely saturating the sites&#39; bandwidth.\n\nTake care.\ni.\n\n"}}