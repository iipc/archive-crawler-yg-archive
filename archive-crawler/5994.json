{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":132996324,"authorName":"joehung302","from":"&quot;joehung302&quot; &lt;joe.hung@...&gt;","profile":"joehung302","replyTo":"LIST","senderId":"3S2S7HMe5_f0CvNYzGDJys00huznTALjPVWXiXvdV71llvCzbHMX27wBYecWkNzHRLPNtN-Och0UPhaNSncdyYDDFsf9tmBR1piGsavF","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Heritrix set up and infrastructure question","postDate":"1250887715","msgId":5994,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGg2bjE3MytyMXAwQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDRBOEVCRkJBMDIwMDAwMTIwMDNCRUJGQUBudGd3Z2F0ZS5sb2MuZ292Pg=="},"prevInTopic":5993,"nextInTopic":5995,"prevInTime":5993,"nextInTime":5995,"topicId":5945,"numMessagesInTopic":9,"msgSnippet":"We run 12 Heritrix (1.x based) on 12 crawlers. Each crawler has 5TB storage. When we re running an Internet crawl, we sometimes take ARC files out of the arcs/","rawEmail":"Return-Path: &lt;joe.hung@...&gt;\r\nX-Sender: joe.hung@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 52764 invoked from network); 21 Aug 2009 20:48:50 -0000\r\nX-Received: from unknown (69.147.108.200)\n  by m3.grp.sp2.yahoo.com with QMQP; 21 Aug 2009 20:48:50 -0000\r\nX-Received: from unknown (HELO n45b.bullet.mail.sp1.yahoo.com) (66.163.168.159)\n  by mta1.grp.re1.yahoo.com with SMTP; 21 Aug 2009 20:48:49 -0000\r\nX-Received: from [69.147.65.149] by n45.bullet.mail.sp1.yahoo.com with NNFMP; 21 Aug 2009 20:48:38 -0000\r\nX-Received: from [98.137.34.36] by t9.bullet.mail.sp1.yahoo.com with NNFMP; 21 Aug 2009 20:48:38 -0000\r\nDate: Fri, 21 Aug 2009 20:48:35 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;h6n173+r1p0@...&gt;\r\nIn-Reply-To: &lt;4A8EBFBA02000012003BEBFA@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;joehung302&quot; &lt;joe.hung@...&gt;\r\nSubject: Re: Heritrix set up and infrastructure question\r\nX-Yahoo-Group-Post: member; u=132996324; y=Q_44w9zK0VzpYaL_ETDlBb34FsgzQI77kXPyXU-66SjsZULTVg\r\nX-Yahoo-Profile: joehung302\r\n\r\nWe run 12 Heritrix (1.x based) on 12 crawlers. Each crawler has 5TB storage=\r\n.\n\nWhen we&#39;re running an Internet crawl, we sometimes take ARC files out of=\r\n the arcs/ directory because after some time we will fill up the 5TB local =\r\nstorage. We only move out individual ARC files and nothing more.\n\nWe use JM=\r\nX and have our own JMX wrapper to check the status of the crawlers. \n\nIf we=\r\n finish a particular job, we might move the individual job directory out so=\r\nmewhere for archive purposes. This would clean up everything associated wit=\r\nh a particular job.\n\nCheers,\n-Joe\n--- In archive-crawler@yahoogroups.com, &quot;=\r\nGina Jones&quot; &lt;gjon@...&gt; wrote:\n&gt;\n&gt; Just curious if anyone else has a set up =\r\nfor crawling similar to ours to see if we can get any lessons learned.\n&gt; \n&gt;=\r\n We have heritrix  2.0.2 set up  and firewalled on a server that we only us=\r\ne for crawling.  We have 3 separate instances of the crawler running and ab=\r\nout 2 TB space available on the server.\n&gt; \n&gt; We have the webui running one =\r\ninstance and we have been running chron jobs on the other two instances.\n&gt; =\r\n\n&gt; We have to keep moving content from our crawling server to our qr/access=\r\n servers.  We don&#39;t have any other options.  \n&gt; \n&gt; The problem that we have=\r\n had recently has to do with the chron jobs, more specifically with the ale=\r\nrts and crawl log.  \n&gt; \n&gt; Is there anything that we should be aware of when=\r\n we are running heritrix and trying to move files out, from the logs dir or=\r\n the jobs dir?  \n&gt; \n&gt; thanks, Gina\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; Gina Jones, gjon@...\n&gt; =\r\nDigital Media Project Coordinator\n&gt; Office of Strategic Initiatives\n&gt; Libra=\r\nry of Congress\n&gt; http://www.loc.gov/webcapture \n&gt; 1-202-707-6604\n&gt; gjon@...=\r\n\n&gt;\n\n\n\n"}}