{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":334763322,"authorName":"Christian Krumm","from":"Christian Krumm &lt;signore.chrissi@...&gt;","profile":"chuk_ol","replyTo":"LIST","senderId":"dbim-e46m3XlHVJD-g0Y2Fd6Nn11ZToMU5GPN-Sr6DAAkDaKf6nWRj-7Glaifw1KY6yA54NAWBIFTEEFxiit_NkJl-Omw9isU3-V1FTq0VnucBLRHTpO","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Question concerning ReplayInputStream.getContentSize()","postDate":"1218272800","msgId":5402,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ4OUQ1RTIwLjQwMzAwMDZAZ29vZ2xlbWFpbC5jb20+","inReplyToHeader":"PDQ4OUM5MUVBLjMwNzA0MDRAZ214Lm5ldD4=","referencesHeader":"PDQ4OUMyNjUxLjIwOTA3QGdvb2dsZW1haWwuY29tPiA8NDg5QzkxRUEuMzA3MDQwNEBnbXgubmV0Pg=="},"prevInTopic":5401,"nextInTopic":0,"prevInTime":5401,"nextInTime":5403,"topicId":5397,"numMessagesInTopic":5,"msgSnippet":"Hi Gordon and Olaf. Thanks for your help! I ll give it a try. Olaf, I m currently useing the 2.6 Version of Jericho, which seems to work fine. I ve downloaded","rawEmail":"Return-Path: &lt;signore.chrissi@...&gt;\r\nX-Sender: signore.chrissi@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 50743 invoked from network); 9 Aug 2008 09:06:48 -0000\r\nX-Received: from unknown (66.218.67.94)\n  by m44.grp.scd.yahoo.com with QMQP; 9 Aug 2008 09:06:48 -0000\r\nX-Received: from unknown (HELO smtpmx11.uni-oldenburg.de) (134.106.87.111)\n  by mta15.grp.scd.yahoo.com with SMTP; 9 Aug 2008 09:06:48 -0000\r\nX-Received: from [192.168.2.27] (p57B6DF5D.dip.t-dialin.net [87.182.223.93])\n\t(authenticated bits=0)\n\tby smtpmx11.uni-oldenburg.de (8.13.1/8.13.1) with ESMTP id m7996cm2001513\n\t(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NO)\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Sat, 9 Aug 2008 11:06:45 +0200\r\nMessage-ID: &lt;489D5E20.4030006@...&gt;\r\nDate: Sat, 09 Aug 2008 11:06:40 +0200\r\nUser-Agent: Thunderbird 2.0.0.16 (X11/20080724)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;489C2651.20907@...&gt; &lt;489C91EA.3070404@...&gt;\r\nIn-Reply-To: &lt;489C91EA.3070404@...&gt;\r\nX-Enigmail-Version: 0.95.0\r\nContent-Type: text/plain; charset=ISO-8859-15\r\nContent-Transfer-Encoding: 7bit\r\nX-PMX-Version: 5.4.3.345767, Antispam-Engine: 2.6.0.325393, Antispam-Data: 2008.8.9.84919\r\nX-PerlMx-Spam: Gauge=IIIIIII, Probability=7%, Report=&#39;BODY_SIZE_2000_2999 0, BODY_SIZE_5000_LESS 0, RDNS_DYNAMIC 0, RDNS_SUSP 0, RDNS_SUSP_SPECIFIC 0, __BOUNCE_CHALLENGE_SUBJ 0, __CP_URI_IN_BODY 0, __CT 0, __CTE 0, __CT_TEXT_PLAIN 0, __FRAUD_419_WEBMAIL 0, __FRAUD_419_WEBMAIL_FROM 0, __HAS_MSGID 0, __MIME_TEXT_ONLY 0, __MIME_VERSION 0, __SANE_MSGID 0, __USER_AGENT 0&#39;\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Christian Krumm &lt;signore.chrissi@...&gt;\r\nSubject: Re: [archive-crawler] Question concerning ReplayInputStream.getContentSize()\r\nX-Yahoo-Group-Post: member; u=334763322; y=b4JDQg6_ZnFH3t2dEpVStJQA2PYAcZ1YYpYbEZ1DLlk4nw\r\nX-Yahoo-Profile: chuk_ol\r\n\r\nHi Gordon and Olaf.\nThanks for your help! I&#39;ll give it a try.\n\nOlaf, I&#39;m currently useing the 2.6 Version of Jericho, which seems to\nwork fine. I&#39;ve downloaded the jar from Sourceforge and added it\nmanually to the local maven repository. I&#39;m useing Jericho to extract\nhyperlink features like the link environment, the anchor text or the\nlink title in a custom JerichoExtractorHTML. Currently, as far as I can\nsay, it works like a charm. I&#39;ve added a feature to my Link Extractor to\nonly extract a limited number of links. The limit is set to 1Mio by\ndefault. If the limit was reached no further links are extracted.\n\nThe OOMEs occurs within the Geo-Parser I&#39;m using.\nIt was developed at OFFIS useing a MySQL Database as backend and\ncyberneko for doing the HTML Parseing.\nThe problem seems to be, that the whole document seems to be loaded into\nmemory for parsing it. I already have added a ContentTypeMatchesRegExp\nto the mid-fetch-rules to only download files with HTML Content-Type.\nNever the less there seems to be sites, which sends text/html as\nContent-Type but than sends binary data.\n\nA site I&#39;ve found whould be\nhttp://www.donnerwetter.de/region/suchplz.hts?search2=&B1=ok\n\nWhen calling this site in firefox I&#39;ll get a text/html content-type\nwith Transfer-Encoding:chunked. I&#39;m useing the Live HTTP Header Plugin.\nBut the data send seems to be binary. Firefox even gets a timeout.\n\n\nSo, to prevent the parser from crashing I added a filter.\nI check the first 10 lines for &lt;html or &lt;!DOCTYPE HTML.\nIf it is not present, I assume that the document is broken or binary,\nand don&#39;t handle it (= skip address parseing). Further I don&#39;t parse\ndocuments, which have a recordered size larger than 500k. The\nHTML-Documents I&#39;ve found so far are all smaller than 500k. Normally\nthey have a size of round about 30k. Documents with more than 400k are\nrare. So I assume that documents larger than 500k are broken or binary\nfiles wrongly declareed as text/html content-type. I skip parseing of\nthem too.\n\nOlaf, you are useing 700k as file boundary. Are you useing\nthe&#39;max-length-bytes&#39; setting of FetchHTTP or are you skipping to large\nfiles whithin your Processor? How much Heap-Space are you useing\nfor running your jobs? I&#39;m currently useing the default of 256MB.\nMy computer only has 512 MB RAM. This configuration seems to work fine,\nas long as the files parsed with cyberneko\nfits into memory. The crawler currently crawls up to 300.000 sites\nbefore crashing because of OOME, I&#39;ve mentioned.\n\n\nChristian\n\n\n\n"}}