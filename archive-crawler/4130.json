{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":302199681,"authorName":"pchoy","from":"&quot;pchoy&quot; &lt;philipchoy@...&gt;","profile":"pchoy","replyTo":"LIST","senderId":"cTgDMVX4zdT_2dyugxiYjQT8xLJEQaIfhxC6EymVfknl5ZMFuk7y2uNXKiMeqi-zaxrUWxZztcOzRp3ZHjlD72hz4ZUWFeM","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Please Help!  How come links extracted fromthis page were not followed/crawled?","postDate":"1176879192","msgId":4130,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGYwNGY4bys2OGdiQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGYwNGI3YitsbDBmQGVHcm91cHMuY29tPg=="},"prevInTopic":4129,"nextInTopic":4133,"prevInTime":4129,"nextInTime":4131,"topicId":4129,"numMessagesInTopic":3,"msgSnippet":"O.K.  I turned on finer logging and it shows LinksScoper consider those links are out of scope. So my question is, why? ... path. ... the","rawEmail":"Return-Path: &lt;philipchoy@...&gt;\r\nX-Sender: philipchoy@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 49413 invoked from network); 18 Apr 2007 06:53:21 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m50.grp.scd.yahoo.com with QMQP; 18 Apr 2007 06:53:21 -0000\r\nReceived: from unknown (HELO n32c.bullet.scd.yahoo.com) (66.94.237.10)\n  by mta6.grp.scd.yahoo.com with SMTP; 18 Apr 2007 06:53:21 -0000\r\nReceived: from [66.218.69.3] by n32.bullet.scd.yahoo.com with NNFMP; 18 Apr 2007 06:53:13 -0000\r\nReceived: from [66.218.66.90] by t3.bullet.scd.yahoo.com with NNFMP; 18 Apr 2007 06:53:13 -0000\r\nDate: Wed, 18 Apr 2007 06:53:12 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;f04f8o+68gb@...&gt;\r\nIn-Reply-To: &lt;f04b7b+ll0f@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;pchoy&quot; &lt;philipchoy@...&gt;\r\nSubject: Re: Please Help!  How come links extracted fromthis page were not followed/crawled?\r\nX-Yahoo-Group-Post: member; u=302199681; y=RqQz2TjXVdposx8jjzsXREae72fFhtfVX7usbkB4aTo\r\nX-Yahoo-Profile: pchoy\r\n\r\n\nO.K.  I turned on finer logging and it shows LinksScoper consider \nthose l=\r\ninks are out of scope. So my question is, why? \n\n\n\n--- In archive-crawler@y=\r\nahoogroups.com, &quot;pchoy&quot; &lt;philipchoy@...&gt; \nwrote:\n&gt;\n&gt; I am very puzzled by t=\r\nhis.  There are links (&lt;A href=3D...&gt;) in the\n&gt; following page that are pre=\r\ntty straight forward:\n&gt; \n&gt; http://vis.cs.ucdavis.edu/~yuho/homepage/aboutme=\r\n/aboutme.htm\n&gt; \n&gt; I am pretty sure links were extracted from this page (I h=\r\nad tried \n&gt; using\n&gt; ExtractorHTML and JerichoExtractorHTML and my own imple=\r\nmentation)...\n&gt; I am using the default job profile so I expected the crawle=\r\nr will \n&gt; follow all the links found. For example, in the page there is:\n&gt; =\r\n\n&gt; &lt;a href=3D&quot;../publications/paper/hpc06.pdf&quot; target=3D&quot;_blank&quot;&gt;[PDF]&lt;/a&gt;\n=\r\n&gt; \n&gt; If I use http://vis.cs.ucdavis.edu/~yuho/homepage/publications/paper\n&gt;=\r\n as seed, then I can retrieve the pdf file without problem.\n&gt; \n&gt; At first I=\r\n thought maybe it&#39;s because links were using relative \npath.\n&gt; But then the=\r\nre are a few links that are not. \n&gt; \n&gt; Is there something special about thi=\r\ns page or I need to change \n&gt; something in the crawler settings?  There is =\r\nnothing mentioned in \nthe \n&gt; logs and reports.\n&gt;\n\n\n\n"}}