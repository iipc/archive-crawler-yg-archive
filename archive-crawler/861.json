{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"stack","from":"stack &lt;stack@...&gt;","replyTo":"LIST","senderId":"BDzUuDplEtkaPcnMgwtRldH--mQ6sRY1cx1Cf0avwi1ND0da-dCqcMzVPV_R2Bs_pc4adYgbMTyzgT9mxn8Epw","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Limiting crawls (mostly) to HTML","postDate":"1093295673","msgId":861,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQxMkE1RTM5LjUwODAyMDdAYXJjaGl2ZS5vcmc+"},"prevInTopic":858,"nextInTopic":862,"prevInTime":860,"nextInTime":862,"topicId":841,"numMessagesInTopic":14,"msgSnippet":"... Would it be better to add this functionality as a mimetype-regex-filter that could be attached variously post-fetch-step? ... Anonymous CVS access seems to","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 42509 invoked from network); 23 Aug 2004 21:21:06 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m20.grp.scd.yahoo.com with QMQP; 23 Aug 2004 21:21:06 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (209.237.232.202)\n  by mta6.grp.scd.yahoo.com with SMTP; 23 Aug 2004 21:21:06 -0000\r\nReceived: (qmail 5928 invoked by uid 100); 23 Aug 2004 21:10:33 -0000\r\nReceived: from debord.archive.org (HELO ?207.241.238.140?) (stack@...@207.241.238.140)\n  by mail-dev.archive.org with SMTP; 23 Aug 2004 21:10:33 -0000\r\nMessage-ID: &lt;412A5E39.5080207@...&gt;\r\nDate: Mon, 23 Aug 2004 14:14:33 -0700\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.7.1) Gecko/20040802 Debian/1.7.1-5\r\nX-Accept-Language: en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nContent-Type: text/plain; charset=us-ascii\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=0.1 required=7.0 tests=AWL autolearn=ham version=2.63\r\nX-eGroups-Remote-IP: 209.237.232.202\r\nFrom: stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] Limiting crawls (mostly) to HTML\r\nX-Yahoo-Group-Post: member; u=168599281\r\n\r\nzhousp wrote:\n\n&gt;I change a little in org.archive.crawler.writer.ARCWriterProcessor and can\n&gt;let user to add some ContentType string. only the content-type list in the\n&gt;user defined values will be save to hard disk. When turn on expert setting,will find\n&gt;some property under ARCWriter setting. Don&#39;t set this value means accept\n&gt;all pages.\n&gt;\n&gt;  \n&gt;\nWould it be better to add this functionality as a mimetype-regex-filter\nthat could be attached variously post-fetch-step?\n\n&gt;Because I can&#39;t access the cvs server now,so post the whole file here.\n&gt;It was made on version 1.17\n&gt;  \n&gt;\nAnonymous CVS access seems to be back now.\n\nSt.Ack\n\n&gt;ansi\t\n&gt;\n&gt;\n&gt;  \n&gt;\n&gt;&gt;zhousp writes:\n&gt;&gt;    \n&gt;&gt;\n&gt;&gt;&gt;I think should change the code to:\n&gt;&gt;&gt;\n&gt;&gt;&gt;        String ct = curi.getContentType();\n&gt;&gt;&gt;        if (ct == null || !ct.startwith(&quot;text/&quot;))\n&gt;&gt;&gt;      \n&gt;&gt;&gt;\n&gt;&gt;For my purposes I only want markup. In a crawl I recently did that\n&gt;&gt;resulted in over 960,000 documents, just under 14,000 (1.5%) were\n&gt;&gt;text/plain, and most of these were robots.txt or similar noise that\n&gt;&gt;was of little interest. The remaining text/* types amounted to much\n&gt;&gt;less than this.\n&gt;&gt;\n&gt;&gt;-- \n&gt;&gt;Tom Emerson                                          Basis Technology Corp.\n&gt;&gt;Software Architect                                 http://www.basistech.com\n&gt;&gt; &quot;Beware the lollipop of mediocrity: lick it once and you suck forever&quot;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;    \n&gt;&gt;\n&gt;\n&gt;\n&gt;\n&gt; \n&gt;Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n&gt; \n&gt;\n\n\n"}}