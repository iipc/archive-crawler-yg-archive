{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137477665,"authorName":"Igor Ranitovic","from":"Igor Ranitovic &lt;igor@...&gt;","profile":"iranitovic","replyTo":"LIST","senderId":"HMGU8M48RNfoLZYenAXEjtwBMzjFiK2VCQIe1ml65zgZLVrSHf9XkcbvS6HExb_AtV0hlpWPGCPEQCL3p0DIV1H_HPyWTK3-","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Best approach question","postDate":"1200684340","msgId":4907,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ3OTBGRDM0LjYwMTAzMDRAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PEEwNzdERjdDRjc3MzM1NERCMjg1Mjc5MDMwRjZBMUE1MzFCODExQE9YWUdFTi5zaXJzaS5wdnQ+","referencesHeader":"PEEwNzdERjdDRjc3MzM1NERCMjg1Mjc5MDMwRjZBMUE1MzFCODExQE9YWUdFTi5zaXJzaS5wdnQ+"},"prevInTopic":4906,"nextInTopic":4908,"prevInTime":4906,"nextInTime":4908,"topicId":4906,"numMessagesInTopic":6,"msgSnippet":"I don t think that you need to run separate jobs for each seed. For example, is you have two seeds as: http://www.foo.com/baz/bar2.html ","rawEmail":"Return-Path: &lt;igor@...&gt;\r\nX-Sender: igor@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 14668 invoked from network); 18 Jan 2008 19:25:44 -0000\r\nX-Received: from unknown (66.218.67.97)\n  by m55.grp.scd.yahoo.com with QMQP; 18 Jan 2008 19:25:44 -0000\r\nX-Received: from unknown (HELO mail.archive.org) (207.241.233.246)\n  by mta18.grp.scd.yahoo.com with SMTP; 18 Jan 2008 19:25:44 -0000\r\nX-Received: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id F1A3A485FF\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Fri, 18 Jan 2008 11:25:43 -0800 (PST)\r\nX-Received: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id u1TojTaYMq7T for &lt;archive-crawler@yahoogroups.com&gt;;\n\tFri, 18 Jan 2008 11:25:42 -0800 (PST)\r\nX-Received: from [192.168.1.107] (c-76-102-230-209.hsd1.ca.comcast.net [76.102.230.209])\n\tby mail.archive.org (Postfix) with ESMTP id 2C87D479D6\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Fri, 18 Jan 2008 11:25:42 -0800 (PST)\r\nMessage-ID: &lt;4790FD34.6010304@...&gt;\r\nDate: Fri, 18 Jan 2008 11:25:40 -0800\r\nUser-Agent: Thunderbird 2.0.0.9 (Windows/20071031)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;A077DF7CF773354DB285279030F6A1A531B811@...&gt;\r\nIn-Reply-To: &lt;A077DF7CF773354DB285279030F6A1A531B811@...&gt;\r\nContent-Type: text/plain; charset=windows-1252; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Igor Ranitovic &lt;igor@...&gt;\r\nSubject: Re: [archive-crawler] Best approach question\r\nX-Yahoo-Group-Post: member; u=137477665; y=0bW5VNgCrFjdT7PQd9xBX1OguJtCkbPmXYeEsIGES2Ndny423g\r\nX-Yahoo-Profile: iranitovic\r\n\r\nI don&#39;t think that you need to run separate jobs for each seed.\n\nFor example, is you have two seeds as:\n\nhttp://www.foo.com/baz/bar2.html\nhttp://www.foo.com/zab/bar2.html\n\nyou can have scope as:\n\n+http://www.foo.com/baz/bar2.html\n+http://www.foo.com/zab/bar2.html\n\nand this decide rule:\n\n&lt;newObject name=&quot;seedsCurrentFolderOnly&quot; \nclass=&quot;org.archive.crawler.deciderules.MatchesListRegExpDecideRule&quot;&gt;\n  &lt;string name=&quot;decision&quot;&gt;REJECT&lt;/string&gt;\n  &lt;string name=&quot;list-logic&quot;&gt;OR&lt;/string&gt;\n  &lt;stringList name=&quot;regexp-list&quot;&gt;\n     &lt;string&gt;(?i)http://www.foo.com/baz/.*/&lt;/string&gt;\n     &lt;string&gt;(?i)http://www.foo.com/zab/.*/&lt;/string&gt;\n   &lt;/stringList&gt;\n&lt;/newObject&gt;\n\n\nCreating the scope and MatchesListRegExpDecideRule can be done easily \nwith little scripting.\n\nI hope this helps.\n\nTake care,\ni.\n\nTravis Jensen wrote:\n&gt; Hi,\n&gt; \n&gt;  \n&gt; \n&gt; I�m looking for some feedback as to a best approach to a crawling \n&gt; problem I need solve.  I have a list of URLs, some of which I only want \n&gt; to crawl that URL, some of which I want to crawl that whole domain \n&gt; (�foo.com�), some I want to crawl only that server (�www.foo.com�), some \n&gt; I want to crawl anything below the given URL, and some I want to crawl \n&gt; everything in the URL�s folder.\n&gt; \n&gt;  \n&gt; \n&gt; The first four are out-of-the-box from my understanding of Heritrix 2, \n&gt; which is great.  The last one doesn�t seem to be, so I�ve been looking \n&gt; at options on how to implement it.  Just to clearly define the problem, \n&gt; if I�m given a seed URL of:\n&gt; \n&gt;  \n&gt; \n&gt; http://www.foo.com/baz/bar.html\n&gt; \n&gt;  \n&gt; \n&gt; then I want to match:\n&gt; \n&gt;  \n&gt; \n&gt; http://www.foo.com/baz/bar2.html, http://www.foo.com/baz/somethingelse.html\n&gt; \n&gt;  \n&gt; \n&gt; but I don�t want to match:\n&gt; \n&gt;  \n&gt; \n&gt; http://www.foo.com/apage.html, http://www.foo.com/baz/bang/anotherpage.html\n&gt; \n&gt;  \n&gt; \n&gt; The two methods I�ve found to do this would be to define a regex of the \n&gt; matching URL and use a MatchesRegExpDecideRule or to create my own \n&gt; DecideRule (call it FolderOnlyDecideRule).\n&gt; \n&gt;  \n&gt; \n&gt; If I use the MatchesRegExpDecideRule, will I have to create a different \n&gt; job for each seed URL (because the regex will be different)?  Or is it \n&gt; possible to say �this job uses this seed URL with this regex�?  Dealing \n&gt; with a different job for each URL seems painful.\n&gt; \n&gt;  \n&gt; \n&gt; If the FolderOnlyDecideRule is the way to go, can I get some pointers on \n&gt; how to go about implementing it.  I�ve been looking through the \n&gt; DecideRules and it hasn�t �clicked� yet. :)\n&gt; \n&gt;  \n&gt; \n&gt; Thanks.\n&gt; \n&gt;  \n&gt; \n&gt; tj\n&gt; \n&gt; \n\n\n"}}