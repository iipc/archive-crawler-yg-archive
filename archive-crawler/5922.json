{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":363624086,"authorName":"Ko, Lauren","from":"&quot;Ko, Lauren&quot; &lt;lauren.ko@...&gt;","profile":"laurendko","replyTo":"LIST","senderId":"TWBXx2cHiVtsnroO78eCSiwBYKKrQPZBqwABeR0D18orl_mYOxUHBRrtIFcQSiwuyIR_LLaEpSwBid3PYnJUIFOHPNfOdBg","spamInfo":{"isSpam":false,"reason":"12"},"subject":"RE: [archive-crawler] How to crawl only URLs which matches pattern?","postDate":"1247590442","msgId":5922,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDc0NTdFQzY0RDFBMzY1NEQ4NjAxMzNFNUExRDIyMTMwM0ExQzQ2QkQ5Q0BHQUJNQjAzLmFkLnVudC5lZHU+","inReplyToHeader":"PGgzNDQ4cytmaW83QGVHcm91cHMuY29tPg==","referencesHeader":"PGgzNDQ4cytmaW83QGVHcm91cHMuY29tPg=="},"prevInTopic":5921,"nextInTopic":0,"prevInTime":5921,"nextInTime":5923,"topicId":5921,"numMessagesInTopic":2,"msgSnippet":"Hello, I think you want to try the regular MatchesRegExpDecideRule instead of the MatchesFilePatternDecideRule which I believe looks at just the suffix of the","rawEmail":"Return-Path: &lt;Lauren.Ko@...&gt;\r\nX-Sender: Lauren.Ko@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 67570 invoked from network); 14 Jul 2009 16:55:21 -0000\r\nX-Received: from unknown (69.147.108.202)\n  by m1.grp.sp2.yahoo.com with QMQP; 14 Jul 2009 16:55:21 -0000\r\nX-Received: from unknown (HELO mailhost.unt.edu) (129.120.188.67)\n  by mta3.grp.re1.yahoo.com with SMTP; 14 Jul 2009 16:55:21 -0000\r\nX-SBRS: 2.9\r\nX-Policy: INTERNAL_RELAY-$RELAY\r\nX-ExtLoopCount1: 1\r\nX-IronPort-Anti-Spam-Filtered: true\r\nX-IronPort-Anti-Spam-Result: AngEAJJUXEqBeNE3gWdsb2JhbACObIkngR0BARYkqFIRhymIT4IngWEFgT0\r\nX-IronPort-AV: E=Sophos;i=&quot;4.42,398,1243832400&quot;; \n   d=&quot;scan&#39;208&quot;;a=&quot;125447224&quot;\r\nX-Received: from gabhub01.ad.unt.edu ([129.120.209.55])\n  by mailhost.unt.edu with ESMTP/TLS/RC4-MD5; 14 Jul 2009 11:54:20 -0500\r\nX-Received: from GABMB03.ad.unt.edu ([129.120.209.68]) by GABHUB01.ad.unt.edu\n ([129.120.209.55]) with mapi; Tue, 14 Jul 2009 11:54:20 -0500\r\nTo: &quot;archive-crawler@yahoogroups.com&quot; &lt;archive-crawler@yahoogroups.com&gt;\r\nDate: Tue, 14 Jul 2009 11:54:02 -0500\r\nThread-Topic: [archive-crawler] How to crawl only URLs which matches pattern?\r\nThread-Index: AcoEn2nn6OMU6N2iSbu10h8Dr9UJewABEem0\r\nMessage-ID: &lt;7457EC64D1A3654D860133E5A1D221303A1C46BD9C@...&gt;\r\nReferences: &lt;h3448s+fio7@...&gt;\r\nIn-Reply-To: &lt;h3448s+fio7@...&gt;\r\nAccept-Language: en-US\r\nContent-Language: en-US\r\nX-MS-Has-Attach:\r\nX-MS-TNEF-Correlator:\r\nacceptlanguage: en-US\r\nContent-Type: text/plain; charset=&quot;us-ascii&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nMIME-Version: 1.0\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;Ko, Lauren&quot; &lt;lauren.ko@...&gt;\r\nSubject: RE: [archive-crawler] How to crawl only URLs which matches pattern?\r\nX-Yahoo-Group-Post: member; u=363624086; y=67yNbFuSmJmKQ_7NNY4nQMtZPvJOA7RT897xY66toP8yTKjY\r\nX-Yahoo-Profile: laurendko\r\n\r\nHello,\nI think you want to try the regular MatchesRegExpDecideRule instead =\r\nof the MatchesFilePatternDecideRule which I believe looks at just the suffi=\r\nx of the uri by default.\n\nLauren Ko\nDigital Projects Unit\nUniversity of Nor=\r\nth Texas Libraries\n________________________________________\nFrom: archive-c=\r\nrawler@yahoogroups.com [archive-crawler@yahoogroups.com] On Behalf Of Nizam=\r\n [bhavin_mca2000@...]\nSent: Thursday, July 09, 2009 1:55 AM\nTo: archi=\r\nve-crawler@yahoogroups.com\nSubject: [archive-crawler] How to crawl only URL=\r\ns which matches pattern?\n\nHi,\n\nHow to crawl only those URL which satisfy re=\r\ngular expression?\n\nFor ex.\n\nI have one domain &quot;www.example.com&quot;. I want to =\r\ncrawl only those URL which contains &quot;mystring&quot; anywhere from domain to quer=\r\ny.\n\nI tried setting following options in scope (in same order) but its not =\r\nworking.\n\norg.archive.crawler.deciderules.RejectDecideRule\norg.archive.craw=\r\nler.deciderules.SurtPrefixedDecideRule\norg.archive.crawler.deciderules.Matc=\r\nhesFilePatternDecideRule\norg.archive.crawler.deciderules.PrerequisiteAccept=\r\nDecideRule\n\nWhere for\norg.archive.crawler.deciderules.MatchesFilePatternDec=\r\nideRule\nRegex trying is\n&#92;S*(word1|word2|word3|word4|word5)+&#92;S*.*\n\nAny point=\r\ner will be really helpful.\n\nThanks.\nBhavin pandya\n\n\n\n\n"}}