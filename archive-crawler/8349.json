{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":551250598,"authorName":"Adam Miller","from":"Adam Miller &lt;adam@...&gt;","replyTo":"LIST","senderId":"iJ0SDrYZzAgsmKtPgQIgVGhnwQN9KjklXTH53rauaSMhFLAPNDCoDUADdNCGT5TmGC1ZKz9CZWp2lFJwnHhmza8wWRvG","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] for each seed, its own WARCs?","postDate":"1379618869","msgId":8349,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDcyNjYxMjcwLTI2ODUtNEVCMS05RTZDLTFFNzQxQTA2MkNDM0BhcmNoaXZlLm9yZz4=","inReplyToHeader":"PGwxYXV1Nyt1Yzk5QGVHcm91cHMuY29tPg==","referencesHeader":"PGwxYXV1Nyt1Yzk5QGVHcm91cHMuY29tPg=="},"prevInTopic":8345,"nextInTopic":8386,"prevInTime":8348,"nextInTime":8350,"topicId":8345,"numMessagesInTopic":3,"msgSnippet":"Hi Nicholas, Currently each thread will be writing into WARCs as the contents are fetched/processed, so the data will be co-mingled. In order to change this","rawEmail":"Return-Path: &lt;adam@...&gt;\r\nX-Sender: adam@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 76984 invoked by uid 102); 19 Sep 2013 19:27:56 -0000\r\nX-Received: from unknown (HELO mtaq6.grp.bf1.yahoo.com) (10.193.84.37)\n  by m2.grp.bf1.yahoo.com with SMTP; 19 Sep 2013 19:27:56 -0000\r\nX-Received: (qmail 14187 invoked from network); 19 Sep 2013 19:27:55 -0000\r\nX-Received: from unknown (HELO mail.archive.org) (207.241.224.6)\n  by mtaq6.grp.bf1.yahoo.com with SMTP; 19 Sep 2013 19:27:55 -0000\r\nX-Received: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id B863568401EB\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Thu, 19 Sep 2013 12:27:54 -0700 (PDT)\r\nX-Received: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id K7j2mNfp9Wk5 for &lt;archive-crawler@yahoogroups.com&gt;;\n\tThu, 19 Sep 2013 12:27:53 -0700 (PDT)\r\nX-Received: from [192.168.0.3] (97-115-178-158.spkn.qwest.net [97.115.178.158])\n\tby mail.archive.org (Postfix) with ESMTPSA id A9DAB68401D9\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Thu, 19 Sep 2013 12:27:52 -0700 (PDT)\r\nContent-Type: multipart/alternative; boundary=&quot;Apple-Mail=_0355BA4A-4B56-4619-B519-2341172706A8&quot;\r\nMessage-Id: &lt;72661270-2685-4EB1-9E6C-1E741A062CC3@...&gt;\r\nMime-Version: 1.0 (Mac OS X Mail 6.5 &#92;(1508&#92;))\r\nDate: Thu, 19 Sep 2013 12:27:49 -0700\r\nReferences: &lt;l1auu7+uc99@...&gt;\r\nTo: archive-crawler@yahoogroups.com\r\nIn-Reply-To: &lt;l1auu7+uc99@...&gt;\r\nX-Mailer: Apple Mail (2.1508)\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Adam Miller &lt;adam@...&gt;\r\nSubject: Re: [archive-crawler] for each seed, its own WARCs?\r\nX-Yahoo-Group-Post: member; u=551250598\r\n\r\n\r\n--Apple-Mail=_0355BA4A-4B56-4619-B519-2341172706A8\r\nContent-Transfer-Encoding: quoted-printable\r\nContent-Type: text/plain;\n\tcharset=windows-1252\r\n\r\nHi Nicholas,\n\nCurrently each thread will be writing into WARCs as the conte=\r\nnts are fetched/processed, so the data will be co-mingled. In order to chan=\r\nge this you would need to write a new warc writer class. You can look at th=\r\ne WARCWriterProcessor, or some of the others under the org.archive.modules.=\r\nwriter namespace.\n\nThere will be some issues with this approach, though. He=\r\nritrix will only fetch each URI once, regardless of how many times it is en=\r\ncountered. This would mean that resources which are linked from more than o=\r\nne URI would only end up in one WARC based on which seed&#39;s path happened to=\r\n encounter it first. This will leave each seed&#39;s WARC missing content that =\r\nwas in scope and fetched, but is now in another WARC. A example would be Ja=\r\nvaScript libraries like JQuery which are often served from CDNs.\n\nAnother o=\r\nption would be to do some post processing of your WARCs and extract the WAR=\r\nC records into separate WARCs by seed. This would require some analysis of =\r\nthe link graph to determine what content should be in your WARC and would r=\r\nesult in lots of duplicated content across your WARCs.\n\nIf you don&#39;t have a=\r\n large number of seeds you may be better off running a separate crawl for e=\r\nach seed. This will result in the contents being split as you want at the c=\r\nost of re-fetching any of the cross linked content across your crawls.\n\nHop=\r\ne this helps,\n\n~Adam\n\n\n\nOn Sep 17, 2013, at 6:16 PM, ideologue2 &lt;taylorn@gm=\r\nail.com&gt; wrote:\n\n&gt; If I specify multiple seeds for the same job, is there a=\r\nny way to have the captured data associated with any given seed written to =\r\nits own distinct set of WARCs (i.e., such that each WARC contains data asso=\r\nciated with no more than one of the enumerated seeds), or is all data captu=\r\nred in the course of the crawl necessarily co-mingled in all of the generat=\r\ned WARCs?\n&gt; \n&gt; ~Nicholas\n&gt; \n&gt; \n\n\r\n--Apple-Mail=_0355BA4A-4B56-4619-B519-2341172706A8\r\nContent-Transfer-Encoding: quoted-printable\r\nContent-Type: text/html;\n\tcharset=windows-1252\r\n\r\n&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=3D&quot;Content-Type&quot; content=3D&quot;text/html charset=\r\n=3Dwindows-1252&quot;&gt;&lt;/head&gt;&lt;body style=3D&quot;word-wrap: break-word; -webkit-nbsp-=\r\nmode: space; -webkit-line-break: after-white-space; &quot;&gt;&lt;div&gt;Hi&nbsp;&lt;span st=\r\nyle=3D&quot;background-color: rgb(255, 255, 255); &quot;&gt;Nicholas,&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;=\r\nspan style=3D&quot;background-color: rgb(255, 255, 255); &quot;&gt;&lt;br&gt;&lt;/span&gt;&lt;/div&gt;&lt;div=\r\n&gt;Currently each thread will be writing into WARCs as the contents are fetch=\r\ned/processed, so the data will be co-mingled. In order to change this you w=\r\nould need to write a new warc writer class. You can look at the WARCWriterP=\r\nrocessor, or some of the others under the org.archive.modules.writer namesp=\r\nace.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;There will be some issues with this approach,=\r\n though. Heritrix will only fetch each URI once, regardless of how many tim=\r\nes it is encountered. This would mean that resources which are linked from =\r\nmore than one URI would only end up in one WARC based on which seed&#39;s path =\r\nhappened to encounter it first. This will leave each seed&#39;s WARC missing co=\r\nntent that was in scope and fetched, but is now in another WARC. A example =\r\nwould be JavaScript libraries like JQuery which are often served from CDNs.=\r\n&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Another option would be to do some post processin=\r\ng of your WARCs and extract the WARC records into separate WARCs by seed. T=\r\nhis would require some analysis of the link graph to determine what content=\r\n should be in your WARC and would result in lots of duplicated content acro=\r\nss your WARCs.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;If you don&#39;t have a large number of=\r\n seeds you may be better off running a separate crawl for each seed. This w=\r\nill result in the contents being split as you want at the cost of re-fetchi=\r\nng any of the cross linked content across your crawls.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;=\r\n&lt;div&gt;Hope this helps,&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;~Adam&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;d=\r\niv&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;&lt;div&gt;&lt;div&gt;On Sep 17, 2013, at 6:16 PM, ideologue2 &lt;&lt;a h=\r\nref=3D&quot;mailto:taylorn@...&quot;&gt;taylorn@...&lt;/a&gt;&gt; wrote:&lt;/div&gt;&lt;br =\r\nclass=3D&quot;Apple-interchange-newline&quot;&gt;&lt;blockquote type=3D&quot;cite&quot;&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n=\r\n\n&lt;div style=3D&quot;background-color: rgb(255, 255, 255); position: static; z-in=\r\ndex: auto; &quot;&gt;\n&lt;span style=3D&quot;display:none&quot;&gt;&nbsp;&lt;/span&gt;\n\n\n\n    &lt;div id=3D&quot;=\r\nygrp-text&quot;&gt;&lt;p&gt;If I specify multiple seeds for the same job, is there any wa=\r\ny to have the captured data associated with any given seed written to its o=\r\nwn distinct set of WARCs (i.e., such that each WARC contains data associate=\r\nd with no more than one of the enumerated seeds), or is all data captured i=\r\nn the course of the crawl necessarily co-mingled in all of the generated WA=\r\nRCs?&lt;br&gt;\n&lt;br&gt;\n~Nicholas&lt;br&gt;\n&lt;br&gt;\n&lt;/p&gt;\n\n    &lt;/div&gt;\n     \n\n    \n\n&lt;/div&gt;\n\n\n\n&lt;!=\r\n-- end group email --&gt;\n\n&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;/body&gt;&lt;/html&gt;\r\n--Apple-Mail=_0355BA4A-4B56-4619-B519-2341172706A8--\r\n\n"}}