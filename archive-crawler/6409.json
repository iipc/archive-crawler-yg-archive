{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"PSzmu5848iocx8jNY6-yWGKqv9rkwVGa-xw9JpzuFCy9Xq2jLtyhv7uza966BbV7CNhOAZ2Sh57DxdgI0PB9rvo0wLWWvd4","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] Extending ExtractorHTML to skip  elements","postDate":"1267392125","msgId":6409,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRCOEFERTdELjcwMzA3MDhAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDZhMDI5ZTJkMTAwMjI3MTM0N241NTc0NDhmN2hiNTc2NGQwMTU0ZTAyYzAyQG1haWwuZ21haWwuY29tPg==","referencesHeader":"PDZhMDI5ZTJkMTAwMjI3MTM0N241NTc0NDhmN2hiNTc2NGQwMTU0ZTAyYzAyQG1haWwuZ21haWwuY29tPg=="},"prevInTopic":6408,"nextInTopic":6414,"prevInTime":6408,"nextInTime":6410,"topicId":6408,"numMessagesInTopic":3,"msgSnippet":"... A more general approach would be allow ExtractorHTML to find all the outlinks in the page as best it can, but then discard the links that are not of","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 87385 invoked from network); 28 Feb 2010 21:22:07 -0000\r\nX-Received: from unknown (98.137.34.44)\n  by m3.grp.sp2.yahoo.com with QMQP; 28 Feb 2010 21:22:07 -0000\r\nX-Received: from unknown (HELO relay02.pair.com) (209.68.5.16)\n  by mta1.grp.sp2.yahoo.com with SMTP; 28 Feb 2010 21:22:07 -0000\r\nX-Received: (qmail 62812 invoked from network); 28 Feb 2010 21:22:06 -0000\r\nX-Received: from 69.181.44.86 (HELO ?192.168.23.128?) (69.181.44.86)\n  by relay02.pair.com with SMTP; 28 Feb 2010 21:22:06 -0000\r\nX-pair-Authenticated: 69.181.44.86\r\nMessage-ID: &lt;4B8ADE7D.7030708@...&gt;\r\nDate: Sun, 28 Feb 2010 13:22:05 -0800\r\nUser-Agent: Thunderbird 2.0.0.23 (Windows/20090812)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;6a029e2d1002271347n557448f7hb5764d0154e02c02@...&gt;\r\nIn-Reply-To: &lt;6a029e2d1002271347n557448f7hb5764d0154e02c02@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Extending ExtractorHTML to skip &lt;img &gt; elements\r\nX-Yahoo-Group-Post: member; u=137285340; y=DGv4xT-25v0d80N6yTB987ZJUvKimqMjAjLtz3K7gicd\r\nX-Yahoo-Profile: gojomo\r\n\r\nanas elghafari wrote:\n&gt; \n&gt; \n&gt; Hi all,\n&gt; \n&gt; I want to save some bandwidth by getting the extractor to not fetch \n&gt; embedded images (rather than my current MO of fetching them then \n&gt; filtering them out by looking at Content-Type). I&#39;ve looked at the \n&gt; source code of ExtractorHTML class and it didn&#39;t seem clear to me how \n&gt; the &lt;img&gt; elements are being captured.\n&gt; \n&gt; So my two small questions: is ExtractorHTML the class to be modified if \n&gt; one wants embedded images not to be fetched at all? 2) If yes, can you \n&gt; give me a rough idea which part of the regex in that class I need to modify?\n\nA more general approach would be allow ExtractorHTML to find all the \noutlinks in the page as best it can, but then discard the links that are \nnot of interest as part of your scoping rules, before they are fetched. \nThat avoids complicating/qualifying ExtractorHTML code.\n\nFor example, by examining the &#39;linkContext&#39; of discovered outlinks, you \ncan get an idea of whether they were discovered in a &quot;&lt;A HREF=&#39;link&#39;&gt;&quot; \nor &quot;&lt;IMG SRC=&#39;link&#39;&gt;&quot; construction. You can look at the \nHopsPathMatchesDecideRule for a existing rule that makes its \nACCEPT/REJECT decision based on the &#39;hopsPath&#39; of a discovered outlink. \nYou may wish to make a LinkContextMatchesDecideRule.\n\nThen, if you add scope rules that REJECT both IMG/@SRC and URIs ending \nin known-image extensions, very few if any image URIs should ever pass \nscope testing (and thus won&#39;t be frontier-enqueued or fetched).\n\n- Gordon @ IA\n\n&gt; Anas\n&gt; \n&gt; \n&gt; \n\n"}}