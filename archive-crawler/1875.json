{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"r0bdhNNb04HLBU38P3OJNMYqY3Rd7TGdIhN-AUobvt5b_Ph-ZGDyBpqYT7T8Lv98ozhphq5Ca5GsMulOdWHJb5FysmWIgBU","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] BDB, state, and disk usage, and other questions","postDate":"1116963870","msgId":1875,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQyOTM4NDFFLjMwNzA3MDNAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDE3MDQzLjU0NDYuODU3NDIzLjY4NzI0OUB0aXBoYXJlcy5iYXNpc3RlY2gubmV0Pg==","referencesHeader":"PDE3MDQxLjYzNDc0LjkxNzcyLjkwMjI4MEB0aXBoYXJlcy5iYXNpc3RlY2gubmV0Pgk8NDI5MjRFRDguMzA4MDYwNEBhcmNoaXZlLm9yZz4gPDE3MDQzLjU0NDYuODU3NDIzLjY4NzI0OUB0aXBoYXJlcy5iYXNpc3RlY2gubmV0Pg=="},"prevInTopic":1873,"nextInTopic":1887,"prevInTime":1874,"nextInTime":1876,"topicId":1868,"numMessagesInTopic":9,"msgSnippet":"... There are BDB parameters which control how aggressively it consolidates and discards older, no longer full JDB files. See especially ","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 60812 invoked from network); 24 May 2005 19:45:06 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m27.grp.scd.yahoo.com with QMQP; 24 May 2005 19:45:06 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (207.241.224.172)\n  by mta2.grp.scd.yahoo.com with SMTP; 24 May 2005 19:45:06 -0000\r\nReceived: (qmail 3499 invoked by uid 100); 24 May 2005 19:44:41 -0000\r\nReceived: from unknown (HELO ?207.241.237.155?) (gojomo@...@207.241.237.155)\n  by mail-dev.archive.org with RC4-MD5 encrypted SMTP; 24 May 2005 19:44:41 -0000\r\nMessage-ID: &lt;4293841E.3070703@...&gt;\r\nDate: Tue, 24 May 2005 12:44:30 -0700\r\nUser-Agent: Mozilla Thunderbird 1.0.2 (Windows/20050317)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;17041.63474.91772.902280@...&gt;\t&lt;42924ED8.3080604@...&gt; &lt;17043.5446.857423.687249@...&gt;\r\nIn-Reply-To: &lt;17043.5446.857423.687249@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=-65.7 required=7.0 tests=AWL,USER_IN_WHITELIST \n\tautolearn=no version=2.63\r\nX-eGroups-Msg-Info: 1:12:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] BDB, state, and disk usage, and other questions\r\nX-Yahoo-Group-Post: member; u=137285340\r\nX-Yahoo-Profile: gojomo\r\n\r\nTom Emerson wrote:\n&gt; stack writes:\n&gt; \n&gt;&gt;Seems like it depends highly on the character of the crawl being run \n&gt;&gt;(Capturing HTML only Tom, you&#39;re throwing out alot of what usually \n&gt;&gt;bulks-up the arcs: images, pdfs, etc.).\n&gt; \n&gt; \n&gt; I just checked and I&#39;m still around 2:1 state-vs-arcs on my HTML only\n&gt; crawl. It may be worth putting a discussion of this into the docs\n&gt; somewhere.\n\nThere are BDB parameters which control how aggressively it consolidates\nand discards older, no longer full JDB files. See especially\n&quot;je.cleaner.minUtilization&quot;. At a cost of more CPU and IO, setting\nmore aggressive cleaning would cut back on disk footprint.\n\nI suppose it&#39;s also possible that the current CPU-intensity of the\ncrawler is causing the BDB cleaner to get behind, but I haven&#39;t looked\ninto testing this hypothesis. Also possible, that something about our\nserialization is too expansive -- serializing out stuff into the\nqueues that doesn&#39;t need to be there, perhaps because it could be\ncostlessly reconstructed later.\n\n(Previously discussed a bit here:\n   http://groups.yahoo.com/group/archive-crawler/message/1758 )\n\n&gt;&gt;You have hold-queues enabled? Then this is what I&#39;d expect (You might \n&gt;&gt;change the &#39;balance-replenish-amount&#39; setting so its less than 3000 so \n&gt;&gt;other queues get rotated in quicker).\n&gt; \n&gt; \n&gt; Yes, hold-queues is enabled.\n&gt; \n&gt; Is there a description of the balance-replenish-amount,\n&gt; queue-total-budget, and cost-policy settings outside of the source\n&gt; code?\n\nUntil these details get integrated into the User Manual,\nyou can learn about these &quot;budgetting&quot; settings in the wiki:\n\n     http://crawler.archive.org/cgi-bin/wiki.pl?BudgetingFrontier\n\nAny non-zero cost policy plus smallish refresh-budget will\nensure that, in the &#39;hold-queues&#39; case, after a queue is active\nfor a while, it gets put to the back of the inactive queues, and\nanother waiting queue gets a chance to be active for a while.\n(If in a long running crawl you see seeds on queues that have\nnever been activated, you probably have either a zero cost\npolicy or a very-large/infinite refresh budget.)\n\n&gt;&gt;&gt;The threads report states that there are 92 in the pool, but lists\n&gt;&gt;&gt;status for 100. How can I find the 8 that aren&#39;t being used?\n&gt;&gt;&gt;\n&gt;&gt;\n&gt;&gt;We ain&#39;t sure why it would report any less than 100 threads in the \n&gt;&gt;pool.  Anything in heritrix_out.log?  Runtime/local errors? Send us over \n&gt;&gt;the report so we can take a look.\n&gt; \n&gt; \n&gt; It&#39;s down to &quot;85 of 89&quot; threads now.\n&gt; \n&gt; THere have been no alerts. However, there are 11 NPEs in the log:\n&gt; \n&gt; java.lang.NullPointerException\n&gt;         at org.archive.util.CachedBdbMap$SoftEntry.clearPhantom(CachedBdbMap.java:508)\n&gt;         at org.archive.util.CachedBdbMap.expungeStaleEntry(CachedBdbMap.java:456)\n&gt;         at org.archive.util.CachedBdbMap.get(CachedBdbMap.java:343)\n&gt;         at org.archive.crawler.frontier.BdbFrontier.next(BdbFrontier.java:514)\n&gt;         at org.archive.crawler.framework.ToeThread.run(ToeThread.java:135)\n&gt; \n&gt; These would account for the 11 missing threads.\n\nAny deviation of the second/total number from the configured number\nof ToeThreads is a definite bug -- it looks like these NPEs are to\nblame.\n\nWith enough &#39;ready&#39; queues of material to crawl, the first number,\nof active threads, should ideally be equal or only momentarily less\nthan the total number of threads. However, especially on faster\nmachines and latest JVMs/OS threading, we&#39;ve been seeing more of a\ngap here recently. I suspect thread scheduling may not be as &#39;fair&#39;\nas previously, so some threads waiting to get an item are overtaken\nby others. As long as CPU is saturated, though, forcing more fairness\nwould just slow all threads equally, and thus this may not be a major\nconcern, and the right adaptation could be to shrink the number of\npoool threads.\n\n- Gordon @ IA\n\n"}}