{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":234926651,"authorName":"Frank McCown","from":"Frank McCown &lt;fmccown@...&gt;","profile":"mccownf","replyTo":"LIST","senderId":"bk-kME99wMYO2TaFJ3xRVrASBDhnUaQzMcrwkMkI-E1rOoaR6Hk03vPSJY2k5Bz98_PlcOjFcz2IlTXYMKiqDAOGMJ6l_9Qh","spamInfo":{"isSpam":false,"reason":"2"},"subject":"Re: [archive-crawler] no links extracted at crawling","postDate":"1159188696","msgId":3348,"canDelete":false,"contentTrasformed":false,"systemMessage":true,"headers":{"messageIdInHeader":"PDQ1MTdEMEQ4LjEwNzAyMDlAY3Mub2R1LmVkdT4=","inReplyToHeader":"PGVmNmhsZCs5NzhpQGVHcm91cHMuY29tPg==","referencesHeader":"PGVmNmhsZCs5NzhpQGVHcm91cHMuY29tPg=="},"prevInTopic":3337,"nextInTopic":3350,"prevInTime":3347,"nextInTime":3349,"topicId":3337,"numMessagesInTopic":5,"msgSnippet":"It doesn t look like anything is being blocked by the robots.txt file. 1) What version of Heritrix are you running? 2) Are you using the DecidingScope with the","rawEmail":"Return-Path: &lt;fmccown@...&gt;\r\nReceived: (qmail 72562 invoked from network); 26 Sep 2006 18:47:41 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m41.grp.scd.yahoo.com with QMQP; 26 Sep 2006 18:47:41 -0000\r\nReceived: from unknown (HELO n8b.bullet.sc5.yahoo.com) (66.163.187.175)\n  by mta4.grp.scd.yahoo.com with SMTP; 26 Sep 2006 18:47:40 -0000\r\nReceived: from [66.163.187.120] by n8.bullet.sc5.yahoo.com with NNFMP; 26 Sep 2006 18:47:15 -0000\r\nReceived: from [66.218.69.3] by t1.bullet.sc5.yahoo.com with NNFMP; 26 Sep 2006 18:47:15 -0000\r\nReceived: from [66.218.66.84] by t3.bullet.scd.yahoo.com with NNFMP; 26 Sep 2006 18:47:15 -0000\r\nX-Sender: fmccown@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 19503 invoked from network); 25 Sep 2006 12:58:24 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m39.grp.scd.yahoo.com with QMQP; 25 Sep 2006 12:58:24 -0000\r\nReceived: from unknown (HELO cartero.cs.odu.edu) (128.82.4.9)\n  by mta1.grp.scd.yahoo.com with SMTP; 25 Sep 2006 12:58:24 -0000\r\nReceived: from [128.82.7.106] (bang.seven.research.odu.edu [128.82.7.106])\n\tby cartero.cs.odu.edu (8.13.6/8.13.6) with ESMTP id k8PCpqGq019123\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Mon, 25 Sep 2006 08:51:52 -0400 (EDT)\r\nMessage-ID: &lt;4517D0D8.1070209@...&gt;\r\nDate: Mon, 25 Sep 2006 08:51:36 -0400\r\nUser-Agent: Mozilla Thunderbird 1.0 (Windows/20041206)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;ef6hld+978i@...&gt;\r\nIn-Reply-To: &lt;ef6hld+978i@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 2:2:2:0\r\nFrom: Frank McCown &lt;fmccown@...&gt;\r\nSubject: Re: [archive-crawler] no links extracted at crawling\r\nX-Yahoo-Group-Post: member; u=234926651; y=yFbS19LnloRB1P_jyWKvcsz2TWu-FV2W19mqIOy4P6b5Ew\r\nX-Yahoo-Profile: mccownf\r\nX-Yahoo-Marked-Not-Spam: \r\nX-Yahoo-Newman-Property: groups-system\r\nX-eGroups-Approved-By: gojomo &lt;gojomo@...&gt; via web; 26 Sep 2006 18:47:15 -0000\r\n\r\nIt doesn&#39;t look like anything is being blocked by the robots.txt file.\n\n1) What version of Heritrix are you running?\n\n2) Are you using the DecidingScope with the default set of DecideRules?\n\n3) Is extractorHTML turned on?\n\nFrank\n\n\nhlm_bk wrote:\n&gt; \n&gt; \n&gt; Hi guys!\n&gt; \n&gt; I got a problem with crawling sites, please help me.\n&gt; \n&gt; All the jobs i make (based on default profile) run without errors, all\n&gt; error logs are clear. It takes serveral seconds for a job to finish,\n&gt; it actaully only processes robots.txt and gets finished.\n&gt; \n&gt; Reports on seeds have status ok:\n&gt; [code] [status] [seed] [redirect]\n&gt; 200 CRAWLED http://209.237.227.195/ &lt;http://209.237.227.195/&gt;\n&gt; \n&gt; In processors-report.txt i found out that ExtractorHTML has no links\n&gt; axtracted (somebody knows why?), here&#39;s the content:\n&gt; \n&gt; Processors report - 200609240604\n&gt; Job being crawled: 11\n&gt; Number of Processors: 10\n&gt; NOTE: Some processors may not return a report!\n&gt; \n&gt; Processor: org.archive.crawler.fetcher.FetchHTTP\n&gt; Function: Fetch HTTP URIs\n&gt; CrawlURIs handled: 2\n&gt; Recovery retries: 0\n&gt; \n&gt; Processor: org.archive.crawler.extractor.ExtractorHTTP\n&gt; Function: Extracts URIs from HTTP response headers\n&gt; CrawlURIs handled: 2\n&gt; Links extracted: 0\n&gt; \n&gt; Processor: org.archive.crawler.extractor.ExtractorHTML\n&gt; Function: Link extraction on HTML documents\n&gt; CrawlURIs handled: 0\n&gt; Links extracted: 0\n&gt; \n&gt; Here&#39;s also a snippet from my arc file :\n&gt; \n&gt; dns:apache.org 195.234.109.2 20060924060337 text/dns 54\n&gt; 20060924060337\n&gt; apache.org. 1781 IN A 209.237.227.195\n&gt; \n&gt; http://apache.org/robots.txt &lt;http://apache.org/robots.txt&gt; \n&gt; 209.237.227.195 20060924060340 text/plain 54\n&gt; 20060924060337\n&gt; apache.org. 1781 IN A 209.237.227.195\n&gt; \n&gt; http://apache.org/ &lt;http://apache.org/&gt; 209.237.227.195 20060924060344 \n&gt; text/html 54\n&gt; 20060924060337\n&gt; apache.org. 1781 IN A 209.237.227.195\n&gt; \n&gt; Thank you!\n&gt; \n&gt; \n\n\n\n\n"}}