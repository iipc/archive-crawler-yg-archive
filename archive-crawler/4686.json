{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"FtL4E1XlSpydgQMyezHGy884lCwmglDakQHBZcn0lLieqZYFo3T7k9l3qThdYjeNltmHz_Z2sKFTxlmlQWs28_ATIG6tTJY","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] semantics of queue-total-budget","postDate":"1195077109","msgId":4686,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ3M0I2REY1LjEwOTAxMDFAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDIwMDcxMTE0MjAyNTQzLjI0MTY4NDdCMTZAbWFpbC5hcmNoaXZlLm9yZz4=","referencesHeader":"PDIwMDcxMTE0MjAyNTQzLjI0MTY4NDdCMTZAbWFpbC5hcmNoaXZlLm9yZz4="},"prevInTopic":4685,"nextInTopic":4688,"prevInTime":4685,"nextInTime":4687,"topicId":4685,"numMessagesInTopic":4,"msgSnippet":"... Exhausted means there was nothing left to crawl -- the queue is empty. Such queues will come back if new URIs are discovered and added to the queue. ","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 6138 invoked from network); 14 Nov 2007 21:51:49 -0000\r\nX-Received: from unknown (66.218.67.96)\n  by m57.grp.scd.yahoo.com with QMQP; 14 Nov 2007 21:51:49 -0000\r\nX-Received: from unknown (HELO relay02.pair.com) (209.68.5.16)\n  by mta17.grp.scd.yahoo.com with SMTP; 14 Nov 2007 21:51:48 -0000\r\nX-Received: (qmail 75925 invoked from network); 14 Nov 2007 21:51:47 -0000\r\nX-Received: from unknown (HELO ?192.168.1.30?) (unknown)\n  by unknown with SMTP; 14 Nov 2007 21:51:47 -0000\r\nX-pair-Authenticated: 76.102.230.209\r\nMessage-ID: &lt;473B6DF5.1090101@...&gt;\r\nDate: Wed, 14 Nov 2007 13:51:49 -0800\r\nUser-Agent: Thunderbird 2.0.0.6 (Windows/20070728)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;20071114202543.2416847B16@...&gt;\r\nIn-Reply-To: &lt;20071114202543.2416847B16@...&gt;\r\nContent-Type: text/plain; charset=windows-1252; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] semantics of queue-total-budget\r\nX-Yahoo-Group-Post: member; u=137285340; y=S4TRJfWo8HSwFQvFZL9WPZz4xt2s0SSfMdxH791touJl\r\nX-Yahoo-Profile: gojomo\r\n\r\nLeo Dagum wrote:\n&gt; I�m trying to configure a crawl across a broad number of sites but \n&gt; fetching only a restricted number of pages from each site. \n&gt;  Specifically,  I�d like to get only 20pages from each site across about \n&gt; 200k sites that are provided through a seed list.  I set q-t-b to 20 and \n&gt; UnitCostAssignment but did not get the behavior I expected. \n&gt; \n&gt;  \n&gt; \n&gt; I�m using HostnameQueueAsssingment policy, so I expected 200k queues to \n&gt; be created and that they get exhausted as they reached their 20 unit \n&gt; budget.  However what I saw was ~180k queues almost immediately marked \n&gt; as exhausted and the crawler busy on just 20k queues.  My understanding \n&gt; is that once a queue is exhausted it does not get scheduled again.  Is \n&gt; that correct?  Or will the exhausted queues get reactivated at some point? \n\n&#39;Exhausted&#39; means there was nothing left to crawl -- the queue is empty. \nSuch queues will come back if new URIs are discovered and added to the \nqueue.\n\nQueues which go over their budget are instead &#39;retired&#39;. They still have \nthe URIs that were waiting, and still get newly discovered URIs -- they \njust aren&#39;t eligible to provide URIs for crawling. The idea, however, is \nthat you could go in and up the total-budget, and these queues would be \nunretired.\n\nSo I could be wrong, but suspect that for the 180k queues that instantly \nbecame exhausted, there is either no/very-little content or some other \nerror (restrictive scope?) is preventing any URIs from being added to \nthose queues.\n\n- Gordon @ IA\n\n"}}