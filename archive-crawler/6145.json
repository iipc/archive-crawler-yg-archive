{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"l5gpjQgYfWZSGanDbXQarisRCirIA42RTzJI3_YRMC_ClQ3gmYwYwAznmYgXIuCQ8dvBcmyObLmEfd8DC8rfuEyDj3_rTCg","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] Recrawling In Heritrix3","postDate":"1257892404","msgId":6145,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRBRjlFQTM0LjYwNDAxMDhAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDY0QkFCMzFCLTQ1RjMtNDBCQS1CQkIzLTBCRUMxMkQ4RTgyRUBnbWFpbC5jb20+","referencesHeader":"PDY0QkFCMzFCLTQ1RjMtNDBCQS1CQkIzLTBCRUMxMkQ4RTgyRUBnbWFpbC5jb20+"},"prevInTopic":6140,"nextInTopic":6151,"prevInTime":6144,"nextInTime":6146,"topicId":6140,"numMessagesInTopic":6,"msgSnippet":"Your setup looks generally correct. Are you perhaps forgetting to both declare the beans by name, *and* insert them by  into the  of the chain bean?","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 75496 invoked from network); 10 Nov 2009 22:33:26 -0000\r\nX-Received: from unknown (98.137.34.44)\n  by m12.grp.re1.yahoo.com with QMQP; 10 Nov 2009 22:33:26 -0000\r\nX-Received: from unknown (HELO relay03.pair.com) (209.68.5.17)\n  by mta1.grp.sp2.yahoo.com with SMTP; 10 Nov 2009 22:33:26 -0000\r\nX-Received: (qmail 65985 invoked from network); 10 Nov 2009 22:33:25 -0000\r\nX-Received: from 67.188.14.54 (HELO ?192.168.1.107?) (67.188.14.54)\n  by relay03.pair.com with SMTP; 10 Nov 2009 22:33:25 -0000\r\nX-pair-Authenticated: 67.188.14.54\r\nMessage-ID: &lt;4AF9EA34.6040108@...&gt;\r\nDate: Tue, 10 Nov 2009 14:33:24 -0800\r\nUser-Agent: Thunderbird 2.0.0.23 (Windows/20090812)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;64BAB31B-45F3-40BA-BBB3-0BEC12D8E82E@...&gt;\r\nIn-Reply-To: &lt;64BAB31B-45F3-40BA-BBB3-0BEC12D8E82E@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Recrawling In Heritrix3\r\nX-Yahoo-Group-Post: member; u=137285340; y=0Z5UidYSViywFRKkFnjVkKfh4BYk9VwnCyYEVDy5GgCN\r\nX-Yahoo-Profile: gojomo\r\n\r\nYour setup looks generally correct. Are you perhaps forgetting to both \ndeclare the beans by name, *and* insert them by &lt;ref&gt; into the &lt;list&gt; of \nthe chain bean?\n\nSome other comments that may help in configuring these features in H3:\n\nMatthew Warhaftig wrote:\n&gt; In H3 I am trying to setup crawl jobs that \n&gt; use FetchHistoryProcessor/PersistStoreProcessor/PersistLoadProcessor to \n&gt; discard duplicate content.  I can get H1 to recrawl correctly but the \n&gt; same technique is not storing a history and finding duplicates for me in \n&gt; H3 (my job setup is based on these \n&gt; postings: https://webarchive.jira.com/wiki/display/Heritrix/Feature+Notes+-+1.12.0 & http://tech.groups.yahoo.com/group/archive-crawler/message/5920).\n&gt; \n&gt; For the storing job I added the following to the default \n&gt; H3 crawler-beans.cxml file.  In the Fetch Chain just after \n&gt; the &quot;fetchHttp&quot; bean:\n&gt;&gt; &lt;bean id=&quot;fetchHistoryProcessor&quot; \n&gt;&gt; class=&quot;org.archive.modules.recrawl.FetchHistoryProcessor&quot; &gt; &lt;property \n&gt;&gt; name=&quot;historyLength&quot; value=&quot;30&quot; /&gt; &lt;/bean&gt;\n&gt;&gt;\n&gt;&gt; &lt;bean id=&quot;persistStoreProcessor&quot; \n&gt;&gt; class=&quot;org.archive.modules.recrawl.PersistStoreProcessor&quot; &gt; &lt;/bean&gt;\n\nUnrelated to your issues, in the near future it will be better to put \nthe persistStoreProcessor as the first in the &#39;dispositionChain&#39; rather \nthan the last position of the &#39;fetchChain&#39;. Essentially, the \ndispositionChain&#39;s activities will be atomic with regard to \ncheckpointing -- any URI that starts the dispositionChain will finish it \nbefore a checkpoint is stored -- but the fetchChain&#39;s activities will not.\n\nAlso unrelated but good to know: H3&#39;s configuration makes it much easier \nfor different components to optionally use separate BDB environments on \ndisk. Two reasons one might want to do so: (1) distribute the IO costs \nover different disks; (2) keep distinct data separate on disk for \nbackup/migration-to-new-jobs, as with the difference between \nqueues/stateof the running crawl, and URI history for deduplication \npurposes.\n\nFor example, you could declare...\n\n&lt;bean id=&quot;persistStoreBdb&quot; class=&quot;org.archive.bdb.BdbModule&quot; \nautowire-candidate=&quot;false&quot;&gt;\n   &lt;property name=&quot;dir&quot; value=&quot;history&quot;/&gt;\n&lt;/bean&gt;\n\n&lt;bean id=&quot;persistStoreProcessor&quot; \nclass=&quot;org.archive.modules.recrawl.PersistStoreProcessor&quot;&gt;\n   &lt;property name=&quot;bdbModule&quot;&gt;\n     &lt;ref bean=&quot;persistStoreBdb&quot;/&gt;\n   &lt;/property&gt;\n  &lt;/bean&gt;\n\n...and then persistent URI history will collect in a &#39;history&#39; directory \n(which could be a full path to anywhere convenient) rather than being \nmixed-in with other crawler state.\n\n(The reason for the &#39;autowire-candidate=&quot;false&quot;&#39; is to prevent this \nBdbModule from being a competitor to the default for all the objects \nthat expect one distinguished instance to be available for autowiring.)\n\n&gt; Then for another job to use this stored history I added the following to \n&gt; the default H3 crawler-bean.cxml file. In the Fetch Chain just after the \n&gt; &quot;preconditions&quot; bean:\n&gt;&gt; &lt;bean id=&quot;persistLoadProcessor&quot; \n&gt;&gt; class=&quot;org.archive.modules.recrawl.PersistLoadProcessor&quot;&gt; &lt;property \n&gt;&gt; name=&quot;preloadSource&quot; \n&gt;&gt; value=&quot;/Users/mattwarhaftig/Documents/heritrix-3.0.0-SNAPSHOT/jobs/basic/state&quot; \n&gt;&gt; /&gt; &lt;/bean&gt;\n&gt; And just after the &quot;fetchHttp&quot; bean:\n&gt;&gt; &lt;bean id=&quot;fetchHistoryProcessor&quot; \n&gt;&gt; class=&quot;org.archive.modules.recrawl.FetchHistoryProcessor&quot; &gt; &lt;property \n&gt;&gt; name=&quot;historyLength&quot; value=&quot;30&quot; /&gt; &lt;/bean&gt;\n\nNote that &#39;preloadSource&#39; causes the processor to scan the named log or \ndirectory, and copy all its contents into its current history database. \nIf using this, make sure you&#39;re not pointing to the same path it&#39;s \ncurrently\n\nYou could also skip the &#39;preload&#39; and directly point the \nPersistLoadProcessor to an existing history store:\n\n&lt;bean id=&quot;persistLoadBdb&quot; class=&quot;org.archive.bdb.BdbModule&quot; \nautowire-candidate=&quot;false&quot;&gt;\n   &lt;property name=&quot;dir&quot; \nvalue=&quot;/Users/mattwarhaftig/Documents/heritrix-3.0.0-SNAPSHOT/jobs/basic/state&quot;/&gt;\n&lt;/bean&gt;\n\n&lt;bean id=&quot;persistLoadProcessor&quot;\n  class=&quot;org.archive.modules.recrawl.PersistLoadProcessor&quot;&gt;\n  &lt;property name=&quot;bdbModule&quot;&gt;\n     &lt;ref bean=&quot;persistLoadBdb&quot;/&gt;\n   &lt;/property&gt;\n&lt;/bean&gt;\n\n(Except for the &#39;preload&#39;, if specified, the PersistLoadProcessor only \nreads from its given BdbModule/environment, so you could reuse a prior \ncrawl&#39;s persist-store target without damaging it.)\n\nThere&#39;s currently a problem with having both a PersistLoadProcessor and \nPersistStoreProcessor in the same crawl using the same \nBdbModule/directory [HER-1706], but that should work by the time of the \nH3 official release.\n\nHope this helps,\n\n- Gordon @ IA\n\n\n&gt; Am I declaring these beans correctly?\n&gt; \n&gt; Thanks,\n&gt; Matt\n&gt; \n&gt; \n&gt; \n\n"}}