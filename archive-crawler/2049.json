{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"stack","from":"stack &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"pZ9pSeuLCszD1o-noYECh3q9aFZL-D7U6CZzBLQydxfc5WfagOzGSbV8QhKvU1nPfH7iYfuqenxMruLeMk2GaQ","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Exception in Extractor","postDate":"1121361623","msgId":2049,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQyRDY5RUQ3LjQwMzA2MDRAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDQyRDY5NjUxLjYwNzA0MDNAY252aS5jb20+","referencesHeader":"PGRiNjE3cCtvdHUwQGVHcm91cHMuY29tPiA8NDJENjkwOEIuNTAwMDAwN0BhcmNoaXZlLm9yZz4gPDQyRDY5NjUxLjYwNzA0MDNAY252aS5jb20+"},"prevInTopic":2048,"nextInTopic":2050,"prevInTime":2048,"nextInTime":2050,"topicId":2046,"numMessagesInTopic":9,"msgSnippet":"... Ok.  So gzip thinks its a good gzip file. ... Sounds like arcreader strict is having no problems parsing. ... So I think its issue w/ how extractor script","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 24669 invoked from network); 14 Jul 2005 17:14:08 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m30.grp.scd.yahoo.com with QMQP; 14 Jul 2005 17:14:08 -0000\r\nReceived: from unknown (HELO dns.duboce.net) (63.203.238.114)\n  by mta6.grp.scd.yahoo.com with SMTP; 14 Jul 2005 17:14:08 -0000\r\nReceived: from [192.168.1.100] ([192.168.1.100])\n\t(authenticated)\n\tby dns-eth1.duboce.net (8.10.2/8.10.2) with ESMTP id j6EGGk911564\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Thu, 14 Jul 2005 09:16:47 -0700\r\nMessage-ID: &lt;42D69ED7.4030604@...&gt;\r\nDate: Thu, 14 Jul 2005 10:20:23 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; PPC Mac OS X Mach-O; en-US; rv:1.7.8) Gecko/20050511\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;db617p+otu0@...&gt; &lt;42D6908B.5000007@...&gt; &lt;42D69651.6070403@...&gt;\r\nIn-Reply-To: &lt;42D69651.6070403@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0\r\nFrom: stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] Exception in Extractor\r\nX-Yahoo-Group-Post: member; u=168599281; y=2tYiNOqBLc0PWrepRpOZ57HvNlQmo7afysMZabqn1DhYHDx2S8-FajQw\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\nRyan Gran wrote:\n\n&gt; Welcome to Darwin!\n&gt; lcm:~ root# gzip -t\n&gt; /RAID01/1/1_job_1120859484/LC-20050712000448-00068-lcs0001.local.arc.gz\n&gt; lcm:~ root#\n&gt;\nOk.  So gzip thinks its a good gzip file.\n\n&gt; lcm:/Users/admin/heritrix-1.4.0/bin root# ./arcreader -s\n&gt; /RAID01/1/1_job_1120859484/LC-20050712000448-00068-lcs0001.local.arc.gz\n&gt; &gt; arcreader.tmp\n&gt; lcm:/Users/admin/heritrix-1.4.0/bin root# ls -al arcreader.tmp\n&gt; -rw-r--r--   1 root  staff  4356497 Jul 14 11:33 arcreader.tmp\n&gt;\n&gt; tail&#39;ing arcreader.tmp doesn&#39;t show anything unexpected.\n&gt;\nSounds like arcreader strict is having no problems parsing.\n\n\n&gt; I&#39;m dying on this command:\n&gt; /Users/Admin/heritrix-1.5.0/bin/extractor $file &gt; $procfn\n&gt;\nSo I think its issue w/ how extractor script is running through ARCs \n(First thing I&#39;d try is removing the buffering of the gzip stream in \nHttpRecord#wrapInputStreamWithHttpRecord).  If you make the problematic \nARC HTTP GETtable (You can send me the URL offlist), I&#39;ll take a look at \nit over on this end.\n\nThanks Ryan.\nSt.Ack\n\n\n\n&gt; lcm:/RAID01/1/1_job_1120859484 root# ls -al\n&gt; LC-20050712000448-00068-lcs0001.*      \n&gt; -rw-r--r--   1 nobody  nobody  100014425 Jul 12 05:53\n&gt; LC-20050712000448-00068-lcs0001.local.arc.gz\n&gt; -rw-r--r--   1 root    nobody    1010352 Jul 14 10:21\n&gt; LC-20050712000448-00068-lcs0001.local.urls\n&gt;\n&gt; The ARC was successfully closed.  As a matter of fact, this crawl is\n&gt; still in progress and I wrote a quick\n&gt; and dirty perl script to process the closed .arc.gz&#39;s only.  I actually\n&gt; have other ARCs causing this as well\n&gt; (all closed, 100 MB) -- this was just the one I found aborting\n&gt; &quot;quickest&quot;.  Basically every 100 MB ARC\n&gt; produces about 100 MB of uncompressed URLs.  The problem doesn&#39;t seem s\n&gt; to be in extracting\n&gt; individual links from a given document in the ARC?\n&gt;\n&gt;\n&gt; stack wrote:\n&gt;\n&gt; &gt;\n&gt; &gt; We&#39;re failing on a basic read of the gzipped ARC.   Does it fail each\n&gt; &gt; time?  What is the output if you do ${HERITRIX_HOME}/bin/arcreader -s\n&gt; &gt; ARCNAME?  Does it read any records from the ARC (or just not the last)?\n&gt; &gt; What does gzip -t say about the ARC?  (There are cases where the last\n&gt; &gt; gzip member in an ARC can be incomplete if Heritrix is shutdown\n&gt; &gt; improperly (Crash, etc.) but usually in this case the ARCs will still\n&gt; &gt; have the &#39;.open&#39; extension).\n&gt; &gt; Thanks,\n&gt; &gt; St.Ack\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; ------------------------------------------------------------------------\n&gt; &gt;\n&gt;\n&gt; ------------------------------------------------------------------------\n&gt; YAHOO! GROUPS LINKS\n&gt;\n&gt;     *  Visit your group &quot;archive-crawler\n&gt;       &lt;http://groups.yahoo.com/group/archive-crawler&gt;&quot; on the web.\n&gt;        \n&gt;     *  To unsubscribe from this group, send an email to:\n&gt;        archive-crawler-unsubscribe@yahoogroups.com\n&gt;       &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;        \n&gt;     *  Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;.\n&gt;\n&gt;\n&gt; ------------------------------------------------------------------------\n&gt;\n\n\n"}}