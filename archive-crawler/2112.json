{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":215515511,"authorName":"Mike Schwartz","from":"Mike Schwartz &lt;mschwartz@...&gt;","profile":"mfschwartz","replyTo":"LIST","senderId":"vFKf4Goc_fCUewFw8YDB-KZKYLg00tl_5icFMdhU9tUIiCBP9FHQiuWyVsiruRWiXTK9gTV6mKZNVk9JPI-4Gq_1CQx-oNPSaQI","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Heretrix downloaded/queued document ratio","postDate":"1124209375","msgId":2112,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDYuMi4zLjQuMi4yMDA1MDgxNjA5NTcwNi4wMjU4MmI5OEB2aG9zdDYuYXRvbWljc2VydmVycy5jb20+","inReplyToHeader":"PDQzMDEzMkJDLjgwMDAwQGFyY2hpdmUub3JnPg==","referencesHeader":"PDYuMi4zLjQuMi4yMDA1MDgxNTEwMTkyMy4wMjRjYTk4OEB2aG9zdDYuYXRvbWljc2VydmVycy5jb20+IDw0MzAxMDg4My44MDAwNkBhcmNoaXZlLm9yZz4gPDYuMi4zLjQuMi4yMDA1MDgxNTE3MjMwNi4wMjUyNTUyOEB2aG9zdDYuYXRvbWljc2VydmVycy5jb20+IDw0MzAxMzJCQy44MDAwMEBhcmNoaXZlLm9yZz4="},"prevInTopic":2111,"nextInTopic":2113,"prevInTime":2111,"nextInTime":2113,"topicId":2104,"numMessagesInTopic":6,"msgSnippet":"hi, Yes, the log entry included below was a seed.  As for scoping: I m using DomainScope, and I have 3 filters set up to crawl only HTML content (slightly","rawEmail":"Return-Path: &lt;mschwartz@...&gt;\r\nX-Sender: mschwartz@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 989 invoked from network); 16 Aug 2005 16:23:17 -0000\r\nReceived: from unknown (66.218.66.218)\n  by m33.grp.scd.yahoo.com with QMQP; 16 Aug 2005 16:23:17 -0000\r\nReceived: from unknown (HELO vhost6.atomicservers.com) (216.58.160.194)\n  by mta3.grp.scd.yahoo.com with SMTP; 16 Aug 2005 16:23:17 -0000\r\nReceived: from dev4lt.localmatters.com ([64.78.237.253])\n\t(authenticated (0 bits))\n\tby vhost6.atomicservers.com (8.11.6/8.11.6) with ESMTP id j7GGMsK03193\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Tue, 16 Aug 2005 10:22:54 -0600\r\nMessage-Id: &lt;6.2.3.4.2.20050816095706.02582b98@...&gt;\r\nX-Mailer: QUALCOMM Windows Eudora Version 6.2.3.4\r\nDate: Tue, 16 Aug 2005 10:22:55 -0600\r\nTo: archive-crawler@yahoogroups.com\r\nIn-Reply-To: &lt;430132BC.80000@...&gt;\r\nReferences: &lt;6.2.3.4.2.20050815101923.024ca988@...&gt;\n &lt;43010883.80006@...&gt;\n &lt;6.2.3.4.2.20050815172306.02525528@...&gt;\n &lt;430132BC.80000@...&gt;\r\nMime-Version: 1.0\r\nContent-Type: multipart/alternative;\n\tboundary=&quot;=====================_75310218==.ALT&quot;\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nX-eGroups-From: Mike Schwartz &lt;mschwartz@...&gt;\r\nFrom: Mike Schwartz &lt;mschwartz@...&gt;\r\nSubject: Re: [archive-crawler] Heretrix downloaded/queued document ratio\r\nX-Yahoo-Group-Post: member; u=215515511; y=SsWj7fzNt3tlg181ILnxYiE-ShvpSdIv8lCp2GBflbmumtByig\r\nX-Yahoo-Profile: mfschwartz\r\n\r\n\r\n--=====================_75310218==.ALT\r\nContent-Type: text/plain; charset=&quot;us-ascii&quot;; format=flowed\r\n\r\nhi,\n\nYes, the log entry included below was a seed.  As for scoping: I&#39;m \nusing DomainScope, and I have 3 filters set up to crawl only HTML \ncontent (slightly modified version of what&#39;s described at \nhttp://groups.yahoo.com/group/archive-crawler/message/1243) as well \nas a URI regexp filter set to avoid crawling https pages.\n\ngrepping thru the Heretrix code it looks like &quot;no-type&quot; has to do \nwith mime type, but I checked an ethereal capture of retrieving \nhttp://www.interstaterestoration.com/ , and it is definitely \nreturning a mime type.  If it wasn&#39;t that might explain the problem \nbecause I have a midfetch-filter that looks at the HTTP response \nheader, looking for (?i)text/html.*)\n\nis it possible the midfetch-filter code has a bug that&#39;s mistakenly \nthinking the mime type isn&#39;t set in the response header?\n\nthanks\n  - Mike\n\nAt 06:26 PM 8/15/2005, you wrote:\n&gt;Mike Schwartz wrote:\n&gt; &gt; thanks for the explanation on this.  I looked at the crawl.log and I see\n&gt; &gt; a whole bunch of my seed URLs with an entry like\n&gt; &gt; 2005-08-15T22:19:21.481Z -5000          -\n&gt; &gt; \n&gt; &lt;http://www.interstaterestoration.com/&gt;http://www.interstaterestoration.com/ \n&gt; - - no-type #095 - - -\n&gt; &gt;\n&gt; &gt; does that mean no mime-type known, or ?\n&gt; &gt;\n&gt; &gt; something seems pretty wrong, as I could believe an occasional site gets\n&gt; &gt; discarded by here 3/4 of my sites are dropping out\n&gt;\n&gt;Consulting FetchStatusCodes, -5000 is &quot;S_OUT_OF_SCOPE&quot;, and is only\n&gt;set by Preselector -- meaning these URIs were scheduled somehow but\n&gt;then fail to pass scope-testing when first considered for crawling.\n&gt;\n&gt;Since there&#39;s no &#39;via&#39; or &#39;hops-path&#39; info, I presume this is a\n&gt;seed. Have you perhaps set up a scope that does not accept some\n&gt;of your seeds?\n&gt;\n&gt;Two possibly-relevant open issues:\n&gt;\n&gt;   Bug [ 1249828 ] -5000 out-of-scope preconditions; -50 failure\n&gt; \n&gt;&lt;https://sourceforge.net/tracker/index.php?func=detail&aid=1249828&group_id=73833&atid=539099&gt;https://sourceforge.net/tracker/index.php?func=detail&aid=1249828&group_id=73833&atid=539099\n&gt;   (probably not the cause of your problem, as it affects prerequisites,\n&gt;   not seeds themselves)\n&gt;\n&gt;   Bug [ 1219486 ] no rule for decidingscope to always crawl seeds\n&gt; \n&gt;&lt;https://sourceforge.net/tracker/index.php?func=detail&aid=1219486&group_id=73833&atid=539099&gt;https://sourceforge.net/tracker/index.php?func=detail&aid=1219486&group_id=73833&atid=539099\n&gt;   (based on the idea that people might want &#39;seeds&#39; to be definitionally\n&gt;   in-scope simply because they&#39;re seeds, even if they wouldn&#39;t otherwise\n&gt;   be ruled-in)\n&gt;\n&gt;- Gordon @ IA\n&gt;\n&gt; &gt; thanks\n&gt; &gt;  - Mike\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; At 03:26 PM 8/15/2005, you wrote:\n&gt; &gt;\n&gt; &gt;&gt; Mike Schwartz wrote:\n&gt; &gt;&gt; &gt; hi,\n&gt; &gt;&gt; &gt;\n&gt; &gt;&gt; &gt; I notice that Heretrix 1.5.0 (taken from the HEAD last week) outputs\n&gt; &gt;&gt; &gt; a down-counting demonimator in the downloaded/queued document\n&gt; &gt;&gt; &gt; ratio.  For example I started a crawl with 2407 seeds, and it\n&gt; &gt;&gt; &gt; initially grew as new pages were discovered, but after a few minutes\n&gt; &gt;&gt; &gt; it reported that I was on page 568 of 593... making it hard to get a\n&gt; &gt;&gt; &gt; sense of what the real % complete is\n&gt; &gt;&gt;\n&gt; &gt;&gt; It&#39;s been this way for a while: URIs that were scheduled, but then\n&gt; &gt;&gt; &#39;disregarded&#39; don&#39;t count as either pending or completed.\n&gt; &gt;&gt;\n&gt; &gt;&gt; The most notable cause of &#39;disregarded&#39; URIs is those that are\n&gt; &gt;&gt; precluded by robots.txt rules -- they get scheduled, but are never\n&gt; &gt;&gt; attempted, and so should neither count as successful, failed, or\n&gt; &gt;&gt; still-pending.\n&gt; &gt;&gt;\n&gt; &gt;&gt; If you&#39;ve added other settings which can cause URIs to be\n&gt; &gt;&gt; ignored after having been initially scheduled -- such as\n&gt; &gt;&gt; narrowing the scope midcrawl, resulting in URIs that get\n&gt; &gt;&gt; ruled out-of-scope on rechecking -- that will also cause\n&gt; &gt;&gt; URIs to be disregarded, and the total &#39;queued&#39; will decrease\n&gt; &gt;&gt; without the &#39;completed&#39; changing.\n&gt; &gt;&gt;\n&gt; &gt;&gt; This area of the crawler needs improvement; the current\n&gt; &gt;&gt; tallies of &#39;percent done&#39; and &#39;estimated time remaining&#39;\n&gt; &gt;&gt; take no account of the potential for more URIs to be\n&gt; &gt;&gt; discovered, and so are almost worse-than-useless.\n&gt; &gt;&gt;\n&gt; &gt;&gt; I think tracking the effective rates of discovery versus\n&gt; &gt;&gt; completion -- and the rates of change of each -- could\n&gt; &gt;&gt; offer more meaningful estimates, for both the whole crawl\n&gt; &gt;&gt; and individual queues. Some notes on possible approaches\n&gt; &gt;&gt; are on the crawler wiki [*] here:\n&gt; &gt;&gt;\n&gt; &gt;&gt;\n&gt; &gt;&gt; \n&gt; &lt;&lt;http://crawler.archive.org/cgi-bin/wiki.pl?CrawlAndQueueDynamics&gt;http://crawler.archive.org/cgi-bin/wiki.pl?CrawlAndQueueDynamics&gt;http://crawler.archive.org/cgi-bin/wiki.pl?CrawlAndQueueDynamics \n&gt;\n&gt; &gt;&gt;\n&gt; &gt;&gt;\n&gt; &gt;&gt; But, implementing some of these ideas is not yet a priority\n&gt; &gt;&gt; for any upcoming releases, so it would take someone interested\n&gt; &gt;&gt; in this area to contribute some code for the situation to\n&gt; &gt;&gt; improve in the short term.\n&gt; &gt;&gt;\n&gt; &gt;&gt; - Gordon @ IA\n&gt; &gt;&gt;\n&gt; &gt;&gt; [*] Reminder: the crawler wiki edit password is available on\n&gt; &gt;&gt; request to any Heritrix users/developers interested in\n&gt; &gt;&gt; adding/revising the content. Email any IA team member for it.\n&gt; &gt;&gt; It&#39;s only protected at all because of past problems with crude\n&gt; &gt;&gt; wiki spam.\n\r\n--=====================_75310218==.ALT\r\nContent-Type: text/html; charset=&quot;us-ascii&quot;\r\n\r\n&lt;html&gt;\n&lt;body&gt;\nhi,&lt;br&gt;&lt;br&gt;\nYes, the log entry included below was a seed.&nbsp; As for scoping: I&#39;m\nusing DomainScope, and I have 3 filters set up to crawl only HTML content\n(slightly modified version of what&#39;s described at\n&lt;a href=&quot;http://groups.yahoo.com/group/archive-crawler/message/1243&quot; eudora=&quot;autourl&quot;&gt;\nhttp://groups.yahoo.com/group/archive-crawler/message/1243&lt;/a&gt;) as well\nas a URI regexp filter set to avoid crawling https pages.&lt;br&gt;&lt;br&gt;\ngrepping thru the Heretrix code it looks like &quot;no-type&quot; has to\ndo with mime type, but I checked an ethereal capture of retrieving\n&lt;a href=&quot;http://www.interstaterestoration.com/&quot; eudora=&quot;autourl&quot;&gt;\nhttp://www.interstaterestoration.com/&lt;/a&gt; , and it is definitely\nreturning a mime type.&nbsp; If it wasn&#39;t that might explain the problem\nbecause I have a midfetch-filter that looks at the HTTP response header,\nlooking for (?i)text/html.*)&lt;br&gt;&lt;br&gt;\nis it possible the midfetch-filter code has a bug that&#39;s mistakenly\nthinking the mime type isn&#39;t set in the response header?&lt;br&gt;&lt;br&gt;\nthanks&lt;br&gt;\n&nbsp;- Mike&lt;br&gt;&lt;br&gt;\n&lt;font size=3&gt;At 06:26 PM 8/15/2005, you wrote:&lt;br&gt;\n&lt;/font&gt;&lt;blockquote type=cite class=cite cite=&quot;&quot;&gt;&lt;tt&gt;Mike Schwartz\nwrote:&lt;br&gt;\n&gt; thanks for the explanation on this.&nbsp; I looked at the crawl.log\nand I see &lt;br&gt;\n&gt; a whole bunch of my seed URLs with an entry like&lt;br&gt;\n&gt; 2005-08-15T22:19:21.481Z\n-5000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - &lt;br&gt;\n&gt;\n&lt;a href=&quot;http://www.interstaterestoration.com/&quot;&gt;\nhttp://www.interstaterestoration.com/&lt;/a&gt; - - no-type #095 - - -&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; does that mean no mime-type known, or ?&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; something seems pretty wrong, as I could believe an occasional site\ngets &lt;br&gt;\n&gt; discarded by here 3/4 of my sites are dropping out&lt;br&gt;&lt;br&gt;\nConsulting FetchStatusCodes, -5000 is &quot;S_OUT_OF_SCOPE&quot;, and is\nonly&lt;br&gt;\nset by Preselector -- meaning these URIs were scheduled somehow but&lt;br&gt;\nthen fail to pass scope-testing when first considered for\ncrawling.&lt;br&gt;&lt;br&gt;\nSince there&#39;s no &#39;via&#39; or &#39;hops-path&#39; info, I presume this is a&lt;br&gt;\nseed. Have you perhaps set up a scope that does not accept some&lt;br&gt;\nof your seeds?&lt;br&gt;&lt;br&gt;\nTwo possibly-relevant open issues:&lt;br&gt;&lt;br&gt;\n&nbsp; Bug [ 1249828 ] -5000 out-of-scope preconditions; -50 failure&lt;br&gt;\n&nbsp;\n&lt;a href=&quot;https://sourceforge.net/tracker/index.php?func=detail&amp;aid=1249828&amp;group_id=73833&amp;atid=539099&quot;&gt;\nhttps://sourceforge.net/tracker/index.php?func=detail&amp;aid=1249828&amp;group_id=73833&amp;atid=539099&lt;/a&gt;\n&lt;br&gt;\n&nbsp; (probably not the cause of your problem, as it affects\nprerequisites,&lt;br&gt;\n&nbsp; not seeds themselves)&lt;br&gt;&lt;br&gt;\n&nbsp; Bug [ 1219486 ] no rule for decidingscope to always crawl\nseeds&lt;br&gt;\n&nbsp;\n&lt;a href=&quot;https://sourceforge.net/tracker/index.php?func=detail&amp;aid=1219486&amp;group_id=73833&amp;atid=539099&quot;&gt;\nhttps://sourceforge.net/tracker/index.php?func=detail&amp;aid=1219486&amp;group_id=73833&amp;atid=539099&lt;/a&gt;\n&lt;br&gt;\n&nbsp; (based on the idea that people might want &#39;seeds&#39; to be\ndefinitionally&lt;br&gt;\n&nbsp; in-scope simply because they&#39;re seeds, even if they wouldn&#39;t\notherwise&lt;br&gt;\n&nbsp; be ruled-in)&lt;br&gt;&lt;br&gt;\n- Gordon @ IA&lt;br&gt;&lt;br&gt;\n&gt; thanks&lt;br&gt;\n&gt;&nbsp; - Mike&lt;br&gt;\n&gt; &lt;br&gt;\n&gt; &lt;br&gt;\n&gt; At 03:26 PM 8/15/2005, you wrote:&lt;br&gt;\n&gt; &lt;br&gt;\n&gt;&gt; Mike Schwartz wrote:&lt;br&gt;\n&gt;&gt; &gt; hi,&lt;br&gt;\n&gt;&gt; &gt;&lt;br&gt;\n&gt;&gt; &gt; I notice that Heretrix 1.5.0 (taken from the HEAD last\nweek) outputs&lt;br&gt;\n&gt;&gt; &gt; a down-counting demonimator in the downloaded/queued\ndocument&lt;br&gt;\n&gt;&gt; &gt; ratio.&nbsp; For example I started a crawl with 2407 seeds,\nand it&lt;br&gt;\n&gt;&gt; &gt; initially grew as new pages were discovered, but after a\nfew minutes&lt;br&gt;\n&gt;&gt; &gt; it reported that I was on page 568 of 593... making it hard\nto get a&lt;br&gt;\n&gt;&gt; &gt; sense of what the real % complete is&lt;br&gt;\n&gt;&gt;&lt;br&gt;\n&gt;&gt; It&#39;s been this way for a while: URIs that were scheduled, but\nthen&lt;br&gt;\n&gt;&gt; &#39;disregarded&#39; don&#39;t count as either pending or completed.&lt;br&gt;\n&gt;&gt;&lt;br&gt;\n&gt;&gt; The most notable cause of &#39;disregarded&#39; URIs is those that\nare&lt;br&gt;\n&gt;&gt; precluded by robots.txt rules -- they get scheduled, but are\nnever&lt;br&gt;\n&gt;&gt; attempted, and so should neither count as successful, failed,\nor&lt;br&gt;\n&gt;&gt; still-pending.&lt;br&gt;\n&gt;&gt;&lt;br&gt;\n&gt;&gt; If you&#39;ve added other settings which can cause URIs to be&lt;br&gt;\n&gt;&gt; ignored after having been initially scheduled -- such as&lt;br&gt;\n&gt;&gt; narrowing the scope midcrawl, resulting in URIs that get&lt;br&gt;\n&gt;&gt; ruled out-of-scope on rechecking -- that will also cause&lt;br&gt;\n&gt;&gt; URIs to be disregarded, and the total &#39;queued&#39; will\ndecrease&lt;br&gt;\n&gt;&gt; without the &#39;completed&#39; changing.&lt;br&gt;\n&gt;&gt;&lt;br&gt;\n&gt;&gt; This area of the crawler needs improvement; the current&lt;br&gt;\n&gt;&gt; tallies of &#39;percent done&#39; and &#39;estimated time remaining&#39;&lt;br&gt;\n&gt;&gt; take no account of the potential for more URIs to be&lt;br&gt;\n&gt;&gt; discovered, and so are almost worse-than-useless.&lt;br&gt;\n&gt;&gt;&lt;br&gt;\n&gt;&gt; I think tracking the effective rates of discovery versus&lt;br&gt;\n&gt;&gt; completion -- and the rates of change of each -- could&lt;br&gt;\n&gt;&gt; offer more meaningful estimates, for both the whole crawl&lt;br&gt;\n&gt;&gt; and individual queues. Some notes on possible approaches&lt;br&gt;\n&gt;&gt; are on the crawler wiki [*] here:&lt;br&gt;\n&gt;&gt;&lt;br&gt;\n&gt;&gt;&lt;br&gt;\n&gt;&gt;\n&lt;&lt;a href=&quot;http://crawler.archive.org/cgi-bin/wiki.pl?CrawlAndQueueDynamics&quot;&gt;\nhttp://crawler.archive.org/cgi-bin/wiki.pl?CrawlAndQueueDynamics&lt;/a&gt;\n&gt;&lt;a href=&quot;http://crawler.archive.org/cgi-bin/wiki.pl?CrawlAndQueueDynamics&quot; eudora=&quot;autourl&quot;&gt;\nhttp://crawler.archive.org/cgi-bin/wiki.pl?CrawlAndQueueDynamics&lt;/a&gt;\n&lt;br&gt;\n&gt;&gt;&lt;br&gt;\n&gt;&gt;&lt;br&gt;\n&gt;&gt; But, implementing some of these ideas is not yet a priority&lt;br&gt;\n&gt;&gt; for any upcoming releases, so it would take someone\ninterested&lt;br&gt;\n&gt;&gt; in this area to contribute some code for the situation to&lt;br&gt;\n&gt;&gt; improve in the short term.&lt;br&gt;\n&gt;&gt;&lt;br&gt;\n&gt;&gt; - Gordon @ IA&lt;br&gt;\n&gt;&gt;&lt;br&gt;\n&gt;&gt; [*] Reminder: the crawler wiki edit password is available\non&lt;br&gt;\n&gt;&gt; request to any Heritrix users/developers interested in&lt;br&gt;\n&gt;&gt; adding/revising the content. Email any IA team member for\nit.&lt;br&gt;\n&gt;&gt; It&#39;s only protected at all because of past problems with\ncrude&lt;br&gt;\n&gt;&gt; wiki spam.&lt;/blockquote&gt;&lt;/body&gt;\n&lt;/html&gt;\n\r\n--=====================_75310218==.ALT--\r\n\n"}}