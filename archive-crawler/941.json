{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"stack","from":"stack &lt;stack@...&gt;","replyTo":"LIST","senderId":"NDn0ZxgWlzj_HVvxTODd_tSfteTyLXzrYDy3_J3EX3gEuonEhgAVFFPfPROA9YnM_LXp7d2qCwhDn_ZRL9t25g","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] persistent crawls","postDate":"1094136258","msgId":941,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQxMzczMUMyLjkwNDA4MDFAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDE2Njk0LjI4NDI2LjcxOTMwNy41MzM2ODVAdGlwaGFyZXMuYmFzaXN0ZWNoLm5ldD4=","referencesHeader":"PDIwMDQwOTAxMjExNTQxLkdBMjU4MzdAYm9vZ2V5bWFuLmFybW9yeS5jb20+CTwxNjY5NC4xNjI5OC43MzY4NjYuOTIyMjE2QHRpcGhhcmVzLmJhc2lzdGVjaC5uZXQ+CTwyMDA0MDkwMTIyMTcwNC5HQTI2MDI0QGJvb2dleW1hbi5hcm1vcnkuY29tPiA8MTY2OTQuMjg0MjYuNzE5MzA3LjUzMzY4NUB0aXBoYXJlcy5iYXNpc3RlY2gubmV0Pg=="},"prevInTopic":940,"nextInTopic":942,"prevInTime":940,"nextInTime":942,"topicId":934,"numMessagesInTopic":14,"msgSnippet":"... If the If-Modified-Since header add doesn t work, we did a little planning yesterday and the feature [ 941072 ] Allow operator-configured mid-HTTP-fetch","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 19448 invoked from network); 2 Sep 2004 14:43:20 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m10.grp.scd.yahoo.com with QMQP; 2 Sep 2004 14:43:20 -0000\r\nReceived: from unknown (HELO dns.duboce.net) (63.203.238.114)\n  by mta5.grp.scd.yahoo.com with SMTP; 2 Sep 2004 14:43:20 -0000\r\nReceived: from archive.org ([192.168.1.105])\n\t(authenticated)\n\tby dns-eth1.duboce.net (8.10.2/8.10.2) with ESMTP id i82E2HB27002\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Thu, 2 Sep 2004 07:02:17 -0700\r\nMessage-ID: &lt;413731C2.9040801@...&gt;\r\nDate: Thu, 02 Sep 2004 07:44:18 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; PPC Mac OS X Mach-O; en-US; rv:1.7b) Gecko/20040421\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;20040901211541.GA25837@...&gt;\t&lt;16694.16298.736866.922216@...&gt;\t&lt;20040901221704.GA26024@...&gt; &lt;16694.28426.719307.533685@...&gt;\r\nIn-Reply-To: &lt;16694.28426.719307.533685@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Remote-IP: 63.203.238.114\r\nFrom: stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] persistent crawls\r\nX-Yahoo-Group-Post: member; u=168599281\r\n\r\nTom Emerson wrote:\n\n&gt;Phil White writes:\n&gt;[...]\n&gt;  \n&gt;\n&gt;&gt;As a result, it&#39;s necessarily a longer term project and I&#39;d prefer to \n&gt;&gt;not have my DSL pegged out for the next 3 years or so.  8)\n&gt;&gt;    \n&gt;&gt;\n&gt;[...]\n&gt;\n&gt;There has been a lot of research done on how to select URLs for\n&gt;subsequent crawling: the major search engines certainly don&#39;t recrawl\n&gt;their entire catalog on a regular basis. Searching on Google (you&#39;ll\n&gt;find papers by Sergei Brin and Larry Page, who both worked on this\n&gt;problem) or on CiteSeer will show a bunch. However, for your task this\n&gt;is probably overkill.\n&gt;\n&gt;One hack comes to mind, which may or may not work:\n&gt;\n&gt;In the Expert Settings for the crawl you can add &quot;Accept&quot; headers to\n&gt;the request. It turns out that the way I implemented this allows you\n&gt;to add *any* header to the request. The upshot is that you could try\n&gt;adding an &#39;If-Modified-Since:&#39; header to the subsequent crawls, giving\n&gt;the date of your initial crawl. It isn&#39;t perfect, but it may help.\n&gt;\n&gt;You could also write a script that extracts all the URLs and then\n&gt;sends a HEAD request to determine which ones have changed... I was\n&gt;thinking of writing something like this, but have not gotten around to\n&gt;it.\n&gt;  \n&gt;\nIf the &#39;If-Modified-Since&#39; header add doesn&#39;t work, we did a little \nplanning yesterday and the feature &#39;[ 941072 ] Allow operator-configured \nmid-HTTP-fetch filters&#39; is to be done for an October 1st-ish release \n(1.2).  This feature would introduce filters after the headers have been \ndownloaded but before we start in on the body.  Filters will say yes or \nno on whether to proceed.  Let me take on the above as a test this \nfeature needs to pass (Another will be a mime-type filter).\n\n(If anyone is interested in features scheduled for 1.2, see the RFE list \nby priority.  At least the highest priority items with the next lowest \npriority items to be done opportunistically).\n\nSt.Ack\n\n&gt;    -tree\n&gt;\n&gt;  \n&gt;\n\n\n"}}