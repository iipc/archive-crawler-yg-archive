{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"X7-KwwLEa0derKi54BVZ180YasBN3u5iiYsR6lmfl-rWLG3mXrR3hzPuFRZloz7uzZ6wta8n1fD1xmmp1hdvS4zu_1JA7GI","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] Domain crawl is rapidly slowing","postDate":"1291331035","msgId":6849,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRDRjgyNURCLjIwNjA3MDhAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PEFBTkxrVGk9REcyWGcyUHc9OEVzTEE1TnpNTm5PdWJZaFloYm54YVJodV96b0BtYWlsLmdtYWlsLmNvbT4=","referencesHeader":"PEFBTkxrVGk9REcyWGcyUHc9OEVzTEE1TnpNTm5PdWJZaFloYm54YVJodV96b0BtYWlsLmdtYWlsLmNvbT4="},"prevInTopic":6844,"nextInTopic":0,"prevInTime":6848,"nextInTime":6850,"topicId":6844,"numMessagesInTopic":2,"msgSnippet":"... Hi, Adam! Some thoughts: The memory usage snapshot you ve provided shows plenty of headroom (~600MB) for utilization to cycle through, so I doubt that the","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 83324 invoked from network); 2 Dec 2010 23:03:57 -0000\r\nX-Received: from unknown (98.137.34.46)\n  by m1.grp.sp2.yahoo.com with QMQP; 2 Dec 2010 23:03:57 -0000\r\nX-Received: from unknown (HELO relay03.pair.com) (209.68.5.17)\n  by mta3.grp.sp2.yahoo.com with SMTP; 2 Dec 2010 23:03:57 -0000\r\nX-Received: (qmail 48879 invoked by uid 0); 2 Dec 2010 23:03:56 -0000\r\nX-Received: from 208.70.27.190 (HELO silverbook.local) (208.70.27.190)\n  by relay03.pair.com with SMTP; 2 Dec 2010 23:03:56 -0000\r\nX-pair-Authenticated: 208.70.27.190\r\nMessage-ID: &lt;4CF825DB.2060708@...&gt;\r\nDate: Thu, 02 Dec 2010 15:03:55 -0800\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.6; en-US; rv:1.9.2.12) Gecko/20101027 Thunderbird/3.1.6\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: =?UTF-8?B?QWRhbSBCcm9rZcWh?= &lt;adam.brokes@...&gt;\r\nReferences: &lt;AANLkTi=DG2Xg2Pw=8EsLA5NzMNnOubYhYhbnxaRhu_zo@...&gt;\r\nIn-Reply-To: &lt;AANLkTi=DG2Xg2Pw=8EsLA5NzMNnOubYhYhbnxaRhu_zo@...&gt;\r\nContent-Type: text/plain; charset=UTF-8; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Domain crawl is rapidly slowing\r\nX-Yahoo-Group-Post: member; u=137285340; y=EkJG3t-Oo3BpRp0Io8jGrIR2qmHFBkHYwmGwK2uM_ahi\r\nX-Yahoo-Profile: gojomo\r\n\r\nOn 12/1/10 2:13 PM, Adam Broke≈° wrote:\n&gt; Hi guys,\n&gt;\n&gt; I am working on czech domain crawl and run into troubles with slowing\n&gt; crawl engine. After three days the speed drops to about 11URL/sec and\n&gt; 300KB/s. When I started the crawl the speed was (stable for about day)\n&gt; 150URL/s and 5000KB/s. In last domain crawls we had figures like this.\n&gt;\n&gt; I am not sure where could be problem. Maybe it could be the bloom\n&gt; frontier, first I tried it with 64bit java but always gat GC OOM\n&gt; exceptions, then after switch to 32b it works. But I didn&#39;t encounter\n&gt; such problems with domain crawl. Yes the crawl is always slowing\n&gt; toward the ends but not so rapidly.\n&gt;\n&gt; Basic info:\n&gt; 1990739 KB used\n&gt; 2188864 KB current heap\n&gt; 2730688 KB max heap\n&gt; 32bit java6 update22\n&gt; debian\n&gt; heritrix 1.14.4\n&gt; order.xml is attached in the end of message\n&gt;\n&gt; Do you have any ideas?\n\nHi, Adam!\n\nSome thoughts:\n\nThe memory usage snapshot you&#39;ve provided shows plenty of headroom \n(~600MB) for utilization to cycle through, so I doubt that the problem \nis low memory causing constant GC.\n\nHow much RAM in the machine? Does &#39;top&#39; or &#39;vmstat&#39; show any use of swap \nmemory, or virtual memory paging in/out? Even a little paging of the \nJava heap space can be deadly for performance, as Java memory access, in \nthe context of constant GC and object-relocation, is highly nonlocal. \n(Since the JVM uses a batch of native memory in addition to the assigned \nheap space, even a chosen heap size below physical RAM can sometimes \nresult in unwanted swapping.)\n\nAre all worker ToeThreads busy? If not, the crawl may have reached the \npoint where politeness is the limiting factor.\n\nIf they are all busy, does a thread report suggest any patterns in both \nwhat processing steps, and kinds of URLs, most threads are busy \nhandling? It&#39;s sometimes the case that certain kinds of unresponsive \nsites take the longest to process -- requiring long (20+ second) \nconnection timeouts. If a whole batch of these sites are all up for \nactive crawling at once -- perhaps even because they are all subdomains \nthat behave the same way -- you may see almost all threads spending \nalmost all of their time waiting for these timeouts.\n\nIf this appears to be the case, some options include:\n(1) shortening the timeouts\n(2) recognizing the batches of related unresponsive sites and using any \nof the usual ways to manually delete/block those URIs\n(3) slightly increasing the number of threads, since most are \neffectively idle (but this runs risks of having too many when again most \nthreads are busy with responsive sites)\n\nOther patterns evident from a threads report on a crawl where all \nthreads are busy may indicate other bottlenecks, perhaps based on disk \nseeks or total IO; feel free to share a threads report snapshot either \non the list or to me directly if none of the above seems to explain the \nissue.\n\nThe Bloom filter shouldn&#39;t be a contributing factor; it doesn&#39;t slow at \nall as it gets filled, it just becomes incrementally less more \nerror-prone, within its configured targets, as the number of inserts grows.\n\n- Gordon @ IA\n\n\n\n"}}