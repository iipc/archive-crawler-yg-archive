{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"64ectlJL86vJzhzI_yjHj7FKnm_GVwQ1_r0KtorrC9JOw-rdq8tnfN5EUDoPMxjkbC8K_gDoSCQEn32BlGdYCDK52f8o-eA","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] multiple ExtractorImpliedURI extractors in one crawl","postDate":"1191018498","msgId":4572,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ2RkQ4MDAyLjMwNjA4MDBAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDQ2RkNCODk5LjgwMjA5MDNAc3RhdHNiaWJsaW90ZWtldC5kaz4=","referencesHeader":"PDQ2RkNCODk5LjgwMjA5MDNAc3RhdHNiaWJsaW90ZWtldC5kaz4="},"prevInTopic":4571,"nextInTopic":4578,"prevInTime":4571,"nextInTime":4573,"topicId":4571,"numMessagesInTopic":3,"msgSnippet":"... It s certainly possible to have more than one ExtractorImpliedURI, though the web UI is flawed in making it unnecessarily hard; see: ","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 50798 invoked from network); 28 Sep 2007 22:28:07 -0000\r\nReceived: from unknown (69.147.108.200)\n  by m47.grp.scd.yahoo.com with QMQP; 28 Sep 2007 22:28:07 -0000\r\nReceived: from unknown (HELO mail.archive.org) (207.241.233.246)\n  by mta1.grp.re1.yahoo.com with SMTP; 28 Sep 2007 22:28:06 -0000\r\nReceived: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id 7D7DE141A553B\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Fri, 28 Sep 2007 15:28:03 -0700 (PDT)\r\nReceived: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id 23846-02-97 for &lt;archive-crawler@yahoogroups.com&gt;;\n\tFri, 28 Sep 2007 15:28:03 -0700 (PDT)\r\nReceived: from [192.168.1.203] (c-76-102-230-209.hsd1.ca.comcast.net [76.102.230.209])\n\tby mail.archive.org (Postfix) with ESMTP id 2C6FF141A54E0\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Fri, 28 Sep 2007 15:28:03 -0700 (PDT)\r\nMessage-ID: &lt;46FD8002.3060800@...&gt;\r\nDate: Fri, 28 Sep 2007 15:28:18 -0700\r\nUser-Agent: Thunderbird 1.5.0.13 (X11/20070824)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;46FCB899.8020903@...&gt;\r\nIn-Reply-To: &lt;46FCB899.8020903@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Virus-Scanned: Debian amavisd-new at archive.org\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] multiple ExtractorImpliedURI extractors in\n one crawl\r\nX-Yahoo-Group-Post: member; u=137285340; y=JPt4vVxIc4eS0FOjpovN39Gg8jqhRO06qi2AWarK5KyN\r\nX-Yahoo-Profile: gojomo\r\n\r\nBjarne Andersen wrote:\n&gt; Hi.\n&gt; \n&gt; Would it be possible to add multiple ExtractorImpliedURI extractors to one crawl.\n&gt; I have a website where a trigger-URI should generate 3 other URIs.\n&gt; \n&gt; Could this be done by adding three extractors with the same trigger ? - or even more logical three build-patterns from the same trigger\n\nIt&#39;s certainly possible to have more than one ExtractorImpliedURI, \nthough the web UI is flawed in making it unnecessarily hard; see:\n\n  http://webteam.archive.org/jira/browse/HER-1068\n\nFor now, you have to hand-edit a crawl order file to put more than one \nProcessor of the same implementing class into a single processing-chain.\n\nAnother option to consider for situations where one URI implies many, or \nthe implied URIs can&#39;t be constructed with the build-pattern, would be \nto write a Beanshell script which does the required \nanalysis/construction, and use the BeanshellProcessor.\n\n- Gordon @ IA\n\n\n"}}