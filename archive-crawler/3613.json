{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":193394005,"authorName":"blah_1977","from":"&quot;blah_1977&quot; &lt;hwangs@...&gt;","profile":"blah_1977","replyTo":"LIST","senderId":"gO7RZ5rCYsD-XuKlm2CKx7bMsEW_RWWi-WmuMifaE0NRZkdjXWB_BtKQebcc8VWHbTV6zzmNpGOqcQu7tFE7x0ymU4x87PtO","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: heritrix stuck","postDate":"1166843589","msgId":3613,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGVtaTZzNStxdDc1QGVHcm91cHMuY29tPg==","inReplyToHeader":"PDQ1OEMyNEI3LjEwOTA1MDhAYXJjaGl2ZS5vcmc+"},"prevInTopic":3611,"nextInTopic":3614,"prevInTime":3612,"nextInTime":3614,"topicId":3603,"numMessagesInTopic":9,"msgSnippet":"Hello, thanks for the quick reply! I am using the most recent stable build: 1.10.1.  I did write a custom extractor and a custom postprocessor and added those","rawEmail":"Return-Path: &lt;hwangs@...&gt;\r\nX-Sender: hwangs@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 28519 invoked from network); 23 Dec 2006 03:13:53 -0000\r\nReceived: from unknown (66.218.67.33)\n  by m25.grp.scd.yahoo.com with QMQP; 23 Dec 2006 03:13:53 -0000\r\nReceived: from unknown (HELO n19.bullet.sp1.yahoo.com) (69.147.64.216)\n  by mta7.grp.scd.yahoo.com with SMTP; 23 Dec 2006 03:13:53 -0000\r\nReceived: from [216.252.122.219] by n19.bullet.sp1.yahoo.com with NNFMP; 23 Dec 2006 03:13:10 -0000\r\nReceived: from [209.73.164.86] by t4.bullet.sp1.yahoo.com with NNFMP; 23 Dec 2006 03:13:10 -0000\r\nReceived: from [66.218.66.84] by t8.bullet.scd.yahoo.com with NNFMP; 23 Dec 2006 03:13:10 -0000\r\nDate: Sat, 23 Dec 2006 03:13:09 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;emi6s5+qt75@...&gt;\r\nIn-Reply-To: &lt;458C24B7.1090508@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;blah_1977&quot; &lt;hwangs@...&gt;\r\nSubject: Re: heritrix stuck\r\nX-Yahoo-Group-Post: member; u=193394005; y=GUyndFaF1HDhNZe7tUbjMd0EA_V0GXNqpSSNNoPUcRTngeQn9JQ\r\nX-Yahoo-Profile: blah_1977\r\n\r\nHello, thanks for the quick reply!\n\nI am using the most recent stable build=\r\n: 1.10.1.  I did write a custom\nextractor and a custom postprocessor and ad=\r\nded those two to the\nprocessing chain in &quot;order.xml&quot;.  My custom extractor =\r\nis an aggressive\nextractor for forms ( i.e., it tries to simulate a form su=\r\nbmission by\niterating over the input elements in the form and constructing =\r\na query\nparameter string).  My custom postprocessor stores the HMTL page\nco=\r\nntent in a CrawlURI&#39;s properties AList, so I can retrieve it later\nfor furt=\r\nher analysis.  I&#39;ve added my extractor after ExtractorHTML and\nmy postproce=\r\nssor as the very last postprocessor in the processing\nchain.  In both cases=\r\n, my custom processors call\nCrawlURI.getHttpRecorder().getCharacterReplaySe=\r\nquence() in order to\nget the HTML page content of the CrawlURI.  I call clo=\r\nse on the\nHttpRecorder and the CharacterReplaySequence in a finally block a=\r\nfter\nI&#39;m done with the two. I believe it is the multiple calls to\nCrawlURI.=\r\ngetHttpRecorder().getCharacterReplaySequence() (which will\nhappen in Extrac=\r\ntorHTML, my custom extractor, and postprocessor) which\ncauses the errors I =\r\nam seeing.  As a temporary workaround, I&#39;ve\nmodified ExtractorHTML by stori=\r\nng the HMTL page content in a\nCrawlURI&#39;s properties AList whenever Extracto=\r\nrHTML does the call to\nCrawlURI.getHttpRecorder().getCharacterReplaySequenc=\r\ne(), so I can just\nretrieve the HTML page content from the properties AList=\r\n later without\nhaving to open and close the RIS.  This temporary workaround=\r\n seems to\nhave cleared up the exceptions for now, but is there a better way=\r\n to\ndo this?\n\nHeritrix is embedded into my WAR.  Crawling goes well usually=\r\n.  This\nproblem doesn&#39;t happen for every link crawled; it just happens for\n=\r\ncertain links, but I&#39;m not sure what triggers the error.  However,\nonce I&#39;v=\r\ne found a website that causes this error, I can reproduce the\nerror everyti=\r\nme I crawl that particular site.  I&#39;ve also duplicated my\napplication as a =\r\nsimple command line app, just to make sure it isn&#39;t\nsome strange interactio=\r\nn with the webapp that&#39;s causing my problem. \nHowever, I still see the same=\r\n behavior and errors.\n\nBefore I made my workaround fix described above, the=\r\n delete was not\nfailing silently.  The log entry was something along the li=\r\nnes of &quot;...\nbecause of FileNotFoundException &lt;filename&gt;.UTF-16BE cannot be =\r\ndeleted\nbecause of open user map region on RIS&quot;.  Or something like that. \n=\r\nI&#39;ll get the exact error message in a follow-up post.  When I made my\nworka=\r\nround fix described above, the delete started failing silently.\n\nThanks muc=\r\nh!\n\n\n--- In archive-crawler@yahoogroups.com, Michael Stack &lt;stack@...&gt; wrot=\r\ne:\n&gt;\n&gt; Regards your first mail, did you do anything custom to the FetchHTTP=\r\n\n(or \n&gt; FetchDNS)?  These are usually responsible for closing the \n&gt; Record=\r\ningInputStream (RIS).  There is a RIS per thread.  Its opened and \n&gt; closed=\r\n in the fetcher per trip down along the processing chain.  In the \n&gt; past t=\r\nhe close would sometimes fail but this was addressed a while back \n&gt; (You a=\r\nre using a recent Heritrix?).  \n&gt; \n&gt; Heritrix is embedded into your WAR or =\r\ndoes your WAR run a remote \n&gt; Heritrix instance?  Does crawling usually wor=\r\nk well?  Its just the odd \n&gt; time it goes awry?\n&gt; \n&gt; Your second mail &#39;seem=\r\ns&#39; to describe a different phenomenon.  After \n&gt; fetchers are finished, ext=\r\nractors go to work and get a character stream \n&gt; on the fetchers&#39; download =\r\n(A ReplayCharSequence).   If we determine\nit a \n&gt; multi-byte stream, we fir=\r\nst convert downloaded bytes to a CharSequence \n&gt; writing the encoding to a =\r\ntemporary file -- the one with the UTF-16BE \n&gt; suffix -- and its this file =\r\nwe pass back to the extractor to run its \n&gt; character-based regexes across.=\r\n  When an extractor is done, its\nsupposed \n&gt; to clean up the temporary file=\r\n.  The delete is failing silently?  Just \n&gt; before the delete, there is a l=\r\nog (&#39;...because of...&#39;).  Whats it\nsay in \n&gt; your case?\n&gt; \n&gt; Thanks,\n&gt; St.A=\r\nck\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; blah_1977 wrote:\n&gt; &gt;\n&gt; &gt; After digging around a bit try=\r\ning to debug this problem, I think the\n&gt; &gt; root cause is in the class\n&gt; &gt; R=\r\neplayCharSequenceFactory.MultiByteReplayCharSequence at the method\n&gt; &gt;\n&gt; &gt; =\r\nprivate void deleteFile(File fileToDelete, final Exception e) {\n&gt; &gt; if (e !=\r\n=3D null) {\n&gt; &gt; // Log why the delete to help with debug of\n&gt; &gt; java.io.Fil=\r\neNotFoundException:\n&gt; &gt; // ....tt53http.ris.UTF-16BE.\n&gt; &gt; logger.severe(&quot;De=\r\nleting &quot; + fileToDelete + &quot; because of &quot;\n&gt; &gt; + e.toString());\n&gt; &gt; }\n&gt; &gt; if =\r\n(fileToDelete !=3D null && fileToDelete.exists()) {\n&gt; &gt; fileToDelete.delete=\r\n();\n&gt; &gt; }\n&gt; &gt; }\n&gt; &gt;\n&gt; &gt; The last line &quot;fileToDelete.delete()&quot; seems to alwa=\r\nys return false\n&gt; &gt; when invoked from ExtractorHTML, indicating that the fi=\r\nle cannot be\n&gt; &gt; deleted (perhaps due to a stream still being open on it). =\r\nThis then\n&gt; &gt; snowballs into the error seen in my previous post.\n&gt; &gt; Has an=\r\nyone any idea on what&#39;s causing this, and how to fix?\n&gt; &gt; Thanks much in ad=\r\nvance.\n&gt; &gt;\n&gt; &gt; --- In archive-crawler@yahoogroups.com \n&gt; &gt; &lt;mailto:archive-=\r\ncrawler%40yahoogroups.com&gt;, &quot;blah_1977&quot; &lt;hwangs@&gt; \n&gt; &gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; I=\r\n&#39;ve written a little web app running on tomcat, which uses heritrix\n&gt; &gt; &gt; t=\r\no crawl specific sites. Lately, I&#39;ve been running into the\nfollowing\n&gt; &gt; &gt; =\r\nerror messages on the command line, after which it seems like the\n&gt; &gt; &gt; who=\r\nle application becomes &quot;stuck&quot;. i.e., no more progress being made\n&gt; &gt; &gt; on =\r\nthe crawl. Here are the error messages:\n&gt; &gt; &gt;\n&gt; &gt; &gt; INFO HttpMethodDirector=\r\n:434 - I/O exception caught when processing\n&gt; &gt; &gt; request: RIS already open=\r\n for ToeThread #35:\n&gt; &gt; &gt;\n&gt; &gt;\nhttp://www.pcrecruiter.net/pcrbin/reg5.exe?i1=\r\n=3DWEBGUEST&i2=3D532335723616234&i3=3DDETAIL&hash=3D508826133&i5=3D&i6=3D12=\r\n%2f21%2f2006%207:12:23%20PM&i7=3DSenior%20software%20engineer%20%20-%20Cont=\r\nent%20%26%20Syndication&i8=3D&i9=3D&i10=3DJ.Job_Title%20Desc&pcr-id=3DP4SAo=\r\n2E%2fQbHmzBnzOGfIEYm775gf6WWf7H%2fBydd2pvkAJ%2fXKJ%2bHqhT0Ky%2b49HifRK6eix7=\r\nA8nL6t%0d%0abj8hq%2b%2fiNyiM\n\n&gt; &gt;\n&lt;http://www.pcrecruiter.net/pcrbin/reg5.e=\r\nxe?i1=3DWEBGUEST&i2=3D532335723616234&i3=3DDETAIL&hash=3D508826133&i5=3D&i6=\r\n=3D12%2f21%2f2006%207:12:23%20PM&i7=3DSenior%20software%20engineer%20%20-%2=\r\n0Content%20%26%20Syndication&i8=3D&i9=3D&i10=3DJ.Job_Title%20Desc&pcr-id=3D=\r\nP4SAo2E%2fQbHmzBnzOGfIEYm775gf6WWf7H%2fBydd2pvkAJ%2fXKJ%2bHqhT0Ky%2b49HifRK=\r\n6eix7A8nL6t%0d%0abj8hq%2b%2fiNyiM&gt;\n&gt; &gt; &gt;\n&gt; &gt; &gt; [ToeThread #35:\n&gt; &gt; &gt;\n&gt; &gt;\nht=\r\ntp://www.pcrecruiter.net/pcrbin/reg5.exe?i1=3DWEBGUEST&i2=3D532335723616234=\r\n&i3=3DDETAIL&hash=3D508826133&i5=3D&i6=3D12%2f21%2f2006%207:12:23%20PM&i7=\r\n=3DSenior%20software%20engineer%20%20-%20Content%20%26%20Syndication&i8=3D&=\r\ni9=3D&i10=3DJ.Job_Title%20Desc&pcr-id=3DP4SAo2E%2fQbHmzBnzOGfIEYm775gf6WWf7=\r\nH%2fBydd2pvkAJ%2fXKJ%2bHqhT0Ky%2b49HifRK6eix7A8nL6t%0d%0abj8hq%2b%2fiNyiM\n\n=\r\n&gt; &gt;\n&lt;http://www.pcrecruiter.net/pcrbin/reg5.exe?i1=3DWEBGUEST&i2=3D53233572=\r\n3616234&i3=3DDETAIL&hash=3D508826133&i5=3D&i6=3D12%2f21%2f2006%207:12:23%20=\r\nPM&i7=3DSenior%20software%20engineer%20%20-%20Content%20%26%20Syndication&i=\r\n8=3D&i9=3D&i10=3DJ.Job_Title%20Desc&pcr-id=3DP4SAo2E%2fQbHmzBnzOGfIEYm775gf=\r\n6WWf7H%2fBydd2pvkAJ%2fXKJ%2bHqhT0Ky%2b49HifRK6eix7A8nL6t%0d%0abj8hq%2b%2fiN=\r\nyiM&gt;]\n&gt; &gt; &gt; 19:14:03,516 INFO HttpMethodDirector:440 - Retrying request\n&gt; &gt;=\r\n &gt;\n&gt; &gt; &gt;\n&gt; &gt; &gt; Has anybody seen anything like this before? Thanks much in a=\r\ndvance.\n&gt; &gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}