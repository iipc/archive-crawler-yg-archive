{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":331152684,"authorName":"sudarat.jeampokakul","from":"&quot;sudarat.jeampokakul&quot; &lt;sudarat.jeampokakul@...&gt;","profile":"sudarat.jeampokakul","replyTo":"LIST","senderId":"WGKrafw_vQQAi8c-0PwH4UbHOtRkxuODh3w-2mdO-LP93_BqDt6MrsxBhsuKuKhDWppl3jzKrtAuCwOG6CnAVOpfm1HugBVgj4HYLUZ4NyMxxH6vaBdHQ6DWHPo","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Nutch crawl problem","postDate":"1197541497","msgId":4822,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZqcjE5cCtmdWMyQGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":4824,"prevInTime":4821,"nextInTime":4823,"topicId":4822,"numMessagesInTopic":2,"msgSnippet":"i use nutch-0.9, hadoop-0.12.2 and i use this command bin/nutch crawl urls -dir crawled -depth 3  have error : - crawl started in: crawled - rootUrlDir =","rawEmail":"Return-Path: &lt;sudarat.jeampokakul@...&gt;\r\nX-Sender: sudarat.jeampokakul@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 2498 invoked from network); 13 Dec 2007 10:24:59 -0000\r\nX-Received: from unknown (66.218.67.97)\n  by m46.grp.scd.yahoo.com with QMQP; 13 Dec 2007 10:24:59 -0000\r\nX-Received: from unknown (HELO n26a.bullet.sp1.yahoo.com) (209.131.38.240)\n  by mta18.grp.scd.yahoo.com with SMTP; 13 Dec 2007 10:24:59 -0000\r\nX-Received: from [216.252.122.217] by n26.bullet.sp1.yahoo.com with NNFMP; 13 Dec 2007 10:24:59 -0000\r\nX-Received: from [209.73.164.83] by t2.bullet.sp1.yahoo.com with NNFMP; 13 Dec 2007 10:24:59 -0000\r\nX-Received: from [66.218.66.79] by t7.bullet.scd.yahoo.com with NNFMP; 13 Dec 2007 10:24:59 -0000\r\nDate: Thu, 13 Dec 2007 10:24:57 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;fjr19p+fuc2@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;sudarat.jeampokakul&quot; &lt;sudarat.jeampokakul@...&gt;\r\nSubject: Nutch crawl problem\r\nX-Yahoo-Group-Post: member; u=331152684; y=WLMwpgHcO8v1Fo2L2JOJMFmTxtM4iw3B62zgBJudD0D0QzNT78MMeGsSG9qo7Q\r\nX-Yahoo-Profile: sudarat.jeampokakul\r\n\r\ni use nutch-0.9, hadoop-0.12.2 and i use this command &quot;bin/nutch crawl \nurl=\r\ns -dir crawled -depth 3&quot;  have error :\n\n- crawl started in: crawled\n- rootU=\r\nrlDir =3D input\n- threads =3D 10\n- depth =3D 3\n- Injector: starting\n- Injec=\r\ntor: crawlDb: crawled/crawldb\n- Injector: urlDir: input\n- Injector: Convert=\r\ning injected urls to crawl db entries.\n- Total input paths to process : 1\n-=\r\n Running job: job_0001\n-  map 0% reduce 0%\n-  map 100% reduce 0%\n-  map 100=\r\n% reduce 100%\n- Job complete: job_0001\n- Counters: 6\n-   Map-Reduce Framewo=\r\nrk\n-     Map input records=3D3\n-     Map output records=3D1\n-     Map input=\r\n bytes=3D22\n-     Map output bytes=3D52\n-     Reduce input records=3D1\n-   =\r\n  Reduce output records=3D1\n- Injector: Merging injected urls into crawl db=\r\n.\n- Total input paths to process : 2\n- Running job: job_0002\n-  map 0% redu=\r\nce 0%\n-  map 100% reduce 0%\n-  map 100% reduce 58%\n-  map 100% reduce 100%\n=\r\n- Job complete: job_0002\n- Counters: 6\n-   Map-Reduce Framework\n-     Map i=\r\nnput records=3D3\n-     Map output records=3D1\n-     Map input bytes=3D60\n- =\r\n    Map output bytes=3D52\n-     Reduce input records=3D1\n-     Reduce outpu=\r\nt records=3D1\n- Injector: done\n- Generator: Selecting best-scoring urls due=\r\n for fetch.\n- Generator: starting\n- Generator: segment: crawled/segments/25=\r\n501213164325\n- Generator: filtering: false\n- Generator: topN: 2147483647\n- =\r\nTotal input paths to process : 2\n- Running job: job_0003\n-  map 0% reduce 0=\r\n%\n-  map 100% reduce 0%\n-  map 100% reduce 100%\n- Job complete: job_0003\n- =\r\nCounters: 6\n-   Map-Reduce Framework\n-     Map input records=3D3\n-     Map =\r\noutput records=3D1\n-     Map input bytes=3D59\n-     Map output bytes=3D77\n-=\r\n     Reduce input records=3D1\n-     Reduce output records=3D1\n- Generator: =\r\n0 records selected for fetching, exiting ...\n- Stopping at depth=3D0 - no m=\r\nore URLs to fetch.\n- No URLs to fetch - check your seed list and URL filter=\r\ns.\n- crawl finished: crawled\n\nbut sometime i crawl some url it has error in=\r\ndexes time that\n\n- Indexer: done\n- Dedup: starting\n- Dedup: adding indexes =\r\nin: crawled/indexes\n- Total input paths to process : 2\n- Running job: job_0=\r\n025\n-  map 0% reduce 0%\n- Task Id : task_0025_m_000001_0, Status : FAILED\nt=\r\nask_0025_m_000001_0: - Error running child\ntask_0025_m_000001_0: java.lang.=\r\nArrayIndexOutOfBoundsException: -1\ntask_0025_m_000001_0:   at \norg.apache.l=\r\nucene.index.MultiReader.isDeleted(MultiReader.java:113)\ntask_0025_m_000001_=\r\n0:   at \norg.apache.nutch.indexer.DeleteDuplicates$InputFormat$DDRecordRead=\r\ne\nr.next(DeleteDuplicates.java:176)\ntask_0025_m_000001_0:   at \norg.apache.=\r\nhadoop.mapred.MapTask$1.next(MapTask.java:157)\ntask_0025_m_000001_0:   at \n=\r\norg.apache.hadoop.mapred.MapRunner.run(MapRunner.java:46)\ntask_0025_m_00000=\r\n1_0:   at org.apache.hadoop.mapred.MapTask.run\n(MapTask.java:175)\ntask_0025=\r\n_m_000001_0:   at \norg.apache.hadoop.mapred.TaskTracker$Child.main\n(TaskTra=\r\ncker.java:1445)\n- Task Id : task_0025_m_000000_0, Status : FAILED\ntask_0025=\r\n_m_000000_0: - Error running child\ntask_0025_m_000000_0: java.lang.ArrayInd=\r\nexOutOfBoundsException: -1\ntask_0025_m_000000_0:   at \norg.apache.lucene.in=\r\ndex.MultiReader.isDeleted(MultiReader.java:113)\ntask_0025_m_000000_0:   at =\r\n\norg.apache.nutch.indexer.DeleteDuplicates$InputFormat$DDRecordReade\nr.next=\r\n(DeleteDuplicates.java:176)\ntask_0025_m_000000_0:   at \norg.apache.hadoop.m=\r\napred.MapTask$1.next(MapTask.java:157)\ntask_0025_m_000000_0:   at \norg.apac=\r\nhe.hadoop.mapred.MapRunner.run(MapRunner.java:46)\ntask_0025_m_000000_0:   a=\r\nt org.apache.hadoop.mapred.MapTask.run\n(MapTask.java:175)\ntask_0025_m_00000=\r\n0_0:   at \norg.apache.hadoop.mapred.TaskTracker$Child.main\n(TaskTracker.jav=\r\na:1445)\n- Task Id : task_0025_m_000000_1, Status : FAILED\ntask_0025_m_00000=\r\n0_1: - Error running child\ntask_0025_m_000000_1: java.lang.ArrayIndexOutOfB=\r\noundsException: -1\ntask_0025_m_000000_1:   at \norg.apache.lucene.index.Mult=\r\niReader.isDeleted(MultiReader.java:113)\ntask_0025_m_000000_1:   at \norg.apa=\r\nche.nutch.indexer.DeleteDuplicates$InputFormat$DDRecordReade\nr.next(DeleteD=\r\nuplicates.java:176)\ntask_0025_m_000000_1:   at \norg.apache.hadoop.mapred.Ma=\r\npTask$1.next(MapTask.java:157)\ntask_0025_m_000000_1:   at \norg.apache.hadoo=\r\np.mapred.MapRunner.run(MapRunner.java:46)\ntask_0025_m_000000_1:   at org.ap=\r\nache.hadoop.mapred.MapTask.run\n(MapTask.java:175)\ntask_0025_m_000000_1:   a=\r\nt \norg.apache.hadoop.mapred.TaskTracker$Child.main\n(TaskTracker.java:1445)\n=\r\n- Task Id : task_0025_m_000001_1, Status : FAILED\ntask_0025_m_000001_1: - E=\r\nrror running child\ntask_0025_m_000001_1: java.lang.ArrayIndexOutOfBoundsExc=\r\neption: -1\ntask_0025_m_000001_1:   at \norg.apache.lucene.index.MultiReader.=\r\nisDeleted(MultiReader.java:113)\ntask_0025_m_000001_1:   at \norg.apache.nutc=\r\nh.indexer.DeleteDuplicates$InputFormat$DDRecordReade\nr.next(DeleteDuplicate=\r\ns.java:176)\ntask_0025_m_000001_1:   at \norg.apache.hadoop.mapred.MapTask$1.=\r\nnext(MapTask.java:157)\ntask_0025_m_000001_1:   at \norg.apache.hadoop.mapred=\r\n.MapRunner.run(MapRunner.java:46)\ntask_0025_m_000001_1:   at org.apache.had=\r\noop.mapred.MapTask.run\n(MapTask.java:175)\ntask_0025_m_000001_1:   at \norg.a=\r\npache.hadoop.mapred.TaskTracker$Child.main\n(TaskTracker.java:1445)\n- Task I=\r\nd : task_0025_m_000001_2, Status : FAILED\ntask_0025_m_000001_2: - Error run=\r\nning child\ntask_0025_m_000001_2: java.lang.ArrayIndexOutOfBoundsException: =\r\n-1\ntask_0025_m_000001_2:   at \norg.apache.lucene.index.MultiReader.isDelete=\r\nd(MultiReader.java:113)\ntask_0025_m_000001_2:   at \norg.apache.nutch.indexe=\r\nr.DeleteDuplicates$InputFormat$DDRecordReade\nr.next(DeleteDuplicates.java:1=\r\n76)\ntask_0025_m_000001_2:   at \norg.apache.hadoop.mapred.MapTask$1.next(Map=\r\nTask.java:157)\ntask_0025_m_000001_2:   at \norg.apache.hadoop.mapred.MapRunn=\r\ner.run(MapRunner.java:46)\ntask_0025_m_000001_2:   at org.apache.hadoop.mapr=\r\ned.MapTask.run\n(MapTask.java:175)\ntask_0025_m_000001_2:   at \norg.apache.ha=\r\ndoop.mapred.TaskTracker$Child.main\n(TaskTracker.java:1445)\n- Task Id : task=\r\n_0025_m_000000_2, Status : FAILED\ntask_0025_m_000000_2: - Error running chi=\r\nld\ntask_0025_m_000000_2: java.lang.ArrayIndexOutOfBoundsException: -1\ntask_=\r\n0025_m_000000_2:   at \norg.apache.lucene.index.MultiReader.isDeleted(MultiR=\r\neader.java:113)\ntask_0025_m_000000_2:   at \norg.apache.nutch.indexer.Delete=\r\nDuplicates$InputFormat$DDRecordReade\nr.next(DeleteDuplicates.java:176)\ntask=\r\n_0025_m_000000_2:   at \norg.apache.hadoop.mapred.MapTask$1.next(MapTask.jav=\r\na:157)\ntask_0025_m_000000_2:   at \norg.apache.hadoop.mapred.MapRunner.run(M=\r\napRunner.java:46)\ntask_0025_m_000000_2:   at org.apache.hadoop.mapred.MapTa=\r\nsk.run\n(MapTask.java:175)\ntask_0025_m_000000_2:   at \norg.apache.hadoop.map=\r\nred.TaskTracker$Child.main\n(TaskTracker.java:1445)\n-  map 100% reduce 100%\n=\r\n- Task Id : task_0025_m_000001_3, Status : FAILED\ntask_0025_m_000001_3: - E=\r\nrror running child\ntask_0025_m_000001_3: java.lang.ArrayIndexOutOfBoundsExc=\r\neption: -1\ntask_0025_m_000001_3:   at \norg.apache.lucene.index.MultiReader.=\r\nisDeleted(MultiReader.java:113)\ntask_0025_m_000001_3:   at \norg.apache.nutc=\r\nh.indexer.DeleteDuplicates$InputFormat$DDRecordReade\nr.next(DeleteDuplicate=\r\ns.java:176)\ntask_0025_m_000001_3:   at \norg.apache.hadoop.mapred.MapTask$1.=\r\nnext(MapTask.java:157)\ntask_0025_m_000001_3:   at \norg.apache.hadoop.mapred=\r\n.MapRunner.run(MapRunner.java:46)\ntask_0025_m_000001_3:   at org.apache.had=\r\noop.mapred.MapTask.run\n(MapTask.java:175)\ntask_0025_m_000001_3:   at \norg.a=\r\npache.hadoop.mapred.TaskTracker$Child.main\n(TaskTracker.java:1445)\n- Task I=\r\nd : task_0025_m_000000_3, Status : FAILED\ntask_0025_m_000000_3: - Error run=\r\nning child\ntask_0025_m_000000_3: java.lang.ArrayIndexOutOfBoundsException: =\r\n-1\ntask_0025_m_000000_3:   at \norg.apache.lucene.index.MultiReader.isDelete=\r\nd(MultiReader.java:113)\ntask_0025_m_000000_3:   at \norg.apache.nutch.indexe=\r\nr.DeleteDuplicates$InputFormat$DDRecordReade\nr.next(DeleteDuplicates.java:1=\r\n76)\ntask_0025_m_000000_3:   at \norg.apache.hadoop.mapred.MapTask$1.next(Map=\r\nTask.java:157)\ntask_0025_m_000000_3:   at \norg.apache.hadoop.mapred.MapRunn=\r\ner.run(MapRunner.java:46)\ntask_0025_m_000000_3:   at org.apache.hadoop.mapr=\r\ned.MapTask.run\n(MapTask.java:175)\ntask_0025_m_000000_3:   at \norg.apache.ha=\r\ndoop.mapred.TaskTracker$Child.main\n(TaskTracker.java:1445)\nException in thr=\r\nead &quot;main&quot; java.io.IOException: Job failed!\n        at org.apache.hadoop.ma=\r\npred.JobClient.runJob(JobClient.java:604)\n        at org.apache.nutch.index=\r\ner.DeleteDuplicates.dedup\n(DeleteDuplicates.java:439)\n        at org.apache=\r\n.nutch.crawl.Crawl.main(Crawl.java:135)\n\nhow i solve it?\n\n\n"}}