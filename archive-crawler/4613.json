{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137477665,"authorName":"Igor Ranitovic","from":"Igor Ranitovic &lt;igor@...&gt;","profile":"iranitovic","replyTo":"LIST","senderId":"qFoSQrE3tF9fBGB_DogLvNZPaLXzPW5jr0GKPpds47NLOPVe4us034NL7E_fSEmO5aKo8WnWGJynSI6gdQfG1XM3W7JODRUB","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] how to crawler the dynamic urls","postDate":"1192801534","msgId":4613,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ3MThCNEZFLjgwOTA5MDVAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGZmOHV1Yis5NDM0QGVHcm91cHMuY29tPg==","referencesHeader":"PGZmOHV1Yis5NDM0QGVHcm91cHMuY29tPg=="},"prevInTopic":4611,"nextInTopic":4614,"prevInTime":4612,"nextInTime":4614,"topicId":4610,"numMessagesInTopic":5,"msgSnippet":"Given that you know the URL, add it as a seed or import it via JMX importURI feature. For more flexibility take a look at ExtractorImpliedURI and ","rawEmail":"Return-Path: &lt;igor@...&gt;\r\nX-Sender: igor@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 28981 invoked from network); 19 Oct 2007 13:46:07 -0000\r\nReceived: from unknown (66.218.67.95)\n  by m48.grp.scd.yahoo.com with QMQP; 19 Oct 2007 13:46:07 -0000\r\nReceived: from unknown (HELO smtp5-g19.free.fr) (212.27.42.35)\n  by mta16.grp.scd.yahoo.com with SMTP; 19 Oct 2007 13:46:06 -0000\r\nReceived: from smtp5-g19.free.fr (localhost.localdomain [127.0.0.1])\n\tby smtp5-g19.free.fr (Postfix) with ESMTP id EDE783F6152\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Fri, 19 Oct 2007 15:46:02 +0200 (CEST)\r\nReceived: from [127.0.0.1] (nor75-24-88-170-99-175.fbx.proxad.net [88.170.99.175])\n\tby smtp5-g19.free.fr (Postfix) with ESMTP id AB7EF3F61E2\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Fri, 19 Oct 2007 15:46:02 +0200 (CEST)\r\nMessage-ID: &lt;4718B4FE.8090905@...&gt;\r\nDate: Fri, 19 Oct 2007 06:45:34 -0700\r\nUser-Agent: Thunderbird 2.0.0.6 (Windows/20070728)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;ff8uub+9434@...&gt;\r\nIn-Reply-To: &lt;ff8uub+9434@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Igor Ranitovic &lt;igor@...&gt;\r\nSubject: Re: [archive-crawler] how to crawler the dynamic urls\r\nX-Yahoo-Group-Post: member; u=137477665; y=LI2w69BvI-C7b7m9alLjG4fOgKuKC0oFhnv6XfQ50BpMEEpzDA\r\nX-Yahoo-Profile: iranitovic\r\n\r\nGiven that you know the URL, add it as a seed or import it via JMX \nimportURI feature.\n\nFor more flexibility take a look at ExtractorImpliedURI and \nBeanShellProcessor.\n\nAlso, I suggest that you use a real user-agent URL or/and an email \naddress where webmaster can reach you if they need to.\n\nTake care,\ni.\n\n\n&gt; the url is dynamic created by ajax,so i could not crawler the urls \n&gt; \n&gt; my seeds.txt:http://auto.sina.com.cn/autocenter/\n&gt; \n&gt; and my order.xml\n&gt; \n&gt; &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;crawl-order \n&gt; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; \n&gt; xsi:noNamespaceSchemaLocation=&quot;heritrix_settings.xsd&quot;&gt;\n&gt;   &lt;meta&gt;\n&gt;     &lt;name&gt;default&lt;/name&gt;\n&gt;     &lt;description&gt;Default Profile&lt;/description&gt;\n&gt;     &lt;operator&gt;Admin&lt;/operator&gt;\n&gt;     &lt;organization&gt;&lt;/organization&gt;\n&gt;     &lt;audience&gt;&lt;/audience&gt;\n&gt;     &lt;date&gt;20071018011022&lt;/date&gt;\n&gt;   &lt;/meta&gt;\n&gt;   &lt;controller&gt;\n&gt;     &lt;string name=&quot;settings-directory&quot;&gt;settings&lt;/string&gt;\n&gt;     &lt;string name=&quot;disk-path&quot;&gt;&lt;/string&gt;\n&gt;     &lt;string name=&quot;logs-path&quot;&gt;logs&lt;/string&gt;\n&gt;     &lt;string name=&quot;checkpoints-path&quot;&gt;checkpoints&lt;/string&gt;\n&gt;     &lt;string name=&quot;state-path&quot;&gt;state&lt;/string&gt;\n&gt;     &lt;string name=&quot;scratch-path&quot;&gt;scratch&lt;/string&gt;\n&gt;     &lt;long name=&quot;max-bytes-download&quot;&gt;0&lt;/long&gt;\n&gt;     &lt;long name=&quot;max-document-download&quot;&gt;0&lt;/long&gt;\n&gt;     &lt;long name=&quot;max-time-sec&quot;&gt;0&lt;/long&gt;\n&gt;     &lt;integer name=&quot;max-toe-threads&quot;&gt;50&lt;/integer&gt;\n&gt;     &lt;integer name=&quot;recorder-out-buffer-bytes&quot;&gt;4096&lt;/integer&gt;\n&gt;     &lt;integer name=&quot;recorder-in-buffer-bytes&quot;&gt;65536&lt;/integer&gt;\n&gt;     &lt;integer name=&quot;bdb-cache-percent&quot;&gt;0&lt;/integer&gt;\n&gt;     &lt;newObject name=&quot;scope&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecidingScope&quot;&gt;\n&gt;       &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;string name=&quot;seedsfile&quot;&gt;seeds.txt&lt;/string&gt;\n&gt;       &lt;boolean name=&quot;reread-seeds-on-config&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;newObject name=&quot;decide-rules&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;         &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;newObject name=&quot;rejectByDefault&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.RejectDecideRule&quot;&gt;\n&gt;           &lt;/newObject&gt;\n&gt;           &lt;newObject name=&quot;acceptIfSurtPrefixed&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.SurtPrefixedDecideRule&quot;&gt;\n&gt;             &lt;string name=&quot;decision&quot;&gt;ACCEPT&lt;/string&gt;\n&gt;             &lt;string name=&quot;surts-source-file&quot;&gt;&lt;/string&gt;\n&gt;             &lt;boolean name=&quot;seeds-as-surt-prefixes&quot;&gt;true&lt;/boolean&gt;\n&gt;             &lt;string name=&quot;surts-dump-file&quot;&gt;&lt;/string&gt;\n&gt;             &lt;boolean name=&quot;also-check-via&quot;&gt;false&lt;/boolean&gt;\n&gt;             &lt;boolean name=&quot;rebuild-on-reconfig&quot;&gt;true&lt;/boolean&gt;\n&gt;           &lt;/newObject&gt;\n&gt;           &lt;newObject name=&quot;rejectIfTooManyHops&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.TooManyHopsDecideRule&quot;&gt;\n&gt;             &lt;integer name=&quot;max-hops&quot;&gt;20&lt;/integer&gt;\n&gt;           &lt;/newObject&gt;\n&gt;           &lt;newObject name=&quot;acceptIfTranscluded&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.TransclusionDecideRule&quot;&gt;\n&gt;             &lt;integer name=&quot;max-trans-hops&quot;&gt;3&lt;/integer&gt;\n&gt;             &lt;integer name=&quot;max-speculative-hops&quot;&gt;1&lt;/integer&gt;\n&gt;           &lt;/newObject&gt;\n&gt;           &lt;newObject name=&quot;rejectIfPathological&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.PathologicalPathDecideRule&quot;&gt;\n&gt;             &lt;integer name=&quot;max-repetitions&quot;&gt;2&lt;/integer&gt;\n&gt;           &lt;/newObject&gt;\n&gt;           &lt;newObject name=&quot;rejectIfTooManyPathSegs&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.TooManyPathSegmentsDecideRule&quot;&gt;\n&gt;             &lt;integer name=&quot;max-path-depth&quot;&gt;20&lt;/integer&gt;\n&gt;           &lt;/newObject&gt;\n&gt;           &lt;newObject name=&quot;MatchesList&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.MatchesListRegExpDecideRule&quot;&gt;\n&gt;             &lt;string name=&quot;decision&quot;&gt;ACCEPT&lt;/string&gt;\n&gt;             &lt;string name=&quot;list-logic&quot;&gt;OR&lt;/string&gt;\n&gt;             &lt;stringList name=&quot;regexp-list&quot;&gt;\n&gt;               \n&gt; &lt;string&gt;http://data&#92;.auto&#92;.sina&#92;.com&#92;.cn/car/subbrand&#92;.php&#92;?\n&gt; subid&#92;=&#92;w+&lt;/string&gt;\n&gt;               &lt;string&gt;http://data&#92;.auto&#92;.sina&#92;.com&#92;.cn/car/car&#92;.php&#92;?\n&gt; carid&#92;=&#92;w+&lt;/string&gt;\n&gt;               &lt;string&gt;http://data&#92;.auto&#92;.sina&#92;.com&#92;.cn/car/car&#92;.php&#92;?\n&gt; carid&#92;=&#92;w+&#92;&amp;tmp&#92;=canshu&lt;/string&gt;\n&gt;             &lt;/stringList&gt;\n&gt;           &lt;/newObject&gt;\n&gt;           &lt;newObject name=&quot;acceptIfPrerequisite&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.PrerequisiteAcceptDecideRule&quot;&gt;\n&gt;           &lt;/newObject&gt;\n&gt;         &lt;/map&gt;\n&gt;       &lt;/newObject&gt;\n&gt;     &lt;/newObject&gt;\n&gt;     &lt;map name=&quot;http-headers&quot;&gt;\n&gt;       &lt;string name=&quot;user-agent&quot;&gt;Mozilla/5.0 (compatible; \n&gt; heritrix/1.12.1 +http://sktest.com)&lt;/string&gt;\n&gt;       &lt;string name=&quot;from&quot;&gt;test@...&lt;/string&gt;\n&gt;     &lt;/map&gt;\n&gt;     &lt;newObject name=&quot;robots-honoring-policy&quot; \n&gt; class=&quot;org.archive.crawler.datamodel.RobotsHonoringPolicy&quot;&gt;\n&gt;       &lt;string name=&quot;type&quot;&gt;classic&lt;/string&gt;\n&gt;       &lt;boolean name=&quot;masquerade&quot;&gt;false&lt;/boolean&gt;\n&gt;       &lt;text name=&quot;custom-robots&quot;&gt;&lt;/text&gt;\n&gt;       &lt;stringList name=&quot;user-agents&quot;&gt;\n&gt;       &lt;/stringList&gt;\n&gt;     &lt;/newObject&gt;\n&gt;     &lt;newObject name=&quot;frontier&quot; \n&gt; class=&quot;org.archive.crawler.frontier.BdbFrontier&quot;&gt;\n&gt;       &lt;float name=&quot;delay-factor&quot;&gt;4.0&lt;/float&gt;\n&gt;       &lt;integer name=&quot;max-delay-ms&quot;&gt;20000&lt;/integer&gt;\n&gt;       &lt;integer name=&quot;min-delay-ms&quot;&gt;2000&lt;/integer&gt;\n&gt;       &lt;integer name=&quot;max-retries&quot;&gt;30&lt;/integer&gt;\n&gt;       &lt;long name=&quot;retry-delay-seconds&quot;&gt;900&lt;/long&gt;\n&gt;       &lt;integer name=&quot;preference-embed-hops&quot;&gt;1&lt;/integer&gt;\n&gt;       &lt;integer name=&quot;total-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt;       &lt;integer name=&quot;max-per-host-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt;       &lt;string name=&quot;queue-assignment-\n&gt; policy&quot;&gt;org.archive.crawler.frontier.NicknameQueueAssignmentPolicy&lt;/st\n&gt; ring&gt;\n&gt;       &lt;string name=&quot;force-queue-assignment&quot;&gt;&lt;/string&gt;\n&gt;       &lt;boolean name=&quot;pause-at-start&quot;&gt;false&lt;/boolean&gt;\n&gt;       &lt;boolean name=&quot;pause-at-finish&quot;&gt;false&lt;/boolean&gt;\n&gt;       &lt;boolean name=&quot;source-tag-seeds&quot;&gt;false&lt;/boolean&gt;\n&gt;       &lt;boolean name=&quot;recovery-log-enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;boolean name=&quot;hold-queues&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;integer name=&quot;balance-replenish-amount&quot;&gt;3000&lt;/integer&gt;\n&gt;       &lt;integer name=&quot;error-penalty-amount&quot;&gt;100&lt;/integer&gt;\n&gt;       &lt;long name=&quot;queue-total-budget&quot;&gt;-1&lt;/long&gt;\n&gt;       &lt;string name=&quot;cost-\n&gt; policy&quot;&gt;org.archive.crawler.frontier.ZeroCostAssignmentPolicy&lt;/string&gt;\n&gt;       &lt;long name=&quot;snooze-deactivate-ms&quot;&gt;300000&lt;/long&gt;\n&gt;       &lt;integer name=&quot;target-ready-backlog&quot;&gt;50&lt;/integer&gt;\n&gt;       &lt;string name=&quot;uri-included-\n&gt; structure&quot;&gt;org.archive.crawler.util.BdbUriUniqFilter&lt;/string&gt;\n&gt;     &lt;/newObject&gt;\n&gt;     &lt;map name=&quot;uri-canonicalization-rules&quot;&gt;\n&gt;       &lt;newObject name=&quot;Lowercase&quot; \n&gt; class=&quot;org.archive.crawler.url.canonicalize.LowercaseRule&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;Userinfo&quot; \n&gt; class=&quot;org.archive.crawler.url.canonicalize.StripUserinfoRule&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;WWW[0-9]*&quot; \n&gt; class=&quot;org.archive.crawler.url.canonicalize.StripWWWNRule&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;SessionIDs&quot; \n&gt; class=&quot;org.archive.crawler.url.canonicalize.StripSessionIDs&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;SessionCFIDs&quot; \n&gt; class=&quot;org.archive.crawler.url.canonicalize.StripSessionCFIDs&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;QueryStrPrefix&quot; \n&gt; class=&quot;org.archive.crawler.url.canonicalize.FixupQueryStr&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;/newObject&gt;\n&gt;     &lt;/map&gt;\n&gt;     &lt;map name=&quot;pre-fetch-processors&quot;&gt;\n&gt;       &lt;newObject name=&quot;Preselector&quot; \n&gt; class=&quot;org.archive.crawler.prefetch.Preselector&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;Preselector#decide-rules&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;         &lt;boolean name=&quot;override-logger&quot;&gt;false&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;recheck-scope&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;block-all&quot;&gt;false&lt;/boolean&gt;\n&gt;         &lt;string name=&quot;block-by-regexp&quot;&gt;&lt;/string&gt;\n&gt;         &lt;string name=&quot;allow-by-regexp&quot;&gt;&lt;/string&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;Preprocessor&quot; \n&gt; class=&quot;org.archive.crawler.prefetch.PreconditionEnforcer&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;Preprocessor#decide-rules&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;         &lt;integer name=&quot;ip-validity-duration-seconds&quot;&gt;21600&lt;/integer&gt;\n&gt;         &lt;integer name=&quot;robot-validity-duration-\n&gt; seconds&quot;&gt;86400&lt;/integer&gt;\n&gt;         &lt;boolean name=&quot;calculate-robots-only&quot;&gt;false&lt;/boolean&gt;\n&gt;       &lt;/newObject&gt;\n&gt;     &lt;/map&gt;\n&gt;     &lt;map name=&quot;fetch-processors&quot;&gt;\n&gt;       &lt;newObject name=&quot;DNS&quot; \n&gt; class=&quot;org.archive.crawler.fetcher.FetchDNS&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;DNS#decide-rules&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;         &lt;boolean name=&quot;accept-non-dns-resolves&quot;&gt;false&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;digest-content&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;string name=&quot;digest-algorithm&quot;&gt;sha1&lt;/string&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;HTTP&quot; \n&gt; class=&quot;org.archive.crawler.fetcher.FetchHTTP&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;HTTP#decide-rules&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;         &lt;newObject name=&quot;midfetch-decide-rules&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;         &lt;integer name=&quot;timeout-seconds&quot;&gt;1200&lt;/integer&gt;\n&gt;         &lt;integer name=&quot;sotimeout-ms&quot;&gt;20000&lt;/integer&gt;\n&gt;         &lt;integer name=&quot;fetch-bandwidth&quot;&gt;0&lt;/integer&gt;\n&gt;         &lt;long name=&quot;max-length-bytes&quot;&gt;0&lt;/long&gt;\n&gt;         &lt;boolean name=&quot;ignore-cookies&quot;&gt;false&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;use-bdb-for-cookies&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;string name=&quot;load-cookies-from-file&quot;&gt;&lt;/string&gt;\n&gt;         &lt;string name=&quot;save-cookies-to-file&quot;&gt;&lt;/string&gt;\n&gt;         &lt;string name=&quot;trust-level&quot;&gt;open&lt;/string&gt;\n&gt;         &lt;stringList name=&quot;accept-headers&quot;&gt;\n&gt;         &lt;/stringList&gt;\n&gt;         &lt;string name=&quot;http-proxy-host&quot;&gt;&lt;/string&gt;\n&gt;         &lt;string name=&quot;http-proxy-port&quot;&gt;&lt;/string&gt;\n&gt;         &lt;string name=&quot;default-encoding&quot;&gt;utf-8&lt;/string&gt;\n&gt;         &lt;boolean name=&quot;digest-content&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;string name=&quot;digest-algorithm&quot;&gt;sha1&lt;/string&gt;\n&gt;         &lt;boolean name=&quot;send-if-modified-since&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;send-if-none-match&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;send-connection-close&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;send-referer&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;send-range&quot;&gt;false&lt;/boolean&gt;\n&gt;         &lt;string name=&quot;bind-address&quot;&gt;&lt;/string&gt;\n&gt;       &lt;/newObject&gt;\n&gt;     &lt;/map&gt;\n&gt;     &lt;map name=&quot;extract-processors&quot;&gt;\n&gt;       &lt;newObject name=&quot;ExtractorHTTP&quot; \n&gt; class=&quot;org.archive.crawler.extractor.ExtractorHTTP&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;ExtractorHTTP#decide-rules&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;ExtractorHTML&quot; \n&gt; class=&quot;org.archive.crawler.extractor.ExtractorHTML&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;ExtractorHTML#decide-rules&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;         &lt;boolean name=&quot;extract-javascript&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;treat-frames-as-embed-links&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;ignore-form-action-urls&quot;&gt;false&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;overly-eager-link-detection&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;ignore-unexpected-html&quot;&gt;true&lt;/boolean&gt;\n&gt;       &lt;/newObject&gt;\n&gt;     &lt;/map&gt;\n&gt;     &lt;map name=&quot;write-processors&quot;&gt;\n&gt;       &lt;newObject name=&quot;MirrorWriter&quot; \n&gt; class=&quot;org.archive.crawler.writer.MirrorWriterProcessor&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;MirrorWriter#decide-rules&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;         &lt;boolean name=&quot;case-sensitive&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;stringList name=&quot;character-map&quot;&gt;\n&gt;         &lt;/stringList&gt;\n&gt;         &lt;stringList name=&quot;content-type-map&quot;&gt;\n&gt;         &lt;/stringList&gt;\n&gt;         &lt;string name=&quot;directory-file&quot;&gt;index.html&lt;/string&gt;\n&gt;         &lt;string name=&quot;dot-begin&quot;&gt;%2E&lt;/string&gt;\n&gt;         &lt;string name=&quot;dot-end&quot;&gt;.&lt;/string&gt;\n&gt;         &lt;stringList name=&quot;host-map&quot;&gt;\n&gt;         &lt;/stringList&gt;\n&gt;         &lt;boolean name=&quot;host-directory&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;string name=&quot;path&quot;&gt;mirror&lt;/string&gt;\n&gt;         &lt;integer name=&quot;max-path-length&quot;&gt;1023&lt;/integer&gt;\n&gt;         &lt;integer name=&quot;max-segment-length&quot;&gt;255&lt;/integer&gt;\n&gt;         &lt;boolean name=&quot;port-directory&quot;&gt;false&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;suffix-at-end&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;string name=&quot;too-long-directory&quot;&gt;LONG&lt;/string&gt;\n&gt;         &lt;stringList name=&quot;underscore-set&quot;&gt;\n&gt;         &lt;/stringList&gt;\n&gt;       &lt;/newObject&gt;\n&gt;     &lt;/map&gt;\n&gt;     &lt;map name=&quot;post-processors&quot;&gt;\n&gt;       &lt;newObject name=&quot;Updater&quot; \n&gt; class=&quot;org.archive.crawler.postprocessor.CrawlStateUpdater&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;Updater#decide-rules&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;LinksScoper&quot; \n&gt; class=&quot;org.archive.crawler.postprocessor.LinksScoper&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;LinksScoper#decide-rules&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;         &lt;boolean name=&quot;override-logger&quot;&gt;false&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;seed-redirects-new-seed&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;integer name=&quot;preference-depth-hops&quot;&gt;-1&lt;/integer&gt;\n&gt;         &lt;newObject name=&quot;scope-rejected-url-rules&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;       &lt;/newObject&gt;\n&gt;       &lt;newObject name=&quot;Scheduler&quot; \n&gt; class=&quot;org.archive.crawler.postprocessor.FrontierScheduler&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;newObject name=&quot;Scheduler#decide-rules&quot; \n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;           &lt;map name=&quot;rules&quot;&gt;\n&gt;           &lt;/map&gt;\n&gt;         &lt;/newObject&gt;\n&gt;       &lt;/newObject&gt;\n&gt;     &lt;/map&gt;\n&gt;     &lt;map name=&quot;loggers&quot;&gt;\n&gt;       &lt;newObject name=&quot;crawl-statistics&quot; \n&gt; class=&quot;org.archive.crawler.admin.StatisticsTracker&quot;&gt;\n&gt;         &lt;integer name=&quot;interval-seconds&quot;&gt;20&lt;/integer&gt;\n&gt;       &lt;/newObject&gt;\n&gt;     &lt;/map&gt;\n&gt;     &lt;string name=&quot;recover-path&quot;&gt;&lt;/string&gt;\n&gt;     &lt;boolean name=&quot;checkpoint-copy-bdbje-logs&quot;&gt;true&lt;/boolean&gt;\n&gt;     &lt;boolean name=&quot;recover-retain-failures&quot;&gt;false&lt;/boolean&gt;\n&gt;     &lt;newObject name=&quot;credential-store&quot; \n&gt; class=&quot;org.archive.crawler.datamodel.CredentialStore&quot;&gt;\n&gt;       &lt;map name=&quot;credentials&quot;&gt;\n&gt;       &lt;/map&gt;\n&gt;     &lt;/newObject&gt;\n&gt;   &lt;/controller&gt;\n&gt; &lt;/crawl-order&gt;\n&gt; \n&gt; \n&gt; \n&gt; url:http://data&#92;.auto&#92;.sina&#92;.com&#92;.cn/car/car&#92;.php&#92;?carid&#92;=&#92;w+ \n&gt; \n&gt; it is created by ajax,i could not see it in the parent page,so my \n&gt; crawel result is 510 parent page,the ajax dynamic url is not in the \n&gt; mirror\n&gt; \n&gt; could anyone help me with the problem?\n&gt; \n&gt; \n&gt; \n&gt;  \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n\n\n"}}