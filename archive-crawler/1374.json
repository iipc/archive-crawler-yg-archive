{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"stackarchiveorg","from":"&quot;stackarchiveorg&quot; &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"0q2dZtkpAqK8Y-PoMd8_bmuBLyK8yN2V7TaDp0UEyHwMuqxx9LROHr7ym7JzBeLD-cEb4pt_V8Z1tfEpqwdk9USM-KA32yyN7Oo6Xw","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: Size of URI","postDate":"1106099602","msgId":1374,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGNza2VpaSs5cjVuQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDIwMDUwMTE4MjEzOTMyLjU5ODAyLnFtYWlsQHdlYjQyMjAzLm1haWwueWFob28uY29tPg=="},"prevInTopic":1370,"nextInTopic":1423,"prevInTime":1373,"nextInTime":1375,"topicId":1367,"numMessagesInTopic":6,"msgSnippet":"... Seems odd.  The size should be available for http content as soon as FetchHTTP is done. Here is code toward end of the FetchHTTP#innerProcess: long","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 19337 invoked from network); 19 Jan 2005 01:53:26 -0000\r\nReceived: from unknown (66.218.66.218)\n  by m23.grp.scd.yahoo.com with QMQP; 19 Jan 2005 01:53:26 -0000\r\nReceived: from unknown (HELO n14a.bulk.scd.yahoo.com) (66.94.237.28)\n  by mta3.grp.scd.yahoo.com with SMTP; 19 Jan 2005 01:53:26 -0000\r\nReceived: from [66.218.69.5] by n14.bulk.scd.yahoo.com with NNFMP; 19 Jan 2005 01:53:25 -0000\r\nReceived: from [66.218.66.91] by mailer5.bulk.scd.yahoo.com with NNFMP; 19 Jan 2005 01:53:25 -0000\r\nDate: Wed, 19 Jan 2005 01:53:22 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;cskeii+9r5n@...&gt;\r\nIn-Reply-To: &lt;20050118213932.59802.qmail@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Length: 2052\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Remote-IP: 66.94.237.28\r\nFrom: &quot;stackarchiveorg&quot; &lt;stack@...&gt;\r\nSubject: Re: Size of URI\r\nX-Yahoo-Group-Post: member; u=168599281\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\n\n--- In archive-crawler@yahoogroups.com, Christoph Spielmann\n&lt;spielc@y...&gt; wrote:\n&gt; Ok i found a solution now myself i just hooked up my\n&gt; processor a bit later... by doing that i was able to\n&gt; get the size of the page with uri.getContentSize() correctly!\n&gt; \n\nSeems odd.  The size should be available for http content as soon as\nFetchHTTP is done.\n\nHere is code toward end of the FetchHTTP#innerProcess:\n\n        long contentSize = rec.getRecordedInput().getSize();\n        curi.setContentSize(contentSize);\n\nI wonder what URL is choking when you do the getContentSize on it? \nPerhaps it has a scheme that is other than HTTP?\n\nCrawlURI also has #getContentLength which is meant to return the\nlength of the html content body.  Its javadoc says:\n\n     * @return For completed HTTP transactions, the length of the\ncontent-body.\n\nIts doing a total recorded length minus length of headers.\n\nWhen I look in the formatting of the crawl.log length column, I see it\ndoes this:\n\n        if (curi.isHttpTransaction()) {\n            if(curi.getContentLength() &gt;= 0) {\n                length = Long.toString(curi.getContentLength());\n            } else if (curi.getContentSize() &gt; 0) {\n                length = Long.toString(curi.getContentSize());\n            }\n            ...\n            \n        } else {\n            if (curi.getContentSize() &gt; 0) {\n                length = Long.toString(curi.getContentSize());\n            } \n            ...\n        }\n\nSo contentLength only is assumed valid only if its a http transaction\nand we&#39;re doing a check for a negative content size if not an http\ntransaction.  Were you checking for negative size?  Could that have\nbeen cause of the crawl crash?  Was there something in\nheritrix_out.log around crawl crash time?\n\n(I understand if you&#39;d like to move on -- but I&#39;m kinda curious as to\nwhy a simple getContentSize wasn&#39;t working for you).\n\nThanks,\nSt.Ack\n\n\n\n\n\n\n&gt; \n&gt; \t\t\n&gt; __________________________________ \n&gt; Do you Yahoo!? \n&gt; Read only the mail you want - Yahoo! Mail SpamGuard. \n&gt; http://promotions.yahoo.com/new_mail\n\n\n\n\n"}}