{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"stack","from":"stack &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"q8hFj15AKgFF77TaUHixiBcKQuY7lVQDT_c6X-H_qpvvOgfE21UQde4Xrw1nKtdfzQgbtIFOfZ6NBdqbNuesQg","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] How to crawl just country X (or language X specific","postDate":"1106699389","msgId":1429,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQxRjZFNDdELjcwMTA3MDlAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGN0M2xvOStoN2c1QGVHcm91cHMuY29tPg==","referencesHeader":"PGN0M2xvOStoN2c1QGVHcm91cHMuY29tPg=="},"prevInTopic":1420,"nextInTopic":0,"prevInTime":1428,"nextInTime":1430,"topicId":1415,"numMessagesInTopic":3,"msgSnippet":"... You ll need to add two facilities not present in Heritrix.  The first is language recognition.  The second is a lookup service that can report on the","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 92619 invoked from network); 26 Jan 2005 00:37:18 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m16.grp.scd.yahoo.com with QMQP; 26 Jan 2005 00:37:18 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (207.241.224.172)\n  by mta6.grp.scd.yahoo.com with SMTP; 26 Jan 2005 00:37:13 -0000\r\nReceived: (qmail 16368 invoked by uid 100); 26 Jan 2005 00:21:42 -0000\r\nReceived: from debord.archive.org (HELO ?207.241.238.140?) (stack@...@207.241.238.140)\n  by mail-dev.archive.org with SMTP; 26 Jan 2005 00:21:42 -0000\r\nMessage-ID: &lt;41F6E47D.7010709@...&gt;\r\nDate: Tue, 25 Jan 2005 16:29:49 -0800\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.7.3) Gecko/20041007 Debian/1.7.3-5\r\nX-Accept-Language: en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;ct3lo9+h7g5@...&gt;\r\nIn-Reply-To: &lt;ct3lo9+h7g5@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=0.7 required=6.5 tests=AWL autolearn=no version=2.63\r\nX-eGroups-Remote-IP: 207.241.224.172\r\nFrom: stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] How to crawl just country X (or language X\n specific\r\nX-Yahoo-Group-Post: member; u=168599281\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\nJussi Kallioniemi wrote:\n\n&gt;\n&gt; Hello,\n&gt;\n&gt; We have a need to crawl and index only those sites (or documents)\n&gt; where:\n&gt; a) or the content is published in language X (spoken in country X)\n&gt; b) the content is published in (any) other language, but the\n&gt; publisher/owner of the URL is from the country X.\n&gt;\n&gt; In other words: we want to collect data specific to a country and the\n&gt; language spoken in that country.\n&gt;\n&gt; - some ideas on how to achieve this:\n&gt; 1) Collect and use a list of known addresses as the initial seed (that\n&gt; meet the country/language criteria)\n&gt; 2) Crawl the list defined in 1) and extract links.\n&gt; 3) For each unique link extracted in 2) - check whether\n&gt; the site or URL meets the country/language criteria, by:\n&gt; - language detection\n&gt; - whois database check (language is different, but publisher belongs\n&gt; to wanted country)\n&gt; - comparison to list of known urls/organization\n&gt; - what else?\n&gt;\n&gt; Possibly repeat 1,2,3) to gather (the as much as possible) complete\n&gt; URL space that belongs to the country/language area.\n&gt;\n&gt; Naturally, digging for the URL space should be done in a way that\n&gt; wastes as little bandwidth as possible (ie. the crawler should stop\n&gt; digging a path as soon as it finds a page not matching the criteria).\n&gt;\n&gt; How, in practise - should such functionality be\n&gt; embedded to heritirix.  Has someone done this before? Where,\n&gt; architecture-wise would such mechanism best fit? Can it even be\n&gt; done or would there be some more suitable tool for doing this.\n\nYou&#39;ll need to add two facilities not present in Heritrix.  The first is \nlanguage recognition.  The second is a lookup service that can report on \nthe physical location of an URL.  You&#39;ll also need to develop a custom \nscope module that tests each URL for language and origin in accordance \nwith the rules cited in your mail above.\n\nOn language recognition, you could try relying upon volunteered language \nin HTML META tags or in pdf metadata but this will probably prove \nfrustrating because most content is absent these tags and even where \npresent, they are likely untrustworthy.  So, you&#39;ll need to plug in a \nlanguage recognizer.  A couple of open-source language guessers can be \nfound listed in this Heritrix \nRFE:http://sourceforge.net/tracker/?group_id=73833&atid=539102&func=detail&aid=899909.  \nThere are also commercial language recognizers that in general do a \nbetter job guessing.\n\nThe Heritrix architecture is most amenable to taking plugins.  You might \nplugin a language-recognition processor after fetching that reads the \njust-downloaded stream till it had sufficent text to make a call on \ncontent language (Sometimes the downloaded content will be insufficent \nfor the language-guesser to make determination).   You&#39;d then keep \naround the discovered language as input for your custom scope.\n\nRegards where an URL is from, you could look for a country domain or \npass the URL or URL IP via a service to ask the physical location.  Here \nis one that seems to allow you to do lookups to a country-level for \nfree: http://www.maxmind.com/app/geoip_country.  I don&#39;t know much about \nsuch services (Maybe others on the list know more on these services).  \nYou will probably want to cache answers returned to save waiting on the \nremote service and/or to save yourself money if the service costs.  The \ngeographic lookup would probably be done inside in your custom scope \nwhen trying to decide whether or not the URL should be crawled.\n\nHope this helps,\nSt.Ack\n\n\n\n\n\n\n&gt;\n&gt; -- Jussi\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------------------------------------------\n&gt; *Yahoo! Groups Links*\n&gt;\n&gt;     * To visit your group on the web, go to:\n&gt;       http://groups.yahoo.com/group/archive-crawler/\n&gt;        \n&gt;     * To unsubscribe from this group, send an email to:\n&gt;       archive-crawler-unsubscribe@yahoogroups.com\n&gt;       &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;        \n&gt;     * Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;.\n&gt;\n&gt;\n\n\n"}}