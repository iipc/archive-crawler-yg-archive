{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":352493089,"authorName":"haidong.pan","from":"&quot;haidong.pan&quot; &lt;haidong.pan@...&gt;","profile":"haidong.pan","replyTo":"LIST","senderId":"gvpTMa2BBdEPqbiLr4y8aXz24JqOH89GC_muYUdw7GaN4mVh7l9tYlbA1MO-ilU4c4ia4rOr_pGPOlEnoRYHClrxVJpTa7HW_3rcPA","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Newbie, Only download html pages in seeds","postDate":"1216036858","msgId":5358,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGc1ZmY1cStrOGtyQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGc1YmRhbis1cWxvQGVHcm91cHMuY29tPg=="},"prevInTopic":5357,"nextInTopic":0,"prevInTime":5357,"nextInTime":5359,"topicId":5353,"numMessagesInTopic":6,"msgSnippet":"Thank you. It s works now. There are many Scopes, It make a big trouble to me. :) ... org.archive.modules.deciderules.DecideRule ... ","rawEmail":"Return-Path: &lt;haidong.pan@...&gt;\r\nX-Sender: haidong.pan@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 91424 invoked from network); 14 Jul 2008 12:00:59 -0000\r\nX-Received: from unknown (66.218.67.95)\n  by m42.grp.scd.yahoo.com with QMQP; 14 Jul 2008 12:00:59 -0000\r\nX-Received: from unknown (HELO n34a.bullet.mail.sp1.yahoo.com) (66.163.168.128)\n  by mta16.grp.scd.yahoo.com with SMTP; 14 Jul 2008 12:00:59 -0000\r\nX-Received: from [216.252.122.217] by n34.bullet.mail.sp1.yahoo.com with NNFMP; 14 Jul 2008 12:00:59 -0000\r\nX-Received: from [66.218.69.4] by t2.bullet.sp1.yahoo.com with NNFMP; 14 Jul 2008 12:00:59 -0000\r\nX-Received: from [66.218.66.77] by t4.bullet.scd.yahoo.com with NNFMP; 14 Jul 2008 12:00:59 -0000\r\nDate: Mon, 14 Jul 2008 12:00:58 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;g5ff5q+k8kr@...&gt;\r\nIn-Reply-To: &lt;g5bdan+5qlo@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;haidong.pan&quot; &lt;haidong.pan@...&gt;\r\nSubject: Re: Newbie, Only download html pages in seeds\r\nX-Yahoo-Group-Post: member; u=352493089; y=2FQ31huQsfagH6kpoIMEzJHaXsr3l2Lh-um97ZdwxQAZol0AQTo\r\nX-Yahoo-Profile: haidong.pan\r\n\r\nThank you.\nIt&#39;s works now.\n\nThere are many Scopes, It make a big trouble to=\r\n me. :)\n\n\n--- In archive-crawler@yahoogroups.com, &quot;haidong.pan&quot;\n&lt;haidong.pa=\r\nn@...&gt; wrote:\n&gt;\n&gt; Hi\n&gt; \n&gt; Thank you very much for your help.\n&gt; Yes, I only =\r\nwant fetch seed URIS, no any other resources.\n&gt; And i follow second advice,=\r\n only 1 URI in sheet: http://localhost\n&gt; The result is:\n&gt; 2008-07-12T22:58:=\r\n37.632Z   -50          - http://localhost/ - -\n&gt; unknown #005 - - - 30t\n&gt; \n=\r\n&gt; This is my full config:\n&gt; global \troot \tmap \tjava.lang.Object\n&gt; global \tr=\r\noot:metadata \tprimary \n&gt; org.archive.modules.writer.DefaultMetadataProvider=\r\n\n&gt; global \troot:metadata:description \tstring \tBasic seeds sites crawl.\n&gt; gl=\r\nobal \troot:metadata:operator-contact-url \tstring \thttp://www.aol.com\n&gt; glob=\r\nal \troot:metadata:robots-honoring-policy \tprimary \n&gt; org.archive.modules.ne=\r\nt.RobotsHonoringPolicy\n&gt; global \troot:metadata:robots-honoring-policy:user-=\r\nagents \tlist \n&gt; java.lang.String\n&gt; global \troot:loggerModule \tprimary \n&gt; or=\r\ng.archive.crawler.framework.CrawlerLoggerModule\n&gt; global \troot:seeds \tprima=\r\nry \torg.archive.modules.seeds.SeedModuleImpl\n&gt; global \troot:scope \tobject \n=\r\n&gt; org.archive.modules.deciderules.DecideRuleSequence\n&gt; global \troot:scope:r=\r\nules \tlist \norg.archive.modules.deciderules.DecideRule\n&gt; global \troot:scope=\r\n:rules:0 \tobject \n&gt; org.archive.modules.deciderules.RejectDecideRule\n&gt; glob=\r\nal \troot:scope:rules:1 \tobject \n&gt; org.archive.modules.deciderules.surt.Surt=\r\nPrefixedDecideRule\n&gt; global \troot:scope:rules:2 \tobject \n&gt; org.archive.modu=\r\nles.deciderules.TooManyHopsDecideRule\n&gt; global \troot:scope:rules:3 \tobject =\r\n\n&gt; org.archive.modules.deciderules.TransclusionDecideRule\n&gt; global \troot:sc=\r\nope:rules:4 \tobject \n&gt; org.archive.modules.deciderules.PathologicalPathDeci=\r\ndeRule\n&gt; global \troot:scope:rules:5 \tobject \n&gt; org.archive.modules.decideru=\r\nles.TooManyPathSegmentsDecideRule\n&gt; global \troot:scope:rules:6 \tobject \n&gt; o=\r\nrg.archive.modules.deciderules.PrerequisiteAcceptDecideRule\n&gt; global \troot:=\r\nuriUniqFilter \tprimary \n&gt; org.archive.crawler.util.BdbUriUniqFilter\n&gt; globa=\r\nl \troot:queue-assignment-policy \tprimary \n&gt; org.archive.crawler.frontier.Su=\r\nrtAuthorityQueueAssignmentPolicy\n&gt; global \troot:server-cache \tprimary \norg.=\r\narchive.modules.net.BdbServerCache\n&gt; global \troot:credential-store \tprimary=\r\n \n&gt; org.archive.modules.credential.CredentialStore\n&gt; global \troot:controlle=\r\nr \tprimary \n&gt; org.archive.crawler.framework.CrawlControllerImpl\n&gt; global \tr=\r\noot:controller:frontier \tprimary \n&gt; org.archive.crawler.frontier.BdbFrontie=\r\nr\n&gt; global \troot:controller:frontier:rules \tlist \n&gt; org.archive.modules.can=\r\nonicalize.CanonicalizationRule\n&gt; global \troot:controller:frontier:rules:0 \t=\r\nobject \n&gt; org.archive.modules.canonicalize.LowercaseRule\n&gt; global \troot:con=\r\ntroller:frontier:rules:1 \tobject \n&gt; org.archive.modules.canonicalize.StripU=\r\nserinfoRule\n&gt; global \troot:controller:frontier:rules:2 \tobject \n&gt; org.archi=\r\nve.modules.canonicalize.StripWWWNRule\n&gt; global \troot:controller:frontier:ru=\r\nles:3 \tobject \n&gt; org.archive.modules.canonicalize.StripSessionIDs\n&gt; global =\r\n\troot:controller:frontier:rules:4 \tobject \n&gt; org.archive.modules.canonicali=\r\nze.StripSessionCFIDs\n&gt; global \troot:controller:frontier:rules:5 \tobject \n&gt; =\r\norg.archive.modules.canonicalize.FixupQueryStr\n&gt; global \troot:controller:fr=\r\nontier:scope \treference \troot:scope\n&gt; global \troot:controller:processors \tm=\r\nap \torg.archive.modules.Processor\n&gt; global \troot:controller:processors:Pres=\r\nelector \tobject \n&gt; org.archive.crawler.prefetch.Preselector\n&gt; global \troot:=\r\ncontroller:processors:Preselector:scope \treference \n&gt; root:scope\n&gt; global \t=\r\nroot:controller:processors:Preprocessor \tobject \n&gt; org.archive.crawler.pref=\r\netch.PreconditionEnforcer\n&gt; global \troot:controller:processors:DNS \tobject =\r\n\n&gt; org.archive.modules.fetcher.FetchDNS\n&gt; global \troot:controller:processor=\r\ns:HTTP \tobject \n&gt; org.archive.modules.fetcher.FetchHTTP\n&gt; global \troot:cont=\r\nroller:processors:HTTP:accept-headers \tlist \n&gt; java.lang.String\n&gt; global \tr=\r\noot:controller:processors:HTTP:midfetch-rules \tobject \n&gt; org.archive.module=\r\ns.deciderules.DecideRuleSequence\n&gt; global \troot:controller:processors:Extra=\r\nctorHTTP \tobject \n&gt; org.archive.modules.extractor.ExtractorHTTP\n&gt; global \tr=\r\noot:controller:processors:ExtractorHTML \tobject \n&gt; org.archive.modules.extr=\r\nactor.ExtractorHTML\n&gt; global \troot:controller:processors:ExtractorCSS \tobje=\r\nct \n&gt; org.archive.modules.extractor.ExtractorCSS\n&gt; global \troot:controller:=\r\nprocessors:ExtractorJS \tobject \n&gt; org.archive.modules.extractor.ExtractorJS=\r\n\n&gt; global \troot:controller:processors:ExtractorSWF \tobject \n&gt; org.archive.m=\r\nodules.extractor.ExtractorSWF\n&gt; global \troot:controller:processors:Archiver=\r\n \tobject \n&gt; org.archive.modules.writer.ARCWriterProcessor\n&gt; global \troot:co=\r\nntroller:processors:Updater \tobject \n&gt; org.archive.crawler.postprocessor.Cr=\r\nawlStateUpdater\n&gt; global \troot:controller:processors:LinksScoper \tobject \n&gt;=\r\n org.archive.crawler.postprocessor.LinksScoper\n&gt; global \n&gt; root:controller:=\r\nprocessors:LinksScoper:log-rejects-rules:rules \tlist \n&gt; org.archive.modules=\r\n.deciderules.DecideRule\n&gt; global \n&gt; root:controller:processors:LinksScoper:=\r\nlog-rejects-rules:rules:0 \n&gt; object \torg.archive.modules.deciderules.Reject=\r\nDecideRule\n&gt; global \n&gt; root:controller:processors:LinksScoper:log-rejects-r=\r\nules:rules:1 \n&gt; object \torg.archive.modules.deciderules.TransclusionDecideR=\r\nule\n&gt; global \n&gt; root:controller:processors:LinksScoper:log-rejects-rules:ru=\r\nles:2 \n&gt; object \torg.archive.modules.deciderules.TooManyHopsDecideRule\n&gt; gl=\r\nobal \troot:controller:processors:LinksScoper:scope \treference \n&gt; root:scope=\r\n\n&gt; global \troot:controller:processors:Scheduler \tobject \n&gt; org.archive.craw=\r\nler.postprocessor.FrontierScheduler\n&gt; global \troot:controller:processors:Sc=\r\nheduler:decide-rules:rules \n&gt; list \torg.archive.modules.deciderules.DecideR=\r\nule\n&gt; global \troot:controller:processors:Scheduler:decide-rules:rules:0 \n&gt; =\r\nobject \torg.archive.modules.deciderules.RejectDecideRule\n&gt; global \troot:con=\r\ntroller:processors:Scheduler:decide-rules:rules:1 \n&gt; object \torg.archive.mo=\r\ndules.deciderules.TransclusionDecideRule\n&gt; global \n&gt; root:controller:proces=\r\nsors:Scheduler:decide-rules:rules:1:max-trans-hops\n&gt; \tint \t0\n&gt; global \troot=\r\n:controller:processors:Scheduler:decide-rules:rules:2 \n&gt; object \torg.archiv=\r\ne.modules.deciderules.TooManyHopsDecideRule\n&gt; global \n&gt;\nroot:controller:pro=\r\ncessors:Scheduler:decide-rules:rules:2:max-hops \tint \t0\n&gt; global \troot:cont=\r\nroller:statistics-tracker \tobject \n&gt; org.archive.crawler.framework.Statisti=\r\ncsTrackerImpl \n&gt; \n&gt; \n&gt; \n&gt; --- In archive-crawler@yahoogroups.com, Gordon Mo=\r\nhr &lt;gojomo@&gt; wrote:\n&gt; &gt;\n&gt; &gt; haidong.pan wrote:\n&gt; &gt; &gt; Hi\n&gt; &gt; &gt; \n&gt; &gt; &gt; I&#39;m tr=\r\nying to fetch html pages only defined in seeds using\n&gt; &gt; &gt; heritrix2.0. and=\r\n don&#39;t want other pages linked in html pages be\n&gt; download.\n&gt; &gt; \n&gt; &gt; If I u=\r\nnderstand correctly, you only want your seed URIs to be\nfetched, \n&gt; &gt; and n=\r\nothing else -- no in-page resources (like images, scripts, or\n&gt; CSS), \n&gt; &gt; =\r\nand no linked HTML or other documents. Is that correct?\n&gt; &gt; \n&gt; &gt; There are =\r\na couple ways to do this -- but the settings you&#39;ve changed \n&gt; &gt; aren&#39;t dir=\r\nectly relevant.\n&gt; &gt; \n&gt; &gt; &gt; This is my settings:\n&gt; &gt; &gt; global \n&gt; &gt; &gt; root:co=\r\nntroller:processors:LinksScoper:seed-redirects-new-seeds \n&gt; &gt; &gt; boolean \tfa=\r\nlse \n&gt; &gt; \n&gt; &gt; We call the set of rules for determining which discovered URI=\r\ns\n&gt; should be \n&gt; &gt; crawled the &#39;scope&#39; of the crawl. Some scopes are define=\r\nd in terms of \n&gt; &gt; the seed URI patterns. For example, if &#39;www.example.com&#39;=\r\n is a\nseed, all \n&gt; &gt; URIs with a host of &#39;www.example.com&#39; are ruled-in.\n&gt; =\r\n&gt; \n&gt; &gt; This &#39;seed-redirects-new-seeds&#39; setting makes the target URIs of \n&gt; =\r\n&gt; redirects (eg HTTP 301/302 responses) from seeds also be considered \n&gt; &gt; =\r\nseeds, for the purpose of scope rules. So if your seed\n&gt; &#39;www.example.com&#39; =\r\n\n&gt; &gt; redirects to &#39;www.other-site.com&#39;, &#39;www.other-site.com&#39; will be\ntreate=\r\nd \n&gt; &gt; just as if you had entered it as a seed. Depending on your scope\nrul=\r\nes, \n&gt; &gt; that might cause all &#39;www.other-site.com&#39; URIs to be ruled in-scop=\r\ne.\n&gt; &gt; \n&gt; &gt; So, this is only tangentially related to your goal.\n&gt; &gt; \n&gt; &gt; &gt; =\r\nglobal \troot:controller:processors:Scheduler:decide-rules:rules \n&gt; &gt; &gt; list=\r\n \torg.archive.modules.deciderules.DecideRule\n&gt; &gt; &gt; global \troot:controller:=\r\nprocessors:Scheduler:decide-rules:rules:0 \n&gt; &gt; &gt; object \torg.archive.module=\r\ns.deciderules.SeedAcceptDecideRule\n&gt; &gt; &gt; global \troot:controller:processors=\r\n:Scheduler:decide-rules:rules:1 \n&gt; &gt; &gt; object \torg.archive.modules.decideru=\r\nles.RejectDecideRule \n&gt; &gt; \n&gt; &gt; Here, you are setting extra decide-rules on =\r\nthe &#39;Scheduler&#39;\nprocessor. \n&gt; &gt; The rules that are set up per-processor onl=\r\ny affect whether that \n&gt; &gt; processor runs on certain URIs -- they are a mec=\r\nhanism for certain\n&gt; steps \n&gt; &gt; to be skipped for some URIs.\n&gt; &gt; \n&gt; &gt; Rules=\r\n are applied in order with the last rule to apply a decision \n&gt; &gt; &#39;winning&#39;=\r\n. (Later rules may PASS.)\n&gt; &gt; \n&gt; &gt; Your rules have no initial default decis=\r\nion in the first position\n&gt; (which \n&gt; &gt; is a good practice to have). So URI=\r\ns start out with a neutral PASS \n&gt; &gt; decision. Then your rule #0 takes any =\r\nURI that is a seed and sets its \n&gt; &gt; decision to ACCEPT. Then your rule #1 =\r\nsets every URIs decision to \n&gt; &gt; REJECT. So the net effect is every URI is =\r\ngiven a REJECT decision,\nand \n&gt; &gt; the Scheduler is *never* run.\n&gt; &gt; \n&gt; &gt; Th=\r\ne Scheduler processor takes discovered URIs and inserts them\ninto the \n&gt; &gt; =\r\nFrontier for later crawling, so this guarantees no URIs discovered \n&gt; &gt; dur=\r\ning the crawl will be crawled. However, even crawling your seeds \n&gt; &gt; requi=\r\nres some non-seed URIs to be scheduled -- the DNS and Robots.txt \n&gt; &gt; URIs =\r\nthat are prerequisites of your URIs.\n&gt; &gt; \n&gt; &gt; So I would expect your change=\r\ns here to prevent anything from being \n&gt; &gt; crawled at all.\n&gt; &gt; \n&gt; &gt; &gt; But i=\r\nt&#39;s not works.\n&gt; &gt; &gt; \n&gt; &gt; &gt; Can i have any help?\n&gt; &gt; \n&gt; &gt; Here are 2 differ=\r\nent ways you could achieve a crawl of only your\n&gt; seed URIs:\n&gt; &gt; \n&gt; &gt; (1) I=\r\nn the chain of processors, remove or disable all Extractor.\nThese \n&gt; &gt; proc=\r\nessors&#39; names all begin &quot;Extractor&quot;. If none are present or\n&gt; enabled, \n&gt; &gt;=\r\n no URIs will be found in fetched results -- not in their response \n&gt; &gt; hea=\r\nders (for redirects), HTML, or anywhere else.\n&gt; &gt; \n&gt; &gt; (2) Adjust the crawl=\r\n scope so that even though other URIs are \n&gt; &gt; discovered, they do not pass=\r\n scope-testing and are not scheduled.\n&gt; &gt; \n&gt; &gt; The most simple way to do th=\r\nis is to take the decide-rule\nconfiguration \n&gt; &gt; from our default profile a=\r\nnd, in the scope, change the \n&gt; &gt; TooManyHopsDecideRule &#39;max-hops&#39; setting =\r\nto 0 (meaning anything more \n&gt; &gt; than 1 normal hop from seeds will be REJEC=\r\nTed) and the \n&gt; &gt; TransclusionDecideRule &#39;max-trans-hops&#39; setting to 0 (mea=\r\nning no \n&gt; &gt; transcluded &#39;inline&#39; hops will be ACCEPTed).\n&gt; &gt; \n&gt; &gt; Another =\r\nway would be to create a custom scope that starts with a \n&gt; &gt; REJECT-all ru=\r\nle then only adds both the SeedAcceptDecideRule (so your \n&gt; &gt; seeds aren&#39;t =\r\nREJECTed) and PrerequisiteAcceptDecideRule (so that the \n&gt; &gt; prerequisite D=\r\nNS and robots URIs aren&#39;t REJECTed).\n&gt; &gt; \n&gt; &gt; Hope this helps clear things =\r\nup,\n&gt; &gt; \n&gt; &gt; - Gordon @ IA\n&gt; &gt;\n&gt;\n\n\n\n"}}