{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":132996324,"authorName":"joehung302","from":"&quot;joehung302&quot; &lt;joe.hung@...&gt;","profile":"joehung302","replyTo":"LIST","senderId":"urrJynIonQA89LobMoOUblR-wFFvgD2pVK_ykQmCPHyjpMogqLWG-jz7pg_DnvJZ3cuVxxJHNia15E0f0VfUznTcABfBZV0N8WGHov16","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: Large crawl experience (like, 500M links)","postDate":"1135103566","msgId":2454,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGRvOWlvZSt0c2tqQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDQzQTc2NjFELjQwNjA1MDdAYXJjaGl2ZS5vcmc+"},"prevInTopic":2450,"nextInTopic":2458,"prevInTime":2453,"nextInTime":2455,"topicId":2391,"numMessagesInTopic":12,"msgSnippet":"Thanks a lot for the insight. I ll change to use 32bit JVM immediately. I m using the BloomUriUniqFilter already. I ll do some reading on SurtPrefixScope and","rawEmail":"Return-Path: &lt;joe.hung@...&gt;\r\nX-Sender: joe.hung@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 90434 invoked from network); 20 Dec 2005 18:33:44 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m27.grp.scd.yahoo.com with QMQP; 20 Dec 2005 18:33:44 -0000\r\nReceived: from unknown (HELO n27.bullet.scd.yahoo.com) (66.94.237.56)\n  by mta4.grp.scd.yahoo.com with SMTP; 20 Dec 2005 18:33:44 -0000\r\nComment: DomainKeys? See http://antispam.yahoo.com/domainkeys\r\nReceived: from [66.218.69.4] by n27.bullet.scd.yahoo.com with NNFMP; 20 Dec 2005 18:32:47 -0000\r\nReceived: from [66.218.66.89] by mailer4.bullet.scd.yahoo.com with NNFMP; 20 Dec 2005 18:32:47 -0000\r\nDate: Tue, 20 Dec 2005 18:32:46 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;do9ioe+tskj@...&gt;\r\nIn-Reply-To: &lt;43A7661D.4060507@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: &quot;joehung302&quot; &lt;joe.hung@...&gt;\r\nSubject: Re: Large crawl experience (like, 500M links)\r\nX-Yahoo-Group-Post: member; u=132996324; y=4TR188DD6mMW-eVtffzoYYJIZ7o_t06l8Ybh9Bf3n7AijIEy-A\r\nX-Yahoo-Profile: joehung302\r\n\r\nThanks a lot for the insight.\n\nI&#39;ll change to use 32bit JVM immediately.\n\nI=\r\n&#39;m using the BloomUriUniqFilter already.\n\nI&#39;ll do some reading on SurtPrefi=\r\nxScope and see if I can do \nsomething to get rid of domain scope.\n\nWill kee=\r\np you guys posted (or, keep bugging you guys).\n\ncheers,\n-joe\n\n--- In archiv=\r\ne-crawler@yahoogroups.com, &quot;Gordon Mohr (archive.org)&quot; \n&lt;gojomo@a...&gt; wrote=\r\n:\n&gt;\n&gt; joehung302 wrote:\n&gt; &gt; I did a proof crawling using BroadScope and 22K=\r\n seeds. I got \nOOME \n&gt; &gt; within a day. I then checkpoint it, restart the cr=\r\nawler, start \n&gt; &gt; another crawl from the checkpoint, OOME within a day.\n&gt; &gt;=\r\n \n&gt; &gt; I then changed to use 5K seeds and BroadScope, OOME within a \nday. \n&gt;=\r\n &gt; Restart with the checkpoint and still OOME within a day.\n&gt; &gt; \n&gt; &gt; I then=\r\n run 5K seeds with DomainScope (kind of given up on \n&gt; &gt; broadscope). OOME =\r\nwithin a day.\n&gt; &gt; \n&gt; &gt; I have my JVM set to -Xmx1500m. BTW, I&#39;m using 64 bi=\r\nt JDK1.5.\n&gt; &gt; \n&gt; &gt; One thing that I observed is, broad scope runs much fast=\r\ner than \n&gt; &gt; domain scope under roughly the same condition. In both \nbroads=\r\ncope \n&gt; &gt; runs I was able to top 1000KB/s bandwidth limit with around 50% \n=\r\ncpu \n&gt; &gt; usage. In the domain scope run I can only get to 500KB/s \nthroughp=\r\nut \n&gt; &gt; with 100% cpu busy. \n&gt; &gt; \n&gt; &gt; I used to be able to run 1.0.4 for a =\r\nweek with &lt;1K seeds and get \n&gt; &gt; around 1M links per day. I thought the bdb=\r\n improvement should be \n&gt; &gt; able to take more seeds and run longer. I reall=\r\ny want the \ncrawler to \n&gt; &gt; run with a big seed list because we&#39;re going to=\r\n seed my big \ncrawl \n&gt; &gt; with links from ODP. \n&gt; &gt; \n&gt; &gt; Any suggestions tha=\r\nt I can try?\n&gt; \n&gt; We&#39;ve run into problems under 64bit JVMs, and they seem m=\r\nostly\n&gt; attributable to the fact that the JVM&#39;s object pointers are larger\n=\r\n&gt; and thus the same object structures will take up more RAM.\n&gt; \n&gt; This post=\r\n from a Sun engineer suggests a rule of thumb of a 40%\n&gt; larger heap to be =\r\ncomparable to a 32bit JVM heap:\n&gt; \n&gt; http://forum.java.sun.com/thread.jspa?=\r\nthreadID=3D671184\n&gt; (see reply #8)\n&gt; \n&gt; So your 1500m heap in a 64bit JVM m=\r\nay be roughly comparable to a\n&gt; 1071m heap in a 32bit JVM.\n&gt; \n&gt; Further, as=\r\n noted in the 1.6 release notes, BerkeleyDB-JE 2.0.90&#39;s\n&gt; internal mechanis=\r\nms for staying within the budgetted cache size\n&gt; are inaccurate under 64bit=\r\n JVMs, so rather than the default 60%\n&gt; cache size, 40% or even 30% would b=\r\ne safer.\n&gt; \n&gt; Even with these adjustments, there are still a few structures=\r\n in\n&gt; the frontier that slowly grow without bound in a broad crawl. We\n&gt; ai=\r\nm to constrain the last of these by the 1.8 release, leading to\n&gt; crawls th=\r\nat wobble (slow down) rather than ever falling down \n(OOME),\n&gt; as long as t=\r\nhere&#39;s still disk space.\n&gt; \n&gt; BdbUriUniqFilter helps defer an OOME until th=\r\nose other structures\n&gt; become a problem, by not letting the URL already-see=\r\nn structures\n&gt; grow without bound. However, it&#39;s pretty inefficient for thi=\r\ns kind\n&gt; of set-membership testing, especially once the crawl is \nbig/dispe=\r\nrse\n&gt; such that the cache isn&#39;t helping much. (It gets very slow.)\n&gt; \n&gt; Blo=\r\nomUriUniqFilter offers another option: its speed doesn&#39;t degrade\n&gt; with the=\r\n number of URIs crawled. However, this comes at the cost of\n&gt; a higher fals=\r\ne-positive rate (misrecognizing a URI as already-seen\n&gt; when it hasn&#39;t been=\r\n) -- and once the crawl gets larger than the \nsize\n&gt; the Bloom filter was d=\r\nesigned for, the false-positive rate grows to\n&gt; approach 100%. The default =\r\nparameters use ~500MB to achieve a 1-in-\n&gt; 4 million false-positive rate th=\r\nrough 125 million URLs; these can\n&gt; be tuned via System properties. (See th=\r\ne BloomUriUniqFilter source\n&gt; and http://crawler.archive.org/cgi-bin/wiki.p=\r\nl?BloomUriUniqFilter\n&gt; for details.)\n&gt; \n&gt; We&#39;ve started work on another Uri=\r\nUniqFilter that uses a batch\n&gt; merging technique described in the 2001 &quot;Hig=\r\nh-Performance Web\n&gt; Crawling&quot; paper by Mark Najork and Allan Heydon, in sec=\r\ntion 3.2,\n&gt; &quot;Efficient Duplicate URL Eliminators&quot;. A rough version is in CV=\r\nS\n&gt; now but it will need more tuning to match or surpass the existing\n&gt; opt=\r\nions. The hope is that it will offer adequate performance into\n&gt; the hundre=\r\nds of millions of URIs without hitting the walls of the\n&gt; current options.\n=\r\n&gt; \n&gt; Regarding the difference between DomainScope and BroadScope\n&gt; performa=\r\nnce:\n&gt; \n&gt; All the &#39;classic&#39; limited scopes -- DomainScope, HostScope,\n&gt; Pat=\r\nhScope -- use an inefficient linear probe against all\n&gt; acceptable patterns=\r\n (usually, all seeds) to test if a URI is\n&gt; in scope. So, with a large numb=\r\ner of seeds, they&#39;re slow\n&gt; CPU hogs.\n&gt; \n&gt; SurtPrefixScope can do anything =\r\nthey can, and much more\n&gt; efficiently, so it&#39;s worth it to recast anything =\r\nyou were\n&gt; using DomainScope for to use SurtPrefixScope instead.\n&gt; \n&gt; --\n&gt; =\r\n\n&gt; One other thing which should help a little in the BdbUriUniqFilter\n&gt; per=\r\nformance bottleneck is to use the &#39;queue budgetting&#39; features\n&gt; so that the=\r\n crawler concentrates on a specific queue (host) for a\n&gt; while, then rotate=\r\ns it out of activity to give other queues a \nchance.\n&gt; In the BdbFrontier e=\r\nxpert settings, this means making sure the\n&gt; &#39;cost-policy&#39; is something oth=\r\ner than ZeroCostAssignmentPolicy,\n&gt; and tending to make the &#39;balance-replen=\r\nish-amount&#39; larger rather\n&gt; than smaller. The current defaults for these ar=\r\ne OK, but if you&#39;ve\n&gt; changed them you may have decreased the potential for=\r\n the BDB cache\n&gt; to benefit from site-locality patterns in discovered links=\r\n.\n&gt; \n&gt; Hope this helps,\n&gt; \n&gt; - Gordon @ IA\n&gt; \n&gt; &gt; --- In archive-crawler@ya=\r\nhoogroups.com, stack &lt;stack@a...&gt; wrote:\n&gt; &gt; \n&gt; &gt;&gt;joehung302 wrote:\n&gt; &gt;&gt;\n&gt; =\r\n&gt;&gt;\n&gt; &gt;&gt;&gt;&gt;Use the bloom filter option for the already-seen in \n&gt; &gt; \n&gt; &gt; BdbF=\r\nrontier. \n&gt; &gt; \n&gt; &gt;&gt;&gt;Seems\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;&gt;to work better when a machine goes ab=\r\nove 30-50million.  Bloom\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;becomes\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;&gt;saturated at 125mil=\r\nlion so thats about the upperbound per \n&gt; &gt; \n&gt; &gt; machine at\n&gt; &gt; \n&gt; &gt;&gt;&gt;the\n&gt;=\r\n &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;&gt;moment unless you up the bloom filter size  (but its already \n&gt; =\r\n&gt; \n&gt; &gt; big and\n&gt; &gt; \n&gt; &gt;&gt;&gt;&gt;you&#39;ll start eating into heap the crawler is usin=\r\ng going about \n&gt; &gt; \n&gt; &gt; its\n&gt; &gt; \n&gt; &gt;&gt;&gt;other\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;&gt;business).  Thereaf=\r\nter the rate of false positives -- reports \n&gt; &gt; \n&gt; &gt; that\n&gt; &gt; \n&gt; &gt;&gt;&gt;we&#39;ve\n&gt;=\r\n &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;&gt;seen an URL when in fact we haven&#39;t -- starts to increase \n&gt; &gt; \n=\r\n&gt; &gt; (Read the\n&gt; &gt; \n&gt; &gt;&gt;&gt;&gt;BloomFilter javadoc for more on its workings).\n&gt; &gt;=\r\n&gt;&gt;&gt;\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;How confident do you guys feel that if I use broad-scope I c=\r\nan \ngo\n&gt; &gt;&gt;&gt;above 50M links (or even 100M links) without OOME on a single \n=\r\n&gt; &gt; \n&gt; &gt; machine?\n&gt; &gt; \n&gt; &gt;&gt;\n&gt; &gt;&gt;I&#39;d suggest you startup a proofing test cra=\r\nwl with BroadScope \nand \n&gt; &gt; \n&gt; &gt; see it \n&gt; &gt; \n&gt; &gt;&gt;does.\n&gt; &gt;&gt;\n&gt; &gt;&gt;On machin=\r\nes with specs like those listed below we&#39;ve pulled down \n&gt; &gt;&gt; &gt;50Million do=\r\ncuments per instance with &gt;125million discovered.  \n&gt; &gt; \n&gt; &gt; Scope \n&gt; &gt; \n&gt; =\r\n&gt;&gt;was not BroadScope.  Once or twice we OOME&#39;d but thought is that \n&gt; &gt;&gt;pro=\r\nbable cause has been addressed in 1.6 release (If there is an \n&gt; &gt; \n&gt; &gt; OOM=\r\nE, \n&gt; &gt; \n&gt; &gt;&gt;you can checkpoint, restart and recover the crawl.  Often it \n=\r\nwill \n&gt; &gt;&gt;continue the crawl as it avoids an exact replay of the \n&gt; &gt; \n&gt; &gt; =\r\ncircumstances \n&gt; &gt; \n&gt; &gt;&gt;that brought on the OOME).\n&gt; &gt;&gt;\n&gt; &gt;&gt;One thing I for=\r\ngot to add to yesterday&#39;s list is regular \n&gt; &gt; \n&gt; &gt; checkpointing \n&gt; &gt; \n&gt; &gt;=\r\n&gt;-- every 4 hours or so.\n&gt; &gt;&gt;\n&gt; &gt;&gt;St.Ack\n&gt; &gt;&gt;\n&gt; &gt;&gt;\n&gt; &gt;&gt;-bash-3.00$ uname -a=\r\n\n&gt; &gt;&gt;Linux crawling015.archive.org 2.6.11-1.27_FC3smp #1 SMP Tue May \n17 \n&gt;=\r\n &gt;&gt;20:43:11 EDT 2005 i686 athlon i386 GNU/Linux\n&gt; &gt;&gt;\n&gt; &gt;&gt;-bash-3.00$ more /=\r\netc/issue\n&gt; &gt;&gt;Fedora Core release 3 (Heidelberg)\n&gt; &gt;&gt;Kernel &#92;r on an &#92;m\n&gt; &gt;=\r\n&gt;\n&gt; &gt;&gt;Dual AMD Opteron(tm) Processor 246  w/ cpu MHz         : \n2009.374 \n&gt;=\r\n &gt; \n&gt; &gt; and \n&gt; &gt; \n&gt; &gt;&gt;cache size      : 1024 KB\n&gt; &gt;&gt;\n&gt; &gt;&gt;[crawling013 5] ~ =\r\n&gt; /lib/libc.so.6\n&gt; &gt;&gt;GNU C Library stable release version 2.3.4 (20050218),=\r\n by Roland \n&gt; &gt; \n&gt; &gt; McGrath \n&gt; &gt; \n&gt; &gt;&gt;et al.\n&gt; &gt;&gt;Copyright (C) 2005 Free S=\r\noftware Foundation, Inc.\n&gt; &gt;&gt;This is free software; see the source for copy=\r\ning conditions.\n&gt; &gt;&gt;There is NO warranty; not even for MERCHANTABILITY or F=\r\nITNESS \nFOR A\n&gt; &gt;&gt;PARTICULAR PURPOSE.\n&gt; &gt;&gt;Configured for i586-suse-linux.\n&gt;=\r\n &gt;&gt;Compiled by GNU CC version 3.3.5 20050117 (prerelease) (SUSE \n&gt; &gt; \n&gt; &gt; L=\r\ninux).\n&gt; &gt; \n&gt; &gt;&gt;Compiled on a Linux 2.6.9 system on 2005-06-10.\n&gt; &gt;&gt;Availab=\r\nle extensions:\n&gt; &gt;&gt;      GNU libio by Per Bothner\n&gt; &gt;&gt;      crypt add-on ve=\r\nrsion 2.1 by Michael Glad and others\n&gt; &gt;&gt;      linuxthreads-0.10 by Xavier =\r\nLeroy\n&gt; &gt;&gt;      GNU Libidn by Simon Josefsson\n&gt; &gt;&gt;      NoVersion patch for=\r\n broken glibc 2.0 binaries\n&gt; &gt;&gt;      BIND-8.2.3-T5B\n&gt; &gt;&gt;      libthread_db =\r\nwork sponsored by Alpha Processor Inc\n&gt; &gt;&gt;      NIS(YP)/NIS+ NSS modules 0.=\r\n19 by Thorsten Kukuk\n&gt; &gt;&gt;Thread-local storage support included.\n&gt; &gt;&gt;For bug=\r\n reporting instructions, please see:\n&gt; &gt;&gt;&lt;http://www.gnu.org/software/libc/=\r\nbugs.html&gt;.\n&gt; &gt;&gt;\n&gt; &gt;&gt;\n&gt; &gt;&gt;\n&gt; &gt;&gt;\n&gt; &gt;&gt;We used sun 1.5.0:\n&gt; &gt;&gt;\n&gt; &gt;&gt;-bash-3.00$=\r\n /usr/local/jdk1.5.0_03/bin/java -version\n&gt; &gt;&gt;java version &quot;1.5.0_03&quot;\n&gt; &gt;&gt;J=\r\nava(TM) 2 Runtime Environment, Standard Edition (build 1.5.0_03-\n&gt; &gt; \n&gt; &gt; b=\r\n07)\n&gt; &gt; \n&gt; &gt;&gt;Java HotSpot(TM) Server VM (build 1.5.0_03-b07, mixed mode)\n&gt; =\r\n&gt;&gt;\n&gt; &gt;&gt;\n&gt; &gt;&gt;\n&gt; &gt;&gt;\n&gt; &gt;&gt;&gt;That to me that seems to be the deciding factor on w=\r\nhether we \n&gt; &gt; \n&gt; &gt; should\n&gt; &gt; \n&gt; &gt;&gt;&gt;start with 5 beefy machines and hope e=\r\nach one can go up to 100M \n&gt; &gt; \n&gt; &gt; links,\n&gt; &gt; \n&gt; &gt;&gt;&gt;or with 10 less beefy =\r\nmachines and each one can go up to 50M \n&gt; &gt; \n&gt; &gt; links\n&gt; &gt; \n&gt; &gt;&gt;&gt;without OO=\r\nME.\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;I know I&#39;m shooting darts in the dark now...I have to start =\r\nthe\n&gt; &gt;&gt;&gt;project planning soon so I&#39;d like to take my best guess with \nall =\r\n\n&gt; &gt; \n&gt; &gt; the\n&gt; &gt; \n&gt; &gt;&gt;&gt;advices I can get.\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;cheers,\n&gt; &gt;&gt;&gt;-joe\n&gt; &gt;=\r\n&gt;&gt;\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;-------------------------------------------=\r\n---------------------\n-\n&gt; &gt; \n&gt; &gt; -------\n&gt; &gt; \n&gt; &gt;&gt;&gt;YAHOO! GROUPS LINKS\n&gt; &gt;&gt;=\r\n&gt;\n&gt; &gt;&gt;&gt;    *  Visit your group &quot;archive-crawler\n&gt; &gt;&gt;&gt;      &lt;http://groups.y=\r\nahoo.com/group/archive-crawler&gt;&quot; on the \n&gt; &gt; \n&gt; &gt; web.\n&gt; &gt; \n&gt; &gt;&gt;&gt;       \n&gt; =\r\n&gt;&gt;&gt;    *  To unsubscribe from this group, send an email to:\n&gt; &gt;&gt;&gt;       arc=\r\nhive-crawler-unsubscribe@yahoogroups.com\n&gt; &gt;&gt;&gt;      &lt;mailto:archive-crawler=\r\n-unsubscribe@yahoogroups.com?\n&gt; &gt; \n&gt; &gt; subject=3DUnsubscribe&gt;\n&gt; &gt; \n&gt; &gt;&gt;&gt;   =\r\n    \n&gt; &gt;&gt;&gt;    *  Your use of Yahoo! Groups is subject to the Yahoo! Terms \n=\r\n&gt; &gt; \n&gt; &gt; of\n&gt; &gt; \n&gt; &gt;&gt;&gt;      Service &lt;http://docs.yahoo.com/info/terms/&gt;.\n&gt; =\r\n&gt;&gt;&gt;\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;------------------------------------------------------------=\r\n----\n-\n&gt; &gt; \n&gt; &gt; -------\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt;  \n&gt; &gt; Y=\r\nahoo! Groups Links\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt;  \n&gt; &gt; \n&gt; &gt;\n&gt;\n\n\n\n\n\n"}}