{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"6gefLyH0-D1UN9NMBRNavR0yqbXI1ORJOHh1VgJY_F2UVZ3Vrf5pPe12U2JfwZAd9vLYY2Uw4Hq3dNZo_NfHdGtCo_ahegE","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Re: Distributed Crawling","postDate":"1175639209","msgId":4017,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ2MTJENEE5LjYwMDA3MDJAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGV1cnI3dStrMGRnQGVHcm91cHMuY29tPg==","referencesHeader":"PGV1cnI3dStrMGRnQGVHcm91cHMuY29tPg=="},"prevInTopic":4006,"nextInTopic":4028,"prevInTime":4016,"nextInTime":4018,"topicId":3834,"numMessagesInTopic":26,"msgSnippet":"... Excellent! ... I am always partial to the latest releases, though you may want to make the determination based on your own reading of the changes/issues.","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 84961 invoked from network); 3 Apr 2007 22:24:38 -0000\r\nReceived: from unknown (66.218.67.34)\n  by m43.grp.scd.yahoo.com with QMQP; 3 Apr 2007 22:24:38 -0000\r\nReceived: from unknown (HELO mail.archive.org) (207.241.233.246)\n  by mta8.grp.scd.yahoo.com with SMTP; 3 Apr 2007 22:24:38 -0000\r\nReceived: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id 87670141C6CF6\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Tue,  3 Apr 2007 15:24:34 -0700 (PDT)\r\nReceived: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id 17192-04-59 for &lt;archive-crawler@yahoogroups.com&gt;;\n\tTue, 3 Apr 2007 15:24:34 -0700 (PDT)\r\nReceived: from [192.168.1.203] (c-76-102-230-209.hsd1.ca.comcast.net [76.102.230.209])\n\tby mail.archive.org (Postfix) with ESMTP id F0E10141BC461\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Tue,  3 Apr 2007 15:24:33 -0700 (PDT)\r\nMessage-ID: &lt;4612D4A9.6000702@...&gt;\r\nDate: Tue, 03 Apr 2007 15:26:49 -0700\r\nUser-Agent: Thunderbird 1.5.0.10 (X11/20070306)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;eurr7u+k0dg@...&gt;\r\nIn-Reply-To: &lt;eurr7u+k0dg@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Virus-Scanned: Debian amavisd-new at archive.org\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Re: Distributed Crawling\r\nX-Yahoo-Group-Post: member; u=137285340; y=Jw2E4C7T9C-iCdDFU_hAGR5wUWyGgXcBu7gy7pPPZC1A\r\nX-Yahoo-Profile: gojomo\r\n\r\njoehung302 wrote:\n&gt; Hi,\n&gt; \n&gt; It&#39;s that time again.\n&gt; \n&gt; We&#39;re going to try 2.5B (maybe more) this time. We&#39;ve upgrade our \n&gt; bandwidth to 250Mbps, all year round.\n&gt; \n&gt; So that means we&#39;re going to keep the crawlers run until they \n&gt; fall. ;)\n\nExcellent!\n\n&gt; Before we start crawling, as usual, more questions:\n&gt; \n&gt; 1. Should we upgrade to 1.12? (We were using 1.8, we know we have to \n&gt; use 1.10 because of the POST bug).\n\nI am always partial to the latest releases, though you may want to make \nthe determination based on your own reading of the changes/issues. Of \n1.12.0-fixed issues, a couple that might be of interest to a broad/deep \ncrawl would be:\n\nhttp://webteam.archive.org/jira/browse/HER-4\n  - don&#39;t misparse robots.txt if &#39;crawl-delay&#39;/&#39;allow&#39; directives present\n\nhttp://webteam.archive.org/jira/browse/HER-1085\n  - fetch additional URIs with &#39;|&#39; in them\n\n&gt; 2. Any Java parameter settings? Last time I tried the HotSpot server \n&gt; VM and it was not usable after a couple days. I ended up having to \n&gt; specify &quot;client mode&quot;.\n\nWe haven&#39;t had a problem with server/HotSpot mode, so no opinion here. \n(Most of our crawls currently use the Sun 1.5.0_07 JVM.)\n\n&gt; 3. Need more explanation on this &#39;reduce-prefix-pattern&#39; trick. How \n&gt; does it help in a long crawl?\n\nThe intent is to ensure related subdomains land on the same crawler. The \nmain benefit is that it gives you a single place to make mid-crawl \nchanges that affect them all. (In the future, it could also assist \nimproved IP or parent-domain-based politeness.)\n\nHere&#39;s a reduction pattern (not necessarily a *good* pattern, but an \nillustrative one) that was used while testing the capability:\n\n^((&#92;w&#92;w&#92;w,&#92;w*)|((au|uk),&#92;w*,&#92;w*)|[&#92;w,]{8})\n\nIts intent with respect to SurtAuthorityQueueAssignment classKeys was:\n\n(1) If it&#39;s a COM/ORG/NET domain, use up through the 2nd-level domain\n\n(2) If it&#39;s a 2-letter TLD known to have broad subdomains (AU/UK with \ntheir com.au, co.uk, etc. subdomains), use up through the 3rd-level domain\n\n(3) For all other cases, use the first 8 characters of the classKey. \n(The untested theory being that all such other cases are a small % of \nhosts so that even if this rule is awfully uneven, it won&#39;t make much of \na difference.)\n\nI&#39;m sure better reduction patterns are possible depending on what you&#39;re \ncrawling; I believe we&#39;ve used other variants of this for our 6-machine \ncrawls.\n\n&gt; 4. Anything you think might be helpful for us to know?\n\nYou&#39;re the trailblazers in this regard -- nothing I can think of offhand \nbut please let us know of any issues you encounter. We&#39;re starting our \nown 2+ billion page Heritrix crawl this summer. (See: \nhttp://wa.archive.org/aroundtheworld/ ).\n\nBest luck!\n\n- Gordon @ IA\n\n\n&gt; Thanks a lot,\n&gt; -Joe\n&gt; \n&gt; \n&gt; \n&gt; \n&gt;  \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n\n"}}