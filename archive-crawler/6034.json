{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"CE_NRTw_GtCsO2LeE93gdc-O7gwZZ5nmUFJqz7x7carCNeUeeOFk9WuNQb-LmgsSiwqrZexH8qyUGWfs2MD5FBEVYg2dQ4g","spamInfo":{"isSpam":false,"reason":"3"},"subject":"Re: [archive-crawler] Output a list of domain names rather than HTML documents ?","postDate":"1253053549","msgId":6034,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRBQjAxNDZELjUwMjAzMDZAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGg4bmRhYysyN3M1QGVHcm91cHMuY29tPg==","referencesHeader":"PGg4bmRhYysyN3M1QGVHcm91cHMuY29tPg=="},"prevInTopic":6031,"nextInTopic":6041,"prevInTime":6033,"nextInTime":6035,"topicId":6031,"numMessagesInTopic":3,"msgSnippet":"A full Heritrix crawl may be overkill for discovering such sites. Heritrix s link-discovery is designed for finding URIs you didn t know existed by examining","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 15144 invoked from network); 15 Sep 2009 22:26:22 -0000\r\nX-Received: from unknown (69.147.108.200)\n  by m6.grp.re1.yahoo.com with QMQP; 15 Sep 2009 22:26:22 -0000\r\nX-Received: from unknown (HELO mail.archive.org) (207.241.231.239)\n  by mta1.grp.re1.yahoo.com with SMTP; 15 Sep 2009 22:26:22 -0000\r\nX-Received: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id 5143C297132\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Tue, 15 Sep 2009 15:26:21 -0700 (PDT)\r\nX-Received: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id v54FsrP47dbl for &lt;archive-crawler@yahoogroups.com&gt;;\n\tTue, 15 Sep 2009 15:26:20 -0700 (PDT)\r\nX-Received: from [192.168.1.79] (c-67-188-14-54.hsd1.ca.comcast.net [67.188.14.54])\n\tby mail.archive.org (Postfix) with ESMTPSA id B6BE214F1AE\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Tue, 15 Sep 2009 15:26:20 -0700 (PDT)\r\nMessage-ID: &lt;4AB0146D.5020306@...&gt;\r\nDate: Tue, 15 Sep 2009 15:25:49 -0700\r\nUser-Agent: Thunderbird 2.0.0.23 (Windows/20090812)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;h8ndac+27s5@...&gt;\r\nIn-Reply-To: &lt;h8ndac+27s5@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 2:3:4:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Output a list of domain names rather than HTML\n documents ?\r\nX-Yahoo-Group-Post: member; u=137285340; y=3M8ijjUzhUBgCpzvJYYPocx27tNF9VtKwfYhxfOTnPzy\r\nX-Yahoo-Profile: gojomo\r\n\r\nA full Heritrix crawl may be overkill for discovering such sites. \nHeritrix&#39;s link-discovery is designed for finding URIs you didn&#39;t know \nexisted by examining every known URI in turn, and its careful \nrecording/writing of responses is designed for creating a verbatim \narchive of what&#39;s discovered.\n\nSince you know the URI patterns, the right kind of advanced queries at \nGoogle, Yahoo, or Bing might do the trick. For example at Google \n[inurl:privacypolicy.html]:\n\nhttp://www.google.com/search?q=inurl%3Aprivacypolicy.html\n\nIt is possible to run a crawl with Heritrix where you write none of the \ncontent retrieved, in which case you would just have the crawl.log of \nall URIs visited, and could scan that later for domains or URI patterns \nof interest. But that would spend a lot of bandwidth -- grabbing a lot \nof unnecessary material, including content with no links like graphics, \nand inconvenience a lot of sites -- just to find a small number of \ncandidate/actual sites of interest. That makes me think it would be \nbetter to start at a search engine, or with a list of hostnames acquired \nsome other way, then probe for the significant URIs.\n\n- Gordon @ IA\n\nsparkles2112@... wrote:\n&gt; I would like to design a crawl that takes a number of seed domains, and returns a list of URLS (domains) that are found from those seed domains matching a certain processing criteria. I do not need to have the html content of the matched domains saved for subsequent use.\n&gt; \n&gt; The criteria I want to test against are: \n&gt; \n&gt; The presence of a certain page on each site found from the seed sites, ie /about-us.html or /privacypolicy.html\n&gt; \n&gt; The presence of a certain substring within the urls of the anchors on the index page, ie &quot;?action=contactus&quot; \n&gt; \n&gt; If any of the criteria are met, I would like the domain added to my output list. \n&gt; \n&gt; Does this sound like a job suitable for this crawler to execute? Is there another way to think about the problem that would be more appropriate for the tool? Basically I&#39;m trying to get a list of domains that are running a certain script in order to contact them for requesting link exchanges. \n&gt; \n&gt; \n&gt; \n&gt; ------------------------------------\n&gt; \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n"}}