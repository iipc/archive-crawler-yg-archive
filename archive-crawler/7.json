{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"&quot;Gordon Mohr&quot; &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"6ppASRigwY6cpbIbmV9cPnjFoTR8FH6BeJI3XZ7nS0-97aYY0b-uMkmMAuL3usUwC7pPujzkmYn7JnDWxxqkfv-KxmeBVfS_GA","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Crawler outline in SEDA-style","postDate":"1045650109","msgId":7,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDAwMGIwMWMyZDgwMCRiNzFkZDM2MCQ2NTBhMDAwYUBnb2xkZW4+"},"prevInTopic":0,"nextInTopic":0,"prevInTime":6,"nextInTime":8,"topicId":7,"numMessagesInTopic":1,"msgSnippet":"At our last design meeting, Raymie and I sketched an outline of crawler operation as a series of discrete stages connected by queues -- a style compatible with","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (EGP: mail-8_2_3_4); 19 Feb 2003 10:21:52 -0000\r\nReceived: (qmail 4883 invoked from network); 19 Feb 2003 10:21:52 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m13.grp.scd.yahoo.com with QMQP; 19 Feb 2003 10:21:52 -0000\r\nReceived: from unknown (HELO mail.archive.org) (209.237.232.3)\n  by mta1.grp.scd.yahoo.com with SMTP; 19 Feb 2003 10:21:52 -0000\r\nReceived: from golden (adsl-67-119-27-26.dsl.snfc21.pacbell.net [67.119.27.26])\n\tby mail.archive.org (8.10.2/8.10.2) with SMTP id h1J9inQ22057\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Wed, 19 Feb 2003 01:44:49 -0800\r\nMessage-ID: &lt;000b01c2d800$b71dd360$650a000a@golden&gt;\r\nTo: &lt;archive-crawler@yahoogroups.com&gt;\r\nSubject: Crawler outline in SEDA-style\r\nDate: Wed, 19 Feb 2003 02:21:49 -0800\r\nMIME-Version: 1.0\r\nContent-Type: text/plain;\n\tcharset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: 7bit\r\nX-Priority: 3\r\nX-MSMail-Priority: Normal\r\nX-Mailer: Microsoft Outlook Express 6.00.2800.1106\r\nX-MIMEOLE: Produced By Microsoft MimeOLE V6.00.2800.1106\r\nFrom: &quot;Gordon Mohr&quot; &lt;gojomo@...&gt;\r\nX-Yahoo-Group-Post: member; u=137285340\r\nX-Yahoo-Profile: gojomo\r\n\r\nAt our last design meeting, Raymie and I sketched an outline\nof crawler operation as a series of discrete stages connected\nby queues -- a style compatible with the SEDA (&quot;Staged Event\nDriven Architecture&quot;) tools available at:\n\n   http://www.cs.berkeley.edu/~mdw/proj/sandstorm/\n\nIn many ways, this is an &quot;inside-out&quot; approach compared to a\nmore typical consciously-threaded design. The SEDA framework \nhandles threading issues; the application is just a set of simple,\nideally non-blocking but thread-safe event handlers dropping \nevent objects into each others&#39; in-sinks.\n\nIn this approach, the entity called &#39;CandidateURI&#39; assumes a\ncentral importance: it is usually the object being pushed to \neach new stage, carrying with it any work done so far. I now\nthink &#39;CrawlURI&#39; is a better name for this object -- after all,\nit&#39;s only a &#39;candidate&#39; for part of its lifecycle. \n\nA CrawlURI object has a lot of state and functionality:\n- a few key required fields\n- an open-ended, hierarchical attribute-value structure\n  for holding whatever data stages need to pass between\n  each other -- or retain persistently across multiple,\n  spaced-out URI revisits\n- tests for whether the CrawlURI meets certain ready/error\n  conditions\n- possibly, convenience protocols for accessing external\n  resources associated with the URI (eg contents from previous\n  visits)\n\nA rough outline of basic crawler operations in the SEDA style\nis below. The same general tasks are being handled as in my \nprevious, classical single-thread pseudocode outline -- except\nin the handleEvent() methods of Stage objects. \n\nI&#39;m assuming that a driver process outside the SEDA/SandStorm \nsystem enqueues &#39;DoURI&#39; events to the URIChoosing stage. (In \nthe SEDA example server apps, connections from external clients,\nas handled by system service threads, serve to kick the system \ninto motion.) These DoURIs can just be empty indicators used to \npush along the process -- the actual URI is chosen after each \nDoURI kick is received -- but in a future distributed setup DoURI \nevents could also indicate local restrictions on the next URI \nto choose.\n\nI&#39;ve named the stages with the &quot;-ing&quot; verb tense, to indicate\nthem as free-floating actions. The &quot;front&quot; of the URI Frontier\nis prompted to give our URIs for processing via a URIChoosing\nstage; the &quot;back&quot; of the URI Frontier which takes either new\nURIs or old URIs at the end of a processing cycle is represented\nby a URIStoring stage.\n\n--\n\nThe basic flow would be:\n\n   EVENT         STAGE\n   ----------    ------------------\n   {DoURI}    -&gt; URIChoosing     (frontier/URI database &quot;front&quot;)\n\n   {CrawlURI} -&gt; Preprocessing   (robots, politeness, dns)\n\n     {CrawlURI} -&gt; DNSLookingUp  (when necessary)\n\n   {CrawlURI} -&gt; Fetching        (which may have substages)\n\n   {CrawlURI} -&gt; Postprocessing  (links, archival)\n\n   {CrawlURI} -&gt; URIStoring      (frontier/URI database &quot;back&quot;)\n\n--\n\nA bit more about the various stage handleEvent() methods:\n\nURIChoosing.handleEvent( (DoURI) element ) ==\n{\n  CrawlURI curi = nextUri(); // decide on URI to address\n\n  nextStage().enqueue(curi); // pass to Preprocessing\n}\n\nPreprocessing.handleEvent( (CrawlURI) element ) ==\n{\n  CrawlURI curi = (CrawlURI) element;\n\n  if ( curi.needsGoverningRobotsTxt() ) {\n    curi.markAsDeferredForRobots();\n    failStage().enqueue( curi );  // pass back to URIStoring\n    return; \n  } \n\n  curi.robotsTxt().apply();       // apply rules & markup results\n  if ( curi.fetchDisallowed() ) {\n    failStage().enqueue( curi );   // pass back to URIStoring\n  }\n\n  if ( curi.needsDNSLookup() ) {\n    dnsStage().enqueue( curi ));  // pass to DNSLookingUp\n    return; \n  } \n\n  politenessPolicy.applyTo( curi ); // apply rules & markup results\n  if ( curi.fetchDisallowed() ) {\n    failStage().enqueue( curi );  // pass back to URIStoring\n    return;\n  }\n\n\n  // other rules for tricky situations\n  // could be implemented here, or as\n  // chained next stage\n\n  nextStage().enqueue( curi ); // pass to Fetching\n\n}\n\nDNSLookingUp.handleEvent((CrawlURI) element) ==\n{\n  // \n  // do dns lookup in staged fashion,\n  // marking up CrawlURI (and local host\n  // database), eventually...\n  //\n\n  if ( curi.domainUnavailable() ) {\n    failStage.enqueue( curi );\n    return;\n  }\n\n  nextStage().enqueue( curi ); // otherwise, return to Preprocessing\n}\n\nFetching.handleEvent( element ) == \n{\n\n  //\n  // do fetching in staged fashion, \n  // marking up CrawlURI, eventually \n  // reaching...\n  //\n\n  nextStage().enqueue( curi ); // pass to Postprocessor\n  \n}\n\nPostprocessing.handleEvent((CrawlURI) element) ==\n{\n  //\n  // do archiving, link extraction, etc.\n  // perhaps enqueuing many new CrawlURIs to \n  // URIStoring stage, and eventually...\n  //\n\n  nextStage().enqueue( curi );  // return to URIStoring\n\n}\n\nURIStoring.handleEvent((CrawlURI) element) ==\n{\n  //\n  // examine CrawlURI for evidence of\n  // correctable/retryable errors\n  //\n  // persist CrawlURI in the right place\n  // for revisiting if/when appropriate\n  //\n  // do *not* push new CrawlURIs into the\n  // full processing loop -- but perhaps put \n  // them at the top of the structures consulted\n  // by URIChoosing\n}\n\n--\n\nThe most basic way to tune the system for best performance\nis to adaptively vary the rate of DoURI enqueues until \nmaximum throughput is observed. \n\nIdeally, though, when the various stage thresholds are set and\nauto-adjusted properly, simply enqueuing DoURIs as fast as a \nfixed-size entry queue will take them should reliably drive the \nsystem to maximum throughput. \n\n--\n\nThoughts? Questions? Concerns?\n\n- Gordon\n\n\n"}}