{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"9Lu4YjxXTsPZQq57kV-UmMzorK213t65NfeskZWoloIW5Ys8lZgmyMUATxgaT6TNyw6mVEUuHKA3CRuMT8Ieq7yUxLvtKrM","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] QuotaEnforcer","postDate":"1152915436","msgId":3054,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ0QjgxN0VDLjcwMjA1QGFyY2hpdmUub3JnPg==","inReplyToHeader":"PGU5OTMycCs5YjF2QGVHcm91cHMuY29tPg==","referencesHeader":"PGU5OTMycCs5YjF2QGVHcm91cHMuY29tPg=="},"prevInTopic":3053,"nextInTopic":0,"prevInTime":3053,"nextInTime":3055,"topicId":2492,"numMessagesInTopic":9,"msgSnippet":"... The QuotaEnforcer doesn t currently work that way, but it s an interesting idea. Could you file a feature-request at Sourceforge for this? This would be","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 97378 invoked from network); 14 Jul 2006 22:15:51 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m40.grp.scd.yahoo.com with QMQP; 14 Jul 2006 22:15:51 -0000\r\nReceived: from unknown (HELO mail.archive.org) (207.241.227.188)\n  by mta6.grp.scd.yahoo.com with SMTP; 14 Jul 2006 22:15:50 -0000\r\nReceived: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id 446E514156CCE\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Fri, 14 Jul 2006 15:15:43 -0700 (PDT)\r\nReceived: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id 16696-02-23 for &lt;archive-crawler@yahoogroups.com&gt;;\n\tFri, 14 Jul 2006 15:15:43 -0700 (PDT)\r\nReceived: from [192.168.1.203] (unknown [67.170.222.19])\n\tby mail.archive.org (Postfix) with ESMTP id 0028914156CC9\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Fri, 14 Jul 2006 15:15:42 -0700 (PDT)\r\nMessage-ID: &lt;44B817EC.70205@...&gt;\r\nDate: Fri, 14 Jul 2006 15:17:16 -0700\r\nUser-Agent: Mail/News 1.5 (X11/20060309)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;e9932p+9b1v@...&gt;\r\nIn-Reply-To: &lt;e9932p+9b1v@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Virus-Scanned: Debian amavisd-new at archive.org\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] QuotaEnforcer\r\nX-Yahoo-Group-Post: member; u=137285340; y=REql8fu_0AK_M-px8RIHOaAM-lHzxXDrdlEI77Hru7Os\r\nX-Yahoo-Profile: gojomo\r\n\r\nbarabasy69 wrote:\n&gt; Hi,\n&gt; \n&gt; I just finished to look at logs from my last crawl. I used the \n&gt; QuotaEnforcer to limit the number of urls from host to a certain \n&gt; values. Since I set it as a prefetcher, the crawl.logs show a lot of -\n&gt; 5003 status code. That&#39;s fine! Now, can I use QuotaEnforcer in the post-\n&gt; processor stage (before Scheduler) so that those url exceeding limits \n&gt; won&#39;t even be scheduled? That will save time to my crawl.\n\nThe QuotaEnforcer doesn&#39;t currently work that way, but it&#39;s an \ninteresting idea. Could you file a feature-request at Sourceforge for this?\n\nThis would be somewhat analogous to the way CrawlMapper can be useful \neither before or after fetching (or both), operating on either the URI \nitself or the discovered &#39;outlink&#39; URIs.\n\nAnother idea regarding QuotaEnforcer is to change the effect of the \n&#39;over-quota&#39; status (-5003) to retire the source queue rather than mark \nthe URI as failed. Then, you wouldn&#39;t have to wait for all URIs to \n&#39;unspool&#39; when a queue goes over quota, and further you could decide to \nraise the quota and proceed with crawling if desired. (That would save \nsome time, but not as much as never scheduling the URIs at all.)\n\n- Gordon @ IA\n\n"}}