{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":472135895,"authorName":"yotpo.official","from":"&quot;yotpo.official&quot; &lt;tomer@...&gt;","profile":"yotpo.official","replyTo":"LIST","senderId":"oufA6OVeoh8E4FWyw4jPYQOXPSa6YCTUP-gEUvmHIzR0zryj7w8t2VdRxua9ZhMg2v24cNyobo4ygcvItnQ6IaBN9jlm0z8EWA","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: Queues Are exhasted","postDate":"1293541416","msgId":6948,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGlmY243OCtiYjZzQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDREMTkxMTk2LjQwMDAzMDNAYXJjaGl2ZS5vcmc+"},"prevInTopic":6947,"nextInTopic":6949,"prevInTime":6947,"nextInTime":6949,"topicId":6942,"numMessagesInTopic":6,"msgSnippet":"Hi again Gordon, I want to clarify a bit more: I m trying to crawl my website that has 10 MB/sec for bandwidth for my crawling, the expected bandwidth for my","rawEmail":"Return-Path: &lt;tomer@...&gt;\r\nX-Sender: tomer@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 99800 invoked from network); 28 Dec 2010 13:04:59 -0000\r\nX-Received: from unknown (66.196.94.106)\n  by m15.grp.re1.yahoo.com with QMQP; 28 Dec 2010 13:04:59 -0000\r\nX-Received: from unknown (HELO n44d.bullet.mail.sp1.yahoo.com) (66.163.169.158)\n  by mta2.grp.re1.yahoo.com with SMTP; 28 Dec 2010 13:04:58 -0000\r\nX-Received: from [69.147.65.173] by n44.bullet.mail.sp1.yahoo.com with NNFMP; 28 Dec 2010 13:04:05 -0000\r\nX-Received: from [98.137.34.35] by t15.bullet.mail.sp1.yahoo.com with NNFMP; 28 Dec 2010 13:03:39 -0000\r\nDate: Tue, 28 Dec 2010 13:03:36 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;ifcn78+bb6s@...&gt;\r\nIn-Reply-To: &lt;4D191196.4000303@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nFrom: &quot;yotpo.official&quot; &lt;tomer@...&gt;\r\nSubject: Re: Queues Are exhasted\r\nX-Yahoo-Group-Post: member; u=472135895; y=DEWow7pUDmhE4TTHnYytjG8jU5hZdXeDFkKno4sNBE_G2mHk6lP5UIk\r\nX-Yahoo-Profile: yotpo.official\r\n\r\nHi again Gordon,\nI want to clarify a bit more:\nI&#39;m trying to crawl my websi=\r\nte that has 10 MB/sec for bandwidth for my crawling, the expected bandwidth=\r\n for my crawling is 1200 KB/s. As for concurrent connections the webmaster =\r\nset it to somewhere around 40 so in the way I&#39;m running today (10 threads a=\r\nnd 10 parallel queues) so that isn&#39;t my problem. The site is pretty big and=\r\n there is no way there is nothing to crawl after a short time. My deepest q=\r\nueue is about 1441733. My reports are:\n\nToeTheards(example of two threads):=\r\n\nToe threads report - 201012280652\n Job being crawled: basic\n Number of toe=\r\n threads in pool: 10 (1 active)\n\n[ToeThread #1:\n -no CrawlURI-\n    WAITING =\r\nfor 1d6h59m316ms\n    step: ABOUT_TO_GET_URI for 1d6h59m316ms\nJava Thread St=\r\nate: TIMED_WAITING\nBlocked/Waiting On: NONE\n    java.lang.Thread.sleep(Nati=\r\nve Method)\n    org.archive.crawler.frontier.\nWorkQueueFrontier.findEligible=\r\nURI(WorkQueueFrontier.java:718)\n    org.archive.crawler.frontier.AbstractFr=\r\nontier.next(AbstractFrontier.java:432)\n    org.archive.crawler.framework.To=\r\neThread.run(ToeThread.java:133)\n]\n[ToeThread #2:\n -no CrawlURI-\n    WAITING=\r\n for 1d11h9m41s841ms\n    step: ABOUT_TO_GET_URI for 1d11h9m41s841ms\nJava Th=\r\nread State: TIMED_WAITING\nBlocked/Waiting On: NONE\n    java.lang.Thread.sle=\r\nep(Native Method)\n    org.archive.crawler.frontier.WorkQueueFrontier.findEl=\r\nigibleURI(WorkQueueFrontier.java:718)\n    org.archive.crawler.frontier.Abst=\r\nractFrontier.next(AbstractFrontier.java:432)\n    org.archive.crawler.framew=\r\nork.ToeThread.run(ToeThread.java:133)\n]\n\n\nmy Frontier report is:\nFrontier r=\r\neport - 201012280654\n Job being crawled: basic\n\n -----=3D=3D=3D=3D=3D STATS=\r\n =3D=3D=3D=3D=3D-----\n Discovered:    1823416\n Queued:        1535496\n Fini=\r\nshed:      287946\n  Successfully: 184173\n  Failed:       245\n  Disregarded:=\r\n  103528\n\n -----=3D=3D=3D=3D=3D QUEUES =3D=3D=3D=3D=3D-----\n Already includ=\r\ned size:     1823416\n               pending:     0\n\n All class queues map s=\r\nize: 11\n             Active queues: 1\n                    In-process: 0\n   =\r\n                      Ready: 0\n                       Snoozed: 1\n          =\r\n Inactive queues: 0 (p3: 0)\n            Retired queues: 0\n          Exhaust=\r\ned queues: 10\n\n             Last state: RUN\n -----=3D=3D=3D=3D=3D MANAGER T=\r\nHREAD =3D=3D=3D=3D=3D-----\nJava Thread State: TIMED_WAITING\nBlocked/Waiting=\r\n On: NONE\n    java.lang.Thread.sleep(Native Method)\n    org.archive.crawler=\r\n.frontier.AbstractFrontier.managementTasks(AbstractFrontier.java:344)\n    o=\r\nrg.archive.crawler.frontier.AbstractFrontier$1.run(AbstractFrontier.java:30=\r\n1)\n\n-----=3D=3D=3D=3D=3D 11 LONGEST QUEUES =3D=3D=3D=3D=3D-----\nLONGEST#0:\n=\r\nQueue com,********My website******************, (p3)\n  1442699 items\n   wak=\r\nes in: 1m13s536ms\n    last enqueued: ********My website******************\n =\r\n     last peeked: ********My website******************\n   total expended: 1=\r\n50244 (total budget: -1)\n   active balance: 312\n   last(avg) cost: 1(0.7)\n =\r\n  totalScheduled fetchSuccesses fetchFailures fetchDisregards fetchResponse=\r\ns robotsDenials successBytes totalBytes fetchNonResponses\n   1671559 125089=\r\n 245 103526 125089 103526 6361559886 6361559886 678\n   SimplePrecedenceProv=\r\nider\n   3\n\nLONGEST#1:\nQueue com,********My website******************,+7 (p3=\r\n)\n  65205 items\n    last enqueued:********My website******************\n    =\r\n  last peeked: ********My website******************\n   total expended: 1 (t=\r\notal budget: -1)\n   active balance: 2999\n   last(avg) cost: 1(1)\n   totalSc=\r\nheduled fetchSuccesses fetchFailures fetchDisregards fetchResponses robotsD=\r\nenials successBytes totalBytes fetchNonResponses\n   65206 1 0 0 1 0 24450 2=\r\n4450 0\n   SimplePrecedenceProvider\n   3\n\nI changed to url&#39;s to ********My w=\r\nebsite****************** and the frontier report continues to be like this.=\r\n\n\nWhat is my problem?\nThank you\n\n\n--- In archive-crawler@yahoogroups.com, G=\r\nordon Mohr &lt;gojomo@...&gt; wrote:\n&gt;\n&gt; You have to look at the frontier and thr=\r\neads reports to better \n&gt; understand the state.\n&gt; \n&gt; With default settings,=\r\n there&#39;s one queue per hostname. When a queue is \n&gt; empty, there&#39;s nothing =\r\nleft to crawl from that hostname.\n&gt; \n&gt; The &#39;parallelQueues&#39; setting you ask=\r\ned about last week will spread a \n&gt; hostname&#39;s URIs over multiple queues, a=\r\nnd thus allow multiple threads to \n&gt; be collecting URIs in parallel. But it=\r\n&#39;s not yet clear that&#39;s your \n&gt; problem; even one thread fetching as fast a=\r\ns possible (no politeness \n&gt; &#39;snoozes&#39;) may fully load your target server, =\r\nand so adding more threads \n&gt; may just mean they&#39;re competing against thems=\r\nelves (for little if any \n&gt; speedup).\n&gt; \n&gt; - Gordon @ IA\n&gt; \n&gt; On 12/27/10 5=\r\n:02 AM, yotpo.official wrote:\n&gt; &gt; What is the reason for this?\n&gt; &gt; I am cra=\r\nwling only my own site and there are no politeness considerations,in this w=\r\nay it will take my for ages to index my site... What can I do to make all 1=\r\n0 threads and queues functional?\n&gt; &gt; Thank you\n&gt; &gt;\n&gt; &gt; --- In archive-crawl=\r\ner@yahoogroups.com, Gordon Mohr&lt;gojomo@&gt;  wrote:\n&gt; &gt;&gt;\n&gt; &gt;&gt; This is a wholly=\r\n normal state for a crawl that&#39;s still working on one queue.\n&gt; &gt;&gt;\n&gt; &gt;&gt; &quot;10 =\r\nexhausted&quot; means that 10 queues once had URIs in them, but finished.\n&gt; &gt;&gt;\n&gt;=\r\n &gt;&gt; &quot;1 in-process&quot; means one queue has offered up a URI which is in the\n&gt; &gt;=\r\n&gt; middle of a processing cycle. Looking at the frontier report will reveal\n=\r\n&gt; &gt;&gt; which queue offered the URI, the count of other URIs in that queue, an=\r\nd\n&gt; &gt;&gt; other details. Looking at the threads report will reveal the process=\r\nor\n&gt; &gt;&gt; currently working on the in-process URI.\n&gt; &gt;&gt;\n&gt; &gt;&gt; With a single qu=\r\neue still holding URIs, and normal politeness settings,\n&gt; &gt;&gt; you would expe=\r\nct on subsequent viewings of this summary to see the queue\n&gt; &gt;&gt; bouncing fr=\r\nom &#39;in-process&#39; to &#39;snoozed&#39; and back, until the queue is\n&gt; &gt;&gt; exhausted. I=\r\nf occasionally new URIs are discovered on other hosts, other\n&gt; &gt;&gt; queues mi=\r\nght reenter active crawling as well.\n&gt; &gt;&gt;\n&gt; &gt;&gt; - Gordon @ IA\n&gt; &gt;&gt;\n&gt; &gt;&gt; On 1=\r\n2/26/10 10:00 AM, yotpo.official wrote:\n&gt; &gt;&gt;&gt; I am running with 10 threads =\r\nand 10 queues and this is my frontier summary after a while:\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;   =\r\n RUN - 11 URI queues: 1 active (1 in-process; 0 ready; 0 snoozed); 0 inacti=\r\nve; 0 ineligible; 0 retired; 10 exhausted\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt; Anybody knows why is =\r\nit happening?\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt; Thank you very much\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt; -----=\r\n-------------------------------\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt; Yahoo! Groups Links\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;=\r\n\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; ------------------------------------\n&gt; &gt;\n&gt; =\r\n&gt; Yahoo! Groups Links\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}