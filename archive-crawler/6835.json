{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"gPtAssGPdwXTvVMQCzgQgGg6_dEoPA6ehbZFwLv9fwLdL7kTu1djRQAkJIBz4Q7COtAXLB3OxgZZVYTqJvs-DZSXZI-YBmk","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] Flushing crawl.log","postDate":"1291053295","msgId":6835,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRDRjNFOEVGLjMwNjAzMDVAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGljdnM3dCtpdG1vQGVHcm91cHMuY29tPg==","referencesHeader":"PGljdnM3dCtpdG1vQGVHcm91cHMuY29tPg=="},"prevInTopic":6834,"nextInTopic":6863,"prevInTime":6834,"nextInTime":6836,"topicId":6834,"numMessagesInTopic":4,"msgSnippet":"Good catch; the side-effects of this batching on monitoring a crawl through crawl.log were unintended. We ll probably roll this back, or figure some other way","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 33093 invoked from network); 29 Nov 2010 17:54:57 -0000\r\nX-Received: from unknown (98.137.34.45)\n  by m6.grp.sp2.yahoo.com with QMQP; 29 Nov 2010 17:54:57 -0000\r\nX-Received: from unknown (HELO relay01.pair.com) (209.68.5.15)\n  by mta2.grp.sp2.yahoo.com with SMTP; 29 Nov 2010 17:54:57 -0000\r\nX-Received: (qmail 65958 invoked by uid 0); 29 Nov 2010 17:54:56 -0000\r\nX-Received: from 70.112.224.182 (HELO silverbook.local) (70.112.224.182)\n  by relay01.pair.com with SMTP; 29 Nov 2010 17:54:56 -0000\r\nX-pair-Authenticated: 70.112.224.182\r\nMessage-ID: &lt;4CF3E8EF.3060305@...&gt;\r\nDate: Mon, 29 Nov 2010 09:54:55 -0800\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.6; en-US; rv:1.9.2.12) Gecko/20101027 Thunderbird/3.1.6\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: kstn4321 &lt;kasatani@...&gt;\r\nReferences: &lt;icvs7t+itmo@...&gt;\r\nIn-Reply-To: &lt;icvs7t+itmo@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Flushing crawl.log\r\nX-Yahoo-Group-Post: member; u=137285340; y=BDAZG4G-JC5cZ2XFo0ghk5ackGjjif7x4I-BfINCbPGs\r\nX-Yahoo-Profile: gojomo\r\n\r\nGood catch; the side-effects of this batching on monitoring a crawl \nthrough crawl.log were unintended. We&#39;ll probably roll this back, or \nfigure some other way to have line-by-line resolution on the tail of the \ncrawl.log even if writing is batched.\n\nFYI, there have been a number of large changes on SVN TRUNK (-SNAPSHOT) \nrelated to performance experiments, and more are coming -- so even \nmoreso than usual, if you&#39;re working with a build directly from SVN or \nthe developer build box: keep an eye out for anomalies, beware of new \nbugs and regressions, and let us know via this list or the JIRA issue \nsystem of any problems you encounter.\n\n- Gordon @ IA\n\nOn 11/29/10 1:37 AM, kstn4321 wrote:\n&gt; Hello,\n&gt;\n&gt; I am using Heritrix 3.0.1-SNAPSHOT and found that it now doesn&#39;t flush the logs very frequently, which makes it hard to watch crawl.log to see if the crawling is going well.\n&gt;\n&gt; The corresponding code seems to be flush() method in GenerationFileHandler.java which was added in r7012.\n&gt; I know that is was added to improve performance, but it makes me very hard to test the crawl settings. Is it possible to revert this change or make it configurable so that you can flush every X records instead of the hard-coded 100?\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------\n&gt;\n&gt; Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n\n"}}