{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"&quot;Gordon Mohr&quot; &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"TVG-5F0FYdd9v517Xdo20ehbJjqrQUf5w8nbvWh14TQYum7GV0cucKvpk3GjU2Sl_YhyNcoEx4Z9ES7gW5TsjI5VCf-C61OmTQ","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: DNS and HTTP staging (was Re: [archive-crawler] Re: Web crawler work ??","postDate":"1047944515","msgId":27,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDAwYzgwMWMyZWNkZSRjZTJkZDQ0MCQ0OGYwZWRkMUBXT1JLU1RBVElPTjIxPg==","referencesHeader":"PDM3ZWQwMWMyZDczNCQ0ZjQ0NjliMCRkNTAwYThjMEBSZWRkeUdCPiA8MDM4MDAxYzJkN2I2JDJjMTIxZjAwJDNhZWJlZGQxQGdvam92YWlvPiA8M2ZlMDAxYzJkOWM3JGU1OGE0YTgwJGQ1MDBhOGMwQFJlZGR5R0I+IDwwMGRjMDFjMmRhMDckNjZlZTEzNjAkM2FlYmVkZDFAZ29qb3ZhaW8+IDwwNzY5MDFjMmRlODEkMTNmY2ZlOTAkZDUwMGE4YzBAdGlkZWxwYXJrLmlzb2Z0dGVjaGluZGlhLmNvbT4gPDAwOGUwMWMyZGY2ZSQzZDQ4NGJlMCQ0ZGViZWRkMUBXT1JLU1RBVElPTjIxPiA8MGVjNjAxYzJlNDA5JDBiYzYwMmMwJGQ1MDBhOGMwQHRpZGVscGFyay5pc29mdHRlY2hpbmRpYS5jb20+IDwxMTY0MDFjMmU0YzYkZmNhMjU1ZjAkZDUwMGE4YzBAdGlkZWxwYXJrLmlzb2Z0dGVjaGluZGlhLmNvbT4gPDAxYTQwMWMyZTUwMSQ5MjI3NDNkMCQ0ZGViZWRkMUBXT1JLU1RBVElPTjIxPiA8MDI0MTAxYzJlOGIyJDZhNTFlNTkwJGQ1MDBhOGMwQHRpZGVscGFyay5pc29mdHRlY2hpbmRpYS5jb20+IDwwM2RhMDFjMmVhNDUkYTNhMWFkMDAkZDUwMGE4YzBAdGlkZWxwYXJrLmlzb2Z0dGVjaGluZGlhLmNvbT4gPDAwYTEwMWMyZWNiYyQyOTZhZmY0MCQ0OGYwZWRkMUBXT1JLU1RBVElPTjIxPiA8MDU0YjAxYzJlY2MwJGRiMzQ3N2MwJGQ1MDBhOGMwQHRpZGVscGFyay5pc29mdHRlY2hpbmRpYS5jb20+"},"prevInTopic":26,"nextInTopic":28,"prevInTime":26,"nextInTime":28,"topicId":24,"numMessagesInTopic":5,"msgSnippet":"I ll take a look. Don t feel obligated to go with Eclipse -- even though it is a very nice environment. Eventually we ll include versioned ant scripts with","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (EGP: mail-8_2_6_1); 17 Mar 2003 23:42:13 -0000\r\nReceived: (qmail 99856 invoked from network); 17 Mar 2003 23:42:13 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m13.grp.scd.yahoo.com with QMQP; 17 Mar 2003 23:42:13 -0000\r\nReceived: from unknown (HELO mail.archive.org) (209.237.232.56)\n  by mta1.grp.scd.yahoo.com with SMTP; 17 Mar 2003 23:42:13 -0000\r\nReceived: from WORKSTATION21 (b116-dyn-72.archive.org [209.237.240.72])\n\tby mail.archive.org (8.12.8/8.10.2) with SMTP id h2HN2RE0020336;\n\tMon, 17 Mar 2003 15:02:28 -0800\r\nMessage-ID: &lt;00c801c2ecde$ce2dd440$48f0edd1@WORKSTATION21&gt;\r\nTo: &lt;archive-crawler@yahoogroups.com&gt;\r\nCc: &lt;wcr-team@...&gt;\r\nReferences: &lt;37ed01c2d734$4f4469b0$d500a8c0@ReddyGB&gt; &lt;038001c2d7b6$2c121f00$3aebedd1@gojovaio&gt; &lt;3fe001c2d9c7$e58a4a80$d500a8c0@ReddyGB&gt; &lt;00dc01c2da07$66ee1360$3aebedd1@gojovaio&gt; &lt;076901c2de81$13fcfe90$d500a8c0@...&gt; &lt;008e01c2df6e$3d484be0$4debedd1@WORKSTATION21&gt; &lt;0ec601c2e409$0bc602c0$d500a8c0@...&gt; &lt;116401c2e4c6$fca255f0$d500a8c0@...&gt; &lt;01a401c2e501$922743d0$4debedd1@WORKSTATION21&gt; &lt;024101c2e8b2$6a51e590$d500a8c0@...&gt; &lt;03da01c2ea45$a3a1ad00$d500a8c0@...&gt; &lt;00a101c2ecbc$296aff40$48f0edd1@WORKSTATION21&gt; &lt;054b01c2ecc0$db3477c0$d500a8c0@...&gt;\r\nSubject: Re: DNS and HTTP staging (was Re: [archive-crawler] Re: Web crawler work ??\r\nDate: Mon, 17 Mar 2003 15:41:55 -0800\r\nMIME-Version: 1.0\r\nContent-Type: text/plain;\n\tcharset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: 7bit\r\nX-Priority: 3\r\nX-MSMail-Priority: Normal\r\nX-Mailer: Microsoft Outlook Express 6.00.2800.1106\r\nX-MimeOLE: Produced By Microsoft MimeOLE V6.00.2800.1106\r\nFrom: &quot;Gordon Mohr&quot; &lt;gojomo@...&gt;\r\nX-Yahoo-Group-Post: member; u=137285340\r\nX-Yahoo-Profile: gojomo\r\n\r\nI&#39;ll take a look. \n\nDon&#39;t feel obligated to go with Eclipse -- even though it is a \nvery nice environment. Eventually we&#39;ll include versioned ant\nscripts with each module so as to support the widest possible\nchoice of dev styles. \n\nUpgrading dnsjava&#39;s async capabilities looks like a good idea.\nI see it has a rudimentary async simulation via a background \nthread-per-call, and also that it uses a fresh UDP socket for every \nlookup to avoid having to do any other response-to-request mapping. \nBoth of those practices seem too wasteful for us (though maybe\nthe disposable UDP socket cost isn&#39;t that high; I&#39;d need to run\ntests to be sure). \n\n- Gordon\n\n----- Original Message ----- \nFrom: &quot;G.B.Reddy&quot; &lt;reddy@...&gt;\nTo: &lt;archive-crawler@yahoogroups.com&gt;\nCc: &lt;wcr-team@...&gt;\nSent: Monday, March 17, 2003 12:07 PM\nSubject: Re: DNS and HTTP staging (was Re: [archive-crawler] Re: Web crawler work ??\n\n\n&gt; Gordon,\n&gt; \n&gt; I have checked in the first version of the asynchronous DNS lookup stage\n&gt; (DNSLookingUp.java). I have also updated the README and the anecdote.cfg\n&gt; file accordingly.\n&gt; \n&gt; I have made my first version without any changes in the dnsjava libraries.\n&gt; However, I would like to reorganize the dnsjava code to support proper\n&gt; interfaces for asynchronous queries. I can do it in the next 3 or 4 days.\n&gt; This would help us in the near future since it contains lot of useful\n&gt; features of a full fledged resolver. At present, my implementation requires\n&gt; that the name server be configured for recursion.\n&gt; \n&gt; At present, the code just prints the received DNS replies and errors. The\n&gt; results/errors are not set into the CrawlURI object yet.\n&gt; \n&gt; Please note that I have not yet updated the .project and .classpath files. I\n&gt; am yet to switch to eclipse.\n&gt; \n&gt; Thanks,\n&gt; Reddy\n&gt; \n&gt; \n&gt; ----- Original Message -----\n&gt; From: &quot;Gordon Mohr&quot; &lt;gojomo@...&gt;\n&gt; To: &quot;G.B.Reddy&quot; &lt;reddy@...&gt;\n&gt; Cc: &lt;wcr-team@...&gt;\n&gt; Sent: Tuesday, March 18, 2003 1:03 AM\n&gt; Subject: Re: DNS and HTTP staging (was Re: [archive-crawler] Re: Web crawler\n&gt; work ??\n&gt; \n&gt; \n&gt; &gt; Great -- I look forward to seeing your design in more detail.\n&gt; &gt;\n&gt; &gt; Feel free to check it into the &#39;Anecdote&#39; module -- for now,\n&gt; &gt; that&#39;s a scratch/prototyping area we can put the first working\n&gt; &gt; versions of things. Perhaps the package could be org.archive.util.dns\n&gt; &gt; or org.archive.seda.dns?\n&gt; &gt;\n&gt; &gt; I expect that when the system is a bit more stable and evolved, we&#39;ll\n&gt; &gt; move it to a new CVS module (and perhaps package structure).\n&gt; &gt;\n&gt; &gt; - Gordon\n&gt; &gt;\n&gt; &gt; ----- Original Message -----\n&gt; &gt; From: &quot;G.B.Reddy&quot; &lt;reddy@...&gt;\n&gt; &gt; To: &quot;Gordon Mohr&quot; &lt;gojomo@...&gt;\n&gt; &gt; Cc: &lt;wcr-team@...&gt;\n&gt; &gt; Sent: Friday, March 14, 2003 8:20 AM\n&gt; &gt; Subject: Re: DNS and HTTP staging (was Re: [archive-crawler] Re: Web\n&gt; crawler work ??\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; &gt; Gordon,\n&gt; &gt; &gt;\n&gt; &gt; &gt; I have made certain modifications to the dnsjava code to remove the\n&gt; tight\n&gt; &gt; &gt; coupling between the caching and the dns reply message processing. I\n&gt; would\n&gt; &gt; &gt; complete this and checkin on Monday.\n&gt; &gt; &gt;\n&gt; &gt; &gt; -Reddy\n&gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt; &gt; ----- Original Message -----\n&gt; &gt; &gt; From: &quot;G.B.Reddy&quot; &lt;reddy@...&gt;\n&gt; &gt; &gt; To: &quot;Gordon Mohr&quot; &lt;gojomo@...&gt;;\n&gt; &lt;archive-crawler@yahoogroups.com&gt;\n&gt; &gt; &gt; Cc: &lt;wcr-team@...&gt;\n&gt; &gt; &gt; Sent: Wednesday, March 12, 2003 9:44 PM\n&gt; &gt; &gt; Subject: Re: DNS and HTTP staging (was Re: [archive-crawler] Re: Web\n&gt; crawler\n&gt; &gt; &gt; work ??\n&gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Gordon,\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; I am done with the asynchronous DNS code. I shall test it more\n&gt; tomorrow\n&gt; &gt; &gt; and\n&gt; &gt; &gt; &gt; checkin. I may start using the caching mechanism present in the\n&gt; dnsjava\n&gt; &gt; &gt; &gt; libraries. They seem to be a bit tightly bound with the response\n&gt; &gt; &gt; processing\n&gt; &gt; &gt; &gt; code which I am using.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; The CrawlURI object as of now contains only the uri string. I would\n&gt; need\n&gt; &gt; &gt; &gt; variables for setting the ipaddress and other state to indicate lookup\n&gt; &gt; &gt; &gt; failures. Please let me know if you have any versions over it.\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; Thanks,\n&gt; &gt; &gt; &gt; Reddy\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; ----- Original Message -----\n&gt; &gt; &gt; &gt; From: &quot;Gordon Mohr&quot; &lt;gojomo@...&gt;\n&gt; &gt; &gt; &gt; To: &lt;archive-crawler@yahoogroups.com&gt;\n&gt; &gt; &gt; &gt; Cc: &lt;wcr-team@...&gt;\n&gt; &gt; &gt; &gt; Sent: Saturday, March 08, 2003 5:00 AM\n&gt; &gt; &gt; &gt; Subject: DNS and HTTP staging (was Re: [archive-crawler] Re: Web\n&gt; crawler\n&gt; &gt; &gt; &gt; work ??\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; These are good decompositions of the steps involved, and the LGPL\n&gt; &gt; &gt; dnsjava\n&gt; &gt; &gt; &gt; &gt; library looks very useful for our needs.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; My tendency would be to think fewer stages are better -- and when\n&gt; &gt; &gt; &gt; &gt; communicating between our stages, rather than using a shared\n&gt; RequestMap,\n&gt; &gt; &gt; &gt; &gt; include on the requesting event whatever context will be needed to\n&gt; deal\n&gt; &gt; &gt; &gt; &gt; with the response when it arrives.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; You can see this technique used in the ostore.network.ADns class I\n&gt; &gt; &gt; &gt; referenced\n&gt; &gt; &gt; &gt; &gt; yesterday -- the user_data object lets any client of the ADns stage\n&gt; &gt; &gt; &gt; recover\n&gt; &gt; &gt; &gt; &gt; the state it needs to deal with ADns&#39;s eventual response. (We may\n&gt; still\n&gt; &gt; &gt; &gt; need\n&gt; &gt; &gt; &gt; &gt; the equivalent of a RequestMap to deal with mapping UDP response\n&gt; packets\n&gt; &gt; &gt; &gt; to\n&gt; &gt; &gt; &gt; &gt; the lookups that triggered them -- but that&#39;d then be a map that can\n&gt; be\n&gt; &gt; &gt; &gt; private\n&gt; &gt; &gt; &gt; &gt; to a single stage.)\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Nothing in the DNS procedure needs to block -- once you assume\n&gt; &gt; &gt; &gt; asynchronous\n&gt; &gt; &gt; &gt; &gt; UDP replies and an in-RAM response cache -- and thus one thread\n&gt; should\n&gt; &gt; &gt; be\n&gt; &gt; &gt; &gt; &gt; as good as (in fact better than) N threads.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Similarly, I don&#39;t think more than 1 UDP socket will be necessary\n&gt; for\n&gt; &gt; &gt; &gt; &gt; all DNS lookups, because as a practical matter, 1 open UDP socket\n&gt; will\n&gt; &gt; &gt; &gt; &gt; never be &quot;busy&quot; in a way that additional UDP sockets would help.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; --\n&gt; &gt; &gt; &gt; &gt; Regarding 404 and other explicit HTTP app errors: these should be\n&gt; &gt; &gt; recorded\n&gt; &gt; &gt; &gt; &gt; into the CrawlURI, and forwarded to the next processing stage, just\n&gt; as\n&gt; &gt; &gt; &gt; &gt; with successes.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Redirects are a special case we haven&#39;t discussed much yet; they\n&gt; would\n&gt; &gt; &gt; &gt; seem\n&gt; &gt; &gt; &gt; &gt; candidates for some sort of expedited fetching. I think, though,\n&gt; such\n&gt; &gt; &gt; &gt; &gt; expedited activity must pass through the full cycle of stages for\n&gt; &gt; &gt; &gt; &gt; proper logging and policy application. (In contrast, retries in the\n&gt; face\n&gt; &gt; &gt; &gt; &gt; of transient errors, which may, at least in some cases, be fed\n&gt; &gt; &gt; immediately\n&gt; &gt; &gt; &gt; &gt; back to the Fetching or Preprocessing stages.)\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; --\n&gt; &gt; &gt; &gt; &gt; The issue of timeouts (esp. in HTTP) is thorny. From what I hear\n&gt; about\n&gt; &gt; &gt; &gt; &gt; crawler traps, we need to not only to be able to deal with hangs,\n&gt; but\n&gt; &gt; &gt; &gt; &gt; also various infinite-length trickles.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; If any of the HTTP-transactions-in-progress is not making sufficient\n&gt; &gt; &gt; &gt; &gt; progress, according to some set of progress-per-time-unit\n&gt; thresholds,\n&gt; &gt; &gt; &gt; &gt; we have to be ready to give up on it. We should mark it as an error,\n&gt; &gt; &gt; &gt; &gt; but probably retain any partial info we did get for later analysis.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Separating this out into its own stage increases synchronization\n&gt; issues.\n&gt; &gt; &gt; &gt; &gt; If timeout analysis can instead be part of the same single-threaded\n&gt; &gt; &gt; stage\n&gt; &gt; &gt; &gt; &gt; where HTTP some-progress-made events (from sockets) are handled, I\n&gt; think\n&gt; &gt; &gt; &gt; &gt; it can be handled very efficiently:\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;    - keep all outstanding transactions on a linked-list\n&gt; &gt; &gt; &gt; &gt;    - whenever progress is reported (from the socket),\n&gt; &gt; &gt; &gt; &gt;      and that progress keeps the transaction above\n&gt; &gt; &gt; &gt; &gt;      acceptable thresholds, move that transaction to\n&gt; &gt; &gt; &gt; &gt;      the head of the list\n&gt; &gt; &gt; &gt; &gt;    - check the tail of the list occasionally to see\n&gt; &gt; &gt; &gt; &gt;      if the worst transactions need to be cut\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; That &quot;occasional&quot; check could mostly occur as part of normal\n&gt; &gt; &gt; &gt; &gt; progress-packet processing; an extremely infrequent timer could\n&gt; &gt; &gt; &gt; &gt; trigger reevaluation in the rare case where all progress on all\n&gt; &gt; &gt; &gt; &gt; sockets has stopped...\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; - Gordon\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; ----- Original Message -----\n&gt; &gt; &gt; &gt; &gt; From: G.B.Reddy\n&gt; &gt; &gt; &gt; &gt; To: archive-crawler@yahoogroups.com\n&gt; &gt; &gt; &gt; &gt; Cc: wcr-team@...\n&gt; &gt; &gt; &gt; &gt; Sent: Friday, March 07, 2003 8:31 AM\n&gt; &gt; &gt; &gt; &gt; Subject: Re: [archive-crawler] Re: Web crawler work ??\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; More insight on the DNS stages.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; As stated in the design earlier, &quot;DNS Querying Stage&quot;, &quot;DNS Response\n&gt; &gt; &gt; &gt; Processing Stage&quot; and &quot;Timeout and Retry Handling Stage&quot;\n&gt; &gt; &gt; &gt; &gt; access/update the shared RequestMap. So, they need to be\n&gt; synchronized.\n&gt; &gt; &gt; We\n&gt; &gt; &gt; &gt; were just thinking whether these need to be three separate\n&gt; &gt; &gt; &gt; &gt; stages or could it be one stage multiplexing each of those incoming\n&gt; &gt; &gt; event\n&gt; &gt; &gt; &gt; types. The pros and cons of them are as below.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Single stage benefit / Multi Stage Issue :\n&gt; &gt; &gt; &gt; &gt; - If it is single stage, then synchronization is not done across\n&gt; stages.\n&gt; &gt; &gt; &gt; Even though, synchronization anyway would be needed\n&gt; &gt; &gt; &gt; &gt; internally in case of single stage, conceptually it looks neater not\n&gt; to\n&gt; &gt; &gt; &gt; synchronize across stages.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Single stage issue / Multi Stage benefit :\n&gt; &gt; &gt; &gt; &gt; - In case of single stage, the event queue would be one and this\n&gt; fact\n&gt; &gt; &gt; &gt; pulls our legs when we want to handle overload conditions.\n&gt; &gt; &gt; &gt; &gt; Since there is no clear count of the distinct elements in the queue,\n&gt; it\n&gt; &gt; &gt; &gt; becomes difficult to analyse and condition the system\n&gt; &gt; &gt; &gt; &gt; accordingly. Whereas, in multi stage, each one having its own queue,\n&gt; &gt; &gt; &gt; conditioning/prioritizating becomes easy.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; I think we would end up going in for multi stage, unless SEDA could\n&gt; take\n&gt; &gt; &gt; &gt; care of it by itself.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; And in case of parallel stages, like the ones in post processing, I\n&gt; &gt; &gt; think\n&gt; &gt; &gt; &gt; most often, synchronization across them may be\n&gt; &gt; &gt; &gt; &gt; unavoidable.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Thanks,\n&gt; &gt; &gt; &gt; &gt; Reddy\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; ----- Original Message -----\n&gt; &gt; &gt; &gt; &gt; From: G.B.Reddy\n&gt; &gt; &gt; &gt; &gt; To: archive-crawler@yahoogroups.com\n&gt; &gt; &gt; &gt; &gt; Cc: wcr-team@...\n&gt; &gt; &gt; &gt; &gt; Sent: Thursday, March 06, 2003 11:21 PM\n&gt; &gt; &gt; &gt; &gt; Subject: Re: [archive-crawler] Re: Web crawler work ??\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Gordon and Raymie,\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Below are the various stages and their design with the issues\n&gt; involved\n&gt; &gt; &gt; in\n&gt; &gt; &gt; &gt; the DNS Resolver and HTTP Client implementation.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; DNS History/Cache Handling Stage :\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Overview:\n&gt; &gt; &gt; &gt; &gt; - Maintains successful lookups in cache.\n&gt; &gt; &gt; &gt; &gt; - Does negative caching.\n&gt; &gt; &gt; &gt; &gt; - Times itself to clean the expired entries based on TTL. (Would use\n&gt; the\n&gt; &gt; &gt; &gt; ssTimer SEDA APIs to schedule itself periodically)\n&gt; &gt; &gt; &gt; &gt; - This stage would be dummy or could be skipped as of now since we\n&gt; want\n&gt; &gt; &gt; to\n&gt; &gt; &gt; &gt; do caching later.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Events:\n&gt; &gt; &gt; &gt; &gt; - Two types of events : DNSCacheLookupEvent, DNSCacheUpdateEvent.\n&gt; &gt; &gt; &gt; &gt; - DNSCacheLookupEvent : If entry is found in cache, the ipaddress is\n&gt; set\n&gt; &gt; &gt; &gt; in the CrawlURI object and is enqueued into the &quot;Page\n&gt; &gt; &gt; &gt; &gt; Requesting Stage&quot;. Else, it is enqueued into the &quot;DNS Querying\n&gt; Stage&quot;.\n&gt; &gt; &gt; &gt; &gt; - DNSCacheUpdateEvent : This event is published by the &quot;DNS Response\n&gt; &gt; &gt; &gt; Processing Stage&quot; every after successful/failed lookup inorder\n&gt; &gt; &gt; &gt; &gt; to update the cache.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Other notes:\n&gt; &gt; &gt; &gt; &gt; - This stage could be single threaded else lot of synchronization\n&gt; might\n&gt; &gt; &gt; be\n&gt; &gt; &gt; &gt; needed.\n&gt; &gt; &gt; &gt; &gt; - Resubmitting events on queue full exceptions while enqueuing into\n&gt; this\n&gt; &gt; &gt; &gt; stage&#39;s queue should be handled by the caller by scheduling\n&gt; &gt; &gt; &gt; &gt; it in future.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; DNS Querying Stage :\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Overview:\n&gt; &gt; &gt; &gt; &gt; - Sends the actual DNS ARecord query packets to the DNS Server. (The\n&gt; &gt; &gt; &gt; response packets are processed in a later stage)\n&gt; &gt; &gt; &gt; &gt; - Maintains a pool of DatagramSocket objects.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Events:\n&gt; &gt; &gt; &gt; &gt; - SendDNSQueryEvent : This is published by the &quot;DNS History/Cache\n&gt; &gt; &gt; Handling\n&gt; &gt; &gt; &gt; Stage&quot; when cache miss happens. The DNS query is formed\n&gt; &gt; &gt; &gt; &gt; and sent out. The response handling sink is set as the &quot;DNS Response\n&gt; &gt; &gt; &gt; Processing Stage&quot;.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Implementation:\n&gt; &gt; &gt; &gt; &gt; - A pool of DatagramSockets of a configurable maximum size is\n&gt; &gt; &gt; maintained.\n&gt; &gt; &gt; &gt; It will be filled incrementally. All these datagram\n&gt; &gt; &gt; &gt; &gt; sockets will be registered to the selector maintained by the SEDA\n&gt; &gt; &gt; &gt; internals. It would be ideal if this pool gets shrunk or expanded\n&gt; &gt; &gt; &gt; &gt; based on the requirement. If it is not shrunk back, then it is an\n&gt; &gt; &gt; &gt; unnecessary overhead on the selector. The reason behind having a\n&gt; &gt; &gt; &gt; &gt; pool is to restrict the number of ports the selector has to listen\n&gt; upon\n&gt; &gt; &gt; &gt; and also not to create individual DatagramSocket objects for\n&gt; &gt; &gt; &gt; &gt; every query. Can this logic of bounded pool, be implemented as a\n&gt; &gt; &gt; &gt; Controller in the SEDA framework (just like the\n&gt; &gt; &gt; &gt; &gt; ThreadPoolController) is an open question.\n&gt; &gt; &gt; &gt; &gt; - When an event comes in, a free datagram socket in the pool will be\n&gt; &gt; &gt; &gt; utilized for sending the message. If all sockets are engaged,\n&gt; &gt; &gt; &gt; &gt; the incoming event should be postponed to reenter again after a\n&gt; period\n&gt; &gt; &gt; of\n&gt; &gt; &gt; &gt; time.\n&gt; &gt; &gt; &gt; &gt; - This stage additionally has also to maintain the list of messages\n&gt; sent\n&gt; &gt; &gt; &gt; out, their IDs and the request timestamps. Let us call this\n&gt; &gt; &gt; &gt; &gt; &quot;RequestMap&quot; for future reference. The ID is the integer, described\n&gt; in\n&gt; &gt; &gt; the\n&gt; &gt; &gt; &gt; RFC DNS message format, used to map the\n&gt; &gt; &gt; &gt; &gt; request-responses. The request timestamp will be made use of in\n&gt; query\n&gt; &gt; &gt; &gt; timeout handling (discussed later).\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Parameters to this stage :\n&gt; &gt; &gt; &gt; &gt; - The DNS server hostname/ipaddress. If this is not given, then the\n&gt; &gt; &gt; &gt; /etc/resolve.conf will be parsed to get the name server (only\n&gt; &gt; &gt; &gt; &gt; the primary would be taken as of now.). As a next step we will have\n&gt; to\n&gt; &gt; &gt; &gt; build a round-robin way of querying the various name servers\n&gt; &gt; &gt; &gt; &gt; in resolve.conf, inorder to be polite with them.\n&gt; &gt; &gt; &gt; &gt; - If resolve.conf is not present, the local host will be assumed as\n&gt; the\n&gt; &gt; &gt;\n&gt; &gt; &gt; &gt; name server.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; DNS Response Processing Stage :\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Overview:\n&gt; &gt; &gt; &gt; &gt; - Processes DNS responses.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Implementation:\n&gt; &gt; &gt; &gt; &gt; - When the DNS datagram packets are received, the ID field in the\n&gt; header\n&gt; &gt; &gt; &gt; should be used to match the corresponding request packet.\n&gt; &gt; &gt; &gt; &gt; - Check for timeouts, and discard it if it had timed out; else, set\n&gt; the\n&gt; &gt; &gt; &gt; ipaddress/canonical name in the CrawlURI object and enqueue\n&gt; &gt; &gt; &gt; &gt; it to the &quot;Page Requesting Stage&quot;. In addition, enqueue an event\n&gt; into\n&gt; &gt; &gt; the\n&gt; &gt; &gt; &gt; &quot;DNS Cache Handling Stage&quot; for it to update its cache. Do\n&gt; &gt; &gt; &gt; &gt; the same, even on DNS Errors like &quot;Name not found authoritative\n&gt; error&quot;.\n&gt; &gt; &gt; &gt; &gt; - The request entry in the RequestMap (maintained for timeout\n&gt; handling)\n&gt; &gt; &gt; &gt; should be removed. This map, being shared across stages,\n&gt; &gt; &gt; &gt; &gt; should be synchronized.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; HTTP Page Requesting Stage :\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Overview:\n&gt; &gt; &gt; &gt; &gt; - Connects to host and sends GET requests for pages.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Events:\n&gt; &gt; &gt; &gt; &gt; - Handles two types of events - StartFetchEvent and\n&gt; &gt; &gt; &gt; ConnectionCompleteEvent.\n&gt; &gt; &gt; &gt; &gt; - The StartFetchEvent will make a TCP connect request to the host.\n&gt; While\n&gt; &gt; &gt; &gt; doing so, we will register the current stage itself to\n&gt; &gt; &gt; &gt; &gt; receive back the ConnectionComplete events. Once we receive this\n&gt; &gt; &gt; &gt; ConnectionCompleteEvent, we should send a HTTP GET request to the\n&gt; &gt; &gt; &gt; &gt; page. The response handling sink is set as the &quot;HTTP Response\n&gt; Processing\n&gt; &gt; &gt; &gt; Stage&quot;. Write failures should be handled.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; HTTP Response Processing Stage :\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Overview:\n&gt; &gt; &gt; &gt; &gt; - Processes downloaded pages.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Implementation:\n&gt; &gt; &gt; &gt; &gt; - Check for timeouts, and discard it if it had timed out; else, read\n&gt; the\n&gt; &gt; &gt; &gt; packets.\n&gt; &gt; &gt; &gt; &gt; - Once the response is completely read, the request entry in the\n&gt; &gt; &gt; &gt; RequestMap (maintained for timeout handling) should be removed.\n&gt; &gt; &gt; &gt; &gt; - One issue here is when we are reading lengthy HTML pages, we might\n&gt; &gt; &gt; &gt; receive half of the page and it might stop after that. So,\n&gt; &gt; &gt; &gt; &gt; essentially the timeout should be applied between chunks of\n&gt; reception.\n&gt; &gt; &gt; &gt; &gt; - Where should the errors like &quot;404 Not Found&quot;, etc be propogated\n&gt; ???\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Timeout and Retry Handling Stage :\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Overview:\n&gt; &gt; &gt; &gt; &gt; This is a single threaded stage which enumerates through the\n&gt; RequestMap\n&gt; &gt; &gt; &gt; and checks for timeouts. The timed out CrawlURIs will be\n&gt; &gt; &gt; &gt; &gt; retried until retry count exhausts. This stage will be self-timed\n&gt; &gt; &gt; &gt; periodically using the SEDA ssTimer APIs.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Other Notes:\n&gt; &gt; &gt; &gt; &gt; This timeout handling is a common stuff between the DNS requests and\n&gt; the\n&gt; &gt; &gt; &gt; HTTP requests.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Parameters to this stage:\n&gt; &gt; &gt; &gt; &gt; - DNS timeout value.\n&gt; &gt; &gt; &gt; &gt; - HTTP timeout value.\n&gt; &gt; &gt; &gt; &gt; - DNS retry count.\n&gt; &gt; &gt; &gt; &gt; - HTTP retry count. ( This would be 1 ).\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; One other thing that could be done is that, the events by themselves\n&gt; &gt; &gt; will\n&gt; &gt; &gt; &gt; contain information as to which next stage the output has\n&gt; &gt; &gt; &gt; &gt; to traverse. This will be flexible and no hardcoding is needed.\n&gt; &gt; &gt; &gt; Especially, in making this non-blocking DNS library an open-source,\n&gt; &gt; &gt; &gt; &gt; it would come handy. Moreover, many users might not want it to be\n&gt; over\n&gt; &gt; &gt; &gt; SEDA. So, we will have to give other interfaces as well.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; I am presently using the library classes given by dnsjava-1.3.2. (\n&gt; &gt; &gt; &gt; http://sourceforge.net/projects/dnsjava/ ). This is an LGPL java\n&gt; &gt; &gt; &gt; &gt; based synchronous implementation of DNS Resolver. I only make use of\n&gt; the\n&gt; &gt; &gt; &gt; classes which encapsulate the formation of request packets,\n&gt; &gt; &gt; &gt; &gt; parses response packets and the various ResourceRecord classes. This\n&gt; &gt; &gt; &gt; library is being used by Java Apache Mail Enterprise Server (\n&gt; &gt; &gt; &gt; &gt; http://james.apache.org/ ). So, it should be pretty reliable and\n&gt; tested.\n&gt; &gt; &gt; &gt; Moreover it has support for IPv6, compression and security\n&gt; &gt; &gt; &gt; &gt; which we can make use of later.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Thanks,\n&gt; &gt; &gt; &gt; &gt; Reddy\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; ----- Original Message -----\n&gt; &gt; &gt; &gt; &gt; From: Gordon Mohr\n&gt; &gt; &gt; &gt; &gt; To: archive-crawler@yahoogroups.com\n&gt; &gt; &gt; &gt; &gt; Cc: Raymie Stata ; wcr-team@...\n&gt; &gt; &gt; &gt; &gt; Sent: Saturday, March 01, 2003 2:43 AM\n&gt; &gt; &gt; &gt; &gt; Subject: Re: [archive-crawler] Re: Web crawler work ??\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Sounds like a reasonable plan.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; By &quot;local name server&quot; do you mean something *very* local -- for\n&gt; &gt; &gt; example,\n&gt; &gt; &gt; &gt; &gt; a standard nameserver we run on the same machine?\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; That would seem to offer other benefits -- such as minimizing the\n&gt; modes\n&gt; &gt; &gt; &gt; &gt; of DNS lookup we have to do and offloading caching to another piece\n&gt; of\n&gt; &gt; &gt; &gt; &gt; software (at least at first).\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; - Gordon\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; ----- Original Message -----\n&gt; &gt; &gt; &gt; &gt; From: G.B.Reddy\n&gt; &gt; &gt; &gt; &gt; To: archive-crawler@yahoogroups.com\n&gt; &gt; &gt; &gt; &gt; Cc: Raymie Stata ; wcr-team@...\n&gt; &gt; &gt; &gt; &gt; Sent: Thursday, February 27, 2003 8:55 AM\n&gt; &gt; &gt; &gt; &gt; Subject: Re: [archive-crawler] Re: Web crawler work ??\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Gordon and Raymie,\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Here goes the proposal for the asynchronous DNS lookup API\n&gt; &gt; &gt; implementation.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; We shall implement a minimal resolver which is capable of sending\n&gt; DNS\n&gt; &gt; &gt; &gt; request packets and processing response packets in an\n&gt; &gt; &gt; &gt; &gt; asynchrounous nio fashion. This resolver class will contact a local\n&gt; name\n&gt; &gt; &gt; &gt; server and rely on it to do the actual lookup. The local\n&gt; &gt; &gt; &gt; &gt; name server will be configured to support recursion and better would\n&gt; be\n&gt; &gt; &gt; to\n&gt; &gt; &gt; &gt; use a name server which does lookup asynchronously. (\n&gt; &gt; &gt; &gt; &gt; SQUID has asynchronous DNS lookup facilities ).  Even if the local\n&gt; name\n&gt; &gt; &gt; &gt; server is not asynchrounous, our java resolver being\n&gt; &gt; &gt; &gt; &gt; asynchronous will be good enough since our primary goal is that we\n&gt; do\n&gt; &gt; &gt; not\n&gt; &gt; &gt; &gt; want any blocking code in our crawler implementation. This\n&gt; &gt; &gt; &gt; &gt; idea even sounds good considering the fact we would only reinvent\n&gt; the\n&gt; &gt; &gt; same\n&gt; &gt; &gt; &gt; wheel if we opt to implement a complete full-fledged\n&gt; &gt; &gt; &gt; &gt; resolver implementation which complies with the RFC 1035 and 1034.\n&gt; We\n&gt; &gt; &gt; can\n&gt; &gt; &gt; &gt; definitely implement this full-fledged resolver but the\n&gt; &gt; &gt; &gt; &gt; real concern is that this would require a lot of testing and the\n&gt; efforts\n&gt; &gt; &gt; &gt; to make it rock solid in terms of robustness would be huge.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; So, the various jobs that we would have to do to build our Simple\n&gt; &gt; &gt; &gt; Asynchronous DNS lookup API would be\n&gt; &gt; &gt; &gt; &gt;     -- Request packet formation and reply packet parsing in the\n&gt; exact\n&gt; &gt; &gt; RFC\n&gt; &gt; &gt; &gt; format.\n&gt; &gt; &gt; &gt; &gt;     -- Use non-blocking IO APIs and do UDP. (We might not need TCP\n&gt; since\n&gt; &gt; &gt; &gt; the name server is only in the local network.)\n&gt; &gt; &gt; &gt; &gt;     -- Do canonical name queries and A record queries.\n&gt; &gt; &gt; &gt; &gt;     -- Implement timeouts.\n&gt; &gt; &gt; &gt; &gt;     -- Implement caching based on TTL. ( This may have to be\n&gt; deferred as\n&gt; &gt; &gt; &gt; pointed by Raymie earlier. )\n&gt; &gt; &gt; &gt; &gt;     -- Integrate with SEDA.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Thanks,\n&gt; &gt; &gt; &gt; &gt; Reddy\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; ----- Original Message -----\n&gt; &gt; &gt; &gt; &gt; From: Gordon Mohr\n&gt; &gt; &gt; &gt; &gt; To: G.B.Reddy\n&gt; &gt; &gt; &gt; &gt; Cc: Raymie Stata ; wcr-team@... ;\n&gt; &gt; &gt; &gt; archive-crawler@yahoogroups.com\n&gt; &gt; &gt; &gt; &gt; Sent: Saturday, February 22, 2003 5:37 AM\n&gt; &gt; &gt; &gt; &gt; Subject: [archive-crawler] Re: Web crawler work ??\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; [CC&#39;ing to archive-crawler@yahoogroups.com]\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Reddy writes:\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; On the first cut do we need to look at implementing an\n&gt; asynchronous\n&gt; &gt; &gt; DNS\n&gt; &gt; &gt; &gt; &gt; &gt; lookup mechanism. If we are not, then it is going to be two\n&gt; stages,\n&gt; &gt; &gt; viz.\n&gt; &gt; &gt; &gt; &gt; &gt; DNSCacheHandlingStage and ResolvingStage, that can be employed\n&gt; using\n&gt; &gt; &gt; the\n&gt; &gt; &gt; &gt; &gt; &gt; blocking DNS lookup calls in Java. The first stage,\n&gt; &gt; &gt; &gt; DNSCacheHandlingStage,\n&gt; &gt; &gt; &gt; &gt; &gt; would check if the entry is available in the cache. If available,\n&gt; he\n&gt; &gt; &gt; &gt; would\n&gt; &gt; &gt; &gt; &gt; &gt; set the resolved address in the CrawlURI object and enqueue it to\n&gt; the\n&gt; &gt; &gt; &gt; &gt; &gt; appropriate next stage. If the cache doesn&#39;t contain the entry,\n&gt; then\n&gt; &gt; &gt; he\n&gt; &gt; &gt; &gt; &gt; &gt; would pass the request to the Resolving stage which would call the\n&gt; &gt; &gt; &gt; &gt; &gt; InetAddress.getByName blocking method to resolve it. The getByName\n&gt; &gt; &gt; &gt; result\n&gt; &gt; &gt; &gt; &gt; &gt; would be set in the CrawlURI object as before and enqueued into\n&gt; the\n&gt; &gt; &gt; &gt; &gt; &gt; appropriate next stage. In addition to this, the Resolving stage\n&gt; will\n&gt; &gt; &gt; &gt; &gt; &gt; enqueue another event into the DNSCacheHandlingStage to enable him\n&gt; &gt; &gt; &gt; update\n&gt; &gt; &gt; &gt; &gt; &gt; his cache. So, the DNSCacheHandlingStage would be handling two\n&gt; types\n&gt; &gt; &gt; of\n&gt; &gt; &gt; &gt; &gt; &gt; events, one is the lookup events and the other is the update cache\n&gt; &gt; &gt; &gt; events.\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; One problem here is that the InetAddress class does not expose its\n&gt; &gt; &gt; cache\n&gt; &gt; &gt; &gt; &gt; &gt; variables to its users. Even we cannot check if the cache has an\n&gt; entry\n&gt; &gt; &gt; &gt; &gt; &gt; before calling the getByName method. So, we should be disabling\n&gt; the\n&gt; &gt; &gt; java\n&gt; &gt; &gt; &gt; &gt; &gt; cache ( using the policy file ) and implementing our own caching\n&gt; &gt; &gt; &gt; mechanism.\n&gt; &gt; &gt; &gt; &gt; &gt; ( The DNSCacheHandlingStage would have to additionally do the job\n&gt; of\n&gt; &gt; &gt; &gt; &gt; &gt; throwing away the expired entries in the cache also.)\n&gt; &gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; Let me know your comments on this.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; This looks like a good first cut. I&#39;m still working to improve my\n&gt; &gt; &gt; &gt; &gt; understanding of the best way to use the staged style, mostly by\n&gt; &gt; &gt; &gt; &gt; looking at their HTTP and HTTP Server (Haboob) code.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; It seems that they&#39;ve tended to use a single Stage object to do\n&gt; &gt; &gt; &gt; &gt; many different steps/aspects of one process, by switching on the\n&gt; &gt; &gt; &gt; &gt; type of QueueElement received.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; So for example their seda.sandStorm.seda.apps.Haboob.http.HttpRecv\n&gt; &gt; &gt; &gt; &gt; accepts events of types....\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;   - httpConnection\n&gt; &gt; &gt; &gt; &gt;   - httpRequest\n&gt; &gt; &gt; &gt; &gt;   - SinkClosedEvent\n&gt; &gt; &gt; &gt; &gt;   - timerEvent\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; And their seda.sandStorm.lib.http.httpServer accepts events of\n&gt; &gt; &gt; &gt; &gt; types...\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;   - ATcpInPacket\n&gt; &gt; &gt; &gt; &gt;   - ATcpConnection\n&gt; &gt; &gt; &gt; &gt;   - aSocketErrorEvent\n&gt; &gt; &gt; &gt; &gt;   - SinkDrainedEvent\n&gt; &gt; &gt; &gt; &gt;   - SinkCloggedEvent\n&gt; &gt; &gt; &gt; &gt;   - SinkClosedEvent\n&gt; &gt; &gt; &gt; &gt;   - ATcpListenSuccessEvent\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; They also use Sinks that are not associated with stages; rather,\n&gt; &gt; &gt; &gt; &gt; they interface to unstaged components which nonetheless result in\n&gt; &gt; &gt; &gt; &gt; an eventual event to some supplied answer Sink. See for example\n&gt; &gt; &gt; &gt; &gt; seda.sandStorm.lib.http.httpConnection.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; So perhaps as a matter of grouping related tasks, the same Stage\n&gt; object\n&gt; &gt; &gt; &gt; &gt; should be re-entered over the course of a lookup, with different\n&gt; &gt; &gt; &gt; triggering\n&gt; &gt; &gt; &gt; &gt; events. For example, you might want to reenter a single\n&gt; &gt; &gt; DNSResolvingStage\n&gt; &gt; &gt; &gt; &gt; over the course of cache lookup, lookup-initiation, result-receiving\n&gt; (or\n&gt; &gt; &gt; &gt; &gt; timeout), etc. I&#39;m not sure; use your judgement as to how many\n&gt; stages\n&gt; &gt; &gt; are\n&gt; &gt; &gt; &gt; &gt; really needed.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; &gt; P.S : We found some openly available async dns client APIs in C\n&gt; &gt; &gt; &gt; language.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; That could be useful as a model. (I doubt we&#39;d want to call out to C\n&gt; &gt; &gt; &gt; &gt; for this simple step, though -- and if we nailed down a truly async\n&gt; Java\n&gt; &gt; &gt; &gt; &gt; DNS facility, a lot of open source projects would probably be quite\n&gt; &gt; &gt; &gt; happy.)\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Also: I heard back from Patrick Eaton about SEDA-style async HTTP\n&gt; client\n&gt; &gt; &gt; &gt; &gt; code... he has a rough implementation for simple usage, and he knows\n&gt; of\n&gt; &gt; &gt; &gt; &gt; another one at Berkeley which goes deeper into HTTP/1.1 conformance\n&gt; and\n&gt; &gt; &gt; &gt; &gt; optimal performance. I&#39;ve asked him to forward whatever additional\n&gt; code\n&gt; &gt; &gt; &gt; &gt; or details he can.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; - Gordon\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; To unsubscribe from this group, send an email to:\n&gt; &gt; &gt; &gt; &gt; archive-crawler-unsubscribe@yahoogroups.com\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Your use of Yahoo! Groups is subject to the Yahoo! Terms of Service.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Yahoo! Groups Sponsor\n&gt; &gt; &gt; &gt; &gt; ADVERTISEMENT\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; To unsubscribe from this group, send an email to:\n&gt; &gt; &gt; &gt; &gt; archive-crawler-unsubscribe@yahoogroups.com\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Your use of Yahoo! Groups is subject to the Yahoo! Terms of Service.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; To unsubscribe from this group, send an email to:\n&gt; &gt; &gt; &gt; &gt; archive-crawler-unsubscribe@yahoogroups.com\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Your use of Yahoo! Groups is subject to the Yahoo! Terms of Service.\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Yahoo! Groups Sponsor\n&gt; &gt; &gt; &gt; &gt; ADVERTISEMENT\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; To unsubscribe from this group, send an email to:\n&gt; &gt; &gt; &gt; &gt; archive-crawler-unsubscribe@yahoogroups.com\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt; &gt; &gt; Your use of Yahoo! Groups is subject to the Yahoo! Terms of Service.\n&gt; &gt; &gt;\n&gt; \n&gt; \n&gt; \n&gt; To unsubscribe from this group, send an email to:\n&gt; archive-crawler-unsubscribe@yahoogroups.com\n&gt; \n&gt;  \n&gt; \n&gt; Your use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/ \n&gt; \n&gt; \n\n"}}