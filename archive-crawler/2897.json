{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":256901594,"authorName":"jonathansiddharth","from":"&quot;jonathansiddharth&quot; &lt;jonathansiddharth@...&gt;","profile":"jonathansiddharth","replyTo":"LIST","senderId":"jR67VnN7FNSExTfw9KQpJMvTkJm4u0qurO0hh_pWmd9fzOWCVi-WkHfauhMQkWDkzqrcrLr3_i8dSlHcifw1w860DrhlhIC6K_Y8D4S2801O0JYmU77PMrWO","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: failed to get char replay sequence","postDate":"1149166200","msgId":2897,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGU1bW5wbys0OXRlQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDQ0N0U4MzNGLjUwOTAzMDFAYXJjaGl2ZS5vcmc+"},"prevInTopic":2893,"nextInTopic":2898,"prevInTime":2896,"nextInTime":2898,"topicId":2891,"numMessagesInTopic":8,"msgSnippet":"Thanks for the reply St.Ack. I think you re right. Although I got these alerts, I dont think the crawl terminated because of that. Because on re-running the","rawEmail":"Return-Path: &lt;jonathansiddharth@...&gt;\r\nX-Sender: jonathansiddharth@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 67037 invoked from network); 1 Jun 2006 12:50:47 -0000\r\nReceived: from unknown (66.218.66.218)\n  by m23.grp.scd.yahoo.com with QMQP; 1 Jun 2006 12:50:47 -0000\r\nReceived: from unknown (HELO n14c.bullet.sc5.yahoo.com) (66.163.187.205)\n  by mta3.grp.scd.yahoo.com with SMTP; 1 Jun 2006 12:50:47 -0000\r\nComment: DomainKeys? See http://antispam.yahoo.com/domainkeys\r\nReceived: from [66.163.187.120] by n14.bullet.sc5.yahoo.com with NNFMP; 01 Jun 2006 12:50:00 -0000\r\nReceived: from [66.218.66.59] by t1.bullet.sc5.yahoo.com with NNFMP; 01 Jun 2006 12:50:00 -0000\r\nReceived: from [66.218.66.87] by t8.bullet.scd.yahoo.com with NNFMP; 01 Jun 2006 12:50:00 -0000\r\nDate: Thu, 01 Jun 2006 12:50:00 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;e5mnpo+49te@...&gt;\r\nIn-Reply-To: &lt;447E833F.5090301@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: &quot;jonathansiddharth&quot; &lt;jonathansiddharth@...&gt;\r\nSubject: Re: failed to get char replay sequence\r\nX-Yahoo-Group-Post: member; u=256901594; y=FCB6hndb_IdbCoZKWSxSEmqFP8j3Sf1y5Vs6icsIIl-KhQpc7vYvnslCmOk\r\nX-Yahoo-Profile: jonathansiddharth\r\n\r\nThanks for the reply St.Ack.\nI think you&#39;re right. Although I got these ale=\r\nrts, I dont think the\ncrawl terminated because of that.\nBecause on re-runni=\r\nng the crawl it again mysteriously stopped after a\n(long) time even though =\r\nI&#39;m sure the crawl was not completed. It was\nonly some 5% done. And this ti=\r\nme there were no alerts.\nHowever I saw some errors in the local-errors.log =\r\nof this sort\n\n2006-06-01T04:42:01.909Z    -2          -\nhttp://en.wikipedia=\r\n.org/wiki/J%C3%BCrgen_Habermas LL\nhttp://en.wikipedia.org/wiki/Bernard_Will=\r\niams no-type #032 - - -\nle:SocketTimeoutException@HTTP\n java.net.SocketTime=\r\noutException: connect timed out: timeout set at\n20000ms.\n\tat\norg.archive.cr=\r\nawler.fetcher.HeritrixProtocolSocketFactory.createSocket(HeritrixProtocolSo=\r\ncketFactory.java:142)\n\tat\norg.apache.commons.httpclient.HttpConnection.open=\r\n(HttpConnection.java:707)\n\tat\norg.apache.commons.httpclient.HttpMethodDirec=\r\ntor.executeWithRetry(HttpMethodDirector.java:382)\n\tat\norg.apache.commons.ht=\r\ntpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:168)\n\tat\n=\r\norg.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:396)=\r\n\n\tat\norg.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java=\r\n:324)\n\tat org.archive.crawler.fetcher.FetchHTTP.innerProcess(FetchHTTP.java=\r\n:408)\n\tat org.archive.crawler.framework.Processor.process(Processor.java:10=\r\n3)\n\tat\norg.archive.crawler.framework.ToeThread.processCrawlUri(ToeThread.ja=\r\nva:306)\n\tat org.archive.crawler.framework.ToeThread.run(ToeThread.java:153)=\r\n\n\n\n\nThere were 2 errors like this. \nI doubt if this caused the crawl to end=\r\n though. Since there were two\nof these and if it was really terminal the fi=\r\nrst one should have\nbrought the crawl to an end.\n\n\nis there anyother condit=\r\nion for which the crawler gracefully gives up.\nLike if there are too many U=\r\nRLs in the frontier queue.\nI&#39;m assuming a heap overflow would have an expli=\r\ncit error message\nindicating that.\n\n(My estimated crawl job time was 4 days=\r\n)\n\n\nthanks,\nJonathan\n\n\n\n\n\n\n\n--- In archive-crawler@yahoogroups.com, Michael=\r\n Stack &lt;stack@...&gt; wrote:\n&gt;\n&gt; jonathansiddharth wrote:\n&gt; &gt; Hi,\n&gt; &gt;         =\r\nThis alert/exception abruptly terminated my crawl job. Could\n&gt; &gt; someone te=\r\nll me what it is and how it can be avoided?\n&gt; \n&gt; The below is an old faithf=\r\nul.  See \n&gt;\nhttp://sourceforge.net/tracker/index.php?func=3Ddetail&aid=3D12=\r\n18961&group_id=3D73833&atid=3D539099.\n \n&gt; It rears its head from time to ti=\r\nme but we&#39;ve not been able to figure \n&gt; why it happens nor how to reliably =\r\nreproduce.  I&#39;m guessing if you\ncrawl \n&gt; that same page again in wikipedia,=\r\n you&#39;ll succeed (least it did just\nnow \n&gt; for me when I tried it).  I&#39;m sur=\r\nprised it terminated your crawl.  \n&gt; Usually we just fail extraction on a p=\r\narticular page and just move to \n&gt; the next in the queue.\n&gt; \n&gt; St.Ack\n&gt; P.S=\r\n. I&#39;ve just added more logging around this exception.   Perhaps\nit&#39;ll \n&gt; tu=\r\nrn up the needed clue.\n&gt;\n\n\n\n\n\n\n"}}