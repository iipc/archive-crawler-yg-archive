{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"GkSylmEtVkRJf1ZjSARK6ERE7fewjYXg4XRwna_XQi-wxzWI9DMWolKVaZ5I_gTzDx0Kpc1JtcF5XnaxzpwoWZ-J42cVQ2k","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] Setting crawl max depth per seed (H3)","postDate":"1328643805","msgId":7611,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRGMzE3RURELjUwMDAwMDVAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGpnanQ3aythNmQ0QGVHcm91cHMuY29tPg==","referencesHeader":"PGpnanQ3aythNmQ0QGVHcm91cHMuY29tPg=="},"prevInTopic":7607,"nextInTopic":7612,"prevInTime":7610,"nextInTime":7612,"topicId":7607,"numMessagesInTopic":4,"msgSnippet":"There s no built-in facility for this. A quick-and-dirty approach to writing a custom DecideRule might look at the source-tag (which can be set to carry","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 6009 invoked from network); 7 Feb 2012 19:43:36 -0000\r\nX-Received: from unknown (98.137.34.45)\n  by m4.grp.sp2.yahoo.com with QMQP; 7 Feb 2012 19:43:36 -0000\r\nX-Received: from unknown (HELO relay02.pair.com) (209.68.5.16)\n  by mta2.grp.sp2.yahoo.com with SMTP; 7 Feb 2012 19:43:36 -0000\r\nX-Received: (qmail 82147 invoked by uid 0); 7 Feb 2012 19:43:32 -0000\r\nX-Received: from 174.234.68.11 (HELO silverbook.local) (174.234.68.11)\n  by relay02.pair.com with SMTP; 7 Feb 2012 19:43:32 -0000\r\nX-pair-Authenticated: 174.234.68.11\r\nMessage-ID: &lt;4F317EDD.5000005@...&gt;\r\nDate: Tue, 07 Feb 2012 11:43:25 -0800\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.7; rv:9.0) Gecko/20111222 Thunderbird/9.0.1\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;jgjt7k+a6d4@...&gt;\r\nIn-Reply-To: &lt;jgjt7k+a6d4@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Setting crawl max depth per seed (H3)\r\nX-Yahoo-Group-Post: member; u=137285340; y=wQ3V9vCOg6hsa3nJ48Z49_2pnMW9CKaO-nOXJc7YtoXO\r\nX-Yahoo-Profile: gojomo\r\n\r\nThere&#39;s no built-in facility for this.\n\nA quick-and-dirty approach to writing a custom DecideRule might look at \nthe &#39;source-tag&#39; (which can be set to carry forward the original seed) \nand then, depending on that, apply different limits to the length of the \n&#39;hops-path&#39; string.\n\nBut, since the crawler is only evaluating the paths it happened to \nfollow, rather than *all* paths or *all shortest paths*, there will be \nsituations where this is unlikely to do exactly what you want.\n\nConsider two seed URIs, A and B.\n\nLet&#39;s say you want to crawl from A to a depth of 1, and from B to a \ndepth of 5.\n\nThe crawl starts. URI A is fetched. An outlink from A goes to C, it&#39;s 1 \nhop away, C is enqueued and marked as having been discovered from &#39;A&#39; \n(as source-tag). C is then fetched. All its outlinks are depth 2, and \nare all marked as discovered via A, and thus over the depth-limit and \nignored.\n\nURI B was also fetched in parallel. It may also have an outlink to C. \nBut if that outlink loses the race to seen-yet testing with the one from \nA, only the one marked as coming from A is enqueued. If the outlink from \nB won the race, 4 more hops from C would have been fetched. But it \ndidn&#39;t, so they&#39;re not (though they might be discovered without \nprejudice via other paths).\n\n- Gordon\n\nOn 2/4/12 10:25 AM, paul.ihde wrote:\n&gt; Hi,\n&gt;\n&gt; The documentation on setting the max depth of crawl has only examples on how to set the max crawl depth on the whole &quot;seed list&quot; level. I would like to know if it&#39;s (and how) possible to set the crawl depth per individual seed. I know that this could be achieved by having one crawl job for every seed, but this would be quite cumbersome. So I suppose there is some mechanism in Heritrix 3 to set the max depth level per seed.\n&gt;\n&gt; A. What I know (and understand) : setting a max depth level on all the seeds\n&gt; As such if my seed list is :\n&gt; * www.domain1.com\n&gt; * www.domain2.com\n&gt; * www.domain3.com\n&gt;\n&gt; and I set the :\n&gt;      &lt;bean class=&quot;org.archive.modules.deciderules.TooManyHopsDecideRule&quot;&gt;\n&gt;       &lt;property name=&quot;maxHops&quot; value=&quot;3&quot; /&gt;\n&gt;      &lt;/bean&gt;\n&gt;\n&gt; then basically it will limit the crawl depth level to all the seed to the same level :\n&gt; * www.domain1.com (max depth = 3)\n&gt; * www.domain2.com (max depth =3)\n&gt; * www.domain3.com (max depth = 3)\n&gt;\n&gt; B. What I would like to do (but I don&#39;t know how) : setting a max depth level at seed level\n&gt; As such if my seed list is :\n&gt; * www.domain1.com\n&gt; * www.domain2.com\n&gt; * www.domain3.com\n&gt;\n&gt; and, I set the crawl depth on each seed, I would like to get :\n&gt; * www.domain1.com (max depth = 1)\n&gt; * www.domain2.com (max depth =7)\n&gt; * www.domain3.com (max depth = 3)\n&gt;\n&gt; Thanks\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------\n&gt;\n&gt; Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n\n"}}