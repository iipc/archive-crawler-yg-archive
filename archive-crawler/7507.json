{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":500983475,"authorName":"David Pane","from":"David Pane &lt;dpane@...&gt;","profile":"david_pane1","replyTo":"LIST","senderId":"YpVN5r-Gr0bP8iVeFW7X7xcztXvR2FeGczzGU5JqaAQV5I5QjnvoHODuhAs4FexpnskD6R_Odtv4xXqBVr6VRbAGIiA","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Question about H3 crawl management","postDate":"1326238163","msgId":7507,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRGMENDOUQzLjIwNTAxMDRAY3MuY211LmVkdT4=","inReplyToHeader":"PDRGMEM4QjQ4LjQwMjAwMDlAYmF5YXJlYS5uZXQ+","referencesHeader":"PDRGMEM3NjRFLjQwMDA3MDBAY3MuY211LmVkdT4gPDRGMEM4QjQ4LjQwMjAwMDlAYmF5YXJlYS5uZXQ+"},"prevInTopic":7506,"nextInTopic":7508,"prevInTime":7506,"nextInTime":7508,"topicId":7505,"numMessagesInTopic":7,"msgSnippet":"Thank you for your responses John. Can you be more specific about your thoughts on writing a script to generate these?  I have tried to generate the mime","rawEmail":"Return-Path: &lt;dpane@...&gt;\r\nX-Sender: dpane@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 58021 invoked from network); 10 Jan 2012 23:29:34 -0000\r\nX-Received: from unknown (98.137.35.162)\n  by m13.grp.sp2.yahoo.com with QMQP; 10 Jan 2012 23:29:34 -0000\r\nX-Received: from unknown (HELO smtp.andrew.cmu.edu) (128.2.11.96)\n  by mta6.grp.sp2.yahoo.com with SMTP; 10 Jan 2012 23:29:34 -0000\r\nX-Received: from [128.2.209.200] (SAVOY.LTI.CS.CMU.EDU [128.2.209.200])\n\t(user=dpane mech=PLAIN (0 bits))\n\tby smtp.andrew.cmu.edu (8.14.4/8.14.4) with ESMTP id q0ANTOVK016318\n\t(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=NOT);\n\tTue, 10 Jan 2012 18:29:24 -0500\r\nMessage-ID: &lt;4F0CC9D3.2050104@...&gt;\r\nDate: Tue, 10 Jan 2012 18:29:23 -0500\r\nUser-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:9.0) Gecko/20111222 Thunderbird/9.0.1\r\nMIME-Version: 1.0\r\nTo: John Lekashman &lt;lekash@...&gt;\r\nCc: archive-crawler@yahoogroups.com\r\nReferences: &lt;4F0C764E.4000700@...&gt; &lt;4F0C8B48.4020009@...&gt;\r\nIn-Reply-To: &lt;4F0C8B48.4020009@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-PMX-Version: 5.5.9.388399, Antispam-Engine: 2.7.2.376379, Antispam-Data: 2010.4.9.4220\r\nX-SMTP-Spam-Clean: 8% (\n BODY_SIZE_1000_LESS 0, BODY_SIZE_2000_LESS 0, BODY_SIZE_5000_LESS 0, BODY_SIZE_7000_LESS 0, BODY_SIZE_700_799 0, __BOUNCE_CHALLENGE_SUBJ 0, __BOUNCE_NDR_SUBJ_EXEMPT 0, __CT 0, __CTE 0, __CT_TEXT_PLAIN 0, __HAS_MSGID 0, __MIME_TEXT_ONLY 0, __MIME_VERSION 0, __MOZILLA_MSGID 0, __SANE_MSGID 0, __TO_MALFORMED_2 0, __USER_AGENT 0)\r\nX-SMTP-Spam-Score: 8%\r\nX-Scanned-By: MIMEDefang 2.60 on 128.2.11.96\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: David Pane &lt;dpane@...&gt;\r\nSubject: Re: [archive-crawler] Question about H3 crawl management\r\nX-Yahoo-Group-Post: member; u=500983475; y=f_xUW_sJclfEyybAQWFvPFMs915u60H-wS1XLDfUDLzy8kr4tQcLLQ\r\nX-Yahoo-Profile: david_pane1\r\n\r\nThank you for your responses John.\n\nCan you be more specific about your thoughts on writing a script to \ngenerate these?  I have tried to generate the mime report and crawl \nsummary reports using perl LWP, but haven&#39;t figured out how to deal with \nthe SSL certificates.\n\n--David\n\n&gt;&gt; 5) Although I can capture the below statistics manually, can you suggest\n&gt;&gt; a way that I can automatically generate/collect the following statistics\n&gt;&gt; from the crawl. I would like to generate this data at least once every\n&gt;&gt; 24 hours and possibly as often as every hour.\n&gt;&gt;\n&gt; Well, you could write a script to do it.\n&gt;\n&gt;&gt; a) Total size of crawled data.\n&gt;&gt; b) total number of pages crawled (mime-type: text/html).\n&gt;&gt;\n\n"}}