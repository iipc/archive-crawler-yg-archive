{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"Michael Stack","from":"Michael Stack &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"aIlA53_l7_8MFoyinr8K0vf_aCMadOeU61M6Zg265dPPxeVthSUshupn4cbI2nmTTftxdD_XcD8yMj_sJCPFuGQp8xNjxjqr","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Memory limits for crawling...","postDate":"1151966882","msgId":3003,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ0QTk5RUEyLjUwMTAxMDdAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGU3dHV2MStrcGFjQGVHcm91cHMuY29tPg==","referencesHeader":"PGU3dHV2MStrcGFjQGVHcm91cHMuY29tPg=="},"prevInTopic":2985,"nextInTopic":0,"prevInTime":3002,"nextInTime":3004,"topicId":2985,"numMessagesInTopic":2,"msgSnippet":"... How many domains?  How much delay?  How many toethreads?  Study the frontier and thread reports over time to figure where the crawler is spending time. ...","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 14965 invoked from network); 3 Jul 2006 22:43:46 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m39.grp.scd.yahoo.com with QMQP; 3 Jul 2006 22:43:46 -0000\r\nReceived: from unknown (HELO mail.archive.org) (207.241.227.188)\n  by mta2.grp.scd.yahoo.com with SMTP; 3 Jul 2006 22:43:46 -0000\r\nReceived: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id D7E5A14156951;\n\tMon,  3 Jul 2006 15:43:47 -0700 (PDT)\r\nReceived: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id 31272-01-2; Mon, 3 Jul 2006 15:43:47 -0700 (PDT)\r\nReceived: from [192.168.1.204] (unknown [67.170.222.19])\n\tby mail.archive.org (Postfix) with ESMTP id 7FFD61415632B;\n\tMon,  3 Jul 2006 15:43:47 -0700 (PDT)\r\nMessage-ID: &lt;44A99EA2.5010107@...&gt;\r\nDate: Mon, 03 Jul 2006 15:48:02 -0700\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686 (x86_64); en-US; rv:1.8.0.2) Gecko/20060405 SeaMonkey/1.0.1\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;e7tuv1+kpac@...&gt;\r\nIn-Reply-To: &lt;e7tuv1+kpac@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Virus-Scanned: Debian amavisd-new at archive.org\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: Michael Stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] Memory limits for crawling...\r\nX-Yahoo-Group-Post: member; u=168599281; y=XsDy6gHEaIfN8q0K1Vy7riFxjkUFDbjqi9HIS8FEncgtwlqfx8Pj1_Gm\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\ncallforshadab wrote:\n&gt;\n&gt; Hi,\n&gt; I am going for a test broad scope crawl. (I may be wrong) I think that\n&gt; after reaching on a certain number of queues of domains, it starts\n&gt; showing some delay.\n&gt;\n\n\n\n\n\nHow many domains?  How much delay?  How many toethreads?  Study the \nfrontier and thread reports over time to figure where the crawler is \nspending time.\n\n\n\n&gt; This delay is because of a large number of queues\n&gt; in the memory. If it reaches at that limit than where it start writing\n&gt; the queues. Does it start using the swap???\n&gt; Please make me clear on this...\n&gt;\n\n\n\n\n\nIn general any data structures that can grow large are stored on disk in \nbdbje.  If sufficent RAM, you shouldn&#39;t be swapping.  For large, \nnon-broad crawls we&#39;ll run with heaps of 2Gigs and above on 4Gig \nmachines with a couple of hundred toethreads. \n\n&gt;\n&gt; What should be the idle combination of memory and the number of\n&gt; Threads for utilizing the maxumum bandwidth.\n&gt;\n&gt; Regards & Thanks...\n&gt;\n\n\n\n\n\n\nStart with defaults and experiment:  Run some small crawls first.  Tune \nfor your particular hardware and bandwidth allotment.\nSt.Ack\n\n"}}