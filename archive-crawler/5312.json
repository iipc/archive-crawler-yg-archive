{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":347770724,"authorName":"wangpingping_cn","from":"&quot;wangpingping_cn&quot; &lt;jenpwang@...&gt;","profile":"wangpingping_cn","replyTo":"LIST","senderId":"5DEKiY0VB0YMSbpvXFEE8FdCsi7dJgPpwk4UoX38I-txDjX5uYiLYAImRIRpHbVRi5tlZgMSk9ZjmrWXpTPU64AzJRLpqrrS2Yo58B8","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Web page for Project &quot;Web Spam Detection for Heritrix&quot; is on Heritrix Wiki","postDate":"1213714338","msgId":5312,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGczOGozMitobW5qQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDQ4NTZBQTMzLjEwNTA0MDRAYXJjaGl2ZS5vcmc+"},"prevInTopic":5310,"nextInTopic":0,"prevInTime":5311,"nextInTime":5313,"topicId":5308,"numMessagesInTopic":4,"msgSnippet":"Thank you guys for these valuable comments. Like Mr. Mohr mentioned, I am trying to build a mock browser-like environment for Heritrix during crawling. Doing","rawEmail":"Return-Path: &lt;jenpwang@...&gt;\r\nX-Sender: jenpwang@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 58060 invoked from network); 17 Jun 2008 14:52:18 -0000\r\nX-Received: from unknown (66.218.67.96)\n  by m48.grp.scd.yahoo.com with QMQP; 17 Jun 2008 14:52:18 -0000\r\nX-Received: from unknown (HELO n47d.bullet.mail.sp1.yahoo.com) (66.163.169.173)\n  by mta17.grp.scd.yahoo.com with SMTP; 17 Jun 2008 14:52:18 -0000\r\nX-Received: from [216.252.122.217] by n47.bullet.mail.sp1.yahoo.com with NNFMP; 17 Jun 2008 14:52:18 -0000\r\nX-Received: from [209.73.164.86] by t2.bullet.sp1.yahoo.com with NNFMP; 17 Jun 2008 14:52:18 -0000\r\nX-Received: from [66.218.66.77] by t8.bullet.scd.yahoo.com with NNFMP; 17 Jun 2008 14:52:18 -0000\r\nDate: Tue, 17 Jun 2008 14:52:18 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;g38j32+hmnj@...&gt;\r\nIn-Reply-To: &lt;4856AA33.1050404@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;wangpingping_cn&quot; &lt;jenpwang@...&gt;\r\nSubject: Re: Web page for Project &quot;Web Spam Detection for Heritrix&quot; is on Heritrix Wiki\r\nX-Yahoo-Group-Post: member; u=347770724; y=9IgkMHAghXuy5PMXGZUO_yIi_QkOd5jG3QSKAFzCyOsuLEuBY7vnz9zX\r\nX-Yahoo-Profile: wangpingping_cn\r\n\r\nThank you guys for these valuable comments.\nLike Mr. Mohr mentioned, I am t=\r\nrying to build a mock browser-like\nenvironment for Heritrix during crawling=\r\n.\nDoing cloaking detection on sample pages is a good idea.\nI don&#39;t know muc=\r\nh about beneficial cloaking, I&#39;ll look into it.\n\nCheers,\n-Ping \n\n--- In arc=\r\nhive-crawler@yahoogroups.com, Gordon Mohr &lt;gojomo@...&gt; wrote:\n&gt;\n&gt; igor@... =\r\nwrote:\n&gt; &gt; Hi Ping,\n&gt; &gt; \n&gt; &gt; It is great that you are undertaking this proj=\r\nect. Here are some of my\n&gt; &gt; initial thoughts.\n&gt; &gt; \n&gt; &gt; - In general, I wou=\r\nld do analysis off-line and not during the crawl.\n&gt; &gt; \n&gt; &gt; - See if Browser=\r\n Monkeys will scale for this project. If yes, then\nyou get\n&gt; &gt; you javascri=\r\npt engine, events simulations, dom and all other\nwonders of a\n&gt; &gt; browser f=\r\nor &quot;free&quot;.\n&gt; \n&gt; FYI, a major goal of this project is to have an effective\nJ=\r\navascript/DOM \n&gt; simulation *inside the crawler*, for both advanced link-ex=\r\ntraction and \n&gt; detection of spammy redirects/JS-cloaking, so offline analy=\r\nsis and \n&gt; reliance on externally-controlled browsers (aka &quot;Browser Monkeys=\r\n&quot;) was \n&gt; ruled out.\n&gt; \n&gt; Comparing the behavior of the inside-the-crawler =\r\nJS/DOM with the \n&gt; full-fledged Firefox JS/DOM would be an valuable test of=\r\n the integrated \n&gt; code&#39;s functionality.\n&gt; \n&gt; &gt; - If you decide to fetch tw=\r\no pages for cloaking detection be sure that\n&gt; &gt; fetches are coming from dif=\r\nferent ip addresses/ranges. Also, be\nsure that\n&gt; &gt; for &quot;browser&quot; fetches yo=\r\nu don&#39;t make robots.txt requests. This is a\n&gt; &gt; telltale to spammers that y=\r\nou are bot regardless of the IP address,\n&gt; &gt; user-agent and other http requ=\r\nest headers. This kind of dual\nfetching can\n&gt; &gt; easily be done with Heritri=\r\nx&#39;s proxy setting and probably a beanshell\n&gt; &gt; processor.\n&gt; \n&gt; Good points.=\r\n At a first level, I hope Ping&#39;s analysis code can do two \n&gt; checks from a =\r\nsingle fetch -- plain link extraction, compared to the \n&gt; results of lettin=\r\ng JS run. Then, for catching another level of tricks, \n&gt; secondary fetches =\r\nvia alternate IPs and User-Agents would be added.\n&gt; \n&gt; &gt; - As you already p=\r\nointed out, dual fetching can be expensive. However,\n&gt; &gt; sampling is probab=\r\nly a good way to go given that spammers are usually\n&gt; &gt; ambitious/greedy. S=\r\no, fetching a couple of pages per host will\nprobably be\n&gt; &gt; good enough. I =\r\nrecommend slash page plus one other link of it.\n&gt; \n&gt; Yes, or some proportio=\r\nn of a site, or perhaps a proportion of any \n&gt; URL-prefix that has a lot of=\r\n content. (EG, when \n&gt; www.example.com/dirA/dirB/* becomes very common, it =\r\nearns a test.)\n&gt; \n&gt; &gt; - As a part of a wish list, it would be good to check=\r\n how often\nwebmasters\n&gt; &gt; implement beneficial cloaking (removing session i=\r\nds, parameters\nand etc.).\n&gt; &gt; Also, if Flash has been a new spamming medium=\r\n.\n&gt; \n&gt; Interesting idea... and if there is significant beneficial cloaking,=\r\n\ncan \n&gt; we determine some heurisitics to distinguish it from bad cloaking?\n=\r\n&gt; \n&gt; - Gordon @ IA\n&gt;\n\n\n\n"}}