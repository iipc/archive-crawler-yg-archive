{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":163894630,"authorName":"steensc42","from":"&quot;steensc42&quot; &lt;steensc42@...&gt;","profile":"steensc42","replyTo":"LIST","senderId":"8a6N0IVdi1hdvL_D7ukVSZj5otSGDjuHsOTJWY4m6mydgI68F75DNieAJE-33wvXgZOzc884HSzpOqfiayjW4jZRO7h4b0c","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: Crawl of 907 danish seeds","postDate":"1069927163","msgId":189,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGJxNGh0citubWF1QGVHcm91cHMuY29tPg==","inReplyToHeader":"PDNGQzJBNzNFLjkwMjAyMDZAYXJjaGl2ZS5vcmc+"},"prevInTopic":182,"nextInTopic":0,"prevInTime":188,"nextInTime":190,"topicId":180,"numMessagesInTopic":4,"msgSnippet":"I will produce a list of the seeds that caused problems and try a recrawl with a newer version of Heritrix, with pdf and doc link extraction disabled. I will","rawEmail":"Return-Path: &lt;steensc42@...&gt;\r\nX-Sender: steensc42@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 89049 invoked from network); 27 Nov 2003 09:59:26 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m17.grp.scd.yahoo.com with QMQP; 27 Nov 2003 09:59:26 -0000\r\nReceived: from unknown (HELO n14.grp.scd.yahoo.com) (66.218.66.69)\n  by mta4.grp.scd.yahoo.com with SMTP; 27 Nov 2003 09:59:25 -0000\r\nReceived: from [66.218.67.248] by n14.grp.scd.yahoo.com with NNFMP; 27 Nov 2003 09:59:25 -0000\r\nDate: Thu, 27 Nov 2003 09:59:23 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nSubject: Re: Crawl of 907 danish seeds\r\nMessage-ID: &lt;bq4htr+nmau@...&gt;\r\nIn-Reply-To: &lt;3FC2A73E.9020206@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Length: 5336\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-eGroups-Remote-IP: 66.218.66.69\r\nFrom: &quot;steensc42&quot; &lt;steensc42@...&gt;\r\nX-Yahoo-Group-Post: member; u=163894630\r\nX-Yahoo-Profile: steensc42\r\n\r\n\nI will produce a list of the seeds that caused problems and try a \nrecrawl with a newer version of Heritrix, with pdf and doc link \nextraction disabled. I will report the results of that crawl when we \nhave them.\n\n--- In archive-crawler@yahoogroups.com, Gordon Mohr &lt;gojomo@a...&gt; \nwrote:\n&gt; Thanks for this report; these are curious results, and we&#39;ll\n&gt; want to track down every place where an expected URI/resource was\n&gt; missed.\n&gt; \n&gt; Was the code grabbed from CVS and built just prior to the run?\n&gt; (We are still making significant destabilizing changes regularly.)\n&gt; \n\nWe did not use the most recent CVS version as we had some minor \nproblems with that version - instead we used an earlier apparently \nmore stable version.\n\n&gt; What configuration options were used? (Can you forward your crawl-\norder\n&gt; file?) What command-line was used to launch the crawler?\n&gt; \n&gt; Without listing all the seeds, can you say whether they were always\n&gt; site roots (http://www.site.org) or sometimes other entry pages\n&gt; (http://www.site.org/subsection/)?\n\nMixture of both\n\n&gt; \n&gt; Steen Christensen wrote:\n&gt;  &gt; Total number of seed URL&#39;s: 907\n&gt;  &gt;\n&gt;  &gt; Harvest start: 11.11.2003-17\n&gt;  &gt; Harverst end: 14.11.2003-12\n&gt;  &gt;\n&gt;  &gt; Harvest time: 67 hours\n&gt;  &gt;\n&gt;  &gt; Total amount of data harvested: 4 GB (compressed), 14 GB \n(uncompressed)\n&gt; \n&gt; How many total resources were successfully collected?\nApprox. 800 000 \n&gt; \n&gt; Did the crawler run out of pages to crawl, or hit an error or user-\nabort?\n&gt; \n\nIt ran out of pages\n\n&gt; The current version of Heritrix will still eventually hit, and be\n&gt; stopped, by memory-footprint limits.\n&gt; \n&gt; How soon these limits are hit depend on the available memory, \ndiversity\n&gt; of URIs crawled, and whether you&#39;ve enabled the experimental disk-\nbased\n&gt; structure for tracking &quot;alreadyIncluded&quot; items. (This is currently \ndone\n&gt; in code, in the Frontier class initialization method.)\n&gt; \n\nWe used the disk-based method - the memory based ran out of memory \nafter approx. 24 Hours\n\n&gt; Using the in-memory only implementation (MemLongFPSet), on a 2GB \ncrawl\n&gt; machine, we recently ran a crawl of ~250 sites which gathered 4.8 \nmillion\n&gt; URIs over 3 days before hitting implementation problems.\n&gt; \n&gt; However, in order to run that long, we had to disable the \nExtractorDOC\n&gt; and ExtractorPDF processors (which have unresolved memory-overuse \nbugs)\n\nWe did not disable doc&#39;s and pdf extraction. We will do this on out \nnext trial.\n\n&gt; and set the expiration of IP and robots info to 3 days (because the\n&gt; refetching of this info after it expires is currently unreliable).\n&gt; \n&gt;  &gt; Coverage analysis:\n&gt;  &gt;\n&gt;  &gt; 367 (40% of the 907) seed URLs were investigated more closely.\n&gt;  &gt; 265 of these were valid sites that should be harvested.\n&gt;  &gt; 101 (38%) were completely missed by the harvester.\n&gt; \n&gt; This is the most surprising result; any URI listed in the seeds\n&gt; should definitely be visited by the crawler. Were there errors\n&gt; evident in the logs for the seed sites missed?\n&gt; \nThe term &quot;missed&quot; is not accurate. A site was classified as missed if \nthe seed-url page could not be retrieved from the archive - often \npart of a framestructure would be stored. \n\n\nAs Bjarne pointed out a number of &quot;missed&quot; sites were due to a robots \nmeta-tag on the frontpage. \n\n&gt; (I would check the crawl.log first. If a negative error code is\n&gt; associated with the URI of interest, you have to look up its\n&gt; meaning in the FetchStatusCodes class -- at least until we\n&gt; move to better, more symbolic/mnemonic error codes. Barring any\n&gt; useful info there, you can also check the runtime-errors.log\n&gt; and the local-errors.log to see if unexpected errors thwarted\n&gt; normal processing.)\n&gt; \n&gt;  &gt; Observed problems:\n&gt;  &gt;\n&gt;  &gt; Relative image URLs seem not to be stored\n&gt;  &gt;\n&gt;  &gt; Example:\n&gt;  &gt; &lt;img src=&quot;../Images/logo.gif&quot; alt=&quot;Logo&quot;&gt;\n&gt; \n&gt; I will look into this further. Keep in mind that when you find\n&gt; specific, reproduceable bugs, you may enter them directly into\n&gt; the project bug-tracking system at:\n&gt; \n&gt;     https://sourceforge.net/tracker/?\nfunc=browse&group_id=73833&atid=539099\nWe will report specific bugs directly to sourceforge in the future.\n&gt; \n&gt;  &gt; Complex framesets:\n&gt;  &gt;\n&gt;  &gt; Example:\n&gt;  &gt;\n&gt;  &gt;                       http://www.centrumdemokraterne.dk\n&gt;  &gt; &lt;http://www.centrumdemokraterne.dk/&gt; (center frame not crawled)\n&gt;  &gt; http://www.chilinet.dk &lt;http://www.chilinet.dk/&gt;\n&gt; \n&gt; I suspect this might be other problems (perhaps evident in\n&gt; the logs) affecting the given frame URIs, rather than a problem\n&gt; with frameset parsing, but I will investigate further.\n&gt; \n&gt; \n&gt;  &gt; A large number of city-sites using the same framework were not \nharvested:\n&gt;  &gt;\n&gt;  &gt;                       http://www.bynet.dk &lt;http://www.bynet.dk/&gt;\n&gt;  &gt;                       http://esbjerg.bynet.dk/\n&gt; \n&gt; Were there errors in the logs explaining why the seed/roots\n&gt; failed?\n&gt; \n&gt;  &gt; Explicit port definitions seem to confuse Heritrix\n&gt;  &gt;\n&gt;  &gt;                       http://dk.yahoo.com:80 \n&lt;http://dk.yahoo.com/&gt;\n&gt; \n&gt; Do you mean sites were collected twice, or not at all with\n&gt; some error?\n&gt; \nNot at all\n&gt;  &gt; PDF files seem not to be stored correctly (Word files are OK.).\n&gt; \n&gt; Before a bug in the ReplayInputStream was fixed on November 17, all\n&gt; content byte values &gt; 127 were being corrupted when sent to\n&gt; ARC files.\n&gt; \nOk - we will try a more recent version\n&gt; - Gordon\n/Steen\n\n\n"}}