{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":362973207,"authorName":"Juergen Umbrich","from":"Juergen Umbrich &lt;juergen@...&gt;","replyTo":"LIST","senderId":"8hNvlXUNCObdKVC1voaMJLZhcEjrL6305W-XoAHFyX-3rWE6M8j8b4_vPYtS5-ArhK0qRhwj6rosat634HfAK2FEID0jZtQ-RtNbdg","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Possible new features/modules","postDate":"1224695192","msgId":5528,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ4RkY1RDk4LjgwMTA2MDlAdW1icmljaC5uZXQ+","inReplyToHeader":"PDQ0MzEzNy4xNTkwNC5xbUB3ZWI1NDYwMy5tYWlsLnJlMi55YWhvby5jb20+","referencesHeader":"PDQ0MzEzNy4xNTkwNC5xbUB3ZWI1NDYwMy5tYWlsLnJlMi55YWhvby5jb20+"},"prevInTopic":5526,"nextInTopic":5544,"prevInTime":5527,"nextInTime":5529,"topicId":5525,"numMessagesInTopic":5,"msgSnippet":"Hi ... ah ok, behind my approach is the requirement that the crawler should avoid unnecessary HTTP lookups. Given resource limitations and assuming that over","rawEmail":"Return-Path: &lt;juergen@...&gt;\r\nX-Sender: juergen@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 14102 invoked from network); 22 Oct 2008 17:07:03 -0000\r\nX-Received: from unknown (66.218.67.94)\n  by m57.grp.scd.yahoo.com with QMQP; 22 Oct 2008 17:07:03 -0000\r\nX-Received: from unknown (HELO mx1.nuigalway.ie) (140.203.201.100)\n  by mta15.grp.scd.yahoo.com with SMTP; 22 Oct 2008 17:07:03 -0000\r\nX-IronPort-Anti-Spam-Filtered: true\r\nX-IronPort-Anti-Spam-Result: ApoEAKT6/kgKhJ0L/2dsb2JhbADGaoNP\r\nX-IronPort-AV: E=Sophos;i=&quot;4.33,465,1220223600&quot;; \n   d=&quot;scan&#39;208&quot;;a=&quot;267649529&quot;\r\nX-Received: from exbe1.ac.nuigalway.ie (HELO EVS1.ac.nuigalway.ie) ([10.132.157.11])\n  by mx1.nuigalway.ie with ESMTP; 22 Oct 2008 18:07:02 +0100\r\nX-Received: from EVS1.ac.nuigalway.ie ([10.132.157.14]) by EVS1.ac.nuigalway.ie with Microsoft SMTPSVC(6.0.3790.3959);\n\t Wed, 22 Oct 2008 18:07:01 +0100\r\nX-Received: from [10.2.17.89] ([140.203.154.11]) by EVS1.ac.nuigalway.ie over TLS secured channel with Microsoft SMTPSVC(6.0.3790.3959);\n\t Wed, 22 Oct 2008 18:07:01 +0100\r\nMessage-ID: &lt;48FF5D98.8010609@...&gt;\r\nDate: Wed, 22 Oct 2008 18:06:32 +0100\r\nUser-Agent: Mozilla-Thunderbird 2.0.0.16 (X11/20080724)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;443137.15904.qm@...&gt;\r\nIn-Reply-To: &lt;443137.15904.qm@...&gt;\r\nContent-Type: text/plain; charset=UTF-8; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nReturn-Path: juergen@...\r\nX-OriginalArrivalTime: 22 Oct 2008 17:07:01.0792 (UTC) FILETIME=[99C64200:01C93468]\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Juergen Umbrich &lt;juergen@...&gt;\r\nSubject: Re: [archive-crawler] Possible new features/modules\r\nX-Yahoo-Group-Post: member; u=362973207\r\n\r\nHi\n&gt; I wrote a DecideRule that checks the header from the contents to see what media type it was, but this requires the file to be downloaded first.\n&gt;\n&gt;   \nah ok, behind my approach is the requirement that the crawler should \navoid unnecessary HTTP lookups.\nGiven resource limitations and assuming that over 70% of the web \ndocuments are text, HTML or XHTML documents, you really don&#39;t want to \ndownload all files.\n\n\n&gt; Is that sort of what your doing?\n&gt;\n&gt;   \nno. I use information sources which are available for a crawler during \nruntime to predict the media type of extracted links.\n\nBest\n\n&gt;\n&gt; ----- Original Message ----\n&gt; From: Juergen Umbrich &lt;juergen@...&gt;\n&gt; To: archive-crawler@yahoogroups.com\n&gt; Sent: Wednesday, October 22, 2008 7:35:15 AM\n&gt; Subject: [archive-crawler] Possible new features/modules\n&gt;\n&gt;\n&gt; Hi all\n&gt;\n&gt; I wrote a module which detects the &quot;real&quot; media type (mime type) of a \n&gt; file based on the magic number approach.\n&gt; At the moment I am comparing the Apache Tika library[1] and the Aduna \n&gt; Aperture library in terms of detection runtime and mime type coverage.\n&gt;\n&gt; If there is an interest in the heritrix community for this module I \n&gt; would like to share or commit the code (but I would need some advices \n&gt; how to do it).\n&gt;\n&gt; I am also working in a project[3] that tries to predict the media type \n&gt; of extracted links based on information extracted from URI, link \n&gt; position and content-type response header field.\n&gt; At the moment I try to integrate this into heritrix to be able to \n&gt; perform a kind of document media type focused crawling.\n&gt; Is there any interest  in the community in these kind of focus crawling?\n&gt;\n&gt; best juergen\n&gt;\n&gt; [1] http://incubator. *apache*. org/*tika* /\n&gt; [2]http://www.aduna- software. com/technologies /aperture/ overview. view\n&gt; [3]http://ieeexplore. ieee.org/ iel5/4577854/ 4577855/04577883 .pdf\n&gt;     \n&gt;\n&gt;\n&gt;       \n&gt;   \n\n"}}