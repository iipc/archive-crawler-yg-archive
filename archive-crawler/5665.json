{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":264783887,"authorName":"pbaclace","from":"&quot;pbaclace&quot; &lt;pbaclace@...&gt;","profile":"pbaclace","replyTo":"LIST","senderId":"IX3ccERwGuv7HGQT1lXimALsYRrGMkRPzbaY1JQFsnzjTE5OSZF5P0OdAfzPyj0AUdg9BrZiyZ0I29lfIm8p9ZPglxr5Bw","spamInfo":{"isSpam":false,"reason":"12"},"subject":"lock contention in ServerCache.getServerFor()","postDate":"1234487434","msgId":5665,"canDelete":false,"contentTrasformed":false,"systemMessage":true,"headers":{"messageIdInHeader":"PGduMmhhYSs2ZXVoQGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":5673,"prevInTime":5664,"nextInTime":5666,"topicId":5665,"numMessagesInTopic":8,"msgSnippet":"A test run of: * Heritrix 1.14.2 on an AWS/EC2, small instance, with 100 worker threads, 1.3M seeds, 900MB heap Has the following resource utilization stats: *","rawEmail":"Return-Path: &lt;pbaclace@...&gt;\r\nReceived: (qmail 15655 invoked from network); 13 Feb 2009 02:16:03 -0000\r\nReceived: from unknown (66.218.67.94)\n  by m56.grp.scd.yahoo.com with QMQP; 13 Feb 2009 02:16:03 -0000\r\nReceived: from unknown (HELO n43d.bullet.mail.sp1.yahoo.com) (66.163.169.157)\n  by mta15.grp.scd.yahoo.com with SMTP; 13 Feb 2009 02:16:03 -0000\r\nDKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoogroups.com; s=lima; t=1234491360; bh=0mO5c3stMyqDc4vieRcv0Ltx7pwF4XFXBPiGDaqLjTM=; h=Received:Received:X-Sender:X-Apparently-To:X-Received:X-Received:X-Received:X-Received:X-Received:Date:To:Message-ID:User-Agent:MIME-Version:Content-Type:Content-Transfer-Encoding:X-Mailer:X-Yahoo-Newman-Property:X-Originating-IP:X-eGroups-Msg-Info:X-Yahoo-Post-IP:From:Subject:X-Yahoo-Group-Post:X-Yahoo-Profile:Sender:X-eGroups-Approved-By:X-eGroups-Auth; b=bflQ2np0kHX3pbtn9Bb5Tqr0ZfewQhFOIig1AvAeXKU8FzKWy6UqAdH/Ozhmm++SGXtwc4gu3mQbBTNilmUseuAaX0iEUN8odGdaporC2rWB5qVIgD456vCi9YXDtwDF\r\nReceived: from [69.147.65.173] by n43.bullet.mail.sp1.yahoo.com with NNFMP; 13 Feb 2009 02:15:59 -0000\r\nReceived: from [66.218.67.200] by t15.bullet.mail.sp1.yahoo.com with NNFMP; 13 Feb 2009 02:15:59 -0000\r\nX-Sender: pbaclace@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 53843 invoked from network); 13 Feb 2009 02:15:28 -0000\r\nX-Received: from unknown (66.218.67.97)\n  by m43.grp.scd.yahoo.com with QMQP; 13 Feb 2009 02:15:28 -0000\r\nX-Received: from unknown (HELO n18c.bullet.sp1.yahoo.com) (69.147.64.129)\n  by mta18.grp.scd.yahoo.com with SMTP; 13 Feb 2009 02:15:28 -0000\r\nX-Received: from [69.147.65.171] by n18.bullet.sp1.yahoo.com with NNFMP; 13 Feb 2009 02:09:04 -0000\r\nX-Received: from [98.137.34.32] by t13.bullet.mail.sp1.yahoo.com with NNFMP; 13 Feb 2009 02:08:47 -0000\r\nDate: Fri, 13 Feb 2009 01:10:34 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;gn2haa+6euh@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-system\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: &quot;pbaclace&quot; &lt;pbaclace@...&gt;\r\nSubject: lock contention in ServerCache.getServerFor()\r\nX-Yahoo-Group-Post: member; u=264783887; y=uvETDHDWvxAwcXPc5_3iR8hqNVuzX6YuTKLXFjYihyR2F-A\r\nX-Yahoo-Profile: pbaclace\r\nX-eGroups-Approved-By: stearcorg &lt;steve@...&gt; via web; 13 Feb 2009 02:15:59 -0000\r\n\r\n\nA test run of:\n  * Heritrix 1.14.2 on an AWS/EC2, small instance, with 100=\r\n worker\nthreads, 1.3M seeds, 900MB heap\n\nHas the following resource utiliza=\r\ntion stats:\n\n  *  230KB/sec of the network\n  * 100% cpu with load between 7=\r\n and 13\n  * disk starts out at 300KB/sec, and 24 hours later is at 1MB/sec\n=\r\n  * number of established HTTP sockets:  ranges from 1 to 7,\noccasional spi=\r\nking to 14\n  * Full GC every 10 minutes\n\nThe limiting resource is the cpu. =\r\n A one core machine should\ntheoretically be able to saturate either the net=\r\nwork or the disk\nbandwidth before the cpu hits the wall, unless it has heav=\r\ny lock\ncontention. \n\nSee how many and where threads are waiting in some jst=\r\nack thread dumps::\n# grep &#39;waiting to lock&#39; /mnt/Heritrix.9.threaddump  |so=\r\nrt |uniq -c\n     25         - waiting to lock &lt;0x5c357d90&gt; (a\norg.archive.c=\r\nrawler.postprocessor.FrontierScheduler)\n     61         - waiting to lock &lt;=\r\n0x5c382828&gt; (a\norg.archive.crawler.datamodel.ServerCache)\n# grep &#39;waiting t=\r\no lock&#39; /mnt/Heritrix.8.threaddump  |sort |uniq -c\n      7         - waitin=\r\ng to lock &lt;0x5c357d90&gt; (a\norg.archive.crawler.postprocessor.FrontierSchedul=\r\ner)\n     56         - waiting to lock &lt;0x5c382828&gt; (a\norg.archive.crawler.d=\r\natamodel.ServerCache)\n# grep &#39;waiting to lock&#39; /mnt/Heritrix.7.threaddump  =\r\n|sort |uniq -c\n     31         - waiting to lock &lt;0x5c357d90&gt; (a\norg.archiv=\r\ne.crawler.postprocessor.FrontierScheduler)\n     62         - waiting to loc=\r\nk &lt;0x5c382828&gt; (a\norg.archive.crawler.datamodel.ServerCache)\n\nExamination o=\r\nf the FrontierScheduler lock shows that it is held in\nthreaddumps 7 and 9 b=\r\ny a thread waiting for ServerCache.\n\nMost threads (about 90) are waiting fo=\r\nr a lock on ServerCache in the\nmethod:\n\n  public synchronized CrawlServer g=\r\netServerFor(String serverKey)\n\nPresumably, a simple name to host/server wou=\r\nld be fast, but one thread\nholds the lock while doing a relatively long BDB=\r\n read operation. \nObviously, having disk io block all cache lookups is not =\r\noptimal,\nespecially when BDB has a lock per file (FileManager).  In my test=\r\n\ncase, the bdb data is 3.6GB and there are about 360 *.jdb files in the\njob=\r\n state directory.  If requests to getServerFor(String) were not\nsynchronize=\r\nd, then BDB should be able to read from multiple *.jdb file\nat the same tim=\r\ne and threads requesting entries cached in memory by\nCachedBDBMap would not=\r\n need to wait.  \n\n\nI think the following high gain, small code footprint im=\r\nprovements\nwould help:\n\n* superficial thread-local caching (1 affected file=\r\n)\n**  the ServerCache lookups are done in many code locations, so it\nseems =\r\neach thread processing a uri might repeatedly do the same lookup\nand get st=\r\nuck waiting\n**  a ThreadLocal cache of one key-value pair could be checked =\r\nbefore\nthe Maps in ServerCache.getServerFor(String) before synchronizing on=\r\n\nthis instance of ServerCache.\n**  this must not interfere with soft refere=\r\nnce tracking, of course\n\n* deep un-knotting by lock-splitting and enabling =\r\nmore concurrency in\nServerCache, CachedBdbMap, and BDB.\n** drop synchroniza=\r\ntion of ServerCache.getServerFor(String)\n** drop synchronization of  Cached=\r\nBdbMap.get(Object)\n** use ConcurrentHashMap for CachedBdbMap.memMap\n** drop=\r\n synchronization of CachedBdbMap.put(K,V) and expose\nputIfAbsent(K,V) if ne=\r\neded.\n*** ServerCache.createServerFor(String) loses synchronization when\nSe=\r\nrverCache.getServerFor(String) drops it.\n\n\nMy particular crawl job exercise=\r\ns the ServerCache more than most jobs,\nbut it is analogous to having a very=\r\n wide, breadth-first crawl. \nCharacteristics of this performance case are s=\r\nhared by all jobs that\ncrawl many thousands of hosts.\n\nSince full GC was oc=\r\ncurring about every 10 minutes, the lock\ncontention was not due to full GC =\r\nfrequency.  A heap histogram showed\nabout 3700 CrawlServer instances at the=\r\n end of the run.\n\nIf this un-knotting can work, there should be substantial=\r\nly better\ndisk and network utilization. \n\n\n\nPaul\n\n\n=3D=3Dthe lucky thread f=\r\nor which ~90 other threads are waiting =3D=3D=3D=3D=3D\n\n&quot;ToeThread #76: htt=\r\np://larhondasteele.com/&quot; prio=3D10 tid=3D0x09316400\nnid=3D0x8ff runnable [0=\r\nxb3706000..0xb37070c0]   java.lang.Thread.State:\nRUNNABLE        \nat java.i=\r\no.RandomAccessFile.readBytes(Native Method)        \nat java.io.RandomAccess=\r\nFile.read(RandomAccessFile.java:322)        \nat\ncom.sleepycat.je.log.FileMa=\r\nnager.readFromFileInternal(FileManager.java:1463)\n      \n- locked &lt;0x585072=\r\nc0&gt; (a com.sleepycat.je.log.FileManager$1)        \nat\ncom.sleepycat.je.log.=\r\nFileManager.readFromFile(FileManager.java:1384) \n      \nat com.sleepycat.je=\r\n.log.FileSource.getBytes(FileSource.java:54)        \nat\ncom.sleepycat.je.lo=\r\ng.LogManager.getLogEntryFromLogSource(LogManager.java:691)\n       \nat com.s=\r\nleepycat.je.log.LogManager.getLogEntry(LogManager.java:661)  \n     \nat com.=\r\nsleepycat.je.tree.IN.fetchTarget(IN.java:1215)        \nat\ncom.sleepycat.je.=\r\ndbi.CursorImpl.searchAndPosition(CursorImpl.java:2103) \n      \nat com.sleep=\r\nycat.je.Cursor.searchInternal(Cursor.java:1782)        \nat com.sleepycat.je=\r\n.Cursor.searchAllowPhantoms(Cursor.java:1752)        \nat com.sleepycat.je.C=\r\nursor.search(Cursor.java:1619)        \nat com.sleepycat.je.Cursor.getSearch=\r\nKey(Cursor.java:1071)        \nat\ncom.sleepycat.util.keyrange.RangeCursor.do=\r\nGetSearchKey(RangeCursor.java:965)\n       \nat\ncom.sleepycat.util.keyrange.R=\r\nangeCursor.getSearchKey(RangeCursor.java:592)\n       \nat\ncom.sleepycat.coll=\r\nections.DataCursor.doGetSearchKey(DataCursor.java:577)\n       \nat\ncom.sleep=\r\nycat.collections.DataCursor.getSearchKey(DataCursor.java:559)\n       \nat\nco=\r\nm.sleepycat.collections.StoredContainer.getValue(StoredContainer.java:299)\n=\r\n       \nat com.sleepycat.collections.StoredMap.get(StoredMap.java:227)     =\r\n   \nat org.archive.util.CachedBdbMap.diskMapGet(CachedBdbMap.java:641)     =\r\n   \nat org.archive.util.CachedBdbMap.get(CachedBdbMap.java:375)        \n- l=\r\nocked &lt;0x5c389a40&gt; (a org.archive.util.CachedBdbMap)    \nat\norg.archive.cra=\r\nwler.datamodel.ServerCache.getServerFor(ServerCache.java:93)\n       \n- lock=\r\ned &lt;0x5c382828&gt; (a org.archive.crawler.datamodel.ServerCache)  \n     \nat\nor=\r\ng.archive.crawler.datamodel.ServerCache.getServerFor(ServerCache.java:125)\n=\r\n       \nat\norg.archive.crawler.prefetch.PreconditionEnforcer.considerDnsPre=\r\nconditions(PreconditionEnforcer.java:227)\n       \nat\norg.archive.crawler.pr=\r\nefetch.PreconditionEnforcer.innerProcess(PreconditionEnforcer.java:111)\n   =\r\n    \nat org.archive.crawler.framework.Processor.process(Processor.java:112)=\r\n\n       \nat\norg.archive.crawler.framework.ToeThread.processCrawlUri(ToeThre=\r\nad.java:302)\n       \nat org.archive.crawler.framework.ToeThread.run(ToeThre=\r\nad.java:151)\n\n\n\n\n"}}