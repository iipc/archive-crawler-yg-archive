{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":225011788,"authorName":"Karl Wright","from":"Karl Wright &lt;kwright@...&gt;","profile":"daddywri","replyTo":"LIST","senderId":"OvgdLhVfKrg1F9mqr0xKuzoAEEGYjQP5oQAGbxY_VIXz9spjhMVg08LsBvRYyjk6lYR9u-Z7JDSJGood61V2ShpJq6Sn5Ffk3sY","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Politeness proposal, and CrawlHost class","postDate":"1137786201","msgId":2574,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQzRDEzRDU5LjgwOTA3MDBAbWV0YWNhcnRhLmNvbT4="},"prevInTopic":0,"nextInTopic":2578,"prevInTime":2573,"nextInTime":2575,"topicId":2574,"numMessagesInTopic":5,"msgSnippet":"Hi, We encountered a new politeness complaint recently.  Basically, the proprietor noticed our crawl not because of excessive bandwidth consumption or even","rawEmail":"Return-Path: &lt;kwright@...&gt;\r\nX-Sender: kwright@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 19938 invoked from network); 20 Jan 2006 19:42:08 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m2.grp.scd.yahoo.com with QMQP; 20 Jan 2006 19:42:08 -0000\r\nReceived: from unknown (HELO metacarta.com) (65.77.47.18)\n  by mta2.grp.scd.yahoo.com with SMTP; 20 Jan 2006 19:42:08 -0000\r\nReceived: from localhost (silene.metacarta.com [65.77.47.24])\n\tby metacarta.com (Postfix) with ESMTP id 5473D518135\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Fri, 20 Jan 2006 14:42:06 -0500 (EST)\r\nReceived: from metacarta.com ([65.77.47.18])\n\tby localhost (silene.metacarta.com [65.77.47.24]) (amavisd-new, port 10024)\n\twith ESMTP id 29881-04; Fri, 20 Jan 2006 14:42:02 -0500 (EST)\r\nReceived: from [65.77.47.197] (dhcp-65-77-47-197.metacarta.com [65.77.47.197])\n\tby metacarta.com (Postfix) with ESMTP\n\tid E4DAF518092; Fri, 20 Jan 2006 14:42:01 -0500 (EST)\r\nMessage-ID: &lt;43D13D59.8090700@...&gt;\r\nDate: Fri, 20 Jan 2006 14:43:21 -0500\r\nUser-Agent: Mozilla Thunderbird 1.0.2 (Windows/20050317)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: Josiah Strandberg &lt;jstrandberg@...&gt;,\n\tKenneth J Baker &lt;bakerkj@...&gt;,\n\tKeith Baker &lt;krbaker@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Virus-Scanned: by amavisd-new-20030616-p10 (Debian) at metacarta.com\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: Karl Wright &lt;kwright@...&gt;\r\nSubject: Politeness proposal, and CrawlHost class\r\nX-Yahoo-Group-Post: member; u=225011788; y=yfSQoCrl69cK4xE96t0mqkHp7Pzt_28Y1W2ORFosn8vAWrE\r\nX-Yahoo-Profile: daddywri\r\n\r\nHi,\n\nWe encountered a new politeness complaint recently.  Basically, the \nproprietor noticed our crawl not because of excessive bandwidth \nconsumption or even number of hits, but because we just continued to \nsteadily read documents over 4 days.\n\nIt seems like it might be therefore a good idea to have a new politeness \nparameter set which would limit the total fetches in a specified period \nof time.  I&#39;m looking for advice on implementing such a politeness feature.\n\nThe problem basically is where the fetch statistics over the last n days \nshould be kept.  The CrawlHost class seems an obvious choice.  However, \nI believe that this class&#39; size is a major determiner of the total \namount of memory Heritrix requires for a crawl.  Is this true?  Or, if I \nmade CrawlHost significantly larger, should I expect there to be little \nimpact on the memory requirements of the crawler?\n\nThanks,\nKarl Wright\n\n"}}