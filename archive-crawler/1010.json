{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":194371199,"authorName":"bjhong02","from":"&quot;bjhong02&quot; &lt;bjhong02@...&gt;","profile":"bjhong02","replyTo":"LIST","senderId":"vh4PFle-45Lk0-bY5kMa8yhvOfDXfObEZbebFIVWFBQdySzt4pnCANfrMPX1bIS5CsEb6Jd-BBkIH2A1ciCPptrrP2ZaQA","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: what&#39;s wrong with reading robots.txt","postDate":"1095741726","msgId":1010,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGNpb2JldSs0bnByQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDE2NzE4LjU0MTEyLjc0NjYyLjExOTYzMkB0aXBoYXJlcy5iYXNpc3RlY2gubmV0Pg=="},"prevInTopic":1009,"nextInTopic":1011,"prevInTime":1009,"nextInTime":1011,"topicId":1004,"numMessagesInTopic":12,"msgSnippet":"... Yes, I get the robots.txt from both my browser and wget. I visit web through a proxy, and I set it at the WUI.","rawEmail":"Return-Path: &lt;bjhong02@...&gt;\r\nX-Sender: bjhong02@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 47463 invoked from network); 21 Sep 2004 04:42:47 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m23.grp.scd.yahoo.com with QMQP; 21 Sep 2004 04:42:47 -0000\r\nReceived: from unknown (HELO n2.grp.scd.yahoo.com) (66.218.66.75)\n  by mta6.grp.scd.yahoo.com with SMTP; 21 Sep 2004 04:42:47 -0000\r\nReceived: from [66.218.66.119] by n2.grp.scd.yahoo.com with NNFMP; 21 Sep 2004 04:42:06 -0000\r\nDate: Tue, 21 Sep 2004 04:42:06 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;ciobeu+4npr@...&gt;\r\nIn-Reply-To: &lt;16718.54112.74662.119632@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Length: 531\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Remote-IP: 66.218.66.75\r\nFrom: &quot;bjhong02&quot; &lt;bjhong02@...&gt;\r\nSubject: Re: what&#39;s wrong with reading robots.txt\r\nX-Yahoo-Group-Post: member; u=194371199\r\nX-Yahoo-Profile: bjhong02\r\n\r\n--- In archive-crawler@yahoogroups.com, Tom Emerson &lt;Tree@b...&gt; wrote:\n&gt; bjhong02 writes:\n&gt; &gt; I downloaded the binary of Heritrix 1.0.0, and tried to test it with\n&gt; &gt; the  seed: www.uiuc.edu. It succeed in dns lookup, but failed to read\n&gt; &gt; robots.txt (really exist).  The error log is as follows.\n&gt; \n&gt; Well, the error says that the read timed out --- can you get the\n&gt; robots.txt file from your browser or from wget?\n\nYes, I get the robots.txt from both my browser and wget.\nI visit web through a proxy, and I set it at the WUI.\n\n\n\n"}}