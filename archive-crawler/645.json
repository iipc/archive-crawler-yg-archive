{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":32488388,"authorName":"Halácsy Péter","from":"=?ISO-8859-1?Q?Hal=E1csy_P=E9ter?= &lt;peter@...&gt;","profile":"halacsypeter","replyTo":"LIST","senderId":"E2Jw7IENybAFKIc9PYZu-CZa-SoMfeVbxlv6tOvQlAwzinFH7vOgndlR1cLZ71BZWTuWtCSXJKsO5FnZ6OABrFjiEgKqgJkc6aiRxl5JNQnNDUtOL2eioCB7wI3c","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] tld crawling","postDate":"1089878896","msgId":645,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQwRjYzQjcwLjMwMDA0MDZAaGFsYWNzeS5jb20+","inReplyToHeader":"PDQwRjVFMTE1LjYwOTA3MDZAYXJjaGl2ZS5vcmc+","referencesHeader":"PDQwRjRGNzFGLjUwMzAxQGhhbGFjc3kuY29tPiA8NDBGNUUxMTUuNjA5MDcwNkBhcmNoaXZlLm9yZz4="},"prevInTopic":642,"nextInTopic":646,"prevInTime":644,"nextInTime":646,"topicId":631,"numMessagesInTopic":5,"msgSnippet":"... Hi! Thanks for your help. After adding a postselector regexp filter with the same regexp the crawler seems to fetch only .hu pages. Transitive filter is","rawEmail":"Return-Path: &lt;peter@...&gt;\r\nX-Sender: peter@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 32364 invoked from network); 15 Jul 2004 08:08:28 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m19.grp.scd.yahoo.com with QMQP; 15 Jul 2004 08:08:28 -0000\r\nReceived: from unknown (HELO amitabha.axelero.hu) (195.228.240.92)\n  by mta1.grp.scd.yahoo.com with SMTP; 15 Jul 2004 08:08:28 -0000\r\nReceived: from amitabha (localhost-02 [127.0.2.1])\n\tby amitabha.axelero.hu (8.12.11/8.12.11) with SMTP id i6F88LCG086543\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Thu, 15 Jul 2004 10:08:22 +0200 (CEST)\r\nReceived: from fe04.axelero.hu [127.0.2.1] via SMTP gateway\n\tby amitabha [195.228.240.92]; id A05208887C7\n\tat Thu, 15 Jul 2004 10:08:21 +0200\r\nReceived: from halacsy.com (244.48-182-adsl-pool.axelero.hu [81.182.48.244])\n\tby fe04.axelero.hu (8.12.11/8.12.11) with ESMTP id i6F88IWs086493\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Thu, 15 Jul 2004 10:08:21 +0200 (CEST)\r\nMessage-ID: &lt;40F63B70.3000406@...&gt;\r\nDate: Thu, 15 Jul 2004 10:08:16 +0200\r\nUser-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.6) Gecko/20040113\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;40F4F71F.50301@...&gt; &lt;40F5E115.6090706@...&gt;\r\nIn-Reply-To: &lt;40F5E115.6090706@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: quoted-printable\r\nX-MIME-Autoconverted: from 8bit to quoted-printable by fe04.axelero.hu id i6F88IWs086493\r\nX-eGroups-Remote-IP: 195.228.240.92\r\nFrom: =?ISO-8859-1?Q?Hal=E1csy_P=E9ter?= &lt;peter@...&gt;\r\nSubject: Re: [archive-crawler] tld crawling\r\nX-Yahoo-Group-Post: member; u=32488388\r\nX-Yahoo-Profile: halacsypeter\r\n\r\nIgor Ranitovic wrote:\n\n&gt; Hi Hal=E1csy P=E9ter,\n&gt;\n&gt;\n&gt;\n&gt; Basically, this mean=\r\ns exclude URLs that do not have .hu in their domain.\n&gt; It is a bit confusin=\r\ng so maybe it would be cleaner to use Filter Scope.\n&gt; Within filter scope y=\r\nou can specify any number of filters that define \n&gt; the scope.\n&gt; In your ca=\r\nse you can use a single URIRegExpFilter:\n&gt; https?://[^/]+&#92;.hu(?::&#92;d+)?/).*\n=\r\n&gt;\n&gt; I have not used filter scope yet, so if you decide to use it please \n&gt; =\r\nlet us know if it works as expected.\n&gt; Also, it is kind of awkward to set u=\r\np the filter scope. The following \n&gt; are three necessary steps to\n&gt; configu=\r\nre it:\n&gt; 1. change scope at &quot;Modules&quot; configuration page.\n&gt; 2. add new URIR=\r\negExpFilter filter at &quot;Filters&quot; configuration page.\n&gt; 3. set regular expres=\r\nsion to added filter from 2. at &quot;Settings&quot; \n&gt; configuration page.\n&gt;\n&gt; Keep =\r\nin mind that transitive and additinalFocusFilter are enabled by \n&gt; default.=\r\n These two filters\n&gt; expend the scope to crawl embedded objects.\n&gt;\nHi!\nThan=\r\nks for your help. After adding a postselector regexp filter with the \nsame =\r\nregexp the crawler seems to fetch only .hu pages. Transitive filter \nis dis=\r\nabled, and I think additioinalFocusFilter is set disabled when \nusing Filte=\r\nrScope.\n\npeter\n\n\n\n\n"}}