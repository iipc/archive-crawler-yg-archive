{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":226767221,"authorName":"Matt Ittigson","from":"Matt Ittigson &lt;cydatamatt@...&gt;","replyTo":"LIST","senderId":"tw4lvv_Q_SbzQ2aQdToBoG1bpUZ4Zp7kU-SY82EfRru81ZXlPbrNkCage3uMC5oXY4eiqoTsvmRnLGyGVL9qUV0FOavEL-V3n5Dp","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Best approach to 7M seeds","postDate":"1125702994","msgId":2157,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDlkMWU0NTI1MDUwOTAyMTYxNjMxOWEzQG1haWwuZ21haWwuY29tPg==","inReplyToHeader":"PDQzMThENTYwLjEwMjA2MDVAYXJjaGl2ZS5vcmc+","referencesHeader":"PDlkMWU0NTI1MDUwODE3MTAyMzQ4Y2Q2MmE4QG1haWwuZ21haWwuY29tPgkgPDQzMDM4NTI3LjgwMjAxMDFAYXJjaGl2ZS5vcmc+CSA8OWQxZTQ1MjUwNTA4MjIxMzQ3NzI2Y2RjZGRAbWFpbC5nbWFpbC5jb20+CSA8OWQxZTQ1MjUwNTA5MDIxMjU4NDlmZDM3M2FAbWFpbC5nbWFpbC5jb20+CSA8MTcxNzYuNDUxNzUuOTI5MzA3LjkzODkxN0B0aXBoYXJlcy5iYXNpc3RlY2gubmV0PgkgPDlkMWU0NTI1MDUwOTAyMTMyMjU2NzgzNGI3QG1haWwuZ21haWwuY29tPgkgPDQzMThDMTBBLjEwMzA1MDVAYXJjaGl2ZS5vcmc+CSA8OWQxZTQ1MjUwNTA5MDIxNTA0NzU2YjRkNDVAbWFpbC5nbWFpbC5jb20+CSA8NDMxOEQ1NjAuMTAyMDYwNUBhcmNoaXZlLm9yZz4="},"prevInTopic":2156,"nextInTopic":2158,"prevInTime":2156,"nextInTime":2158,"topicId":2116,"numMessagesInTopic":25,"msgSnippet":"... Part of our application is to grab the links found in each URL and dump them out into a separate file.  Without the extractors, would curi.getOutLinks be","rawEmail":"Return-Path: &lt;cydatamatt@...&gt;\r\nX-Sender: cydatamatt@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 44672 invoked from network); 2 Sep 2005 23:16:35 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m2.grp.scd.yahoo.com with QMQP; 2 Sep 2005 23:16:35 -0000\r\nReceived: from unknown (HELO zproxy.gmail.com) (64.233.162.196)\n  by mta5.grp.scd.yahoo.com with SMTP; 2 Sep 2005 23:16:35 -0000\r\nReceived: by zproxy.gmail.com with SMTP id i11so472709nzh\n        for &lt;archive-crawler@yahoogroups.com&gt;; Fri, 02 Sep 2005 16:16:35 -0700 (PDT)\r\nReceived: by 10.36.220.26 with SMTP id s26mr2918180nzg;\n        Fri, 02 Sep 2005 16:16:34 -0700 (PDT)\r\nReceived: by 10.36.55.19 with HTTP; Fri, 2 Sep 2005 16:16:34 -0700 (PDT)\r\nMessage-ID: &lt;9d1e45250509021616319a3@...&gt;\r\nDate: Fri, 2 Sep 2005 18:16:34 -0500\r\nTo: archive-crawler@yahoogroups.com\r\nIn-Reply-To: &lt;4318D560.1020605@...&gt;\r\nMime-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Transfer-Encoding: quoted-printable\r\nContent-Disposition: inline\r\nReferences: &lt;9d1e4525050817102348cd62a8@...&gt;\n\t &lt;43038527.8020101@...&gt;\n\t &lt;9d1e45250508221347726cdcdd@...&gt;\n\t &lt;9d1e4525050902125849fd373a@...&gt;\n\t &lt;17176.45175.929307.938917@...&gt;\n\t &lt;9d1e45250509021322567834b7@...&gt;\n\t &lt;4318C10A.1030505@...&gt;\n\t &lt;9d1e45250509021504756b4d45@...&gt;\n\t &lt;4318D560.1020605@...&gt;\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: Matt Ittigson &lt;cydatamatt@...&gt;\r\nSubject: Re: [archive-crawler] Best approach to 7M seeds\r\nX-Yahoo-Group-Post: member; u=226767221\r\n\r\nOn 9/2/05, Igor Ranitovic &lt;igor@...&gt; wrote:\n&gt; Hi Matt,\n&gt; \n&gt; Stack j=\r\nust brought up that you need to turn off the extractors.\n\nPart of our appli=\r\ncation is to grab the links found in each URL and\ndump them out into a sepa=\r\nrate file.  Without the extractors, would\ncuri.getOutLinks be empty without=\r\n the extractors?\n\n&gt; If you want embeds (images, frames, etc.) than leave ex=\r\ntractors on, setup max-hops to 1 and enable\n&gt; additionalScopeFocus and set =\r\nmax-embed-hops.\n\nWould there be a huge difference in possible memory usage =\r\nwith or\nwithout the extractors (I might need them anyways, from above)?\n \n&gt;=\r\n Also, if you have 7M URLs from ~7M different hosts that would require a lo=\r\nt of memory since for each\n&gt; host we need to create a separate queue. There=\r\nfore, we suggest that you change default\n&gt; QueueAssignmentPolicy to somethi=\r\nng like this\n&gt; http://crawler.archive.org/apidocs/org/archive/crawler/front=\r\nier/BucketQueueAssignmentPolicy.html\n&gt; \n&gt; Let us know if this is working ou=\r\nt for you.\n\nThanks.  I should have some preliminary results for you soon.  =\r\nI\nappreciate all the help from everyone.\n\n-matt\n\n&gt; &gt;&gt;Hi Matt,\n&gt; &gt;&gt;\n&gt; &gt;&gt;If y=\r\nou are planning to fetch only 7M URLs and not continue with traversing newl=\r\ny discover urls,\n&gt; &gt;&gt;you can use broad scope and import URIs as non seeds d=\r\nirectly to frontier.\n&gt; &gt;&gt;Would that work?\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; I&#39;ll try that first a=\r\nnd get back to everyone.\n&gt; &gt;\n&gt; &gt; Thanks for the suggestion.\n&gt; &gt;\n&gt; &gt; -matt\n&gt;=\r\n &gt;\n&gt; &gt;\n&gt; &gt;&gt;&gt;On 9/2/05, Tom Emerson &lt;Tree@...&gt; wrote:\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;\n=\r\n&gt; &gt;&gt;&gt;&gt;If you are interested in only getting those 7M seeds wouldn&#39;t it be\n&gt;=\r\n &gt;&gt;&gt;&gt;easier to just write a script in Perl to spin over them and fetch the\n=\r\n&gt; &gt;&gt;&gt;&gt;content?\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;Good question.\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;I really like the=\r\n Heritrix GUI.  The JMX integration is a great way to\n&gt; &gt;&gt;&gt;track the progre=\r\nss of the spider from other processes.  The coming\n&gt; &gt;&gt;&gt;clustered spidering=\r\n is a way to go from, say, 7M seeds to 70M seeds.\n&gt; &gt;&gt;&gt;We use the ARC files=\r\n on the backend and have written a module that\n&gt; &gt;&gt;&gt;pulls links out of Heri=\r\ntrix in the way we need &#39;em.  And we&#39;ve used\n&gt; &gt;&gt;&gt;Heritrix to get to the po=\r\nint that we had 7M seeds.\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;Not that all of those things couldn&#39;t =\r\nbe replicated in a simpler\n&gt; &gt;&gt;&gt;system than Heritrix ... and perhaps should=\r\n be if our biggest problem\n&gt; &gt;&gt;&gt;is figuring out a way to spider 7M seeds.\n&gt;=\r\n &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;-matt\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;Yahoo! Groups Links\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;=\r\n&gt;\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;&gt;\n&gt; &gt;&gt;\n&gt; &gt;&gt;\n&gt; &gt;&gt;Yahoo! Groups Li=\r\nnks\n&gt; &gt;&gt;\n&gt; &gt;&gt;\n&gt; &gt;&gt;\n&gt; &gt;&gt;\n&gt; &gt;&gt;\n&gt; &gt;&gt;\n&gt; &gt;&gt;\n&gt; &gt;&gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; Yahoo! =\r\nGroups Links\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; Yahoo! Groups Lin=\r\nks\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt;\n\n"}}