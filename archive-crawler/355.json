{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137477665,"authorName":"Igor Ranitovic","from":"Igor Ranitovic &lt;igor@...&gt;","profile":"iranitovic","replyTo":"LIST","senderId":"r1bhFVV-_Bglci4K14-0tCEwLEHDsokRcxGKGcO6BhiOZ4HaR-1FagVbEFOYoxFCvbnL1IAWahi5Yeu3WN5a2wEJFCGSvsJe","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Large seed lists: some troubles","postDate":"1083172733","msgId":355,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQwOEZFNzdELjgwODA1MDlAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PHMwOGY3ZDMyLjAwNEBsb2MuZ292Pg==","referencesHeader":"PHMwOGY3ZDMyLjAwNEBsb2MuZ292Pg=="},"prevInTopic":353,"nextInTopic":356,"prevInTime":354,"nextInTime":356,"topicId":353,"numMessagesInTopic":4,"msgSnippet":"... If you are setting up crawling machines for a large audince (non-root users) you can configure limits in /etc/security/limits.conf. For example you can","rawEmail":"Return-Path: &lt;igor@...&gt;\r\nX-Sender: igor@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 77651 invoked from network); 28 Apr 2004 17:28:20 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m23.grp.scd.yahoo.com with QMQP; 28 Apr 2004 17:28:20 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (209.237.232.202)\n  by mta5.grp.scd.yahoo.com with SMTP; 28 Apr 2004 17:28:19 -0000\r\nReceived: (qmail 27896 invoked by uid 100); 28 Apr 2004 17:21:15 -0000\r\nReceived: from b116-dyn-56.archive.org (HELO archive.org) (igor@...@209.237.240.56)\n  by mail-dev.archive.org with SMTP; 28 Apr 2004 17:21:15 -0000\r\nMessage-ID: &lt;408FE77D.8080509@...&gt;\r\nDate: Wed, 28 Apr 2004 10:18:53 -0700\r\nUser-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.0; en-US; rv:1.6b) Gecko/20031205 Thunderbird/0.4\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;s08f7d32.004@...&gt;\r\nIn-Reply-To: &lt;s08f7d32.004@...&gt;\r\nContent-Type: text/plain; charset=us-ascii; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=0.0 required=6.0 tests=AWL autolearn=ham version=2.63\r\nX-eGroups-Remote-IP: 209.237.232.202\r\nFrom: Igor Ranitovic &lt;igor@...&gt;\r\nSubject: Re: [archive-crawler] Large seed lists: some troubles\r\nX-Yahoo-Group-Post: member; u=137477665\r\nX-Yahoo-Profile: iranitovic\r\n\r\n&gt; I happen to have a seed list of nearly 1024 entries.  Not totally \n&gt; surprisingly, Heritrix behaves a little oddly with that many seeds.  \n&gt; First, crawls with either 0.6.0 or the latest CVS build fail because too \n&gt; many files are opened almost immediately, and then neither socket \n&gt; operations nor file logging are able to proceed.  A typical exception:\n&gt;  java.io.FileNotFoundException: \n&gt; /crawl/heritrix/heritrix-0.6.0/jobs/crs-20040427190708335/disk/scratch/bphc.hrsa.gov.ff0 \n&gt; (Too many open files)\n&gt;         at java.io.FileOutputStream.open(Native Method)\n&gt;         at java.io.FileOutputStream.&lt;init&gt;(FileOutputStream.java:179)\n&gt;         at java.io.FileOutputStream.&lt;init&gt;(FileOutputStream.java:131)\n&gt;         at \n&gt; org.archive.io.FlipFileOutputStream.&lt;init&gt;(FlipFileOutputStream.java:69)\n&gt;         at \n&gt; org.archive.io.DiskBackedByteQueue.initializeStreams(DiskBackedByteQueue.java:67)\n&gt;         at org.archive.util.DiskQueue.&lt;init&gt;(DiskQueue.java:100)\n&gt;         at org.archive.util.DiskBackedQueue.&lt;init&gt;(DiskBackedQueue.java:59)\n&gt;         at org.archive.crawler.basic.KeyedQueue.&lt;init&gt;(KeyedQueue.java:76)\n&gt;         at \n&gt; org.archive.crawler.basic.Frontier.keyedQueueFor(Frontier.java:927)\n&gt;         at \n&gt; org.archive.crawler.basic.Frontier.scheduleForRetry(Frontier.java:1333)\n&gt;         at org.archive.crawler.basic.Frontier.finished(Frontier.java:676)\n&gt;         at \n&gt; org.archive.crawler.framework.ToeThread.processCrawlUri(ToeThread.java:200)\n&gt;         at org.archive.crawler.framework.ToeThread.run(ToeThread.java:124)\n&gt; You can get past that by allowing a larger number of open files for the \n&gt; process (which requires running Heritrix with root privilege), as in:\n&gt;    # (ulimit -n 4096; JAVA_OPTS=-Xmx320 bin/heritrix -p 9876)\n\nIf you are setting up crawling machines for a large audince (non-root users) you can configure \nlimits in /etc/security/limits.conf. For example you can setup open files limit for all users in \nwebcrawler group as:\n\n#Each line describes a limit for a user in the form:\n#\n#&lt;domain&gt;        &lt;type&gt;  &lt;item&gt;  &lt;value&gt;\n#\n#&lt;domain&gt;      &lt;type&gt;  &lt;item&gt;         &lt;value&gt;\n#\n\n@webcrawler     hard    nofile  32768\n\n\nNow all users in the webcrawler group can set limits. Also, I set the limits in my bash profile so \nthat I don&#39;t need to worry about it at all.\n\ni.\n\n"}}