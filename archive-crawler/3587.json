{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":191387937,"authorName":"pandae667","from":"&quot;pandae667&quot; &lt;aaron667@...&gt;","profile":"pandae667","replyTo":"LIST","senderId":"CGVAo2BufBWI6W0di1NZ1ToGBVmT7wbWTLcfB38nmTXON8Mbo7cu5dX3UbnQs4bZTSSNXfAidoPdxj7rr9oOEYp64XKt","spamInfo":{"isSpam":false,"reason":"6"},"subject":"writing a crawl.log per processed domain","postDate":"1165782397","msgId":3587,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGVsaHFodCs2OTRiQGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":3590,"prevInTime":3586,"nextInTime":3588,"topicId":3587,"numMessagesInTopic":2,"msgSnippet":"Hi everyone, I m currently having a problem that I m not able to solve. I am currently spidering a rather big set of seeds and thus my crawl.log gets really","rawEmail":"Return-Path: &lt;aaron667@...&gt;\r\nX-Sender: aaron667@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 87248 invoked from network); 10 Dec 2006 20:36:43 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m23.grp.scd.yahoo.com with QMQP; 10 Dec 2006 20:36:43 -0000\r\nReceived: from unknown (HELO n8c.bullet.sp1.yahoo.com) (69.147.64.170)\n  by mta6.grp.scd.yahoo.com with SMTP; 10 Dec 2006 20:36:43 -0000\r\nReceived: from [216.252.122.219] by n8.bullet.sp1.yahoo.com with NNFMP; 10 Dec 2006 20:26:37 -0000\r\nReceived: from [66.218.69.6] by t4.bullet.sp1.yahoo.com with NNFMP; 10 Dec 2006 20:26:37 -0000\r\nReceived: from [66.218.66.77] by t6.bullet.scd.yahoo.com with NNFMP; 10 Dec 2006 20:26:37 -0000\r\nDate: Sun, 10 Dec 2006 20:26:37 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;elhqht+694b@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;pandae667&quot; &lt;aaron667@...&gt;\r\nSubject: writing a crawl.log per processed domain\r\nX-Yahoo-Group-Post: member; u=191387937; y=cJFx6bIahKJMU4hRYz7eP5HZdVo4L8wcEF0bHRhZc6FPtkKq\r\nX-Yahoo-Profile: pandae667\r\n\r\nHi everyone,\n\nI&#39;m currently having a problem that I&#39;m not able to solve.\nI =\r\nam currently spidering a rather big set of seeds and thus my\ncrawl.log gets=\r\n really big. Unfortunatly I have to post-process the\ncrawl.log to retrieve =\r\nsome additional informations for some ULRs I&#39;m\ninterested in. (Basically th=\r\ne linkpath from a seed to the URLs in\nquestion).\n\nTo ease this process I&#39;d =\r\nlike to split up the crawl.log into multiple\nfiles (one per domain). But I =\r\ndon&#39;t wanna do this after my crawl is\ndone, I want heritrix to do this on t=\r\nhe fly (either additional to the\nnormal crawl.log or as an optional way to =\r\noutput the contained data).\n\nI traced down the place the crawl.log gets wri=\r\ntten to the &quot;void\nlog(CrawlURI curi)&quot; method in AbstractFrontier.java, so I=\r\n know _where_\nit happens - but I have no clue how to change the normal beha=\r\nvior to\nwhat I want/need.\n\nDoes anyone have some useful ideas?\n\nRegards\n  O=\r\nlaf Freyer\n\n\n"}}