{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"K8uZsDdjYuBSEluGUbpQSVcSpwdv4IGKlJ5Qn1AiVwENwlw4-UzPGndR_E6siCemktrdWRU3So4g8Z75f6CJJ55N2LqyT7Q","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Rescheduling crawl job slowing down [1 Attachment]","postDate":"1329794522","msgId":7619,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRGNDMwRERBLjgwNzA4QGFyY2hpdmUub3JnPg==","inReplyToHeader":"PENBS181S1hTeS1qU2tCRlZwYnVldFEzWWNxdTdWaWhXemlfUGZxNmFRa2paZ0Q5enBtZ0BtYWlsLmdtYWlsLmNvbT4=","referencesHeader":"PENBS181S1hTeS1qU2tCRlZwYnVldFEzWWNxdTdWaWhXemlfUGZxNmFRa2paZ0Q5enBtZ0BtYWlsLmdtYWlsLmNvbT4="},"prevInTopic":7618,"nextInTopic":0,"prevInTime":7618,"nextInTime":7620,"topicId":7618,"numMessagesInTopic":2,"msgSnippet":"It would take a closer analysis of the settings and logs to know whether this is exactly what it should be doing, or not. (For example: are all the URIs you d","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 3390 invoked from network); 21 Feb 2012 03:22:05 -0000\r\nX-Received: from unknown (98.137.35.162)\n  by m5.grp.sp2.yahoo.com with QMQP; 21 Feb 2012 03:22:05 -0000\r\nX-Received: from unknown (HELO relay02.pair.com) (209.68.5.16)\n  by mta6.grp.sp2.yahoo.com with SMTP; 21 Feb 2012 03:22:05 -0000\r\nX-Received: (qmail 3772 invoked by uid 0); 21 Feb 2012 03:22:02 -0000\r\nX-Received: from 70.36.143.78 (HELO silverbook.local) (70.36.143.78)\n  by relay02.pair.com with SMTP; 21 Feb 2012 03:22:02 -0000\r\nX-pair-Authenticated: 70.36.143.78\r\nMessage-ID: &lt;4F430DDA.80708@...&gt;\r\nDate: Mon, 20 Feb 2012 19:22:02 -0800\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.7; rv:10.0.2) Gecko/20120216 Thunderbird/10.0.2\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: Mahmoud Mubarak &lt;mahmoudmubarak@...&gt;\r\nReferences: &lt;CAK_5KXSy-jSkBFVpbuetQ3Ycqu7VihWzi_Pfq6aQkjZgD9zpmg@...&gt;\r\nIn-Reply-To: &lt;CAK_5KXSy-jSkBFVpbuetQ3Ycqu7VihWzi_Pfq6aQkjZgD9zpmg@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Rescheduling crawl job slowing down [1 Attachment]\r\nX-Yahoo-Group-Post: member; u=137285340; y=EwqbBIwPlU9UrFKSHpz-3l3ssjuCdUSMnBnvMwkyimJ3\r\nX-Yahoo-Profile: gojomo\r\n\r\nIt would take a closer analysis of the settings and logs to know whether \nthis is exactly what it should be doing, or not.\n\n(For example: are all the URIs you&#39;d expect to be revisited being \nrevisited at the desired intervals? Are any of the duplication-reduction \nfeatures in effect and preventing redundant downloads? Are there any \nerrors evident that are sometimes causing URIs to not be rescheduled as \ndesired?)\n\nNote that the ReschedulingProcessor is a crude first experiment/example \nof what&#39;s possible by setting a per-CrawlURI revisit-interval. It&#39;s not \nbeen used in production crawls elsewhere, as far as I know, so there&#39;s \nno idea of what&#39;s &#39;normal&#39; for such a crawl.\n\nAlso, it would highly depend on the target sites. While many sites could \nbe expected to consistently grow over time, others might \nretire/take-down old material faster than new material is \nposted/discovered-via-revisiting-old-URIs.\n\n- Gordon\n\nOn 2/20/12 6:06 AM, Mahmoud Mubarak wrote:\n&gt; [Attachment(s) &lt;#TopText&gt; from Mahmoud Mubarak included below]\n&gt;\n&gt; We have been running a crawl job for 18 days under the\n&gt; ReschedulingProcessor. As seen in the attached chart, the crawler&#39;s\n&gt; throughput is generally gradually going down. Is this normal for a\n&gt; rescheduling crawl job? Does it continue to slow down indefinitely? Are\n&gt; there any measures to take to help keep the rate steady?\n&gt;\n&gt;\n&gt;\n&gt;\n&gt; --\n&gt; Mahmoud A. Mubarak\n&gt; Bibliotheca Alexandrina\n&gt;\n&gt; Attachment(s) from Mahmoud Mubarak\n&gt;\n&gt; 1 of 1 File(s)\n&gt;\n&gt; Rescheduling_crawl_rates_6hrs.ods\n&gt; &lt;http://xa.yimg.com/kq/groups/8759867/940321563/name/Rescheduling_crawl_rates_6hrs%2Eods&gt;\n&gt;\n&gt; \n\n"}}