{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":340093092,"authorName":"winter_lamm","from":"&quot;winter_lamm&quot; &lt;winter_lamm@...&gt;","profile":"winter_lamm","replyTo":"LIST","senderId":"pxI-ns3z5YTTlS77LdLI_NZnSAD2Sutsd3AKLKJusplymJHWwnHAi0x9f1jM5-6e1M6xf8fWAmia-gPRQz9eQctAHOHj5iPUxzwvrQ","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: download single page","postDate":"1205504279","msgId":5060,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZyZTFlbis1MDlqQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGFscGluZS5XTlQuMS4wMC4wODAzMTIyMzAyNTgwLjE0NjBAYmVydD4="},"prevInTopic":5054,"nextInTopic":5063,"prevInTime":5059,"nextInTime":5061,"topicId":5050,"numMessagesInTopic":5,"msgSnippet":"Hello, Thank you for your hints, but when I use your settings, i will always get only the html page. (At the crawl report only the mime type text/html ist","rawEmail":"Return-Path: &lt;winter_lamm@...&gt;\r\nX-Sender: winter_lamm@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 99840 invoked from network); 14 Mar 2008 14:18:01 -0000\r\nX-Received: from unknown (66.218.67.94)\n  by m48.grp.scd.yahoo.com with QMQP; 14 Mar 2008 14:18:01 -0000\r\nX-Received: from unknown (HELO n48a.bullet.mail.sp1.yahoo.com) (66.163.168.142)\n  by mta15.grp.scd.yahoo.com with SMTP; 14 Mar 2008 14:18:00 -0000\r\nX-Received: from [216.252.122.217] by n48.bullet.mail.sp1.yahoo.com with NNFMP; 14 Mar 2008 14:18:00 -0000\r\nX-Received: from [66.218.69.6] by t2.bullet.sp1.yahoo.com with NNFMP; 14 Mar 2008 14:18:00 -0000\r\nX-Received: from [66.218.66.90] by t6.bullet.scd.yahoo.com with NNFMP; 14 Mar 2008 14:18:00 -0000\r\nDate: Fri, 14 Mar 2008 14:17:59 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;fre1en+509j@...&gt;\r\nIn-Reply-To: &lt;alpine.WNT.1.00.0803122302580.1460@bert&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;winter_lamm&quot; &lt;winter_lamm@...&gt;\r\nSubject: Re: download single page\r\nX-Yahoo-Group-Post: member; u=340093092; y=nmoimbkUkAPqhUnbWuEgW0sE6-66EqXHFltHRpBl_f6qwwVV09I\r\nX-Yahoo-Profile: winter_lamm\r\n\r\nHello,\n\nThank you for your hints, but when I use your settings, i will alwa=\r\nys\nget only the html page. (At the crawl report only the mime type\ntext/htm=\r\nl ist displayed).\n\nWhat am i doing wrong?? \n\nAt the seed is use for instanc=\r\ne \nhttp://www.yahoo.com\nIs that wrong?\n\nThank you for your help!\n\nBest,\nChr=\r\nis\n\n\n\n--- In archive-crawler@yahoogroups.com, Bert Wendland &lt;bwendland@...&gt;=\r\n\nwrote:\n&gt;\n&gt; \n&gt; Here is the decision chaine that we use to collect a single =\r\npage\n(Heritrix \n&gt; 1.12.0):\n&gt; \n&gt; 1) REJECT by default (RejectDecideRule)\n&gt; 2=\r\n) ACCEPT if Surt prefixed (SurtPrefixedDecideRule)\n&gt;       seeds-as-surt-pr=\r\nefixes: true\n&gt;       also-check-via: false\n&gt; 3) REJECT if too many hops (To=\r\noManyHopsDecideRule)\n&gt;       max-hops: 0\n&gt; 4) ACCEPT if transcluded (Transc=\r\nlusionDecideRule)\n&gt;       max-trans-hops: 1\n&gt;       max-speculative-hops: 1=\r\n\n&gt; 5) ACCEPT if prerequisite (PrerequisiteAcceptDecideRule)\n&gt; \n&gt; Rule 3) re=\r\nstricts the crawl to the given page (i.e. no HTML link\nwill be \n&gt; followed)=\r\n. Rule 4) allows to collect all the embedded contents\n(images & \n&gt; co.). Ru=\r\nle 5) is necessary to fetch the robots.txt file of the remote \n&gt; site.\n&gt; \n&gt;=\r\n Best,\n&gt;    Bert\n&gt; \n&gt; On Tue, 11 Mar 2008, 17:28, Micah Wedemeyer wrote:\n&gt; =\r\n\n&gt; &gt; This might be no help, but based on my (very limited) experience,\nhere=\r\n&#39;s\n&gt; &gt; what I would look at:\n&gt; &gt;\n&gt; &gt; Set up your decision rules as follows:=\r\n\n&gt; &gt;\n&gt; &gt; 1) REJECT all (RejectDecideRule)\n&gt; &gt; 2) ACCEPT by file pattern for=\r\n what you want (js, jpeg, jpg) - try the\n&gt; &gt; ALL enumeration in MatchesFile=\r\nPatternDecideRule, it will include\nlots of\n&gt; &gt; media stuff, but I don&#39;t kno=\r\nw about javascript\n&gt; &gt; 3) ACCEPT by file pattern for anything not covered i=\r\nn step 2\n&gt; &gt; 4) ACCEPT seed - SeedAcceptDecideRule\n&gt; &gt;\n&gt; &gt; Hope this helps.=\r\n\n&gt; &gt;\n&gt; &gt; Micah\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; winter_lamm wrote:\n&gt; &gt;&gt;\n&gt; &gt;&gt;\n&gt; &gt;&gt; Hello,\n&gt; &gt;&gt;\n&gt; =\r\n&gt;&gt; I would like to download a single page (and all of its images,\n&gt; &gt;&gt; java=\r\nscript,...) with heritrix, but i do not know the real\nsettings for\n&gt; &gt;&gt; thi=\r\ns. Either only the page (html/text) will be downloaded, or\nheritrix\n&gt; &gt;&gt; wi=\r\nll follow a lot of links on the page and loads all content.\n&gt; &gt;&gt;\n&gt; &gt;&gt; I use=\r\nd rejectIfTooManyHops =3D 0 to only get the links from my\nseed, but\n&gt; &gt;&gt; wh=\r\nat other options will i need?\n&gt; &gt;&gt;\n&gt; &gt;&gt; Can anyone give me a hint to solve =\r\nthis problem please.\n&gt; &gt;&gt;\n&gt; &gt;&gt; Thank you.\n&gt; &gt;\n&gt;\n\n\n\n"}}