{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":132996324,"authorName":"joehung302","from":"&quot;joehung302&quot; &lt;joe.hung@...&gt;","profile":"joehung302","replyTo":"LIST","senderId":"m8gBReeiADo5FsN35re9w7jNpQi5Db6JE09IQSxV-cATGONNnfQNcODsNI5OmgE2rb9pJ6K85snH85vre-1PzX0xiaP7IqK-0gCWXCrX","spamInfo":{"isSpam":false,"reason":"6"},"subject":"OOME Re: [archive-crawler] Re: Distributed Crawling","postDate":"1176247857","msgId":4080,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGV2aDZuaCtqbWY4QGVHcm91cHMuY29tPg==","inReplyToHeader":"PDQ2MUMwNjY3LjcwNjAxQGFyY2hpdmUub3JnPg=="},"prevInTopic":4078,"nextInTopic":4081,"prevInTime":4079,"nextInTime":4081,"topicId":3834,"numMessagesInTopic":26,"msgSnippet":"Does the following parameters make sense? hold-queues: true balance-replenish-amount: 3000 target-ready-backlog: 2000 cost-policy: AntiCalendar I just randomly","rawEmail":"Return-Path: &lt;joe.hung@...&gt;\r\nX-Sender: joe.hung@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 67767 invoked from network); 10 Apr 2007 23:31:41 -0000\r\nReceived: from unknown (66.218.67.33)\n  by m43.grp.scd.yahoo.com with QMQP; 10 Apr 2007 23:31:41 -0000\r\nReceived: from unknown (HELO n31c.bullet.sp1.yahoo.com) (209.131.38.210)\n  by mta7.grp.scd.yahoo.com with SMTP; 10 Apr 2007 23:31:41 -0000\r\nReceived: from [216.252.122.219] by n31.bullet.sp1.yahoo.com with NNFMP; 10 Apr 2007 23:30:57 -0000\r\nReceived: from [209.73.164.86] by t4.bullet.sp1.yahoo.com with NNFMP; 10 Apr 2007 23:30:57 -0000\r\nReceived: from [66.218.66.88] by t8.bullet.scd.yahoo.com with NNFMP; 10 Apr 2007 23:30:57 -0000\r\nDate: Tue, 10 Apr 2007 23:30:57 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;evh6nh+jmf8@...&gt;\r\nIn-Reply-To: &lt;461C0667.70601@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;joehung302&quot; &lt;joe.hung@...&gt;\r\nSubject: OOME Re: [archive-crawler] Re: Distributed Crawling\r\nX-Yahoo-Group-Post: member; u=132996324; y=khDaWXvVYYYJth1-WWWm30i613qfSayXWRMYzomflU9b9nma5g\r\nX-Yahoo-Profile: joehung302\r\n\r\nDoes the following parameters make sense?\n\nhold-queues: true\nbalance-replen=\r\nish-amount: 3000\ntarget-ready-backlog: 2000\ncost-policy: AntiCalendar\n\nI ju=\r\nst randomly picked the numbers after reading your post...\n\n\n--- In archive-=\r\ncrawler@yahoogroups.com, Gordon Mohr &lt;gojomo@...&gt; \nwrote:\n&gt;\n&gt; joehung302 wr=\r\note:\n&gt; &gt; so far there I&#39;ve got the first proof crawling (single instance \nb=\r\nut \n&gt; &gt; HashMap&#39;ed) going for 4 days with 12M docs downloaded. I just \ngot =\r\nthe \n&gt; &gt; first OOME error. I wonder if it&#39;s because that I turned the \nopti=\r\non\n&gt; &gt; \n&gt; &gt;  &lt;boolean name=3D&quot;hold-queues&quot;&gt;false&lt;/boolean&gt;\n&gt; &gt; \n&gt; &gt; to fals=\r\ne. We were using &quot;true&quot; for the last crawl but we thought \nit \n&gt; &gt; might be=\r\n a better practice to rotate the queues more frequently \n(to \n&gt; &gt; prevent t=\r\nhe busy crawling on certain sites).\n&gt; \n&gt; This is likely a contributor to th=\r\ne problem.\n&gt; \n&gt; The &#39;hold-queues&#39; setting originally made a giant differenc=\r\ne: for \nqueues \n&gt; that went &#39;inactive&#39;, only their name (queue key) was hel=\r\nd in \nmemory, \n&gt; while all &#39;ready&#39; queue objects (significantly larger than=\r\n just \nthe key) \n&gt; were held in memory. (In both cases, the actual URI cont=\r\nents of \nthe \n&gt; queues are on disk until needed.)\n&gt; \n&gt; Now, both the queue =\r\nof &#39;ready&#39; queues and the queue of &#39;inactive&#39; \nqueues \n&gt; are handled the sa=\r\nme way, with only the queue name definitely in \nmemory \n&gt; until the queue i=\r\ns needed.\n&gt; \n&gt; However, there will still be significant indirect effects. W=\r\nith \n&gt; &#39;hold-queues&#39; as false, all queues are created in the &#39;ready&#39; \nstate=\r\n. \n&gt; Essentially, *all* queues are round-robined for providing a URI to \n&gt; =\r\ncrawl. (As soon as one URI finishes, then the queue politeness \nwait, the \n=\r\n&gt; queue goes to the back of the &#39;ready&#39; rotation.)\n&gt; \n&gt; There will be at le=\r\nast two large effects of this in a broad crawl:\n&gt; \n&gt; (1) little chance of k=\r\neeping important in-memory object \ncaches &#39;warm&#39;: \n&gt; some queue/host/server=\r\n objects are in soft-reference caches \nbecause \n&gt; while they go unused (dur=\r\ning politeness delay and waiting in \nthe &#39;ready&#39; \n&gt; queue) for a while they=\r\n&#39;ll soon be needed again. With a humongous \n&gt; &#39;ready&#39; queue, chances are th=\r\ney&#39;ll be dropped from the cache \nbefore \n&gt; reused, so every URI crawled wil=\r\nl require a read-in and write-out \nof \n&gt; these related objects. (Lots more =\r\nIO, lots more temporary-low-\nmemory- \n&gt; conditions-forcing-soft-reference-c=\r\nlearing.)\n&gt; \n&gt; (2) small queues (eg &lt;5, &lt;20, &lt;100 URIs) won&#39;t get a chance =\r\nto \nfinish \n&gt; until *every* queue gets through that same number of items. T=\r\nhat \ncould \n&gt; mean a lot more nonempty queues in total -- and even with onl=\r\ny the \nqueue \n&gt; name in memory, could explain your problem in a long crawl.=\r\n (A \nfinished \n&gt; queue has no memory footprint, but even the smallest fille=\r\nd queue \nhas at \n&gt; least its name in memory).\n&gt; \n&gt; So for large/broad crawl=\r\ns, &#39;hold-queues&#39; should definitely be true.\n&gt; \n&gt; There are other ways to ge=\r\nt the desired &#39;broader rotation&#39; \nor &#39;less \n&gt; intense crawling&#39; effect you =\r\nwant, without going to round-robining \nall \n&gt; queues. Increasing politeness=\r\n delays is an obvious route, but \nanother is \n&gt; to increase the &#39;target-rea=\r\ndy-backlog&#39; value.\n&gt; \n&gt; The crawler aims to always keep this many queues in=\r\n the &#39;ready&#39; \nqueue, \n&gt; even if all threads are busy. So it will activate q=\r\nueues \nfrom &#39;inactive&#39; \n&gt; whenever the backlog falls below this number. Mak=\r\ning the number \nlarger \n&gt; means more queues are in &#39;active&#39; rotation -- so =\r\neven with fast \n&gt; politness settings, they may take a while to be hit again=\r\n, while \nother \n&gt; queues are in front of them. As these finish (or deplete =\r\n\ntheir &#39;budget&#39;, \n&gt; see below), others will come from &#39;inactive&#39; to replace=\r\n them.\n&gt; \n&gt; The other useful intensity-affecting settings are the &#39;cost&#39; an=\r\nd \n&gt; &#39;budget&#39; related values. A queue gets a &#39;balance-replenish-amount&#39; \n&gt; =\r\nsession-budget whenever it first becomes &#39;ready&#39;. Each URI crawled \n&gt; deple=\r\ntes that budget in accordance with the &#39;cost-policy&#39;. When \nthe \n&gt; session-=\r\nbudget reaches 0, the queue goes to the back of \nthe &#39;inactive&#39; \n&gt; queues t=\r\no give others a chance to crawl.\n&gt; \n&gt; Assuming a UnitCostAssignmentPolicy (=\r\nevery URI costs 1), a \n&gt; &#39;balance-replenish-amount&#39; of 1 would be a degener=\r\nate case much \nlike \n&gt; &#39;hold-queues&#39; being false: each queue would contribu=\r\nte one URI to \nbe \n&gt; crawled before getting to the back of one global line.=\r\n With a \n&gt; &#39;balance-replenish-amount&#39; of 100, a queue would give out up to =\r\n\n100 URIs \n&gt; before deactivating. This has the nice property of letting sma=\r\nll \nsites \n&gt; finish the first time they become &#39;active, while larger sites =\r\n\nrotate in \n&gt; and out of active crawling to let newly-discovered small site=\r\ns a \nchance \n&gt; to finish.\n&gt; \n&gt; So:\n&gt;   - &#39;target-ready-backlog&#39; and politen=\r\ness settings affect how \nintensely \n&gt; a queue is crawled while it is &#39;activ=\r\ne&#39;\n&gt;   - &#39;balance-replenish-amount&#39; and &#39;cost-policy&#39; affect how long a \nla=\r\nrge \n&gt; queue stays &#39;active&#39; before making way for other queues\n&gt;   - &#39;hold-=\r\nqueues&#39; at false makes all queues round-robin in \nthe &#39;ready&#39; \n&gt; state; a m=\r\ninimum &#39;balance-replenish-amount&#39; (with a nonzero cost \npolicy) \n&gt; makes al=\r\nl queues round-robin through the &#39;inactive&#39; state. In \neither \n&gt; case, the =\r\nqueue load (and memory load) can get much higher because \n&gt; queues neither =\r\nfinish nor get crawled frequently enough to skip \n&gt; roundtrips to disk.\n&gt; \n=\r\n&gt; &gt; Do you want to look the OOME problem further? What information \nshould =\r\n\n&gt; &gt; I send?\n&gt; \n&gt; If it recurs after adjusting your queue behaviors, good i=\r\nnfo is \nalways:\n&gt; \n&gt; - progress-statistics.log shortly before and after OOM=\r\nE\n&gt; \n&gt; - &#39;jmap -histo&#39; of heap, at times as close (before and after) OOME \n=\r\nas \n&gt; possible\n&gt; \n&gt; - if reproduceable in JDK 1.6, the better error stack d=\r\nump at time \nof \n&gt; OOME (to confirm if it is in fact heap-related), and if =\r\nnecessary \nthe \n&gt; HeapDumpOnOutOfMemoryError automatic full heap dump, for =\r\nlater \nanalysis \n&gt; of what&#39;s overgrown\n&gt; \n&gt; - Gordon @ IA\n&gt;\n\n\n\n"}}