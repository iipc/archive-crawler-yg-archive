{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":165458231,"authorName":"Bjarne Andersen","from":"Bjarne Andersen &lt;bja@...&gt;","profile":"bjarne_dk2000","replyTo":"LIST","senderId":"UzYwxoALrlrZfih2HiIfiXx6eWxCqnNF7y7d5NjQq_hLdSKuF_hhEcDateIWIyJX43lRwr_2KPY0DRVi-VsEvTJxByclrqjS8YnxqfPBNeE","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] continuous crawling proposal","postDate":"1107247966","msgId":1453,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQxRkY0MzVFLjUwNDAwMDFAc3RhdHNiaWJsaW90ZWtldC5kaz4=","inReplyToHeader":"PFBpbmUuTE5YLjQuNTYuMDUwMjAxMDA1ODUxMC4xMzQ0OEBwaWtlc3BlYWsubWV0YWNhcnRhLmNvbT4=","referencesHeader":"PFBpbmUuTE5YLjQuNTYuMDUwMjAxMDA1ODUxMC4xMzQ0OEBwaWtlc3BlYWsubWV0YWNhcnRhLmNvbT4="},"prevInTopic":1452,"nextInTopic":1454,"prevInTime":1452,"nextInTime":1454,"topicId":1452,"numMessagesInTopic":24,"msgSnippet":"You might want to take a look at the Automated Revisiting Module being developed at the moment by kris@archive.org It does implement a new Frontier including a","rawEmail":"Return-Path: &lt;bja@...&gt;\r\nX-Sender: bja@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 15279 invoked from network); 1 Feb 2005 08:53:14 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m21.grp.scd.yahoo.com with QMQP; 1 Feb 2005 08:53:14 -0000\r\nReceived: from unknown (HELO luna.statsbiblioteket.dk) (130.225.24.87)\n  by mta1.grp.scd.yahoo.com with SMTP; 1 Feb 2005 08:53:13 -0000\r\nReceived: from [130.225.25.67] (pc975.sb.statsbiblioteket.dk [130.225.25.67])\n by luna.statsbiblioteket.dk\n (iPlanet Messaging Server 5.2 HotFix 1.16 (built May 14 2003))\n with ESMTP id &lt;0IB800LK05ZYZI@...&gt; for\n archive-crawler@yahoogroups.com; Tue, 01 Feb 2005 09:52:46 +0100 (MET)\r\nDate: Tue, 01 Feb 2005 09:52:46 +0100\r\nIn-reply-to: &lt;Pine.LNX.4.56.0502010058510.13448@...&gt;\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-id: &lt;41FF435E.5040001@...&gt;\r\nOrganization: Statsbiblioteket\r\nMIME-version: 1.0\r\nContent-type: multipart/mixed; boundary=&quot;Boundary_(ID_TxDmSv5KI+9r0fTQd4Yxuw)&quot;\r\nX-Accept-Language: en-us, en\r\nUser-Agent: Mozilla Thunderbird 1.0 (X11/20041206)\r\nReferences: &lt;Pine.LNX.4.56.0502010058510.13448@...&gt;\r\nX-eGroups-Remote-IP: 130.225.24.87\r\nFrom: Bjarne Andersen &lt;bja@...&gt;\r\nSubject: Re: [archive-crawler] continuous crawling proposal\r\nX-Yahoo-Group-Post: member; u=165458231\r\nX-Yahoo-Profile: bjarne_dk2000\r\n\r\n\r\n--Boundary_(ID_TxDmSv5KI+9r0fTQd4Yxuw)\r\nContent-type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-transfer-encoding: 7BIT\r\n\r\nYou might want to take a look at the Automated Revisiting Module being \ndeveloped at the moment by kris@...\n\nIt does implement a new Frontier including a new Queing-mechanism along \nwith a simple algoritm to decide when to bring URI&#39;s to the top of the \nqueue (based on historical results - next-ready-time goes either up or \ndown everytime a page is fetched and compared to the last fetch)\n\nIt is available from the continous build box at crawler.archive.org (a \nCVS-brach called *_AR....)\n\nbest\nBjarne Andersen\n\nJohn R. Frank wrote:\n&gt; Stack,\n&gt; \n&gt; What do you think of these three steps as a possible way to implement\n&gt; continuous crawling in Heritrix?  Details for each of these three are\n&gt; discussed below.\n&gt; \n&gt; 1) extend the work queue&#39;s logic to only dequeue &quot;ready&quot; URLs\n&gt; \n&gt; 2) decide when to recheck a given page based on a simple model\n&gt; \n&gt; 3) detect substantive page changes and store the info in AlreadySeen\n&gt; \n&gt; \n&gt; \n&gt; 1) To do this, we need a queueing mechanism that blocks the dequeuing of a\n&gt; CrawlURI until we are past its assigned next &quot;okay to crawl&quot; moment.\n&gt; Where should we store this timestamp?  As you said, the BDB keys are\n&gt; overloaded with too much meaning already, so putting a seconds since the\n&gt; epoch in there is not so good:\n&gt; http://crawler.archive.org/xref/org/archive/crawler/frontier/BdbMultipleWorkQueues.html#246\n&gt; \n&gt; Perhaps this timestamp belongs in CandidateURI where the\n&gt; schedulingDirective pieces are?  For example, if the schedulingDirective\n&gt; is negative, then it could be interpreted as a timestamp.  So for a\n&gt; document next Wednesday, it would get:\n&gt; \n&gt; jrf@localhost~$ date +%s -d &quot;Feb 9 01:20:29 EST 2005&quot;\n&gt; 1107930029\n&gt; \n&gt; with a minus sign in front:  -1107930029\n&gt; \n&gt; Adding `date +%s -d now` now to that will give a positive number when it\n&gt; is okay to crawl.  This would require modifications to the four-bit\n&gt; interpretation of priority in the BDB key computation.  An escape value\n&gt; of 1111 might tell the queue that it needs to look in the object to find\n&gt; the value of the timestamp.\n&gt; \n&gt; The problem with this is that suddenly the queue is not a queue, because\n&gt; the keys are the sorting mechanism on the queue in the BDB implementation,\n&gt; right?  Do you see a way fix to this besides cycling through all the curi\n&gt; with 1111 looking at the full value of the timestamp?\n&gt; \n&gt; \n&gt; \n&gt; 2) To compute the time at which to refetch, we can predict the likelihood\n&gt; that the page has been modified as a function of time since last modified.\n&gt; See below for discussion of detecting last modified.  An easy function to\n&gt; use for this modeling comes from the Michaelis-Menton model of enzyme\n&gt; kinetics:\n&gt; \n&gt;       t is time elapsed after a modification of the content\n&gt; \n&gt;       P(t) is the probability that the page has changed by time t\n&gt; \n&gt;                          a\n&gt;                       k t\n&gt;              P(t) =  ---------------\n&gt;                            a\n&gt;                    1  + k t\n&gt; \n&gt; At small t, P is small.  At large t, P tends to 1, i.e. certainty of\n&gt; change.  It is easiest to choose a=2, which is the smallest integer value\n&gt; that gives step-like behavior.  We can then set k by fitting this function\n&gt; to any given page&#39;s history (details below).\n&gt; \n&gt; Given k, we can use P(t) to predict when to refetch a document.  We pick a\n&gt; threshold probability above which we want to refetch.  If we set it low,\n&gt; then we want to recheck more often.  If we set it high, that means we&#39;re\n&gt; willing to tolerate more stale content in order to not recheck as often.\n&gt; \n&gt; When P(t) exceeds the chosen threshold, then we want to recheck it.  By\n&gt; inverting the probability function, this threshold gives us a time to\n&gt; wait before rechecking the page:\n&gt; \n&gt;                  k                (-1/a)\n&gt;        t = ( ----------   -   k )\n&gt;              threshold\n&gt; \n&gt;    For clarity that is:\n&gt;    t = (((k / threshold) - k ) ^ (-1/a))\n&gt; \n&gt; t is the time interval between the most recent known modification event\n&gt; and that time in the future when the expected probability of change is\n&gt; just above threshold.  For robustness, we should define a time within\n&gt; which all pages must be rechecked.  In python, the function might look\n&gt; like:\n&gt; \n&gt; def delay(k, threshold):\n&gt;     Days = 60 * 60 * 24\n&gt;     maxRecheckDelay = 20 * Days\n&gt;     thresholdDelay = (((k / threshold) - k ) ^ (-1/alpha))\n&gt;     return minimum(maxRecheckDelay, thresholdDelay)\n&gt; \n&gt; \n&gt; 3. Since last-modified information is not universally provided by document\n&gt; repositories, we need a mechanism to detect substantive content changes\n&gt; and record them in the BDB.  I&#39;m looking into tools for this kind of\n&gt; content hashing that could be run in the extractor chain and stored in the\n&gt; object that gets into BDB.\n&gt; \n&gt; Suppose we have such a content hash, then the interval of time between two\n&gt; known modification events is an upper bound because there could have been\n&gt; a modification event that we did not observe between these observed\n&gt; events.  If these upper bounds are not far off the real value, then we can\n&gt; accurately approximate the probability of modification at half the\n&gt; observed interval as being 50%.  That is, we use the previously observed\n&gt; modification intervals to estimate what the next actual interval will be.\n&gt; If the average of the last, say, five observed intervals is T, then we\n&gt; estimate that at (T/2) in the future, the probability of modification will\n&gt; be 50%.  This let&#39;s us estimate a value for k based on previously observed\n&gt; modification intervals:\n&gt; \n&gt;                -a\n&gt;        k = (T/2)    which for a=2 is (two over T) squared.\n&gt; \n&gt; \n&gt; Some logic is required to make sure that only the last few, say five,\n&gt; meaningful modification intervals are averaged to make T.  This moving\n&gt; window average allows Heritrix to more rapidly adapt to pages that have\n&gt; varying update frequencies, which is most pages.\n&gt; \n&gt; \n&gt; Thoughts?  Reactions?\n&gt; \n&gt; John\n&gt; \n&gt; ------------------------------------------------------------------------\n&gt; *Yahoo! Groups Links*\n&gt; \n&gt;     * To visit your group on the web, go to:\n&gt;       http://groups.yahoo.com/group/archive-crawler/\n&gt;        \n&gt;     * To unsubscribe from this group, send an email to:\n&gt;       archive-crawler-unsubscribe@yahoogroups.com\n&gt;       &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;        \n&gt;     * Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;. \n&gt; \n&gt; \n\r\n--Boundary_(ID_TxDmSv5KI+9r0fTQd4Yxuw)\r\nContent-type: text/x-vcard; charset=utf-8; name=bja.vcf\r\nContent-disposition: attachment; filename=bja.vcf\r\n\r\n[ Attachment content not displayed ]\r\n--Boundary_(ID_TxDmSv5KI+9r0fTQd4Yxuw)--\r\n\n"}}