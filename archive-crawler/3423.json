{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":170503557,"authorName":"Gaudry","from":"&quot;Gaudry&quot; &lt;michelgaudry@...&gt;","profile":"michelgaudry","replyTo":"LIST","senderId":"FFOvJNwMKzQdUjQ5IydnA-LRbozhzn8F36bx-agjVkJcvScOrjY662ocTOLPCGoeI5lsG8i4aN75KtF2OgA8tOW8JettBEM","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: Slow crawl with Heritrix 1.8","postDate":"1160580528","msgId":3423,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGVnajJqaCtncnJkQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDQ1MkJGQUVELjEwODA3MDdAYXJjaGl2ZS5vcmc+"},"prevInTopic":3417,"nextInTopic":0,"prevInTime":3422,"nextInTime":3424,"topicId":3413,"numMessagesInTopic":3,"msgSnippet":"... time, ... Thank you very much for your indications. I indeed have more information about my problem. With another crawl of about 300 seeds, I get theses","rawEmail":"Return-Path: &lt;michelgaudry@...&gt;\r\nX-Sender: michelgaudry@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 47975 invoked from network); 11 Oct 2006 15:29:37 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m40.grp.scd.yahoo.com with QMQP; 11 Oct 2006 15:29:36 -0000\r\nReceived: from unknown (HELO n17a.bullet.scd.yahoo.com) (66.94.237.46)\n  by mta2.grp.scd.yahoo.com with SMTP; 11 Oct 2006 15:29:36 -0000\r\nReceived: from [66.218.69.3] by n17.bullet.scd.yahoo.com with NNFMP; 11 Oct 2006 15:28:49 -0000\r\nReceived: from [66.218.66.80] by t3.bullet.scd.yahoo.com with NNFMP; 11 Oct 2006 15:28:49 -0000\r\nDate: Wed, 11 Oct 2006 15:28:48 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;egj2jh+grrd@...&gt;\r\nIn-Reply-To: &lt;452BFAED.1080707@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;Gaudry&quot; &lt;michelgaudry@...&gt;\r\nSubject: Re: Slow crawl with Heritrix 1.8\r\nX-Yahoo-Group-Post: member; u=170503557; y=V1j8lx5Kass-2CcVZiuSLGF1lkO3E1aCu6oYpzbzv4cWzcWGWYLk\r\nX-Yahoo-Profile: michelgaudry\r\n\r\n--- In archive-crawler@yahoogroups.com, Gordon Mohr &lt;gojomo@...&gt; wrote:\n&gt;\n&gt;=\r\n Gaudry wrote:\n&gt; &gt; Hello,\n&gt; &gt; \n&gt; &gt; I&#39;m using Heritrix 1.8 and I configured =\r\na profile based on\n&gt; &gt; &quot;deciding-default&quot;.\n&gt; &gt; \n&gt; &gt; I tried crawls with abo=\r\nut 200 URL and max-toe-threads at 500 and it&#39;s\n&gt; &gt; very slow, with an avera=\r\nge of 25 active threads, 3 URI/s and 60 Kb/s.\n&gt; &gt; The others ToeThreads are=\r\n in status &quot;ABOUT_TO_GET_URI&quot;.\n&gt; &gt; \n&gt; &gt; There is also 149 queues with 42 ac=\r\ntive and 107 exhausted.\n&gt; &gt; \n&gt; &gt; I already reduced some &#39;waiting&#39; parameter=\r\ns of the Frontier like\n&gt; &gt; delay-factor, min-delay-ms, ...\t\n&gt; &gt; \n&gt; &gt; Do you=\r\n have an idea of what is happening ? \n&gt; \n&gt; It may be crawling as fast as it=\r\n can while respecting the politeness \n&gt; settings. Heritrix will only open o=\r\nne request to any one host at a\ntime, \n&gt; and will pause between requests in=\r\n accordance with the various &#39;delay&#39; \n&gt; settings.\n&gt; \n&gt; With 149 queues, tha=\r\nt means there are only 149 target sites available \n&gt; with URIs to crawl. Ha=\r\nving more than 149 ToeThreads won&#39;t help.\n&gt; \n&gt; Still, only 3 URI/s seems lo=\r\nw, unless either:\n&gt; (1) You are very bandwidth-constrained\n&gt; (2) The resour=\r\nces your are crawling are very large\n&gt; (3) Your target sites are unresponsi=\r\nve/unreachable, so most are waiting \n&gt; for a connection-timeout most of the=\r\n time\n&gt; \n&gt; The threads report or crawl log might help distinguish among the=\r\nse, or \n&gt; suggest what else is amiss. Even just the single line summary of =\r\nthread \n&gt; statuses (from the &#39;reports&#39; page) might help.\n&gt; \n&gt; - Gordon @ IA=\r\n\n&gt;\n\nThank you very much for your indications. I indeed have more\ninformatio=\r\nn about my problem. With another crawl of about 300 seeds, I\nget theses res=\r\nults in seeds report :\n\n23 % of -2 (HTTP connect failed)\n27 % of -6 (Prereq=\r\nuisite domain-lookup failed, precluding fetch attempt)\n15 % -61 (Prerequisi=\r\nte robots.txt-fetch failed, precluding a fetch\nattempt)\n\nthe other could be=\r\n reached. In my browser, I can get most of the seeds\nwith errors above. \n\nT=\r\nhis amount of error explains why a lot of queues finish exhausted :\n\n263 qu=\r\neues: 71 active (49 in-process; 0 ready; 22 snoozed); 0\ninactive; 0 retired=\r\n; 192 exhausted\n\n(only 49 of 71 actives queues are processed, is it normal =\r\n?)\n\nHere is a typical log with -2 failure :\n\n2006-10-11T14:41:09.076Z  1  -=\r\n dns:www.example.ch P\nhttp://www.example.ch/ text/dns #104 2006101114410877=\r\n5+18 - - -\n2006-10-11T14:41:09.784Z 200   62   http://www.example.ch/robots=\r\n.txt P\nhttp://www.example.ch/ text/plain #002 20061011144109585+142 \n2006-1=\r\n0-11T14:45:00.234Z  -2  - http://www.example.ch/ - - no-type\n#293 - - - le:=\r\nSocketTimeoutException@HTTP,10t\n\nMichel\n\n\n\n\n\n\n\n\n\n\n"}}