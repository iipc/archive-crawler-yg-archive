{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":165458231,"authorName":"Bjarne Andersen","from":"Bjarne Andersen &lt;bja@...&gt;","profile":"bjarne_dk2000","replyTo":"LIST","senderId":"wugT-xcey3O2ILlgbs4WZOYxA0nT6a7b7Zj6Tsn_ixh82BgyGh3J0XP2pQAkrsf5VuXAyZDrYao0O5SX7FbH-Xpx2T9h0FFW5gwQfzCngVM","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] downloading just a few pages from each site","postDate":"1122961269","msgId":2071,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQyRUYwNzc1LjgwNjA3MDNAc3RhdHNiaWJsaW90ZWtldC5kaz4=","inReplyToHeader":"PDQyRUU2NEM4LjMwMzA5MDdAbG9jYWxtYXR0ZXJzLmNvbT4=","referencesHeader":"PFBpbmUuTE5YLjQuNTguMDUwODAxMTkzNTU3MC4yNjY0QGVpbnN0ZWluLnNzbG1pdC51bmliby5pdD4gPDQyRUU2NEM4LjMwMzA5MDdAbG9jYWxtYXR0ZXJzLmNvbT4="},"prevInTopic":2066,"nextInTopic":2073,"prevInTime":2070,"nextInTime":2072,"topicId":2064,"numMessagesInTopic":5,"msgSnippet":"Our experience with the DomainSensitiveFrontier is that it s not suited for large seed-lists (e.g. 10.000 seeds which is our default crawl-size) - things slow","rawEmail":"Return-Path: &lt;bja@...&gt;\r\nX-Sender: bja@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 63085 invoked from network); 2 Aug 2005 05:41:11 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m23.grp.scd.yahoo.com with QMQP; 2 Aug 2005 05:41:11 -0000\r\nReceived: from unknown (HELO luna.statsbiblioteket.dk) (130.225.24.87)\n  by mta6.grp.scd.yahoo.com with SMTP; 2 Aug 2005 05:41:11 -0000\r\nReceived: from [130.225.25.67] (pc975.sb.statsbiblioteket.dk [130.225.25.67])\n by luna.statsbiblioteket.dk\n (iPlanet Messaging Server 5.2 HotFix 1.16 (built May 14 2003))\n with ESMTP id &lt;0IKK005R9YGLCP@...&gt; for\n archive-crawler@yahoogroups.com; Tue, 02 Aug 2005 07:41:09 +0200 (MEST)\r\nDate: Tue, 02 Aug 2005 07:41:09 +0200\r\nIn-reply-to: &lt;42EE64C8.3030907@...&gt;\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-id: &lt;42EF0775.8060703@...&gt;\r\nOrganization: Statsbiblioteket\r\nMIME-version: 1.0\r\nContent-type: multipart/mixed; boundary=&quot;Boundary_(ID_vesoCw7QDz1T4vbTHcGNvw)&quot;\r\nX-Accept-Language: en-us, en\r\nUser-Agent: Mozilla Thunderbird 1.0 (X11/20041206)\r\nReferences: &lt;Pine.LNX.4.58.0508011935570.2664@...&gt;\n &lt;42EE64C8.3030907@...&gt;\r\nX-eGroups-Msg-Info: 1:12:0\r\nFrom: Bjarne Andersen &lt;bja@...&gt;\r\nSubject: Re: [archive-crawler] downloading just a few pages from each site\r\nX-Yahoo-Group-Post: member; u=165458231; y=pKwM7bjS7UG6lIDFVk23wfATYur8Oe-CtOWcmAO76J8zkQC6GJ2zDA\r\nX-Yahoo-Profile: bjarne_dk2000\r\n\r\n\r\n--Boundary_(ID_vesoCw7QDz1T4vbTHcGNvw)\r\nContent-type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-transfer-encoding: 8BIT\r\n\r\nOur experience with the DomainSensitiveFrontier is that it&#39;s not suited \nfor large seed-lists (e.g. 10.000 seeds which is our default crawl-size) \n- things slow down a lot (we suspect the reading of the settings-object \nfor each UURI to be the bottleneck) - same crawl with default \nBdbFrontier is at least 10-20 times faster.\n\nWe wanted to limit the crawl to a fixed number of objects pr. domain \n(defined as domain.dk) - so that sports.tv2.dk and news.tv2.dk were \ncounted in the same queue.\n\nTo obtain this a very simple new QueueAssignmentPolicy was written \n(could possibly be more effective than using String.split) - se my post \non the list from 5th july 2005 (2 posts - because you have to rebuild \nheritrix yourself to get the new QueueAssignmentPolicy to work from the UI)\n\nWith this DomainnameQueueAssignmentPolicy and the default \nBdbFrontier-setting: queue-total-budget - you can count objects pr. \ndomain- it works just fine and is very fast compared to \nDomainSensitiveFrontier\n\nbest\nBjarne Andersen\n\nRob Eger wrote:\n&gt; Marco,\n&gt; \n&gt; You can use the DomainSensitiveFrontier and set the &quot;max-docs&quot; parameter\n&gt; in the Frontier settings to the maximum number from each website.\n&gt; \n&gt; Rob.\n&gt; \n&gt; Marco Baroni wrote:\n&gt;  &gt; Dear All,\n&gt;  &gt;\n&gt;  &gt; I&#39;ve been looking into the User Manual, but I was not able to find \n&gt; out how\n&gt;  &gt; to do the following: I would like to do a crawl in which I do not \n&gt; download\n&gt;  &gt; more than N pages from each web-site.\n&gt;  &gt;\n&gt;  &gt; E.g., a SURT scope crawl of pages from the .de sites, where I do not\n&gt;  &gt; download more than 10 pages from each (www)?&#92;.[^&#92;.]+&#92;.de domain (or, if\n&gt;  &gt; that is not possible, where I do not download more than 10 pages from the\n&gt;  &gt; same IP).\n&gt;  &gt;\n&gt;  &gt; Is this possible? Is it documented somewhere?\n&gt;  &gt;\n&gt;  &gt; Thanks a lot.\n&gt;  &gt;\n&gt;  &gt; Regards,\n&gt;  &gt;\n&gt;  &gt; Marco\n&gt;  &gt;\n&gt; \n&gt; -- \n&gt; Rob Eger\n&gt; Senior Software Engineer\n&gt; Local Matters, Inc.\n&gt; \n&gt; 1517 Blake Street, Floor Two\n&gt; Denver, CO  80202\n&gt; reger@...\n&gt; www.localmatters.com\n&gt; O 303-572-1122 x203\n&gt; F 303-572-1123\n&gt; \n&gt; ------------------------------------------------------------------------\n&gt; YAHOO! GROUPS LINKS\n&gt; \n&gt;     *  Visit your group &quot;archive-crawler\n&gt;       &lt;http://groups.yahoo.com/group/archive-crawler&gt;&quot; on the web.\n&gt;        \n&gt;     *  To unsubscribe from this group, send an email to:\n&gt;        archive-crawler-unsubscribe@yahoogroups.com\n&gt;       &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;        \n&gt;     *  Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;.\n&gt; \n&gt; \n&gt; ------------------------------------------------------------------------\n&gt; \n\n-- \nBjarne Andersen\nIT-udvikler\n\nSTATSBIBLIOTEKET\nUniversitetsparken\n8000 ï¿½rhus C\nTlf. 89462165 - Mobil 28713889\nCVR/SE 10100682 - EAN 5798000791084\nhttp://statsbiblioteket.dk\n\r\n--Boundary_(ID_vesoCw7QDz1T4vbTHcGNvw)\r\nContent-type: text/x-vcard; charset=utf-8; name=bja.vcf\r\nContent-disposition: attachment; filename=bja.vcf\r\n\r\n[ Attachment content not displayed ]\r\n--Boundary_(ID_vesoCw7QDz1T4vbTHcGNvw)--\r\n\n"}}