{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"84yWsaTLYl1_BLisRkfAo03hc455EYb4LKcqxN3jrMoOUJidJJdT9yZcki66ARf6qFru4r30hyuH00R1mDuxWbZA-lF7C7I","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] Re: Deduplication in Heritrix-3","postDate":"1263862200","msgId":6316,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRCNTUwMUI4LjYwNzAzMDdAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGhpbW1qaytwNHB2QGVHcm91cHMuY29tPg==","referencesHeader":"PGhpbW1qaytwNHB2QGVHcm91cHMuY29tPg=="},"prevInTopic":6304,"nextInTopic":0,"prevInTime":6315,"nextInTime":6317,"topicId":6302,"numMessagesInTopic":4,"msgSnippet":"Some further thoughts on this: For now, the deduplication functionality leaves it up to the operator to ensure all URIs from the first crawl are somehow ","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 91501 invoked from network); 19 Jan 2010 00:50:15 -0000\r\nX-Received: from unknown (98.137.34.45)\n  by m5.grp.sp2.yahoo.com with QMQP; 19 Jan 2010 00:50:15 -0000\r\nX-Received: from unknown (HELO relay00.pair.com) (209.68.5.9)\n  by mta2.grp.sp2.yahoo.com with SMTP; 19 Jan 2010 00:50:15 -0000\r\nX-Received: (qmail 22488 invoked from network); 19 Jan 2010 00:50:01 -0000\r\nX-Received: from 71.202.38.39 (HELO ?192.168.23.128?) (71.202.38.39)\n  by relay00.pair.com with SMTP; 19 Jan 2010 00:50:01 -0000\r\nX-pair-Authenticated: 71.202.38.39\r\nMessage-ID: &lt;4B5501B8.6070307@...&gt;\r\nDate: Mon, 18 Jan 2010 16:50:00 -0800\r\nUser-Agent: Thunderbird 2.0.0.23 (Windows/20090812)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;himmjk+p4pv@...&gt;\r\nIn-Reply-To: &lt;himmjk+p4pv@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Re: Deduplication in Heritrix-3\r\nX-Yahoo-Group-Post: member; u=137285340; y=h68198YyeNLmiEgFzYH_ZJ6jFvW_BkXi9oBhUXRGHHJp\r\nX-Yahoo-Profile: gojomo\r\n\r\nSome further thoughts on this:\n\nFor now, the deduplication functionality leaves it up to the operator to \nensure all URIs from the first crawl are somehow \nreconsidered/rediscovered. One way to achieve this is to re-feed all \nsuccesses from the first crawl to a later crawl as seeds; another is to \nalways allow pages to be re-fetched/re-extracted, and only applying \ncontent-based (rather than conditional-get header-based) deduplication \nrules, so the followup crawl follows the same discovery paths as the \noriginal crawl.\n\nWe may in the future allow link-graph info from the earlier crawls to be \ncarried forward along with other history, so that even in the event of a \n&#39;304-Not Modified&#39; response, all the outlinks of the (unchanged) page \ncan be rescheduled for reconsideration, as if discovered. So far, we \nhaven&#39;t implemented such an on-line link graph database for crawl-time \nuse. (Each URI just knows its immediate &#39;via&#39; predecessor, until that \nURI reaches completion, and extracted outlink info is only logged, not \nindexed for later random access.)\n\n- Gordon @ IA\n\nsriram_varahan1 wrote:\n&gt; Hello Noah,\n&gt; \n&gt; Thanks for the reply.\n&gt; \n&gt; In addition to setting sendIfModifiedSince property to false I also had to set the sendIfNoneMatch property to false to get it working.\n&gt; Now the deduplication works perfectly fine.\n&gt; \n&gt; Thanks again.\n&gt; Sriram Varahan.\n&gt; \n&gt; --- In archive-crawler@yahoogroups.com, Noah Levitt &lt;nlevitt@...&gt; wrote:\n&gt;&gt; You say &quot;It found there was no modification&quot; - by this do you mean the server returned a 304? \n&gt;&gt;\n&gt;&gt; If that is the case, then you probably want to set the fetchHttp property &quot;sendIfModifiedSince&quot; to false. With that setting disabled (and certain other settings retaining their default values), heritrix will fetch the content and extract links from it, as it normally does. Deduplication will still be enabled, too, except it will examine the content to check for duplication instead of asking the server. (Relevant settings include the warcWriter properties skipIdenticalDigests and writeRevisitForIdenticalDigests.)\n&gt;&gt;\n&gt;&gt; Noah\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; sriram_varahan1 wrote:\n&gt;&gt;&gt; Hello,\n&gt;&gt;&gt;  \n&gt;&gt;&gt;       I am using Heritrix-3.1.1 Snapshot release. \n&gt;&gt;&gt;\n&gt;&gt;&gt; I have enabled the deduplication feature. I first mirrored a site and got about 270 pages.\n&gt;&gt;&gt;\n&gt;&gt;&gt; Now I relaunched the job. Heritrix just checked for the seed url. It found there was no modification in it and hence it did not check the other pages in the site for updates.\n&gt;&gt;&gt;\n&gt;&gt;&gt; Is this the expected behaviour in deduplication?\n&gt;&gt;&gt;\n&gt;&gt;&gt; As a workaround I  pulled all the links from the crawl.log and populated them in seeds.txt. It then checked the other pages as well.\n&gt;&gt;&gt;\n&gt;&gt;&gt; Is there any other way of getting around this problem?\n&gt;&gt;&gt;\n&gt;&gt;&gt; Thanks,\n&gt;&gt;&gt; Sriram Varahan.\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; ------------------------------------\n&gt;&gt;&gt;\n&gt;&gt;&gt; Yahoo! Groups Links\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; ------------------------------------\n&gt; \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n"}}