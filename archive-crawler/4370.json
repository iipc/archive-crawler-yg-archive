{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":299179219,"authorName":"mjjjhjemj","from":"&quot;mjjjhjemj&quot; &lt;bosoxchamps@...&gt;","profile":"mjjjhjemj","replyTo":"LIST","senderId":"uGU96lbdhguOoU-I61mHwUWZD_ZQ-eUV6wl0K3QgsHMjEwqcVdVe26krlzYS8CWnnyxH8mhMlix8aIZVVxvVWBCaJE_vXGIgjQk","spamInfo":{"isSpam":false,"reason":"6"},"subject":"How to setup a crawl that gathers the hostnames without downloading files","postDate":"1182960749","msgId":4370,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGY1dTI5ZCtwaWxwQGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":4374,"prevInTime":4369,"nextInTime":4371,"topicId":4370,"numMessagesInTopic":7,"msgSnippet":"Is this possible? I have a very large crawl that has numerous seeds and may potentially take weeks to complete. I do not want to crawl local sites accessible ","rawEmail":"Return-Path: &lt;bosoxchamps@...&gt;\r\nX-Sender: bosoxchamps@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 57635 invoked from network); 27 Jun 2007 16:13:14 -0000\r\nReceived: from unknown (66.218.66.72)\n  by m45.grp.scd.yahoo.com with QMQP; 27 Jun 2007 16:13:14 -0000\r\nReceived: from unknown (HELO n30c.bullet.sp1.yahoo.com) (209.131.38.254)\n  by mta14.grp.scd.yahoo.com with SMTP; 27 Jun 2007 16:13:14 -0000\r\nReceived: from [216.252.122.216] by n30.bullet.sp1.yahoo.com with NNFMP; 27 Jun 2007 16:12:29 -0000\r\nReceived: from [209.73.164.86] by t1.bullet.sp1.yahoo.com with NNFMP; 27 Jun 2007 16:12:29 -0000\r\nReceived: from [66.218.66.77] by t8.bullet.scd.yahoo.com with NNFMP; 27 Jun 2007 16:12:29 -0000\r\nDate: Wed, 27 Jun 2007 16:12:29 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;f5u29d+pilp@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;mjjjhjemj&quot; &lt;bosoxchamps@...&gt;\r\nSubject: How to setup a crawl that gathers the hostnames without downloading files\r\nX-Yahoo-Group-Post: member; u=299179219; y=-LSq8YXAitVcvagdKhn-_Pegl1mSONHOPHP79jvy5ePH9mOL\r\nX-Yahoo-Profile: mjjjhjemj\r\n\r\nIs this possible?\n\nI have a very large crawl that has numerous seeds and ma=\r\ny potentially\ntake weeks to complete. I do not want to crawl local sites ac=\r\ncessible\nunder a certain IP mask. Where Heritrix will exclude sites based o=\r\nn IP\nentered into a surts-source-file with decision=3D&#39;REJECT&#39; these sites\n=\r\nare accessed using the typical hostname and not IP and are therefore\nnot ex=\r\ncluded.\n\nI have been given an exclude list in typical hostname &#39;www.cnn.com=\r\n&#39;\nform, but have confirmed that it is not complete and therefore my\ncrawl s=\r\ncope is greater than it should be. This brings me to why I wish\nto complete=\r\n a test crawl where the goal is to gather only the lists of\nURIs traversed,=\r\n but not gather all the files. I will then parse the\ncrawl.log and do a loo=\r\nkup on the hostname to determine if the IP and\ncanonical name and see if th=\r\ney should be included in the crawl scope.\n\nAny help would be greatly apprec=\r\niated.\n\nThanks,\nMike\n\n\n"}}