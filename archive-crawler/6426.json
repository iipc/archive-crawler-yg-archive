{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":325624130,"authorName":"Noah Levitt","from":"Noah Levitt &lt;nlevitt@...&gt;","profile":"nlevitt0","replyTo":"LIST","senderId":"zSAMn5_tLElWEX6yCs8eKNsfOW3zxmVXksph6DuQ2w04pM1DAhozAPHcWJh9s4g3TpTwdS8Ml6wCbt3E3gUQefvg7xtYq5EZ","spamInfo":{"isSpam":false,"reason":"3"},"subject":"Re: [archive-crawler] Repair of corrupted ARC files","postDate":"1267742967","msgId":6426,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRCOTAzOEY3LjQwMTA4MDhAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGhtbTAzMCszdHVtQGVHcm91cHMuY29tPg==","referencesHeader":"PGhtbTAzMCszdHVtQGVHcm91cHMuY29tPg=="},"prevInTopic":6425,"nextInTopic":0,"prevInTime":6425,"nextInTime":6427,"topicId":6419,"numMessagesInTopic":3,"msgSnippet":"Hello Eleonora, The tool gzip-chunks can be used to discard bad data from arcs and warcs, i.e. to implement Gordon s suggestion. It s included in this source","rawEmail":"Return-Path: &lt;nlevitt@...&gt;\r\nX-Sender: nlevitt@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 19431 invoked from network); 4 Mar 2010 22:49:29 -0000\r\nX-Received: from unknown (66.196.94.105)\n  by m3.grp.sp2.yahoo.com with QMQP; 4 Mar 2010 22:49:29 -0000\r\nX-Received: from unknown (HELO mail.archive.org) (207.241.231.239)\n  by mta1.grp.re1.yahoo.com with SMTP; 4 Mar 2010 22:49:29 -0000\r\nX-Received: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id 6235054170E\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Thu,  4 Mar 2010 14:49:28 -0800 (PST)\r\nX-Received: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id Y9lmauXeFP3x for &lt;archive-crawler@yahoogroups.com&gt;;\n\tThu,  4 Mar 2010 14:49:27 -0800 (PST)\r\nX-Received: from [10.116.0.178] (unknown [71.202.38.39])\n\tby mail.archive.org (Postfix) with ESMTPSA id 9F976189F19D\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Thu,  4 Mar 2010 14:49:27 -0800 (PST)\r\nMessage-ID: &lt;4B9038F7.4010808@...&gt;\r\nDate: Thu, 04 Mar 2010 14:49:27 -0800\r\nUser-Agent: Thunderbird 2.0.0.23 (X11/20090817)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;hmm030+3tum@...&gt;\r\nIn-Reply-To: &lt;hmm030+3tum@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 2:3:4:0:0\r\nFrom: Noah Levitt &lt;nlevitt@...&gt;\r\nSubject: Re: [archive-crawler] Repair of corrupted ARC files\r\nX-Yahoo-Group-Post: member; u=325624130; y=FaeWVwmOhYtExpya8zwoemC4zwpAY-5j0sKLQFk33Z3UzEc\r\nX-Yahoo-Profile: nlevitt0\r\n\r\nHello Eleonora,\n\nThe tool gzip-chunks can be used to discard bad data from arcs and warcs, i.e. to implement Gordon&#39;s suggestion.\nIt&#39;s included in this source distribution - http://builds.archive.org:8080/misc/ia-tools-0.0.1.tar.bz2\n\nIf you try this tool I&#39;d be interested to hear how it works for you.\n\n-----\nUsage:\n  gzip-chunks [OPTION...] FILE\n\nIdentifies valid gzip chunks in the input and writes them verbatim to the output.\n\nHelp Options:\n  -h, --help               Show help options\n\nApplication Options:\n  --verbose                Report verbosely on gzip doings\n  -o, --output=FILE        Write to specified file (default is stdout)\n  -x, --invalid            Invert the operation: write chunks that are NOT valid gzip chunks\n  --split                  Write each chunk to a separate file, in a randomly named directory in temp space\n  -d, --split-dir=PATH     Write each chunk to a separate file in the specified directory\n  --start=OFFSET           Start processing input at specified byte offset\n  --end=OFFSET             Stop processing input at specified byte offset\n\nThis tool dumps valid gzip chunks from the input. To put it another way, it\nelides invalid data.\n\nExamples of usage:\n\n  # salvage good records from a bad warc.gz\n  gzip-chunks bad.warc.gz &gt; repaired.warc.gz\n\n  # save invalid gzip chunks toward end of file for inspection\n  gzip-chunks --invalid --split --start=90000000 bad.warc.gz\n-----\n\nNoah\n\n\neleonora_nicchiarelli wrote:\n&gt; Dear all, \n&gt; \n&gt; We are archiving arc.gz files created by Heritrix through the Netarchive Suite. We have strong reasons to believe that one of our files has been corrupted on the disk (its size is only ~19 MB, and it is not possible to unzip it conventionally). \n&gt; \n&gt; Now we would like to &quot;extend&quot; the file to a valid arc.gz file so that it is possible to view its contents through e.g. wayback all the same (which is not possible at the moment). Is there a standard way to do this? \n&gt; \n&gt; Thanks in advance, \n&gt; \n&gt; Eleonora\n&gt; \n\n"}}