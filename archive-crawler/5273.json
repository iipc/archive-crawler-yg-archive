{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"qZDsOpUW2kTgB2IZwqlojlcJwafnHQ5FHTWRN27ahn9bh3RS_tv6SENmdYKcFfHaJloFB_c9pQ7gS1zKGM3rSUNHhl6MEck","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Re: Content type specific crawling?","postDate":"1212442209","msgId":5273,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ4NDQ2NjYxLjgwNzA2MDZAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGcyMWJhaytxaGNkQGVHcm91cHMuY29tPg==","referencesHeader":"PGcyMWJhaytxaGNkQGVHcm91cHMuY29tPg=="},"prevInTopic":5265,"nextInTopic":5277,"prevInTime":5272,"nextInTime":5274,"topicId":5248,"numMessagesInTopic":9,"msgSnippet":"Do you have a REJECT rule first that applies to everything, then the ContentTypeMatchesRegExpDecideRule to ACCEPT the right kind of content? Otherwise, the","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 23905 invoked from network); 2 Jun 2008 21:30:05 -0000\r\nX-Received: from unknown (66.218.67.96)\n  by m54.grp.scd.yahoo.com with QMQP; 2 Jun 2008 21:30:05 -0000\r\nX-Received: from unknown (HELO relay01.pair.com) (209.68.5.15)\n  by mta17.grp.scd.yahoo.com with SMTP; 2 Jun 2008 21:30:04 -0000\r\nX-Received: (qmail 66079 invoked from network); 2 Jun 2008 21:30:04 -0000\r\nX-Received: from unknown (HELO ?192.168.1.15?) (unknown)\n  by unknown with SMTP; 2 Jun 2008 21:30:04 -0000\r\nX-pair-Authenticated: 67.180.197.118\r\nMessage-ID: &lt;48446661.8070606@...&gt;\r\nDate: Mon, 02 Jun 2008 14:30:09 -0700\r\nUser-Agent: Thunderbird 2.0.0.14 (Windows/20080421)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;g21bak+qhcd@...&gt;\r\nIn-Reply-To: &lt;g21bak+qhcd@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Re: Content type specific crawling?\r\nX-Yahoo-Group-Post: member; u=137285340; y=kriw1WKwskUDKcXI5n7LnW0ajaIVJCf0b5tkUoXy-ICV\r\nX-Yahoo-Profile: gojomo\r\n\r\nDo you have a REJECT rule first that applies to everything, then the \nContentTypeMatchesRegExpDecideRule to ACCEPT the right kind of content?\n\nOtherwise, the decision of the decide-rules will be ambiguous (PASS), \nand in the case of Processor decide-rules, anything but a REJECT allows \nthe Processor to run. (See Processor.process().)\n\n- Gordon @ IA\n\nlpeterus wrote:\n&gt; Hi!\n&gt; \n&gt; Thanks for the reply. I did have a ContentTypeMatchesRegExpDecideRule\n&gt; under the writer processor section with the following regex\n&gt; (?i)application/xml.*\n&gt; But it still seems to be writing the text/html pages from dynamic\n&gt; URLs. Did I use the wrong type of expression? Thanks.\n&gt; \n&gt; --- In archive-crawler@yahoogroups.com, &quot;ermhes82&quot; &lt;ermhes@...&gt; wrote:\n&gt;&gt; You can prevent this if you include in decide-rules a \n&gt;&gt; ContentTypeMatchesRegExpDecideRule o \n&gt;&gt; ContentTypeNotMatchesRegExpDecideRule.\n&gt;&gt;\n&gt;&gt; Mario.\n&gt;&gt;\n&gt;&gt; --- In archive-crawler@yahoogroups.com, &quot;lpeterus&quot; &lt;lpeterus@&gt; wrote:\n&gt;&gt;&gt; Hi all!\n&gt;&gt;&gt;\n&gt;&gt;&gt; I have a question about how to exclude dynamic URLs. I&#39;m using regular\n&gt;&gt;&gt; expression rules based on suggestions from previous posting. I would\n&gt;&gt;&gt; like to filter out everything except for text/xml and application/xml\n&gt;&gt;&gt; files. The filters are applied on the scope, midfetch, and the arc\n&gt;&gt;&gt; writer processor. \n&gt;&gt;&gt; So far everything works ok, except it still dowloads some text/html\n&gt;&gt;&gt; files even though html is part of the rejection regexp in the scope.\n&gt;&gt;&gt; Turns out all of the text/html downloads are dynamic URLs like this, \n&gt;&gt;&gt; http://somewebpage/subdir/?C=D;O=A \n&gt;&gt;&gt; My question then is how do I prevent these text/html from being\n&gt;&gt;&gt; written into the arc file. Thanks!\n&gt;&gt;&gt;\n&gt;&gt;&gt; Shawn\n&gt;&gt;&gt;\n&gt; \n&gt; \n&gt; \n&gt; ------------------------------------\n&gt; \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n"}}