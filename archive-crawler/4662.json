{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":274489225,"authorName":"molzbh","from":"&quot;molzbh&quot; &lt;anmol.bhasin@...&gt;","profile":"molzbh","replyTo":"LIST","senderId":"aV7rSM0rzJ6Ys3GU5dG0re7kRTcdJiXOk-Bh38mHAtS1tBvNwDRg8yTHm6f-bmkUy22V0NcR1emGis1uRvxKO_ep9R--yuk5","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Weird problem with robots fetch","postDate":"1194397210","msgId":4662,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZncjJtcSsxb3FxQGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":0,"prevInTime":4661,"nextInTime":4663,"topicId":4662,"numMessagesInTopic":1,"msgSnippet":"Hi, I am running into this weird problem while fetching pages from a webiste http://www.vanillasoft.com The url I am trying to fetch is : ","rawEmail":"Return-Path: &lt;anmol.bhasin@...&gt;\r\nX-Sender: anmol.bhasin@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 75445 invoked from network); 7 Nov 2007 01:00:11 -0000\r\nX-Received: from unknown (66.218.67.94)\n  by m45.grp.scd.yahoo.com with QMQP; 7 Nov 2007 01:00:11 -0000\r\nX-Received: from unknown (HELO n32a.bullet.sp1.yahoo.com) (209.131.38.211)\n  by mta15.grp.scd.yahoo.com with SMTP; 7 Nov 2007 01:00:11 -0000\r\nX-Received: from [216.252.122.219] by n32.bullet.sp1.yahoo.com with NNFMP; 07 Nov 2007 01:00:11 -0000\r\nX-Received: from [66.218.69.3] by t4.bullet.sp1.yahoo.com with NNFMP; 07 Nov 2007 01:00:10 -0000\r\nX-Received: from [66.218.66.78] by t3.bullet.scd.yahoo.com with NNFMP; 07 Nov 2007 01:00:10 -0000\r\nDate: Wed, 07 Nov 2007 01:00:10 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;fgr2mq+1oqq@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: multipart/alternative; boundary=&quot;1-5982203678-7811043766=:7&quot;\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;molzbh&quot; &lt;anmol.bhasin@...&gt;\r\nSubject: Weird problem with robots fetch\r\nX-Yahoo-Group-Post: member; u=274489225; y=eNhQZh-sQHhLiSO0b0l18QQb985w70pTNow_iXyi7Ztq\r\nX-Yahoo-Profile: molzbh\r\n\r\n\r\n--1-5982203678-7811043766=:7\r\nContent-Type: text/plain; charset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nHi,\n\nI am running into this weird problem while fetching pages from a webis=\r\nte\nhttp://www.vanillasoft.com\n\nThe url I am trying to fetch is :\nhttp://www=\r\n.vanillasoft.com/product-info\n\nBasically, the page aint fetched and the cra=\r\nwl log shows\n\n2007-11-07T00:33:59.509Z    -2          1\nhttp://www.vanillas=\r\noft.com/robots.txt - - text/html #048 - - -\nle:IOException@HTTP,3t\n\n2007-11=\r\n-07T00:33:59.511Z   -61          -\nhttp://www.vanillasoft.com/product-info =\r\n- - no-type #041 - - - -\n\nWhen I try the robots fetch from the browser, I a=\r\nm somehow sent to the\nhome page, however the headers I receive do not have =\r\na 301/302 response\ncode. Here is the request/reponse header\n\nhttp://www.van=\r\nillasoft.com/robots.txt\n\n\n\nGET /robots.txt HTTP/1.1\n\nHost: www.vanillasoft.=\r\ncom\n\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.8.0.4)\nGecko/=\r\n20060527 SUSE/1.5.0.4-1.9 Firefox/1.5.0.4\n\nAccept:\ntext/xml,application/xml=\r\n,application/xhtml+xml,text/html;q=3D0.9,text/plai&#92;\nn;q=3D0.8,image/png,*/*=\r\n;q=3D0.5\n\nAccept-Language: en-us,en;q=3D0.5\n\nAccept-Encoding: gzip,deflate\n=\r\n\nAccept-Charset: ISO-8859-1,utf-8;q=3D0.7,*;q=3D0.7\n\nKeep-Alive: 300\n\nConne=\r\nction: keep-alive\n\n\n\nHTTP/1.x 404 Not Found\n\nDate: Wed, 07 Nov 2007 00:54:5=\r\n1 GMT\n\nServer: Apache/2.2.4 (Win32) PHP/5.2.3\n\nX-Powered-By: PHP/5.2.3\n\nSet=\r\n-Cookie:\nSESS368d89119d82145b8a6f429eecea871a=3D67r5vkruulja8tiq9lm1b2qkc3;=\r\n\nexpires=3DFri, 30 Nov 2007 04:28:11 GMT; path=3D/; domain=3D.vanillasoft.c=\r\nom\n\nLast-Modified: Tue, 06 Nov 2007 12:47:09 GMT\n\nEtag: &quot;b950419ffc8e46f165=\r\n5abd9a8d25c17f&quot;\n\nExpires: Sun, 19 Nov 1978 05:00:00 GMT\n\nCache-Control: mus=\r\nt-revalidate\n\nContent-Encoding: gzip\n\nContent-Length: 3118\n\nKeep-Alive: tim=\r\neout=3D5, max=3D100\n\nConnection: Keep-Alive\n\nContent-Type: text/html; chars=\r\net=3Dutf-8\n\n\n\nThe crawler however shows an IO Exception while fetching the =\r\nrobots\n\n\n2007-11-07T00:33:28.313Z    -2          1\nhttp://www.vanillasoft.c=\r\nom/robots.txt - - text/html #046 - - -\nle:IOException@HTTP\n  java.io.IOExce=\r\nption: mark/reset not supported\n     at java.io.InputStream.reset(InputStre=\r\nam.java:331)\n     at\norg.apache.commons.httpclient.HttpConnection.isRespons=\r\neAvailable(HttpCon&#92;\nnection.java:918)\n     at\norg.apache.commons.httpclient=\r\n.HttpMethodBase.readResponseBody(HttpMethod&#92;\nBase.java:1717)\n     at\norg.ap=\r\nache.commons.httpclient.HttpMethodBase.readResponseBody(HttpMethod&#92;\nBase.ja=\r\nva:1660)\n     at\norg.archive.httpclient.HttpRecorderGetMethod.readResponseB=\r\nody(HttpRecord&#92;\nerGetMethod.java:99)\n     at\norg.archive.crawler.fetcher.Fe=\r\ntchHTTP$2.readResponseBody(FetchHTTP.java:&#92;\n400)\n     at\norg.apache.commons=\r\n.httpclient.HttpMethodBase.readResponse(HttpMethodBase&#92;\n.java:1623)\n     at=\r\n\norg.apache.commons.httpclient.HttpMethodBase.execute(HttpMethodBase.java&#92;\n=\r\n:1000)\n     at\norg.archive.httpclient.HttpRecorderGetMethod.execute(HttpRec=\r\norderGetMeth&#92;\nod.java:117)\n     at\norg.apache.commons.httpclient.HttpMethod=\r\nDirector.executeWithRetry(HttpMe&#92;\nthodDirector.java:393)\n     at\norg.apache=\r\n.commons.httpclient.HttpMethodDirector.executeMethod(HttpMetho&#92;\ndDirector.j=\r\nava:168)\n     at\norg.apache.commons.httpclient.HttpClient.executeMethod(Htt=\r\npClient.java:3&#92;\n96)\n     at\norg.apache.commons.httpclient.HttpClient.execut=\r\neMethod(HttpClient.java:3&#92;\n24)\n     at\norg.archive.crawler.fetcher.FetchHTT=\r\nP.innerProcess(FetchHTTP.java:417)\n     at\norg.archive.crawler.framework.Pr=\r\nocessor.process(Processor.java:103)\n     at\norg.archive.crawler.framework.T=\r\noeThread.processCrawlUri(ToeThread.java:3&#92;\n28)\n     at org.archive.crawler.=\r\nframework.ToeThread.run(ToeThread.java:153)\n\n\nAny idea what might be going =\r\non ? Alternately, is there a way to evade\nfetching the robots prerequisite =\r\nfor a particular website\n\n\n\r\n--1-5982203678-7811043766=:7\r\nContent-Type: text/html; charset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n&lt;font face=3D&quot;arial narrow&quot;&gt;Hi,&lt;br&gt;&lt;br&gt;I am running into this weird problem=\r\n while fetching pages from a webiste&lt;br&gt;http://www.vanillasoft.com&lt;br&gt;&lt;br&gt;T=\r\nhe url I am trying to fetch is : &lt;br&gt;http://www.vanillasoft.com/product-inf=\r\no&lt;br&gt;&lt;br&gt;Basically, the page aint fetched and the crawl log shows&lt;br&gt;&lt;br&gt;20=\r\n07-11-07T00:33:59.509Z&nbsp;&nbsp;&nbsp; &lt;/font&gt;&lt;font color=3D&quot;#ff007f&quot; fac=\r\ne=3D&quot;arial narrow&quot;&gt;-2&nbsp;&lt;/font&gt;&lt;font face=3D&quot;arial narrow&quot;&gt;&nbsp;&nbsp;&=\r\nnbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1 http://www.vanillasoft.com/robots.txt=\r\n - - text/html #048 - - - le:IOException@HTTP,3t&lt;br&gt;&lt;br&gt;2007-11-07T00:33:59=\r\n.511Z&nbsp;&nbsp; &lt;/font&gt;&lt;font color=3D&quot;#ff4040&quot; face=3D&quot;arial narrow&quot;&gt;-61&=\r\nnbsp;&nbsp;&nbsp;&lt;/font&gt;&lt;font face=3D&quot;arial narrow&quot;&gt;&nbsp;&nbsp;&nbsp;&nbsp=\r\n;&nbsp;&nbsp; - http://www.vanillasoft.com/product-info - - no-type #041 - =\r\n- - -&lt;br&gt;&lt;br&gt;When I try the robots fetch from the browser, I am somehow sen=\r\nt to the home page, however the headers I receive do not have a 301/302 res=\r\nponse code. Here is the request/reponse header&lt;br&gt;&lt;br&gt;http://www.vanillasof=\r\nt.com/robots.txt&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/font&gt;&lt;font color=3D&quot;#4040ff&quot; face=3D&quot;aria=\r\nl narrow&quot;&gt;GET /robots.txt HTTP/1.1&lt;br&gt;&lt;br&gt;Host: www.vanillasoft.com&lt;br&gt;&lt;br&gt;=\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.8.0.4) Gecko/20060=\r\n527 SUSE/1.5.0.4-1.9 Firefox/1.5.0.4&lt;br&gt;&lt;br&gt;Accept: text/xml,application/xm=\r\nl,application/xhtml+xml,text/html;q=3D0.9,text/plain;q=3D0.8,image/png,*/*;=\r\nq=3D0.5&lt;br&gt;&lt;br&gt;Accept-Language: en-us,en;q=3D0.5&lt;br&gt;&lt;br&gt;Accept-Encoding: gz=\r\nip,deflate&lt;br&gt;&lt;br&gt;Accept-Charset: ISO-8859-1,utf-8;q=3D0.7,*;q=3D0.7&lt;br&gt;&lt;br=\r\n&gt;Keep-Alive: 300&lt;br&gt;&lt;br&gt;Connection: keep-alive&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;HTTP/1.x 404 =\r\nNot Found&lt;br&gt;&lt;br&gt;Date: Wed, 07 Nov 2007 00:54:51 GMT&lt;br&gt;&lt;br&gt;Server: Apache/=\r\n2.2.4 (Win32) PHP/5.2.3&lt;br&gt;&lt;br&gt;X-Powered-By: PHP/5.2.3&lt;br&gt;&lt;br&gt;Set-Cookie: S=\r\nESS368d89119d82145b8a6f429eecea871a=3D67r5vkruulja8tiq9lm1b2qkc3; expires=\r\n=3DFri, 30 Nov 2007 04:28:11 GMT; path=3D/; domain=3D.vanillasoft.com&lt;br&gt;&lt;b=\r\nr&gt;Last-Modified: Tue, 06 Nov 2007 12:47:09 GMT&lt;br&gt;&lt;br&gt;Etag: &quot;b950419ffc8e46=\r\nf1655abd9a8d25c17f&quot;&lt;br&gt;&lt;br&gt;Expires: Sun, 19 Nov 1978 05:00:00 GMT&lt;br&gt;&lt;br&gt;Ca=\r\nche-Control: must-revalidate&lt;br&gt;&lt;br&gt;Content-Encoding: gzip&lt;br&gt;&lt;br&gt;Content-L=\r\nength: 3118&lt;br&gt;&lt;br&gt;Keep-Alive: timeout=3D5, max=3D100&lt;br&gt;&lt;br&gt;Connection: Ke=\r\nep-Alive&lt;br&gt;&lt;br&gt;Content-Type: text/html; charset=3Dutf-8&lt;br&gt;&lt;/font&gt;&lt;font fa=\r\nce=3D&quot;arial narrow&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;The crawler however shows an IO Exception w=\r\nhile fetching the robots&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/font&gt;&lt;font color=3D&quot;#ff4040&quot; face=3D&quot;=\r\narial narrow&quot;&gt;2007-11-07T00:33:28.313Z&nbsp;&nbsp;&nbsp; -2&nbsp;&nbsp;&nbs=\r\np;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1 http://www.vanillasoft.com/robots.=\r\ntxt - - text/html #046 - - - le:IOException@HTTP&lt;br&gt;&nbsp;&lt;/font&gt;&lt;font colo=\r\nr=3D&quot;#ff4040&quot; face=3D&quot;arial narrow&quot;&gt;java.io.IOException: mark/reset not sup=\r\nported&lt;br&gt;&nbsp;&nbsp; &nbsp;at java.io.InputStream.reset(InputStream.java:=\r\n331)&lt;br&gt;&nbsp;&nbsp; &nbsp;at org.apache.commons.httpclient.HttpConnection.=\r\nisResponseAvailable(HttpConnection.java:918)&lt;br&gt;&nbsp;&nbsp; &nbsp;at org.a=\r\npache.commons.httpclient.HttpMethodBase.readResponseBody(HttpMethodBase.jav=\r\na:1717)&lt;br&gt;&nbsp;&nbsp; &nbsp;at org.apache.commons.httpclient.HttpMethodBa=\r\nse.readResponseBody(HttpMethodBase.java:1660)&lt;br&gt;&nbsp;&nbsp; &nbsp;at org.=\r\narchive.httpclient.HttpRecorderGetMethod.readResponseBody(HttpRecorderGetMe=\r\nthod.java:99)&lt;br&gt;&nbsp;&nbsp; &nbsp;at org.archive.crawler.fetcher.FetchHTT=\r\nP$2.readResponseBody(FetchHTTP.java:400)&lt;br&gt;&nbsp;&nbsp; &nbsp;at org.apach=\r\ne.commons.httpclient.HttpMethodBase.readResponse(HttpMethodBase.java:1623)&lt;=\r\nbr&gt;&nbsp;&nbsp; &nbsp;at org.apache.commons.httpclient.HttpMethodBase.execu=\r\nte(HttpMethodBase.java:1000)&lt;br&gt;&nbsp;&nbsp; &nbsp;at org.archive.httpclien=\r\nt.HttpRecorderGetMethod.execute(HttpRecorderGetMethod.java:117)&lt;br&gt;&nbsp;&n=\r\nbsp; &nbsp;at org.apache.commons.httpclient.HttpMethodDirector.executeWithR=\r\netry(HttpMethodDirector.java:393)&lt;br&gt;&nbsp;&nbsp; &nbsp;at org.apache.commo=\r\nns.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:168)=\r\n&lt;br&gt;&nbsp;&nbsp; &nbsp;at org.apache.commons.httpclient.HttpClient.executeM=\r\nethod(HttpClient.java:396)&lt;br&gt;&nbsp;&nbsp; &nbsp;at org.apache.commons.http=\r\nclient.HttpClient.executeMethod(HttpClient.java:324)&lt;br&gt;&nbsp;&nbsp; &nbsp;=\r\nat org.archive.crawler.fetcher.FetchHTTP.innerProcess(FetchHTTP.java:417)&lt;b=\r\nr&gt;&nbsp;&nbsp; &nbsp;at org.archive.crawler.framework.Processor.process(Pro=\r\ncessor.java:103)&lt;br&gt;&nbsp;&nbsp; &nbsp;at org.archive.crawler.framework.Toe=\r\nThread.processCrawlUri(ToeThread.java:328)&lt;br&gt;&nbsp;&nbsp; &nbsp;at org.arc=\r\nhive.crawler.framework.ToeThread.run(ToeThread.java:153)&lt;br&gt;&lt;/font&gt;&lt;font fa=\r\nce=3D&quot;arial narrow&quot;&gt;&lt;br&gt;&lt;br&gt;Any idea what might be going on ? Alternately, =\r\nis there a way to evade fetching the robots prerequisite for a particular w=\r\nebsite&lt;br&gt;&lt;/font&gt;&lt;br&gt;\n\r\n--1-5982203678-7811043766=:7--\r\n\n"}}