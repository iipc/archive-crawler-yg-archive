{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":235746949,"authorName":"Gordon Paynter","from":"&quot;Gordon Paynter&quot; &lt;Gordon.Paynter@...&gt;","replyTo":"LIST","senderId":"huBMDrJagUqDt4tjbXZU9DxCb7cVlDRPwXB1Yr2OssKqyRzehS4M_hlTqeXFcjcHFIfBlFJXtY82pmvaBLNjM--ZlbQMcip8utjA9VJ44u-QvhYiQLHt","spamInfo":{"isSpam":false,"reason":"13"},"subject":"Re: [archive-crawler] The crawler doesn&#39;t seem to stop\tcrawling","postDate":"1128891735","msgId":2229,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PHMzNGEzYzJkLjA3OEBzaGFkYm9sdC5uYXRsaWIuZ292dC5uej4="},"prevInTopic":2228,"nextInTopic":0,"prevInTime":2228,"nextInTime":2230,"topicId":2227,"numMessagesInTopic":3,"msgSnippet":"Hi: I had a problem like this with a more recent version of Heretrix, and it turned out that the problem was that at the end of a single site crawl, there was","rawEmail":"Return-Path: &lt;Gordon.Paynter@...&gt;\r\nX-Sender: Gordon.Paynter@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 90676 invoked from network); 9 Oct 2005 21:04:12 -0000\r\nReceived: from unknown (66.218.66.218)\n  by m32.grp.scd.yahoo.com with QMQP; 9 Oct 2005 21:04:12 -0000\r\nReceived: from unknown (HELO jupiter.natlib.govt.nz) (210.55.131.76)\n  by mta3.grp.scd.yahoo.com with SMTP; 9 Oct 2005 21:04:11 -0000\r\nMessage-Id: &lt;s34a3c2d.078@...&gt;\r\nX-Mailer: Novell GroupWise Internet Agent 6.5.4 \r\nDate: Mon, 10 Oct 2005 10:02:15 +1300\r\nTo: &lt;archive-crawler@yahoogroups.com&gt;\r\nMime-Version: 1.0\r\nContent-Type: text/plain; charset=US-ASCII\r\nContent-Transfer-Encoding: quoted-printable\r\nContent-Disposition: inline\r\nX-SEEmail-Version: 2.0\r\nX-SEEmail: Liverton v2.15 MailMarshal Configuration\r\nX-eGroups-Msg-Info: 4:13:32:0\r\nFrom: &quot;Gordon Paynter&quot; &lt;Gordon.Paynter@...&gt;\r\nSubject: Re: [archive-crawler] The crawler doesn&#39;t seem to stop\n\tcrawling\r\nX-Yahoo-Group-Post: member; u=235746949\r\n\r\nHi:\n\nI had a problem like this with a more recent version of Heretrix, and =\r\nit turned out that the problem was that at the end of a single site crawl, =\r\nthere was a couple of links that could not be downloaded from the site (i.e=\r\n. the site had broken links) that the crawler hung around trying to downloa=\r\nd.\n\nThe crawler was set up to attempt to download these links, but because =\r\nit is very polite, it would only download one at a time. And also because i=\r\nt is so polite, it would wait 5 minutes (900 seconds) between attempts. But=\r\n because it was thorough, it would try again each time it failed, up to som=\r\nething like 30 retries. (I may have those numbers a little bit wrong.)  As =\r\na result, one broken link on the site would cause the crawler to linger for=\r\n about (900 * 30) seconds, which is almost 8 hours.\n\nYou can diagnose this =\r\nby looking at the ToeThreads and Frontier reports while the crawler is runn=\r\ning: if it looks like there&#39;s nothing happening, and there&#39;s never more tha=\r\nn one download in progress, this is likely your problem.  To solve it, I su=\r\nggest you check the max-retries and retry-delay-seconds parameters (the nam=\r\nes be different in your version of Heretrix), and set them to something lik=\r\ne 3 retries and a 60 second delay.\n\nGordon\n\n\n&gt;&gt;&gt; ashwind18@... 10/09/=\r\n05 7:34 a.m. &gt;&gt;&gt;\nHi,\n\nI am kind of new to the Heritrix crawler and i am cur=\r\nrently using it\nfor some project.\n\nWhat i noticed when crawling my site was=\r\n that the crawler seems to\nkeep crawling for quite some time. It took me ab=\r\nout 8 hours to crawl\nmy site, which is a small site. Is this normal or have=\r\n i configured\nthe crawler wrongly?\n\nWhat i am confused is that the crawler =\r\njust seems to crawl on and on,\nas if it were crawling the site again or goi=\r\nng out of the scope. Or\nperhaps the crawler was waiting for some downloads =\r\nor processes.\n\nThe configuration i used were pretty much the default settin=\r\ngs, which\nmeans i just entered the project site and the email requirements.=\r\n\nOther than those, i left the settings unchanged.\n\nBy the way, i am current=\r\nly using Heritrix 1.2.0.\n\nCan someone please enlighten me? Your attention i=\r\ns kindly appreciated.\nThanks\n\nAdrian\n\n\n\n\n\n\n \nYahoo! Groups Links\n\n\n\n \n\n\n\n\n\n=\r\n\n"}}