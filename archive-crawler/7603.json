{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":500983475,"authorName":"david_pane1","from":"&quot;david_pane1&quot; &lt;dpane@...&gt;","profile":"david_pane1","replyTo":"LIST","senderId":"a5pm-9tBvaFdSm-Rk1-qobScVlw143WgoFhbZjjEk0te0xUVZlilxF_Qn1aJLdudDc-XCjORh8hcCEBeImBI35ZN_pjzUm4","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: questions on how to setup Heritrix 3 on two machines","postDate":"1328114450","msgId":7603,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGpnYnB1aStvbm9nQGVHcm91cHMuY29tPg==","inReplyToHeader":"PGpnYmplMitmYzd0QGVHcm91cHMuY29tPg=="},"prevInTopic":7602,"nextInTopic":7604,"prevInTime":7602,"nextInTime":7604,"topicId":7341,"numMessagesInTopic":9,"msgSnippet":"Yes, they can work together but you must feed both instances the same seed list.  It will then decide based on domains which seeds (and discovered URIs) each","rawEmail":"Return-Path: &lt;dpane@...&gt;\r\nX-Sender: dpane@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 90417 invoked from network); 1 Feb 2012 16:40:55 -0000\r\nX-Received: from unknown (98.137.35.161)\n  by m4.grp.sp2.yahoo.com with QMQP; 1 Feb 2012 16:40:55 -0000\r\nX-Received: from unknown (HELO ng9-ip1.bullet.mail.ne1.yahoo.com) (98.138.215.180)\n  by mta5.grp.sp2.yahoo.com with SMTP; 1 Feb 2012 16:40:55 -0000\r\nX-Received: from [98.138.217.177] by ng9.bullet.mail.ne1.yahoo.com with NNFMP; 01 Feb 2012 16:40:51 -0000\r\nX-Received: from [69.147.65.150] by tg2.bullet.mail.ne1.yahoo.com with NNFMP; 01 Feb 2012 16:40:51 -0000\r\nX-Received: from [98.137.34.72] by t7.bullet.mail.sp1.yahoo.com with NNFMP; 01 Feb 2012 16:40:51 -0000\r\nDate: Wed, 01 Feb 2012 16:40:50 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;jgbpui+onog@...&gt;\r\nIn-Reply-To: &lt;jgbje2+fc7t@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;david_pane1&quot; &lt;dpane@...&gt;\r\nSubject: Re: questions on how to setup Heritrix 3 on two machines\r\nX-Yahoo-Group-Post: member; u=500983475; y=xdfqLp-Dp_ryup4P71mrx460GcaUtiG2QzMgzKNxm70x6c41qB0mFw\r\nX-Yahoo-Profile: david_pane1\r\n\r\nYes, they can work together but you must feed both instances the same seed =\r\nlist.  It will then decide based on domains which seeds (and discovered URI=\r\ns) each will crawl.\n\nThese two properties shows each crawler instance what =\r\nits name (localName) is and how many crawlers (crawlerCount) it is &quot;sharing=\r\n&quot; the crawl with.\n\n&lt;property name=3D&quot;localName&quot;      value=3D&quot;1&quot; /&gt;\n&lt;proper=\r\nty name=3D&quot;crawlerCount&quot;   value=3D&quot;2&quot; /&gt;\n\nIf one crawler finds URIs that t=\r\nhe other crawler is suppose to crawl, it places those URIs in the diversion=\r\ns folder.  You have to manually move those diversion files to the other cra=\r\nwler instance (with some modifications to the file before placing them in t=\r\nhe actions folder of the other crawler instance).\n\n--David\n\n--- In archive-=\r\ncrawler@yahoogroups.com, &quot;hatoum13&quot; &lt;hatoum13@...&gt; wrote:\n&gt;\n&gt; Hi Davi,\n&gt; \n&gt;=\r\n Thanks for your response,\n&gt; \n&gt; Apparently you are talking about the same m=\r\nachine (physically one computer).\n&gt; \n&gt; In my case, i have technical constra=\r\nints which is a very limited memory in my machines (3 GB for each one) and =\r\nI want to accelerate the crawl by launching it in two machines (connected i=\r\nn the same network) :\n&gt; 1 st machine : instance with 2 GB of memory \n&gt; 2 nd=\r\n machine : instance with 2 GB of memory \n&gt; My question is : Can the two ins=\r\ntances works together on the same seeds.txt (which contains 12 millions lin=\r\ne)?\n&gt; \n&gt; \n&gt; --- In archive-crawler@yahoogroups.com, &quot;david_pane1&quot; &lt;dpane@&gt; =\r\nwrote:\n&gt; &gt;\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; After creating a job on the mail page on the Herit=\r\nrix web interface, under &quot;Add Job Directory&quot;(in example below the jobname i=\r\ns myjob1), place your seed file into the jobname directory.\n&gt; &gt; \n&gt; &gt; From t=\r\nhe directory where you installed heritrix, you will see a directory jobs, i=\r\nnside jobs will be a directory named &quot;jobname&quot;&quot;\n&gt; &gt; \n&gt; &gt; .../HeritrixInstal=\r\nlDirectory/jobs/myjob1/seeds.txt\n&gt; &gt; \n&gt; &gt; each instance should have the ide=\r\nntical seed list placed in its jobs directory.  Seed list should have a for=\r\nmat like this:\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; http://www.domain.com/\n&gt; &gt; http://www.domain2.=\r\ncom/\n&gt; &gt; http://www.domain3.com/\n&gt; &gt; http://www.domain4.com/\n&gt; &gt; \n&gt; &gt; I hop=\r\n this helps\n&gt; &gt; \n&gt; &gt; --David\n&gt; &gt; --- In archive-crawler@yahoogroups.com, &quot;h=\r\natoum13&quot; &lt;hatoum13@&gt; wrote:\n&gt; &gt; &gt;\n&gt; &gt; &gt; Hi,\n&gt; &gt; &gt; \n&gt; &gt; &gt; I&#39;m trying to inst=\r\nall H3 on 2 different machines (in a local network) to crawl a large seeds =\r\nfile (more than 10 millions URL), I&#39;m faced to little problem, how can I pu=\r\nt the same seeds file for both instances?\n&gt; &gt; &gt; \n&gt; &gt; &gt; I tried to make the =\r\nfile reachable from a web server but the Job can&#39;t be built because of an e=\r\nxception when it&#39;s creating the seed&#39;s bean.\n&gt; &gt; &gt; \n&gt; &gt; &gt; Thanks\n&gt; &gt; &gt; \n&gt; &gt;=\r\n &gt; --- In archive-crawler@yahoogroups.com, &quot;david_pane1&quot; &lt;dpane@&gt; wrote:\n&gt; =\r\n&gt; &gt; &gt;\n&gt; &gt; &gt; &gt; With some effort, tips from Gordan and using the H1 to get an=\r\n idea of the property names of the HashCrawlMapper, I was able to successfu=\r\nlly configure and run a two machine test crawl.  I figured I would post thi=\r\ns for others to refer to in the future.  \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Using t=\r\nhe default crawler-beans.cxml, I added the following (in addition to the ne=\r\ncessary user-agent and the seed list changes )\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; I defined t=\r\nhe following in crawler-beans.cxml on machine 1:\n&gt; &gt; &gt; &gt;   &lt;bean id=3D&quot;hash=\r\nCrawlMapperProcessor&quot; class=3D&quot;org.archive.crawler.processor.HashCrawlMappe=\r\nr&quot;&gt;\n&gt; &gt; &gt; &gt;  \t&lt;property name=3D&quot;localName&quot;      value=3D&quot;0&quot; /&gt;\n&gt; &gt; &gt; &gt; \t&lt;pr=\r\noperty name=3D&quot;diversionDir&quot;   value=3D&quot;diversions&quot; /&gt;\n&gt; &gt; &gt; &gt; \t&lt;property n=\r\name=3D&quot;checkUri&quot;       value=3D&quot;True&quot; /&gt;\n&gt; &gt; &gt; &gt; \t&lt;property name=3D&quot;checkOu=\r\ntlinks&quot;  value=3D&quot;False&quot; /&gt;\n&gt; &gt; &gt; &gt; \t&lt;property name=3D&quot;rotationDigits&quot; valu=\r\ne=3D&quot;10&quot; /&gt;\n&gt; &gt; &gt; &gt; \t&lt;property name=3D&quot;crawlerCount&quot;   value=3D&quot;2&quot; /&gt;\n&gt; &gt; &gt;=\r\n &gt;   &lt;/bean&gt;\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; and this definition on machine #2 (o=\r\nnly change was local-name value):\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt;   &lt;bean id=3D&quot;hashCrawlM=\r\napperProcessor&quot; class=3D&quot;org.archive.crawler.processor.HashCrawlMapper&quot;&gt;\n&gt; =\r\n&gt; &gt; &gt;  \t&lt;property name=3D&quot;localName&quot;      value=3D&quot;1&quot; /&gt;\n&gt; &gt; &gt; &gt; \t&lt;property=\r\n name=3D&quot;diversionDir&quot;   value=3D&quot;diversions&quot; /&gt;\n&gt; &gt; &gt; &gt; \t&lt;property name=3D=\r\n&quot;checkUri&quot;       value=3D&quot;True&quot; /&gt;\n&gt; &gt; &gt; &gt; \t&lt;property name=3D&quot;checkOutlinks=\r\n&quot;  value=3D&quot;False&quot; /&gt;\n&gt; &gt; &gt; &gt; \t&lt;property name=3D&quot;rotationDigits&quot; value=3D&quot;1=\r\n0&quot; /&gt;\n&gt; &gt; &gt; &gt; \t&lt;property name=3D&quot;crawlerCount&quot;   value=3D&quot;2&quot; /&gt;\n&gt; &gt; &gt; &gt;   &lt;=\r\n/bean&gt;\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; Then I added in call to hashCrawlMapperProcessor in=\r\n the candidateProcessors chain.\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt;  &lt;!-- now, processors are =\r\nassembled into ordered CandidateChain bean --&gt;\n&gt; &gt; &gt; &gt;  &lt;bean id=3D&quot;candida=\r\nteProcessors&quot; class=3D&quot;org.archive.modules.CandidateChain&quot;&gt;\n&gt; &gt; &gt; &gt;   &lt;prop=\r\nerty name=3D&quot;processors&quot;&gt;\n&gt; &gt; &gt; &gt;    &lt;list&gt;\n&gt; &gt; &gt; &gt;     &lt;!-- apply scoping =\r\nrules to each individual candidate URI... --&gt;\n&gt; &gt; &gt; &gt;     &lt;ref bean=3D&quot;cand=\r\nidateScoper&quot;/&gt;\n&gt; &gt; &gt; &gt;     &lt;!-- check every URI discovered even before it i=\r\ns ever enqueued --&gt;\n&gt; &gt; &gt; &gt;     &lt;ref bean=3D&quot;hashCrawlMapperProcessor&quot;/&gt;\n&gt; =\r\n&gt; &gt; &gt; \n&gt; &gt; &gt; &gt;     &lt;!-- ...then prepare those ACCEPTed to be enqueued to fr=\r\nontier. --&gt;\n&gt; &gt; &gt; &gt;     &lt;ref bean=3D&quot;preparer&quot;/&gt;\n&gt; &gt; &gt; &gt;    &lt;/list&gt;\n&gt; &gt; &gt; &gt;=\r\n   &lt;/property&gt;\n&gt; &gt; &gt; &gt;  &lt;/bean&gt;\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; and a call to hashCrawlMap=\r\nperProcessor in the FetchChain\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt;  &lt;!-- now, processors are a=\r\nssembled into ordered FetchChain bean --&gt;\n&gt; &gt; &gt; &gt;  &lt;bean id=3D&quot;fetchProcess=\r\nors&quot; class=3D&quot;org.archive.modules.FetchChain&quot;&gt;\n&gt; &gt; &gt; &gt;   &lt;property name=3D&quot;=\r\nprocessors&quot;&gt;\n&gt; &gt; &gt; &gt;    &lt;list&gt;\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt;     &lt;!-- re-check scope, if=\r\n so enabled... --&gt;\n&gt; &gt; &gt; &gt;     &lt;ref bean=3D&quot;preselector&quot;/&gt;\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt;=\r\n     &lt;ref bean=3D&quot;hashCrawlMapperProcessor&quot;/&gt;\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; .\n&gt; &gt; &gt; &gt; .\n=\r\n&gt; &gt; &gt; &gt; .\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; --David\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; --- I=\r\nn archive-crawler@yahoogroups.com, &quot;david_pane1&quot; &lt;dpane@&gt; wrote:\n&gt; &gt; &gt; &gt; &gt;\n=\r\n&gt; &gt; &gt; &gt; &gt; I am new to using Heritrix 3 and have only limited experience wit=\r\nh H1.  I would like to setup H3 on two (maybe more in the future) machines =\r\nfor a distributed crawl.  I would also like to apply the HashCrawlMapper to=\r\n the processing chains so the URIs are shared between the two crawlers. \n&gt; =\r\n&gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Although there are discussions about multiple machine cr=\r\nawls and the use of HashCrawlMapper, I could not find specifics on the setu=\r\np of this (i.e even an example crawler-beans.cxml with a default configurat=\r\nion).   I understand that both crawlers should have the same configuration.=\r\n  However, how do you assign a crawler/node name to each so that the HashCr=\r\nawlMapper can assign URIs and each crawler understands which ones to crawl.=\r\n?\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Additionally, when attempting to define a name bean =\r\nfor the HashCrawlMapper I am unclear on how to identify the available prope=\r\nrty names and values.  (And this is true for any bean that is not clearly d=\r\nefined as the default crawler-beans.cxml.)\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; I understan=\r\nd that the customization of the configuration for optimal performance may t=\r\nake many iterations, but can anyone help me define the initial configuratio=\r\nn of a two crawler/machine system which would work as a distributed crawl.\n=\r\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; Thank you,\n&gt; &gt; &gt; &gt; &gt; \n&gt; &gt; &gt; &gt; &gt; -David\n&gt; &gt; &gt; &gt; &gt;\n&gt; &gt; &gt;=\r\n &gt;\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n\n\n\n"}}