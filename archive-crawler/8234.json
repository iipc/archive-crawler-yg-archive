{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":473207283,"authorName":"Kristinn Sigur√∞sson","from":"=?iso-8859-1?Q?Kristinn_Sigur=F0sson?= &lt;kristinn@...&gt;","profile":"kristsi25","replyTo":"LIST","senderId":"cuD7DyXQF4p6TiFUtO9vzSfPY0dj65Q9FpLShcHq4v61b58qVnyyhgazuxNpbpOCARbTtdWQUbVE35j-kys1icii7CY-lg116vjZB1XXP17i00RxCzRrkvTNR7EMEehbc1r2bUUQuUbn","spamInfo":{"isSpam":false,"reason":"12"},"subject":"RE: [archive-crawler] Heritrix 3.1.x Content Extraction","postDate":"1374491273","msgId":8234,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEU0ODZEOTNFMzcyRDhDNDI4MkU4REYwNzgzOTJGMTJEQTAwQTgwQGJsaWtpLmJva2hsYWRhLmxvY2FsPg==","inReplyToHeader":"PGtzYnFjbitvbTkzQGVHcm91cHMuY29tPg==","referencesHeader":"PGtzYnFjbitvbTkzQGVHcm91cHMuY29tPg=="},"prevInTopic":8233,"nextInTopic":8245,"prevInTime":8233,"nextInTime":8235,"topicId":8233,"numMessagesInTopic":7,"msgSnippet":"Yes, you ll need to write your own Processor. In its basic form, this is very simple; Just extend the Processor class and implement the two abstract methods","rawEmail":"Return-Path: &lt;kristinn@...&gt;\r\nX-Sender: kristinn@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 81944 invoked by uid 102); 22 Jul 2013 11:08:40 -0000\r\nX-Received: from unknown (HELO mtaq2.grp.bf1.yahoo.com) (10.193.84.33)\n  by m4.grp.bf1.yahoo.com with SMTP; 22 Jul 2013 11:08:40 -0000\r\nX-Received: (qmail 1181 invoked from network); 22 Jul 2013 11:08:40 -0000\r\nX-Received: from unknown (HELO vala.bok.hi.is) (130.208.186.10)\n  by mtaq2.grp.bf1.yahoo.com with SMTP; 22 Jul 2013 11:08:40 -0000\r\nX-Received: from bliki.bokhlada.local (bliki.bok.hi.is [130.208.186.6])\n\tby vala.bok.hi.is (8.13.8/8.13.8) with ESMTP id r6MB8bdq001996\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Mon, 22 Jul 2013 11:08:37 GMT\r\nX-Received: from BLIKI.bokhlada.local ([2002:82d0:ba06::82d0:ba06]) by\n bliki.bokhlada.local ([2002:82d0:ba06::82d0:ba06]) with mapi id\n 14.01.0438.000; Mon, 22 Jul 2013 11:07:53 +0000\r\nTo: &quot;archive-crawler@yahoogroups.com&quot; &lt;archive-crawler@yahoogroups.com&gt;\r\nThread-Topic: [archive-crawler] Heritrix 3.1.x Content Extraction\r\nThread-Index: AQHOhJ87TmBC5xKV40yau83syNaadJlwi4cg\r\nDate: Mon, 22 Jul 2013 11:07:53 +0000\r\nMessage-ID: &lt;E486D93E372D8C4282E8DF078392F12DA00A80@...&gt;\r\nReferences: &lt;ksbqcn+om93@...&gt;\r\nIn-Reply-To: &lt;ksbqcn+om93@...&gt;\r\nAccept-Language: en-US, is-IS\r\nContent-Language: en-US\r\nX-MS-Has-Attach: \r\nX-MS-TNEF-Correlator: \r\nContent-Type: text/plain; charset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nMIME-Version: 1.0\r\nX-Spam-Status: No, score=0.0 required=4.6 tests=none autolearn=disabled\n\tversion=3.3.1\r\nX-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on gleipnir.rhi.hi.is\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: =?iso-8859-1?Q?Kristinn_Sigur=F0sson?= &lt;kristinn@...&gt;\r\nSubject: RE: [archive-crawler] Heritrix 3.1.x Content Extraction\r\nX-Yahoo-Group-Post: member; u=473207283; y=Ut0_SzC2Q1CUJ9ryg5EGV4LRrq8kRR9QJWwT17D3g-k-i7Xv\r\nX-Yahoo-Profile: kristsi25\r\n\r\nYes, you&#39;ll need to write your own Processor.\n\nIn its basic form, this is v=\r\nery simple; Just extend the Processor class and implement the two abstract =\r\nmethods (shouldProcess and innerProcess).\n\nYou can look to the Extractor cl=\r\nasses (see ExtractorUniversal for a fairly simple one) for how a processor =\r\ncan get access to the downloaded content. But basically it is done like so:=\r\n\n\nInputStream instream =3D curi.getRecorder().getContentReplayInputStream()=\r\n;\n\nThe content replay stream is available to processors that run after the =\r\nFetchHTTP processor.\n\nIf you invoke CrawlURI.linkExtractorFinished(), that =\r\nshould prevent subsequent extractors from extracting links from that item. =\r\nThus, if you insert your own Processor in between the FetchHTTP processor a=\r\nnd the link extractors it should be able to control if link extraction is p=\r\nerformed or not.\n\nI&#39;m afraid there is no H3 developer documentation.\n\n- Kri=\r\ns\n\n\n-----------------------------------------------------------------------=\r\n--\nLandsb=F3kasafn =CDslands - H=E1sk=F3lab=F3kasafn | Arngr=EDmsg=F6tu 3 -=\r\n 107 Reykjav=EDk\nS=EDmi/Tel: +354 5255600 | www.landsbokasafn.is\n----------=\r\n---------------------------------------------------------------\nfyrirvari/d=\r\nisclaimer - http://fyrirvari.landsbokasafn.is\n&gt; -----Original Message-----\n=\r\n&gt; From: archive-crawler@yahoogroups.com [mailto:archive-\n&gt; crawler@yahoogro=\r\nups.com] On Behalf Of Pheonix\n&gt; Sent: 19. j=FAl=ED 2013 16:44\n&gt; To: archive=\r\n-crawler@yahoogroups.com\n&gt; Subject: [archive-crawler] Heritrix 3.1.x Conten=\r\nt Extraction\n&gt;\n&gt;\n&gt;\n&gt; Hello,\n&gt;\n&gt; I&#39;ve downloaded the heritrix source code fr=\r\nom sourceforge and have\n&gt; everything set up in Eclipse IDE (such as correct=\r\ning the weird asm\n&gt; jar dependency). The system runs successfully from Ecli=\r\npse (in Linux\n&gt; RedHat environment).\n&gt;\n&gt; Where would be the best place to i=\r\nntegrate a classifier that analyzes\n&gt; a webpage&#39;s content (using structural=\r\n features, etc.)?\n&gt; I have written a DecideRule class to deal with filterin=\r\ng at the point\n&gt; of examining a URI, but at some point I would like to look=\r\n at a\n&gt; page&#39;s content and analyze it before letting the crawler extract\n&gt; =\r\nfurther links to crawl in the future. Where would be the best place\n&gt; to mo=\r\ndify or rewrite? Do I need to write a whole new Processor?\n&gt;\n&gt; Alternativel=\r\ny, where is the point that webpage content is fetched?\n&gt; For example, is it=\r\n in the ContentFetcher (and its various subclasses\n&gt; such as ExtracterHTML,=\r\n etc.) Where in the system is the entirety of\n&gt; the content of the webpage =\r\navailable?\n&gt; (to clarify the last question, I&#39;m talking about the point whe=\r\nre the\n&gt; HTML/page data is available for the extractors to match the conten=\r\nt\n&gt; against regular expressions to find things like PDF&#39;s, further URI&#39;s,\n&gt;=\r\n etc.?)\n&gt;\n&gt; Is there developer documentation for Heritrix 3.1.x? (the doc o=\r\nn the\n&gt; Confluence page deals only with classes relevant to Heritrix 1.x,\n&gt;=\r\n describing old classes like Scope and Filter).\n&gt;\n&gt; Thanks, any help is mos=\r\nt greatly appreciated.\n&gt; [Note: I deleted an older version of this post, as=\r\n I have now\n&gt; clarified my question]\n&gt;\n&gt;\n&gt;\n&gt; \n\n"}}