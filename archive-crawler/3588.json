{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":187404531,"authorName":"astar_t","from":"&quot;astar_t&quot; &lt;astar_t@...&gt;","profile":"astar_t","replyTo":"LIST","senderId":"r30aOzVfe2FVKH4V4fNLNFku2SMQ8SGBJm2MhwrvaUx_8-P6rUBrV3UdENkr754OCu88VUlLjC9OmK1_7QZ3fnth_Ag","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: How to stop filtering of already seen URIs based on previous fetch status code?","postDate":"1165857992","msgId":3588,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGVsazRjOCttc3Y1QGVHcm91cHMuY29tPg==","inReplyToHeader":"PDQ1NzlEMDRCLjEwMTA0QGFyY2hpdmUub3JnPg=="},"prevInTopic":3582,"nextInTopic":3589,"prevInTime":3587,"nextInTime":3589,"topicId":3580,"numMessagesInTopic":5,"msgSnippet":"Hi again, actually upon further analysis, you are right, the URI I had force fed into the crawler via JMX did indeed eventually get crawled.  When I took a","rawEmail":"Return-Path: &lt;astar_t@...&gt;\r\nX-Sender: astar_t@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 54556 invoked from network); 11 Dec 2006 17:27:08 -0000\r\nReceived: from unknown (66.218.67.33)\n  by m36.grp.scd.yahoo.com with QMQP; 11 Dec 2006 17:27:08 -0000\r\nReceived: from unknown (HELO n27b.bullet.scd.yahoo.com) (209.73.160.77)\n  by mta7.grp.scd.yahoo.com with SMTP; 11 Dec 2006 17:27:08 -0000\r\nReceived: from [209.73.164.83] by n27.bullet.scd.yahoo.com with NNFMP; 11 Dec 2006 17:26:33 -0000\r\nReceived: from [66.218.66.78] by t7.bullet.scd.yahoo.com with NNFMP; 11 Dec 2006 17:26:33 -0000\r\nDate: Mon, 11 Dec 2006 17:26:32 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;elk4c8+msv5@...&gt;\r\nIn-Reply-To: &lt;4579D04B.10104@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;astar_t&quot; &lt;astar_t@...&gt;\r\nSubject: Re: How to stop filtering of already seen URIs based on previous fetch status code?\r\nX-Yahoo-Group-Post: member; u=187404531; y=XIYVb4ahM_jrWxpkopsDMiSRBpeD3A1NCse213uaz6YLmQ\r\nX-Yahoo-Profile: astar_t\r\n\r\nHi again, actually upon further analysis, you are right, the URI I \nhad for=\r\nce fed into the crawler via JMX did indeed eventually get \ncrawled.  When I=\r\n took a look at the frontier report it was placed in \nqueue but I didn&#39;t se=\r\ne it in the crawl.log for a while so figured it \nhad been skipped.  It must=\r\n have just taken a while to get crawled or \nshow up in the log.\n\nWhile on t=\r\nhe topic, I&#39;m wondering is there a way to do this type of \nforce feeding of=\r\n URIs via the Heritrix GUI or profile settings?  The \nmethod I use for this=\r\n currently is with a script that greps out URIs \nin the crawl.log then feed=\r\ns the matches to the crawler via JMX \ncommands.  This does work out okay, b=\r\nut I&#39;m curious if there is maybe \nanother way that is built into Heritrix s=\r\nomewhere (?)\n\nThanks again for the help !\nAdam\n\n--- In archive-crawler@yaho=\r\nogroups.com, Gordon Mohr &lt;gojomo@...&gt; \nwrote:\n&gt;\n&gt; astar_t wrote:\n&gt; &gt; Hi, I&#39;=\r\nm running a crawl where initially some URIs were rejected \nby a \n&gt; &gt; Decide=\r\nRule that was added by mistake.  So the URIs show up in the \n&gt; &gt; crawl.log =\r\nas having a -5000 fetch code.  However, I have realized \nthat \n&gt; &gt; I would =\r\nactually like to crawl a subset of these URIs that have \nalready \n&gt; &gt; been =\r\nrejected.  \n&gt; &gt; \n&gt; &gt; So I tried to import the URIs back into the frontier w=\r\nith force \nfetch \n&gt; &gt; via JMX cmdline but they are not being fetched.  I&#39;m =\r\nassuming \nthis is \n&gt; &gt; because they are &quot;already seen&quot; URIs so the BdbUriUn=\r\niqFilter is \n&gt; &gt; ignoring them.\n&gt; &gt; \n&gt; &gt; Is there a way I can force Heritrx=\r\n to retry a fetch of the URIs \nthat \n&gt; &gt; previously had a -5000 code ?\n&gt; \n&gt;=\r\n As Stack notes, this should work. The &#39;force-fetch&#39; flag means to \nignore =\r\n\n&gt; the already-included status. However, it doesn&#39;t ignore scoping -- \nare =\r\n\n&gt; you sure the URIs, as added, would be ruled in-scope?\n&gt; \n&gt; (Are they app=\r\nearing anywhere after your force-fetch add -- in the \n&gt; frontier report, in=\r\n the crawl.log, etc.?)\n&gt; \n&gt; - Gordon @ IA\n&gt;\n\n\n\n"}}