{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"stack","from":"stack &lt;stack@...&gt;","replyTo":"LIST","senderId":"aoQ14Z-lVihRW7mkxxgT23kHP1DzTUr3dFt3jRzJ5nFmGOqXSwQNQYKaYVu_1xuxeBcY9uPWNSl1UV6b0q3FyQ","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Determining a sites Page depth?","postDate":"1090423512","msgId":689,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQwRkU4QUQ4LjEwNTA0MDdAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGNkbHYzZStiOTExQGVHcm91cHMuY29tPg==","referencesHeader":"PGNkbHYzZStiOTExQGVHcm91cHMuY29tPg=="},"prevInTopic":688,"nextInTopic":698,"prevInTime":688,"nextInTime":690,"topicId":688,"numMessagesInTopic":4,"msgSnippet":"... Would you be asking these questions post-crawl? There is perl script in the bin directory called hoppath.pl that looks at crawl.log files.  If you give it","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 88093 invoked from network); 21 Jul 2004 15:24:51 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m2.grp.scd.yahoo.com with QMQP; 21 Jul 2004 15:24:51 -0000\r\nReceived: from unknown (HELO dns.duboce.net) (63.203.238.114)\n  by mta5.grp.scd.yahoo.com with SMTP; 21 Jul 2004 15:24:50 -0000\r\nReceived: from archive.org ([192.168.1.105])\n\t(authenticated)\n\tby dns-eth1.duboce.net (8.10.2/8.10.2) with ESMTP id i6LEk1A19263\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Wed, 21 Jul 2004 07:46:02 -0700\r\nMessage-ID: &lt;40FE8AD8.1050407@...&gt;\r\nDate: Wed, 21 Jul 2004 08:25:12 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; PPC Mac OS X Mach-O; en-US; rv:1.7b) Gecko/20040421\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;cdlv3e+b911@...&gt;\r\nIn-Reply-To: &lt;cdlv3e+b911@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Remote-IP: 63.203.238.114\r\nFrom: stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] Determining a sites Page depth?\r\nX-Yahoo-Group-Post: member; u=168599281\r\n\r\nAhnu Nahki wrote:\n\n&gt;I want to find out the distance from a home page, to another page on\n&gt;the site, how many links away is that page from the start of the site.\n&gt;We have an application that requires the page depth of a site. We used\n&gt;to determine it using an old crawler we have. We&#39;d like to use\n&gt;heritrix to do the same thing, but I dont know what in the API I use\n&gt;to determine how far a page is from the starting page. Some one had\n&gt;mentioned hopsfilter class, but I really dont understand it or have\n&gt;any proper documentation to go by. Any help would be greatly appreciated.\n&gt;\n&gt;Regards,\n&gt;Ahnu\n&gt;  \n&gt;\nWould you be asking these questions post-crawl? There is perl script in \nthe bin directory called hoppath.pl that looks at crawl.log files.  If \nyou give it a URI, it will list the referrers the crawler followed to \nget from initial &#39;seed&#39; URI to queried URI (See the head of the script \nfor notes on edits that need to be made before it can be run).\n\nOtherwise, regards what to use in the API, Heritrix has classes that \nbundle URIs and their state (CandidateURI, CrawlURI).  Part of the state \nkept by a URI is the path from the initial &#39;seed&#39; URI.  See \nCandidateURI#pathFromSeed here \nhttp://crawler.archive.org/xref/org/archive/crawler/datamodel/CandidateURI.html#57).  \nSee here in CrawlScope for an example of counting hops: \nhttp://crawler.archive.org/xref/org/archive/crawler/framework/CrawlScope.html#247.\n\nYours,\nSt.Ack\n\n&gt;\n&gt;\n&gt;\n&gt; \n&gt;Yahoo! Groups Links\n&gt;\n&gt;\n&gt;\n&gt; \n&gt;\n&gt;  \n&gt;\n\n\n"}}