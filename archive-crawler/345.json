{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":182123250,"authorName":"kaisa_kaunonen","from":"&quot;kaisa_kaunonen&quot; &lt;kaisa.kaunonen@...&gt;","profile":"kaisa_kaunonen","replyTo":"LIST","senderId":"U-SbPkR4J9ZEptdaj5neDRSN3wxx7ioJtRf9liv72UTn4b_AztLWuSHaUYuKDneLGhrXBpj2hnfejHehMuX2acbgW_fWwoMMgC8RnrBkckK2oO52","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: FYI/ plan for post-1.0 scope definition reworking","postDate":"1082982382","msgId":345,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGM2aXY1ZStsYmFzQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDQwODk4QTQ3LjIwMjAzMDVAYXJjaGl2ZS5vcmc+"},"prevInTopic":337,"nextInTopic":346,"prevInTime":344,"nextInTime":346,"topicId":337,"numMessagesInTopic":3,"msgSnippet":"Hi, The new proposal seems very versatile, looks like it could handle those jobs I could think of. I suppose the scope rules would be like a tunnel and when","rawEmail":"Return-Path: &lt;kaisa.kaunonen@...&gt;\r\nX-Sender: kaisa.kaunonen@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 50227 invoked from network); 26 Apr 2004 12:27:22 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m11.grp.scd.yahoo.com with QMQP; 26 Apr 2004 12:27:22 -0000\r\nReceived: from unknown (HELO n18.grp.scd.yahoo.com) (66.218.66.73)\n  by mta5.grp.scd.yahoo.com with SMTP; 26 Apr 2004 12:27:21 -0000\r\nReceived: from [66.218.67.134] by n18.grp.scd.yahoo.com with NNFMP; 26 Apr 2004 12:26:25 -0000\r\nDate: Mon, 26 Apr 2004 12:26:22 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;c6iv5e+lbas@...&gt;\r\nIn-Reply-To: &lt;40898A47.2020305@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Length: 7156\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-eGroups-Remote-IP: 66.218.66.73\r\nFrom: &quot;kaisa_kaunonen&quot; &lt;kaisa.kaunonen@...&gt;\r\nSubject: Re: FYI/ plan for post-1.0 scope definition reworking\r\nX-Yahoo-Group-Post: member; u=182123250\r\nX-Yahoo-Profile: kaisa_kaunonen\r\n\r\nHi,\nThe new proposal seems very versatile, looks like it could handle\nthose jobs I could think of.\n\nI suppose the scope rules would be like a tunnel and when each URI\ngoes through, the  URI&#39;s status could change between include/exclude\nmany times. Because the last rule always wins and there are no\nbranches it&#39;s important to pay attention to rule order.\n \nWhat about collecting domains with some subdomains excluded? \nWhat if I want to crawl domain &#39;www.main.fi&#39; but not a subdomain\n&#39;www.pictures.main.fi&#39; which contains only pictures. The exception is\nthat I want to include some old pictures which reside in\nwww.pictures.main.fi/old_pics\n\nSo\n(1) IncludeIf(sameDomainAsAnySeed(seeds, group1=www.main.fi))\n(2) ExcludeIf(sameDomainAsAnySeed(seeds, group2=www.pictures.main.fi))\n(3) IncludeIf(pathExtensionOf(www.pictures.main.fi/old_pics))\n\n(The order here is important if &#39;and&#39; is not allowed between rules ?)\n\nOr could I handle this with by using more regular expressions\n\n(1) IncludeIf(sameDomainAsAnySeed(seeds = www.main.fi))\n(2) ExcludeIf(regexpMatch(www.pictures.main.fi/*)\n(3) IncludeIf(regexpMatch(www.pictures.main.fi/old_pics/*)\n\n(here * is a general form of regexp not Java)\n\n\n\n\n--- In archive-crawler@yahoogroups.com, Gordon Mohr &lt;gojomo@a...&gt;\nwrote:\n&gt; We are planning a change in the way in which a crawl&#39;s scope --\n&gt; its definition of what URIs are included and excluded -- is\n&gt; modelled and specified after the 1.0 Heritrix release. (That is\n&gt; to say, sometime in May or after.) The hope is to make alternate\n&gt; scope choices more understandable and flexible.\n&gt; \n&gt; The new approach is somewhat like (and inspired by) HTTrack&#39;s\n&gt; &#39;scan rules&#39;/filters, Alexa&#39;s mask/ignore/void syntax for\n&gt; adjusting recurring crawls, or the Nutch &#39;regex-urlfilter&#39;\n&gt; facility, but is a little more general than any of those.\n&gt;\n&gt; \n&gt; NEW APPROACH\n&gt; \n&gt; We are planning a new standard Scope model that should be easier to\n&gt; understand when used for simple, common crawls, as well as better\n&gt; accomodate certain &#39;mixed&#39; focus requirements. This model retains\nthe\n&gt; idea that at the highest level, the &#39;Scope&#39; is a swappable,\n&gt; self-contained component that is consulted for a yes/no judgement on\n&gt; whether or not a particular candidate URI is &#39;in scope&#39; for a crawl.\n&gt; \n&gt; In the common case, though, we will think of the Scope is thought of\n&gt; as a series of ScopeRules. Each ScopeRule contains a Matcher and a\n&gt; ScopeAction. A Matcher can be thought of as a Filter ranamed for\n&gt; clarity: it returns true if its conditions are matched. A\n&gt; ScopeAction is (for now) either INCLUDE or EXCLUDE.\n&gt; \n&gt; To define a Scope, the operator configures an ordered series of\n&gt; ScopeRules. A URI under consideration begins with the assumed\n&gt; status EXCLUDED, but then each rule is applied in turn to the\n&gt; candidate URI. If the rule&#39;s Matcher matches, then the supplied\n&gt; action is applied to the URI&#39;s current include/exclude status,\n&gt; possibly changing that status. After all rules have been applied,\n&gt; if the URI&#39;s status is INCLUDED it is &quot;in scope&quot; and scheduled\n&gt; for crawling; if its status is EXCLUDED it is discarded.\n&gt; \n&gt; There are no branches, but much of what nested conditionals\n&gt; can achieve is possible, in a form that should be be easier to\n&gt; follow than arbitrary expressions.\n&gt; \n&gt; The list of available Matchers would include things like:\n&gt; \n&gt;    sameDomainAsAnySeed()\n&gt;    sameDomainAsAnyUriInFile(&quot;filename&quot;)\n&gt;    pathExtensionOf(&quot;http://www.berkeley.edu/research/&quot;)\n&gt;    embeddedResourceWithinHops(3)\n&gt;    regexpMatch(&quot;.*cgi-bin.*&quot;)\n&gt;    pathSlashesGreaterThan(10)\n&gt; \n&gt; ...covering everything our existing focus- and filter-\n&gt; based classes do. By ordering exclude and include actions,\n&gt; combinations that were awkward before -- or even impossible\n&gt; given the current interface -- become straightforward.\n&gt; \n&gt; For example, a previous request that was hard for us to\n&gt; accomodate was the idea: &quot;crawl exactly these X hosts,\n&gt; and get offsite images if only on the same domains.&quot; That is,\n&gt; don&#39;t wander off the exact hosts to follow links, or even\n&gt; get offsite images -- except when the offsite image shares\n&gt; the same domain.\n&gt; \n&gt; Our relevant function-of-seeds tests -- host-based and\n&gt; domain-based -- were exclusive of each other (at the &#39;focus&#39;\n&gt; level) and difficult to mix-in with path-based criteria\n&gt; (at the &#39;transitive&#39; level).\n&gt; \n&gt; As a series of ScopeRules, this can be achieved as:\n&gt; \n&gt;    includeIf(sameHostAsAnySeed())\n&gt;    includeIf(embeddedResourceWithinHops(1))\n&gt;    excludeIf(not(sameDomainAsAnySeed())\n&gt; \n&gt; Further refinements to this basic model are possible:\n&gt; \n&gt; (1) Allow rules to offer more actions than include/exclude,\n&gt;      such as an early exit from the rule chain. Then meeting\n&gt;      a certain test might mean &#39;exclude regardless of subsequent\n&gt;      rules&#39; or &#39;include regardless of subsequent rules&#39;.\n&gt;      (More speculative: let rules mark-up URIs in ways that\n&gt;      affect their future scoping, processing, or the handling\n&gt;      of other URIs discovered off them.) This sort of\n&gt;      refinement could allieviate the otherwise inefficient\n&gt;      calculation of ultimately irrelevant rules.\n&gt; \n&gt; (2) Segment the ScopeRules into 2 distinct chains: one\n&gt;      chain that is &quot;core&quot; or perhaps &quot;static&quot; rules, defining\n&gt;      the main focus of the crawl, and another chain which approves\n&gt;      related URIs dynamically. This would somewhat replicate\n&gt;      the intent of the &#39;focus&#39; vs. &#39;transitive&#39; split in the 1.0\n&gt;      scope model, and make possible a Scope which says, &quot;get\n&gt;      all this &#39;core&#39;, and then anything else within N link-hops\n&gt;      of any &#39;core&#39; items.&quot; (Current link-hop limits apply from\n&gt;      seeds, not from site boundaries.)\n&gt; \n&gt; (3) Allow a seedlist-annotation syntax to help create\n&gt;      mixed scopes. For example, each URI listed in a seed\n&gt;      file might be followed with a label -- &#39;group1&#39;,\n&gt;      &#39;group2&#39;, etc. This could then be used to refer back to\n&gt;      a URI set in Scope Rules -- sameHostAsSeeds(&quot;group1&quot;),\n&gt;      samePathAsSeeds(&quot;group2&quot;), etc.\n&gt; \n&gt; (4) As is suggested by the syntax for listing ScopeRules\n&gt;      above, they could be scripting code supplied by the\n&gt;      crawl operator, in Python, Javascript, or other scripting\n&gt;      langauges that we might embed in our Java app. Then\n&gt;      other optimizations and tests of arbitrary complexity\n&gt;      could be added as needed, as either one ScopeRule among\n&gt;      many or as the entire scope. Further, such scripts\n&gt;      could reuse and combine predefined Matcher functions.\n&gt; \n&gt; Our first steps to validate this approach can likely reuse\n&gt; the existing multi-admin-page system for setting up filters\n&gt; to set up rules; as we acquire confidence in how it would\n&gt; be used, we could integrate it all into the main settings\n&gt; page, or its own scope definition page. We could also offer\n&gt; a &#39;testing page&#39; where you could feed URIs (plus specified\n&gt; other attributes) to the system and see what each rule does,\n&gt; and the final answer given.\n&gt; \n&gt; Comments wanted! Remember this new plan won&#39;t be acted upon\n&gt; until some time in May at the earliest, so the 1.0 crawler\n&gt; will continue to use the old approach.\n&gt; \n&gt; - Gordon\n\n\n"}}