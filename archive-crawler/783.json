{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr (Internet Archive)","from":"&quot;Gordon Mohr (Internet Archive)&quot; &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"_qzjjD4FLcLKhTYjKXIr-NQChZJJJzKitf0FOJVXRbxdPTBGmBlsiFgk2qKq9KHrSY5qBmC7zeA_8NdgCRStJlzHp6Ov5SEKljNxkAmVO1nLPI__P81Fs7w_2-I","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Re: terminating a crawl not terminating completely?","postDate":"1092275139","msgId":783,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQxMUFDQkMzLjYwNDA2MDNAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGNmZTdncCtzcDZnQGVHcm91cHMuY29tPg==","referencesHeader":"PGNmZTdncCtzcDZnQGVHcm91cHMuY29tPg=="},"prevInTopic":781,"nextInTopic":0,"prevInTime":782,"nextInTime":784,"topicId":779,"numMessagesInTopic":4,"msgSnippet":"... Sort of, but that s not as bad as it sounds. Java doesn t reclaim used memory until it s needed. So as soon as most of that memory is needed, it will be","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 50694 invoked from network); 12 Aug 2004 01:45:51 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m19.grp.scd.yahoo.com with QMQP; 12 Aug 2004 01:45:51 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (209.237.232.202)\n  by mta2.grp.scd.yahoo.com with SMTP; 12 Aug 2004 01:45:51 -0000\r\nReceived: (qmail 6193 invoked by uid 100); 12 Aug 2004 01:35:36 -0000\r\nReceived: from b116-dyn-227.archive.org (HELO ?207.241.238.227?) (gojomo@...@207.241.238.227)\n  by mail-dev.archive.org with SMTP; 12 Aug 2004 01:35:36 -0000\r\nMessage-ID: &lt;411ACBC3.6040603@...&gt;\r\nDate: Wed, 11 Aug 2004 18:45:39 -0700\r\nUser-Agent: Mozilla Thunderbird 0.7.1 (X11/20040626)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;cfe7gp+sp6g@...&gt;\r\nIn-Reply-To: &lt;cfe7gp+sp6g@...&gt;\r\nContent-Type: text/plain; charset=us-ascii; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=0.1 required=7.0 tests=AWL autolearn=ham version=2.63\r\nX-eGroups-Remote-IP: 209.237.232.202\r\nFrom: &quot;Gordon Mohr (Internet Archive)&quot; &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Re: terminating a crawl not terminating completely?\r\nX-Yahoo-Group-Post: member; u=137285340\r\nX-Yahoo-Profile: gojomo\r\n\r\nrobeger wrote:\n&gt; So if the used memory is at 128000 after completing a crawl, does the\n&gt; next crawl start from that value as a &quot;zero point&quot; (I know the used\n&gt; memory is never at 0, but its very small at initial startup)?\n\nSort of, but that&#39;s not as bad as it sounds. Java doesn&#39;t reclaim used\nmemory until it&#39;s needed. So as soon as most of that memory is needed, it\nwill be recycled.\n\nWe could add a forced garbage-collection at crawl ends and other\nkey transitions, but the chief effect would be cosmetic.\n\nFinished jobs consume a tiny sliver of memory in the &#39;completed\njobs&#39; list, but that effect should be negligible unless (1) you\nrun tens of thousands of crawls without ever moving any of the\njobs away and restarting the crawler; (2) we have undiscovered\nheld-reference bugs.\n\nI know of one reported bug that might keep a terminated crawl&#39;s\nstructures around indefinitely:\n\n   [ 1002319 ] Terminating paused crawl leaves zombie threads\n   https://sourceforge.net/tracker/index.php?func=detail&aid=1002319&group_id=73833&atid=539099\n\n- Gordon @ IA\n\n\n&gt; --- In archive-crawler@yahoogroups.com, &quot;Kaisa Kaunonen&quot;\n&gt; &lt;kaisa.kaunonen@h...&gt; wrote:\n&gt; \n&gt;&gt;Crawler stays alive after all jobs completed\n&gt;&gt;unless specifically terminated (Shut down Heritrix software -link)\n&gt;&gt;\n&gt;&gt;If you reload the admin console page, while Heritrix is alive\n&gt;&gt;although not crawling anything, the &#39;Used memory&#39; value\n&gt;&gt;grows. Reason is that your reload is recorded in heritrix_out.log\n&gt;&gt;which grows (well, anyway, I couldn&#39;t find any other reason :)\n&gt;&gt;\n&gt;&gt;You can return default memory values,\n&gt;&gt;&#39;Used memory&#39; and &#39;Heap size&#39;, by shutting down Heritrix and\n&gt;&gt;restarting it.\n&gt;&gt;\n&gt;&gt;kk\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;--- In archive-crawler@yahoogroups.com, &quot;robeger&quot; &lt;reger@a...&gt; wrote:\n&gt;&gt;\n&gt;&gt;&gt;When terminating a crawl in progress I&#39;ve noticed that the memory\n&gt;&gt;\n&gt;&gt;used\n&gt;&gt;\n&gt;&gt;&gt;value does not go back down after terminating.  It actually appears\n&gt;&gt;\n&gt;&gt;to\n&gt;&gt;\n&gt;&gt;&gt;keep increasing, and the crawler running line still says &quot;yes&quot;\n&gt;&gt;\n&gt;&gt;despite\n&gt;&gt;\n&gt;&gt;&gt;no current job showing\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;Status of crawler as of Aug. 10, 2004 22:14:03 GMT        \n&gt;&gt;&gt;Alerts:  no alerts\n&gt;&gt;&gt;Crawler is running \t\n&gt;&gt;&gt;No job ready for crawling (create new)\n&gt;&gt;&gt;0 jobs pending, 7 completed   \t\n&gt;&gt;&gt;\t \n&gt;&gt;&gt;Crawler status\n&gt;&gt;&gt;Crawler running:  \tYes\n&gt;&gt;&gt;Current job:  \tNone\n&gt;&gt;&gt;Jobs pending:  \t0\n&gt;&gt;&gt;Jobs completed:  7\n&gt;&gt;&gt;\t\n&gt;&gt;&gt;Used memory:  \t115987 KB\n&gt;&gt;&gt;Heap size:  \t170980 KB\n&gt;&gt;&gt;Max heap size:  520256 KB\n&gt;&gt;&gt;Alerts: \t0 (0 new)\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;And a little bit later (no crawl started by me):\n&gt;&gt;&gt;\n&gt;&gt;&gt; Status of crawler as of Aug. 10, 2004 22:17:07 GMT        \n&gt;&gt;&gt;Alerts:  no alerts\n&gt;&gt;&gt;Crawler is running \t\n&gt;&gt;&gt;No job ready for crawling (create new)\n&gt;&gt;&gt;0 jobs pending, 7 completed   \t\n&gt;&gt;&gt;\t \n&gt;&gt;&gt;Crawler status\n&gt;&gt;&gt;Crawler running:  \tYes\n&gt;&gt;&gt;Current job:  \tNone\n&gt;&gt;&gt;Jobs pending:  \t0\n&gt;&gt;&gt;Jobs completed:  7\n&gt;&gt;&gt;\t\n&gt;&gt;&gt;Used memory:  \t116124 KB\n&gt;&gt;&gt;Heap size:  \t170980 KB\n&gt;&gt;&gt;Max heap size:  520256 KB\n&gt;&gt;&gt;Alerts: \t0 (0 new)\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt;  \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n&gt;  \n&gt; \n\n\n"}}