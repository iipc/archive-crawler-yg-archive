{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":278688455,"authorName":"Maciej Gawinecki","from":"Maciej Gawinecki &lt;mgawinecki@...&gt;","profile":"dzieciou","replyTo":"LIST","senderId":"AZ2zxBuGSpZSLAHeBMRvyii-6qL3RMFmbWRmuzi9zDbJRF3CPKDmSFEHJwr6a48ROHPR2p7vwlw6wlpFqX5BEoXEhBPXr2Ho7vBc8O8o","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Are there frontiers that can read a list of URLs from a file?","postDate":"1248720371","msgId":5944,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRBNkRGNUYzLjMwNjAxMDlAZ21haWwuY29tPg==","inReplyToHeader":"PEE4NzMyRUZCMTQzREU1NDU5OUJFMTlCMjY3MDEzRUFCMDEwNDJCRUNCRjk1QFNCTUFJTEJPWDEuc2Iuc3RhdHNiaWJsaW90ZWtldC5kaz4=","referencesHeader":"PGg0azZocCthc2JhQGVHcm91cHMuY29tPiA8QTg3MzJFRkIxNDNERTU0NTk5QkUxOUIyNjcwMTNFQUIwMTA0MkJFQ0JGOTVAU0JNQUlMQk9YMS5zYi5zdGF0c2JpYmxpb3Rla2V0LmRrPg=="},"prevInTopic":5943,"nextInTopic":0,"prevInTime":5943,"nextInTime":5945,"topicId":5942,"numMessagesInTopic":3,"msgSnippet":"I ve posted a question for similar problem/task you ve made and I ve got similar answer: http://tech.groups.yahoo.com/group/archive-crawler/message/5938 You re","rawEmail":"Return-Path: &lt;mgawinecki@...&gt;\r\nX-Sender: mgawinecki@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 51011 invoked from network); 27 Jul 2009 18:47:27 -0000\r\nX-Received: from unknown (69.147.108.202)\n  by m8.grp.re1.yahoo.com with QMQP; 27 Jul 2009 18:47:27 -0000\r\nX-Received: from unknown (HELO mail-bw0-f223.google.com) (209.85.218.223)\n  by mta3.grp.re1.yahoo.com with SMTP; 27 Jul 2009 18:47:27 -0000\r\nX-Received: by bwz23 with SMTP id 23so2858926bwz.22\n        for &lt;archive-crawler@yahoogroups.com&gt;; Mon, 27 Jul 2009 11:46:26 -0700 (PDT)\r\nX-Received: by 10.204.124.7 with SMTP id s7mr3415716bkr.105.1248720386738;\n        Mon, 27 Jul 2009 11:46:26 -0700 (PDT)\r\nReturn-Path: &lt;mgawinecki@...&gt;\r\nX-Received: from ?192.168.1.57? (host129-144-dynamic.58-82-r.retail.telecomitalia.it [82.58.144.129])\n        by mx.google.com with ESMTPS id 28sm11893495fkx.24.2009.07.27.11.46.24\n        (version=TLSv1/SSLv3 cipher=RC4-MD5);\n        Mon, 27 Jul 2009 11:46:25 -0700 (PDT)\r\nMessage-ID: &lt;4A6DF5F3.3060109@...&gt;\r\nDate: Mon, 27 Jul 2009 20:46:11 +0200\r\nUser-Agent: Thunderbird 2.0.0.22 (Windows/20090605)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;h4k6hp+asba@...&gt; &lt;A8732EFB143DE54599BE19B267013EAB01042BECBF95@...&gt;\r\nIn-Reply-To: &lt;A8732EFB143DE54599BE19B267013EAB01042BECBF95@...&gt;\r\nContent-Type: text/plain; charset=windows-1252; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Maciej Gawinecki &lt;mgawinecki@...&gt;\r\nSubject: Re: [archive-crawler] Are there frontiers that can read a list of\n URLs from a file?\r\nX-Yahoo-Group-Post: member; u=278688455; y=Oe7sl55wehEAgw03pf1fw_WJgrjF9cyAjVG-UnaGsfTw-ug\r\nX-Yahoo-Profile: dzieciou\r\n\r\nI&#39;ve posted a question for similar problem/task you&#39;ve made and I&#39;ve got \nsimilar answer:\n\nhttp://tech.groups.yahoo.com/group/archive-crawler/message/5938\n\nYou&#39;re task then is rather scraping, not crawling and simple hand-made \nsolution can be easier for that purpose.\n\nHTH,\nMaciej\n\nBjarne Andersen pisze:\n&gt; \n&gt; \n&gt; All frontiers does this - reading URLs from the so called seed list \n&gt; (default seed.txt). So to limit the crawler to just grab the URLs and \n&gt; nothing else you need to set all default hops-filters to 0.\n&gt; \n&gt;  \n&gt; \n&gt; Maybe it&#39;s even overkill to use a web crawler to do this - since the \n&gt; crawler was build to - yes CRAWL - that is finding new links and \n&gt; following them. Maybe you&#39;re better of with something much simpler like \n&gt; wget or curl\n&gt; \n&gt;  \n&gt; \n&gt; best\n&gt; \n&gt; Bjarne Andersen\n&gt; \n&gt;  \n&gt; \n&gt; *From:* archive-crawler@yahoogroups.com \n&gt; [mailto:archive-crawler@yahoogroups.com] *On Behalf Of *huatsing@...\n&gt; *Sent:* Monday, July 27, 2009 2:29 PM\n&gt; *To:* archive-crawler@yahoogroups.com\n&gt; *Subject:* [archive-crawler] Are there frontiers that can read a list of \n&gt; URLs from a file?\n&gt; \n&gt;  \n&gt; \n&gt;  \n&gt; \n&gt; Hey everyone, I am have a list of URLs which I would like to crawl (just \n&gt; these urls and nothing else). Does heritrix support a frontier like this?\n&gt; \n&gt; \n&gt; \n&gt; \n\n\n"}}