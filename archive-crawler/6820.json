{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":457969421,"authorName":"Allen Sim","from":"Allen Sim &lt;allensim81@...&gt;","profile":"ssgtitanic","replyTo":"LIST","senderId":"tPic6dYCInZOKQGMZ766ViArlEfick1VCa1L1_O1Esp-BHySXRXN4C5PaWqXpunCECMZrOCD3p8bLqS2_dcgBjSB6Gc_mxc","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Auto Stopping Problem","postDate":"1290503339","msgId":6820,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEFBTkxrVGk9RFpaWGNnYUtQZEdNbUNVaDRtUW8zbkUxaDI1MDFiT2lWY2NVQ0BtYWlsLmdtYWlsLmNvbT4=","inReplyToHeader":"PDRDRUFCRjI5LjQwNDA4QGFyY2hpdmUub3JnPg==","referencesHeader":"PGljNTRhZStucDVsQGVHcm91cHMuY29tPgk8NENFQUJGMjkuNDA0MDhAYXJjaGl2ZS5vcmc+"},"prevInTopic":6812,"nextInTopic":6821,"prevInTime":6819,"nextInTime":6821,"topicId":6809,"numMessagesInTopic":10,"msgSnippet":"Dear Gordon, I am so glad to hear from you! Wow, Indeed you are very Sharp and you understood my problem! I tried to type the following in my terminal and i","rawEmail":"Return-Path: &lt;allensim81@...&gt;\r\nX-Sender: allensim81@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 5915 invoked from network); 23 Nov 2010 09:09:01 -0000\r\nX-Received: from unknown (98.137.34.44)\n  by m3.grp.sp2.yahoo.com with QMQP; 23 Nov 2010 09:09:01 -0000\r\nX-Received: from unknown (HELO mail-qw0-f48.google.com) (209.85.216.48)\n  by mta1.grp.sp2.yahoo.com with SMTP; 23 Nov 2010 09:09:01 -0000\r\nX-Received: by qwb7 with SMTP id 7so1130546qwb.21\n        for &lt;archive-crawler@yahoogroups.com&gt;; Tue, 23 Nov 2010 01:09:00 -0800 (PST)\r\nMIME-Version: 1.0\r\nX-Received: by 10.224.80.198 with SMTP id u6mr2409093qak.113.1290503339864; Tue,\n 23 Nov 2010 01:08:59 -0800 (PST)\r\nX-Received: by 10.224.28.198 with HTTP; Tue, 23 Nov 2010 01:08:59 -0800 (PST)\r\nIn-Reply-To: &lt;4CEABF29.40408@...&gt;\r\nReferences: &lt;ic54ae+np5l@...&gt;\n\t&lt;4CEABF29.40408@...&gt;\r\nDate: Tue, 23 Nov 2010 17:08:59 +0800\r\nMessage-ID: &lt;AANLkTi=DZZXcgaKPdGMmCUh4mQo3nE1h2501bOiVccUC@...&gt;\r\nTo: Gordon Mohr &lt;gojomo@...&gt;\r\nCc: archive-crawler@yahoogroups.com\r\nContent-Type: multipart/alternative; boundary=0015175cfb8e2771ef0495b4b98e\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Allen Sim &lt;allensim81@...&gt;\r\nSubject: Re: [archive-crawler] Auto Stopping Problem\r\nX-Yahoo-Group-Post: member; u=457969421; y=EGfBJrhCHkUlNCgm3iwQzWuxEI8jButlokvkbYgBuF707z532A\r\nX-Yahoo-Profile: ssgtitanic\r\n\r\n\r\n--0015175cfb8e2771ef0495b4b98e\r\nContent-Type: text/plain; charset=ISO-8859-1\r\n\r\nDear Gordon,\nI am so glad to hear from you!\nWow, Indeed you are very Sharp and you understood my problem!\nI tried to type the following in my terminal and i got the following:\n[root@localhost ~]# wget http://www.swinburne.edu.my\n--2010-11-23 17:04:43--  http://www.swinburne.edu.my/\nResolving www.swinburne.edu.my... failed: Temporary failure in name\nresolution.\nwget: unable to resolve host address `www.swinburne.edu.my&#39;\nBut the strange thing is that i can browse successfully\nwww.swinburne.edu.myat the machine&#39;s graphical browser.\nWhat&#39;s wrong with it? Is it because of my proxy setting or my DNS setting.\nPlease advice and looking forward to hear from you.\nThanks for your guidance and advice,\nAllen WIlson\n\nOn Tue, Nov 23, 2010 at 3:06 AM, Gordon Mohr &lt;gojomo@...&gt; wrote:\n\n&gt; The fact that the first error is a DNS failure, and that prevents further\n&gt; progress, suggests that the ability of the crawler machine to do DNS lookups\n&gt; -- both from a command-line, and from Java -- is the first thing to look at.\n&gt;\n&gt; On the crawling machine itself, can you visit &lt;\n&gt; http://www.swinburne.edu.my/&gt; (from a command-line browser or tool like\n&gt; &#39;wget&#39;/&#39;curl&#39; if the machine doesn&#39;t have a graphical browser)?\n&gt;\n&gt; There *might* be a little more detail on the DNS error in the\n&gt; &#39;local-errors.log&#39; in the crawl&#39;s logs directory as well.\n&gt;\n&gt; - Gordon @ IA\n&gt;\n&gt;\n&gt; On 11/18/10 10:09 PM, ssgtitanic wrote:\n&gt;\n&gt;&gt; Hi,\n&gt;&gt; Hi,\n&gt;&gt; I successfully downloaded and deployed WCT 1.5 and indeed it&#39;s a wonderful\n&gt;&gt; tool for harvesting!\n&gt;&gt; This morning I tried to harvest few websites. The first two websites that\n&gt;&gt; I harvested were okay. As I proceed to my third website, The Target\n&gt;&gt; Instances itself only run for few seconds (00:00:18) then it automatically\n&gt;&gt; &#39;Stopping&#39; then after few seconds it turned to &#39;harvested&#39; with 0 bytes data\n&gt;&gt; downloaded.I restart my server and Apache-tomcat, the problem still persist.\n&gt;&gt;\n&gt;&gt;  Following is the crwal.log logfile:\n&gt;&gt; 2010-11-18T04:14:11.482Z    -1          - dns:www.swinburne.edu.my P\n&gt;&gt; http://www.swinburne.edu.my/ text/dns #001 20101118041409425+2055 - - 3t\n&gt;&gt; 2010-11-18T04:14:11.786Z    -6          - http://www.swinburne.edu.my/ -\n&gt;&gt; - no-type #002 - - - 2t\n&gt;&gt; Displaying: 100% of 239 B\n&gt;&gt; crawl report.txt:\n&gt;&gt; Crawl Name:\n&gt;&gt; Crawl Status: Finished\n&gt;&gt; Duration Time: 20s617ms\n&gt;&gt; Total Seeds Crawled: 0\n&gt;&gt; Total Seeds not Crawled: 1\n&gt;&gt; Total Hosts Crawled: -1\n&gt;&gt; Total Documents Crawled: 2\n&gt;&gt; Processed docs/sec: 0\n&gt;&gt; Bandwidth in Kbytes/sec: 0\n&gt;&gt; Total Raw Data Size in Bytes: 0 (0 B)\n&gt;&gt; Novel Bytes: 0 (0 B)\n&gt;&gt; Displaying: 100% of 271 B\n&gt;&gt; Frontier report.txt\n&gt;&gt; frontier empty\n&gt;&gt; Displaying: 100% of 15 B\n&gt;&gt;\n&gt;&gt; Can you please guide me. what&#39;s wrong with it? Is it my setting?\n&gt;&gt; As I am refeering to Heritrix status code, I found the following:\n&gt;&gt;  -1 DNS lookup failed\n&gt;&gt;  -6 Prerequisite domain-lookup failed, precluding fetch attempt\n&gt;&gt;\n&gt;&gt; How am I going to fix it? Please help and advice.\n&gt;&gt;\n&gt;&gt; Looking forward to hear from you.\n&gt;&gt;\n&gt;&gt; Thanks in advance,\n&gt;&gt; Allen Wilson\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; ------------------------------------\n&gt;&gt;\n&gt;&gt; Yahoo! Groups Links\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n\r\n--0015175cfb8e2771ef0495b4b98e\r\nContent-Type: text/html; charset=ISO-8859-1\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\nDear Gordon,&lt;br&gt;I am so glad to hear from you!&lt;br&gt;Wow, Indeed you are very =\r\nSharp and you understood my problem! &lt;br&gt;I tried to type the following in m=\r\ny terminal and i got the following:&lt;br&gt;[root@localhost ~]# wget &lt;a href=3D&quot;=\r\nhttp://www.swinburne.edu.my&quot;&gt;http://www.swinburne.edu.my&lt;/a&gt;&lt;br&gt;\n--2010-11-=\r\n23 17:04:43--=A0 &lt;a href=3D&quot;http://www.swinburne.edu.my/&quot;&gt;http://www.swinbu=\r\nrne.edu.my/&lt;/a&gt;&lt;br&gt;Resolving www.swinburne.edu.my... failed: Temporary fail=\r\nure in name resolution.&lt;br&gt;wget: unable to resolve host address `&lt;a href=3D=\r\n&quot;http://www.swinburne.edu.my&quot;&gt;www.swinburne.edu.my&lt;/a&gt;&#39;&lt;br&gt;\nBut the str=\r\nange thing is that i can browse successfully &lt;a href=3D&quot;http://www.swinburn=\r\ne.edu.my&quot;&gt;www.swinburne.edu.my&lt;/a&gt; at the machine&#39;s graphical browser. =\r\n&lt;br&gt;What&#39;s wrong with it? Is it because of my proxy setting or my DNS s=\r\netting. &lt;br&gt;\nPlease advice and looking forward to hear from you. &lt;br&gt;Thanks=\r\n for your guidance and advice,&lt;br&gt;Allen WIlson&lt;br&gt;&lt;br&gt;On Tue, Nov 23, 2010 =\r\nat 3:06 AM, Gordon Mohr &lt;span dir=3D&quot;ltr&quot;&gt;&lt;&lt;a href=3D&quot;mailto:gojomo@arch=\r\nive.org&quot;&gt;gojomo@...&lt;/a&gt;&gt;&lt;/span&gt; wrote:&lt;br&gt;\n&lt;div class=3D&quot;gmail_q=\r\nuote&quot;&gt;&lt;blockquote class=3D&quot;gmail_quote&quot; style=3D&quot;margin: 0pt 0pt 0pt 0.8ex;=\r\n border-left: 1px solid rgb(204, 204, 204); padding-left: 1ex;&quot;&gt;The fact th=\r\nat the first error is a DNS failure, and that prevents further progress, su=\r\nggests that the ability of the crawler machine to do DNS lookups -- both fr=\r\nom a command-line, and from Java -- is the first thing to look at.&lt;br&gt;\n\n&lt;br=\r\n&gt;\nOn the crawling machine itself, can you visit &lt;&lt;a href=3D&quot;http://www.s=\r\nwinburne.edu.my/&quot; target=3D&quot;_blank&quot;&gt;http://www.swinburne.edu.my/&lt;/a&gt;&gt; (f=\r\nrom a command-line browser or tool like &#39;wget&#39;/&#39;curl&#39; if th=\r\ne machine doesn&#39;t have a graphical browser)?&lt;br&gt;\n\n&lt;br&gt;\nThere *might* be=\r\n a little more detail on the DNS error in the &#39;local-errors.log&#39; in=\r\n the crawl&#39;s logs directory as well.&lt;br&gt;\n&lt;br&gt;\n- Gordon @ IA&lt;div&gt;&lt;div&gt;&lt;/=\r\ndiv&gt;&lt;div class=3D&quot;h5&quot;&gt;&lt;br&gt;\n&lt;br&gt;\nOn 11/18/10 10:09 PM, ssgtitanic wrote:&lt;br&gt;=\r\n\n&lt;/div&gt;&lt;/div&gt;&lt;blockquote class=3D&quot;gmail_quote&quot; style=3D&quot;margin: 0pt 0pt 0pt=\r\n 0.8ex; border-left: 1px solid rgb(204, 204, 204); padding-left: 1ex;&quot;&gt;&lt;div=\r\n&gt;&lt;div&gt;&lt;/div&gt;&lt;div class=3D&quot;h5&quot;&gt;\nHi,&lt;br&gt;\nHi,&lt;br&gt;\nI successfully downloaded an=\r\nd deployed WCT 1.5 and indeed it&#39;s a wonderful tool for harvesting!&lt;br&gt;=\r\n\nThis morning I tried to harvest few websites. The first two websites that =\r\nI harvested were okay. As I proceed to my third website, The Target Instanc=\r\nes itself only run for few seconds (00:00:18) then it automatically &#39;St=\r\nopping&#39; then after few seconds it turned to &#39;harvested&#39; with 0 =\r\nbytes data downloaded.I restart my server and Apache-tomcat, the problem st=\r\nill persist.&lt;br&gt;\n\n&lt;br&gt;\n =A0Following is the crwal.log logfile:&lt;br&gt;\n2010-11-=\r\n18T04:14:11.482Z =A0 =A0-1 =A0 =A0 =A0 =A0 =A0- dns:&lt;a href=3D&quot;http://www.s=\r\nwinburne.edu.my&quot; target=3D&quot;_blank&quot;&gt;www.swinburne.edu.my&lt;/a&gt; P &lt;a href=3D&quot;ht=\r\ntp://www.swinburne.edu.my/&quot; target=3D&quot;_blank&quot;&gt;http://www.swinburne.edu.my/&lt;=\r\n/a&gt; text/dns #001 20101118041409425+2055 - - 3t&lt;br&gt;\n\n2010-11-18T04:14:11.78=\r\n6Z =A0 =A0-6 =A0 =A0 =A0 =A0 =A0- &lt;a href=3D&quot;http://www.swinburne.edu.my/&quot; =\r\ntarget=3D&quot;_blank&quot;&gt;http://www.swinburne.edu.my/&lt;/a&gt; - - no-type #002 - - - 2=\r\nt&lt;br&gt;\nDisplaying: 100% of 239 B&lt;br&gt;\ncrawl report.txt:&lt;br&gt;\nCrawl Name:&lt;br&gt;\nC=\r\nrawl Status: Finished&lt;br&gt;\nDuration Time: 20s617ms&lt;br&gt;\nTotal Seeds Crawled: =\r\n0&lt;br&gt;\nTotal Seeds not Crawled: 1&lt;br&gt;\nTotal Hosts Crawled: -1&lt;br&gt;\nTotal Docu=\r\nments Crawled: 2&lt;br&gt;\nProcessed docs/sec: 0&lt;br&gt;\nBandwidth in Kbytes/sec: 0&lt;b=\r\nr&gt;\nTotal Raw Data Size in Bytes: 0 (0 B)&lt;br&gt;\nNovel Bytes: 0 (0 B)&lt;br&gt;\nDispl=\r\naying: 100% of 271 B&lt;br&gt;\nFrontier report.txt&lt;br&gt;\nfrontier empty&lt;br&gt;\nDisplay=\r\ning: 100% of 15 B&lt;br&gt;\n&lt;br&gt;\nCan you please guide me. what&#39;s wrong with i=\r\nt? Is it my setting?&lt;br&gt;\nAs I am refeering to Heritrix status code, I found=\r\n the following:&lt;br&gt;\n =A0-1 DNS lookup failed&lt;br&gt;\n =A0-6 Prerequisite domain=\r\n-lookup failed, precluding fetch attempt&lt;br&gt;\n&lt;br&gt;\nHow am I going to fix it?=\r\n Please help and advice.&lt;br&gt;\n&lt;br&gt;\nLooking forward to hear from you.&lt;br&gt;\n&lt;br=\r\n&gt;\nThanks in advance,&lt;br&gt;\nAllen Wilson&lt;br&gt;\n&lt;br&gt;\n&lt;br&gt;\n&lt;br&gt;&lt;/div&gt;&lt;/div&gt;\n------=\r\n------------------------------&lt;br&gt;\n&lt;br&gt;\nYahoo! Groups Links&lt;br&gt;\n&lt;br&gt;\n&lt;*&=\r\ngt; =A0To visit your group on the web, go to:&lt;br&gt;\n =A0 =A0 &lt;a href=3D&quot;http:=\r\n//groups.yahoo.com/group/archive-crawler/&quot; target=3D&quot;_blank&quot;&gt;http://groups.=\r\nyahoo.com/group/archive-crawler/&lt;/a&gt;&lt;br&gt;\n&lt;br&gt;\n&lt;*&gt; =A0Your email setti=\r\nngs:&lt;br&gt;\n =A0 =A0 Individual Email | Traditional&lt;br&gt;\n&lt;br&gt;\n&lt;*&gt; =A0To c=\r\nhange settings online go to:&lt;br&gt;\n =A0 =A0 &lt;a href=3D&quot;http://groups.yahoo.co=\r\nm/group/archive-crawler/join&quot; target=3D&quot;_blank&quot;&gt;http://groups.yahoo.com/gro=\r\nup/archive-crawler/join&lt;/a&gt;&lt;br&gt;\n =A0 =A0 (Yahoo! ID required)&lt;br&gt;\n&lt;br&gt;\n&lt;=\r\n*&gt; =A0To change settings via email:&lt;br&gt;\n =A0 =A0 &lt;a href=3D&quot;mailto:archi=\r\nve-crawler-digest@yahoogroups.com&quot; target=3D&quot;_blank&quot;&gt;archive-crawler-digest=\r\n@yahoogroups.com&lt;/a&gt;&lt;br&gt;\n =A0 =A0 &lt;a href=3D&quot;mailto:archive-crawler-fullfea=\r\ntured@yahoogroups.com&quot; target=3D&quot;_blank&quot;&gt;archive-crawler-fullfeatured@yahoo=\r\ngroups.com&lt;/a&gt;&lt;br&gt;\n&lt;br&gt;\n&lt;*&gt; =A0To unsubscribe from this group, send a=\r\nn email to:&lt;br&gt;\n =A0 =A0 &lt;a href=3D&quot;mailto:archive-crawler-unsubscribe@yaho=\r\nogroups.com&quot; target=3D&quot;_blank&quot;&gt;archive-crawler-unsubscribe@yahoogroups.com&lt;=\r\n/a&gt;&lt;br&gt;\n&lt;br&gt;\n&lt;*&gt; =A0Your use of Yahoo! Groups is subject to:&lt;br&gt;\n =A0=\r\n =A0 &lt;a href=3D&quot;http://docs.yahoo.com/info/terms/&quot; target=3D&quot;_blank&quot;&gt;http:/=\r\n/docs.yahoo.com/info/terms/&lt;/a&gt;&lt;br&gt;\n&lt;br&gt;\n&lt;/blockquote&gt;\n&lt;/blockquote&gt;&lt;/div&gt;&lt;=\r\nbr&gt;\n\r\n--0015175cfb8e2771ef0495b4b98e--\r\n\n"}}