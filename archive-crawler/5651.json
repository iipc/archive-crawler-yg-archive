{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"oe1rbdwYpmR_dmV6s0AWt2QEmffaORRhRdx_aNPBrn_FAu6Oyn3jXp3ZDclKuD3Q_QOeHpRBK7m24Ya3q83xaT6MrGTHam8","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Re: Help with crawling sites without robots.txt and return the following responses","postDate":"1232832295","msgId":5651,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ5N0I4NzI3LjMwMzAzMDdAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGdsN3RnaitvOGRqQGVHcm91cHMuY29tPg==","referencesHeader":"PGdsN3RnaitvOGRqQGVHcm91cHMuY29tPg=="},"prevInTopic":5641,"nextInTopic":8738,"prevInTime":5650,"nextInTime":5652,"topicId":5636,"numMessagesInTopic":4,"msgSnippet":"There s currently no way to tell Heritrix not to request a robots.txt, and changing that would probably require custom coding. We are unlikely to make the","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 39801 invoked from network); 24 Jan 2009 21:24:54 -0000\r\nX-Received: from unknown (66.218.67.94)\n  by m54.grp.scd.yahoo.com with QMQP; 24 Jan 2009 21:24:54 -0000\r\nX-Received: from unknown (HELO relay01.pair.com) (209.68.5.15)\n  by mta15.grp.scd.yahoo.com with SMTP; 24 Jan 2009 21:24:54 -0000\r\nX-Received: (qmail 36319 invoked from network); 24 Jan 2009 21:24:53 -0000\r\nX-Received: from 70.137.152.225 (HELO ?10.0.13.77?) (70.137.152.225)\n  by relay01.pair.com with SMTP; 24 Jan 2009 21:24:53 -0000\r\nX-pair-Authenticated: 70.137.152.225\r\nMessage-ID: &lt;497B8727.3030307@...&gt;\r\nDate: Sat, 24 Jan 2009 13:24:55 -0800\r\nUser-Agent: Thunderbird 2.0.0.19 (Windows/20081209)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;gl7tgj+o8dj@...&gt;\r\nIn-Reply-To: &lt;gl7tgj+o8dj@...&gt;\r\nContent-Type: text/plain; charset=UTF-8; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Re: Help with crawling sites without robots.txt\n and return the following responses\r\nX-Yahoo-Group-Post: member; u=137285340; y=lSrXRxGEk27siWL4Odn3FcAMwm8gi_Zm0HUxsZuUYsQ4\r\nX-Yahoo-Profile: gojomo\r\n\r\nThere&#39;s currently no way to tell Heritrix not to request a robots.txt,\nand changing that would probably require custom coding. We are unlikely\nto make the fetching of robots.txt optional.\n\nStill, if you are legitimately ignoring the contents of robots.txt \nbecause you have permission to do so, and the configured number of \ndelayed retries fails to get the robots.txt document, the crawler should \ncontinue to get other URIs on the same site. (See HER-601.)\n\nIf this is not the case in your tests please provide more details: \nversion of Heritrix, a summary of your crawl configuration, what appears \nin the crawl.log and frontier report about the target site (to confirm \nthat URIs are waiting and haven&#39;t errored for other reasons), etc.\n\n- Gordon @ IA\n\nmjjjhjemj wrote:\n&gt; --- In archive-crawler@yahoogroups.com, &quot;mjjjhjemj&quot; &lt;bosoxchamps@...&gt;\n&gt; wrote:\n&gt;&gt; I would like to configure Heritrix to not even look for a robots.txt.\n&gt;&gt; I have permission for the sites I am crawling to ignore the robots.txt\n&gt;&gt; which I have done, but the problem is even when the configuration is\n&gt;&gt; setup to ignore the robots.txt Heritrix still wants to download first\n&gt;&gt; and then apparently ignore if configured to do so. I have also tried\n&gt;&gt; the &#39;custom&#39; robots.txt configuration with no success. If the\n&gt;&gt; robots.txt is not present and the response falls under examples 2 or 3\n&gt;&gt; then your are stuck.\n&gt;&gt;\n&gt;&gt; Continues to Crawl site example\n&gt;&gt; -------------------------------\n&gt;&gt; 1. http://www.mysite1.com/robots.txt\n&gt;&gt; response: 404 Not Found\n&gt;&gt; Not Found\n&gt;&gt; The requested URL /robots.txt was not found on this server.\n&gt;&gt; * Heritrix continues to crawl www.mysite1.com\n&gt;&gt;\n&gt;&gt; Fails to continue to crawl examples\n&gt;&gt; -----------------------------------\n&gt;&gt; 2. http://www.mysite2.com/robots.txt\n&gt;&gt; response: 301 - moved permanently\n&gt;&gt; and then the server issues a 301 and serves back\n&gt;&gt; &#39;http://www.mysite2.com/ShortUrlErrorPage.jsp&#39;\n&gt;&gt; Invalid Short URL pattern Please redefine your Short URL pattern!\n&gt;&gt;\n&gt;&gt; 3. http://www.mysite3/robots.txt\n&gt;&gt; response: Connection Interrupted\n&gt;&gt; The connection to the server was reset while the page was loading.\n&gt;&gt; The network link was interrupted while negotiating a connection.\n&gt;&gt; Please try again.\n&gt;&gt;\n&gt; \n&gt; Could someone please help me on this?\n&gt; \n&gt; Thanks,\n&gt; Mike\n&gt; \n&gt; \n&gt; ------------------------------------\n&gt; \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n\n"}}