{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":157788590,"authorName":"Niti Witthayawiroj","from":"Niti Witthayawiroj &lt;niti_wit@...&gt;","profile":"niti_wit","replyTo":"LIST","senderId":"ZdjmT-HUqHsVxISYxCi5gW95MxHhjWWkrBOP8P07OCCUvA22pXBG7LYDm3IW68W0deaeP7bcg1uz0F5WrpFcqsMduqZiUny7Tygf7O6w","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Links Structure","postDate":"1105459370","msgId":1350,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDIwMDUwMTExMTYwMjUwLjcxMjMucW1haWxAd2ViNjA1MDEubWFpbC55YWhvby5jb20+","inReplyToHeader":"PDQxREYzNTQzLjMwMjA0MDFAYXJjaGl2ZS5vcmc+"},"prevInTopic":1335,"nextInTopic":0,"prevInTime":1349,"nextInTime":1351,"topicId":1319,"numMessagesInTopic":9,"msgSnippet":"Hi Igor, yes it right. Regards, Niti ... org.archive.crawler.datamodel.CoreAttributeConstants; ... Logger.getLogger(LinkStructureProcessor.class.getName()); ","rawEmail":"Return-Path: &lt;niti_wit@...&gt;\r\nX-Sender: niti_wit@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 51629 invoked from network); 11 Jan 2005 16:02:51 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m14.grp.scd.yahoo.com with QMQP; 11 Jan 2005 16:02:51 -0000\r\nReceived: from unknown (HELO web60501.mail.yahoo.com) (216.109.116.122)\n  by mta4.grp.scd.yahoo.com with SMTP; 11 Jan 2005 16:02:51 -0000\r\nReceived: (qmail 7126 invoked by uid 60001); 11 Jan 2005 16:02:50 -0000\r\nComment: DomainKeys? See http://antispam.yahoo.com/domainkeys\r\nDomainKey-Signature: a=rsa-sha1; q=dns; c=nofws;\n  s=s1024; d=yahoo.com;\n  b=GoP1ISvU5nohyjUYLcaDJi0UGNVtQtPWFMu9C+sn5xuEz9Wdwvnpnvw+d4i4eFh5Fkt9kthBwN/xB8VUbtUD5/Owol4Yw5pRf8AZ0zjIWrfYvSV11QQk7qdpMWnuta3K4v62BGJLcO6euam9nVmDVrSmLjM/AlYftxvPoMop3fg=  ;\r\nMessage-ID: &lt;20050111160250.7123.qmail@...&gt;\r\nReceived: from [130.75.87.125] by web60501.mail.yahoo.com via HTTP; Tue, 11 Jan 2005 08:02:50 PST\r\nDate: Tue, 11 Jan 2005 08:02:50 -0800 (PST)\r\nTo: archive-crawler@yahoogroups.com\r\nIn-Reply-To: &lt;41DF3543.3020401@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=us-ascii\r\nX-eGroups-Remote-IP: 216.109.116.122\r\nFrom: Niti Witthayawiroj &lt;niti_wit@...&gt;\r\nSubject: Re: [archive-crawler] Links Structure\r\nX-Yahoo-Group-Post: member; u=157788590\r\nX-Yahoo-Profile: niti_wit\r\n\r\nHi Igor,\n\nyes it right.\n\nRegards,\nNiti\n\n--- Igor Ranitovic &lt;igor@...&gt; wrote:\n\n&gt; Hi Niti,\n&gt; \n&gt; This is cool.\n&gt; If I am not wrong you needed different link\n&gt; information then just from-to URLs, one hope away,\n&gt; right?\n&gt; \n&gt; i.\n&gt; \n&gt; \n&gt; &gt; Hi,\n&gt; &gt;  \n&gt; &gt; Thank so much for your suggestion. Now i can get\n&gt; the informations of \n&gt; &gt; link structure from Heritrix. My\n&gt; supervisor(Chistian) help me to write a \n&gt; &gt; new java class and add it to the\n&gt; org.archive.crawler.writer package. It \n&gt; &gt; will write information of link pages to\n&gt; heritrix_out.log file.\n&gt; &gt;  \n&gt; &gt; The code of the new class:\n&gt; &gt;  \n&gt; &gt; package org.archive.crawler.writer;\n&gt; &gt; import java.io.*;\n&gt; &gt; import java.util.*;\n&gt; &gt; import org.archive.crawler.datamodel.*;\n&gt; &gt; import org.archive.crawler.framework.Processor;\n&gt; &gt; import java.util.logging.Logger;\n&gt; &gt; import\n&gt;\norg.archive.crawler.datamodel.CoreAttributeConstants;\n&gt; &gt; import\n&gt; javax.management.AttributeNotFoundException;\n&gt; &gt; import javax.management.MBeanException;\n&gt; &gt; import javax.management.ReflectionException;\n&gt; &gt; import org.archive.crawler.settings.Type;\n&gt; &gt; import org.archive.crawler.settings.SimpleType;\n&gt; &gt; import org.apache.commons.httpclient.URIException;\n&gt; &gt; public class LinkStructureProcessor extends\n&gt; Processor\n&gt; &gt; {\n&gt; &gt;     /**\n&gt; &gt;      * Key to use asking settings for arc path\n&gt; value.\n&gt; &gt;      */\n&gt; &gt;     public static final String ATTR_PATH =&quot;path&quot;;\n&gt; &gt;     /**\n&gt; &gt;      * Logger.\n&gt; &gt;      */\n&gt; &gt;     private static final Logger logger =\n&gt; &gt;        \n&gt;\nLogger.getLogger(LinkStructureProcessor.class.getName());\n&gt; &gt;     /**\n&gt; &gt;      * Where to drop link files.\n&gt; &gt;      */\n&gt; &gt;     private File outputDir;\n&gt; &gt;  private PrintWriter writer = null;\n&gt; &gt;  public LinkStructureProcessor(String name) {\n&gt; &gt;         super(name, &quot;LinkStructure processor&quot;);\n&gt; &gt;         Type e = addElementToDefinition(\n&gt; &gt;             new SimpleType(ATTR_PATH, &quot;Where to\n&gt; store link files&quot;, \n&gt; &gt; &quot;links&quot;));\n&gt; &gt;         e.setOverrideable(false);\n&gt; &gt;     }\n&gt; &gt;  protected void readConfiguration()\n&gt; &gt;         throws AttributeNotFoundException,\n&gt; MBeanException, \n&gt; &gt; ReflectionException {\n&gt; &gt;         // set up output directory\n&gt; &gt;         setOutputDir((String)\n&gt; getAttribute(ATTR_PATH));\n&gt; &gt;     }\n&gt; &gt;     public synchronized void initialTasks() {\n&gt; &gt;         // ReadConfiguration populates settings\n&gt; used creating ARCWriter.\n&gt; &gt;         try {\n&gt; &gt;             readConfiguration();\n&gt; &gt;         } catch (MBeanException e) {\n&gt; &gt;            \n&gt; logger.warning(e.getLocalizedMessage());\n&gt; &gt;         } catch (ReflectionException e) {\n&gt; &gt;            \n&gt; logger.warning(e.getLocalizedMessage());\n&gt; &gt;         } catch (AttributeNotFoundException e) {\n&gt; &gt;            \n&gt; logger.warning(e.getLocalizedMessage());\n&gt; &gt;         }\n&gt; &gt;     }\n&gt; &gt;  public File getOutputDir() {\n&gt; &gt;         return this.outputDir;\n&gt; &gt;     }\n&gt; &gt;     public void setOutputDir(String buffer) {\n&gt; &gt;         this.outputDir = new File(buffer);\n&gt; &gt;         if (!this.outputDir.isAbsolute()) {\n&gt; &gt;             // OutputDir should be relative to\n&gt; &quot;disk&quot;\n&gt; &gt;             this.outputDir = new\n&gt; File(getController().getDisk(), buffer);\n&gt; &gt;         }\n&gt; &gt;         if (!this.outputDir.exists()) {\n&gt; &gt;             try {\n&gt; &gt;                 this.outputDir.mkdirs();\n&gt; &gt;             } catch (Exception e) {\n&gt; &gt;                 e.printStackTrace();\n&gt; &gt;             }\n&gt; &gt;         }\n&gt; &gt;     }\n&gt; &gt;    /**\n&gt; &gt;      * Takes a CrawlURI and writes its\n&gt; accompaining link structure to disk\n&gt; &gt;      *\n&gt; &gt;      * @param curi CrawlURI to process.\n&gt; &gt;      */\n&gt; &gt;     protected void innerProcess(CrawlURI curi) {\n&gt; &gt;         // If failure, or we haven&#39;t fetched the\n&gt; resource yet, return\n&gt; &gt;         if (curi.getFetchStatus() &lt;= 0) {\n&gt; &gt;             return;\n&gt; &gt;         }\n&gt; &gt;         Set links = (Set)curi.getAList().\n&gt; &gt;            \n&gt; getObject(CoreAttributeConstants.A_HTML_LINKS);\n&gt; &gt;   if(links != null) {\n&gt; &gt;    if(outputDir == null) {\n&gt; &gt;     setOutputDir(&quot;links&quot;);\n&gt; &gt;    }\n&gt; &gt;    if(writer == null) {\n&gt; &gt;     try\n&gt; &gt;     {\n&gt; &gt;      writer = new PrintWriter(new FileWriter(new\n&gt; File(outputDir, \n&gt; &gt; getName())), true);\n&gt; &gt;     }\n&gt; &gt;     catch (IOException e)\n&gt; &gt;     {\n&gt; &gt;      e.printStackTrace();\n&gt; &gt;     }\n&gt; &gt;    }\n&gt; &gt;    StringWriter sw = new StringWriter();\n&gt; &gt;    PrintWriter writer = new PrintWriter(sw);\n&gt; &gt;    writer.print(&quot;from &quot;);\n&gt; &gt;    writer.println(curi.getURIString());\n&gt; &gt;    UURI uu = curi.getUURI();\n&gt; &gt;    for (Iterator i = links.iterator();\n&gt; i.hasNext();) {\n&gt; &gt;     String link = (String)i.next();\n&gt; &gt;     writer.print(&quot; to &quot;);\n&gt; &gt;     try\n&gt; &gt;     {\n&gt; &gt;      UURI uuto = uu.resolve(link);\n&gt; &gt;      writer.println(uuto);\n&gt; &gt;     }\n&gt; &gt;     catch (URIException e)\n&gt; &gt;     {\n&gt; &gt;      writer.println(link);\n&gt; &gt;     }\n&gt; &gt;    }\n&gt; &gt;    System.out.println(sw.getBuffer());\n&gt; &gt;   }\n&gt; &gt;     }\n&gt; &gt;  public void crawlEnding(String sExitMessage) {\n&gt; &gt;   // sExitMessage is unused.\n&gt; &gt;   if(writer != null) {\n&gt; &gt;    this.writer.close();\n&gt; &gt;   }\n&gt; &gt;  }\n&gt; &gt; }\n&gt; &gt;  \n&gt; &gt; we added this class to the\n&gt; conf/modules/processors.options and add it to \n&gt; &gt; the writers processors module when create a new\n&gt; crawl job.\n&gt; &gt;  \n&gt; &gt; Regards,\n&gt; &gt; Niti\n&gt; &gt; \n&gt; &gt; */Igor Ranitovic &lt;igor@...&gt;/* wrote:\n&gt; &gt; \n&gt; &gt;     Hi Niti,\n&gt; &gt; \n&gt; &gt;     Yes, the commandline will output links only\n&gt; one hop away.\n&gt; &gt;     Heritrix does not use PageRank therefore we\n&gt; don&#39;t have that info as\n&gt; &gt;     part of Heritrix reports.\n&gt; &gt;     However, crawl.log has information that you\n&gt; need but it will require\n&gt; &gt;     some work. Take a look at\n&gt; &gt;     hoppath.pl -- that might give you some ideas\n&gt; on how to approach this\n&gt; &gt;     problem.\n&gt; &gt; \n&gt; &gt;     For example:\n&gt; &gt;     $HERITRIX_HOME/bin/hoppath.pl crawl.log\n&gt; &gt;     http://www.nyrock.com/images/jr_thumb.gif\n&gt; &gt; \n&gt; &gt;     2004-11-30-23-31-36 -\n&gt; http://www.nyrock.com/movies/200cigs.htm\n&gt; &gt;     2004-11-30-23-31-34  P\n&gt; http://www.nyrock.com/robots.txt\n&gt; \n=== message truncated ===\n\n\n__________________________________________________\nDo You Yahoo!?\nTired of spam?  Yahoo! Mail has the best spam protection around \nhttp://mail.yahoo.com \n\n"}}