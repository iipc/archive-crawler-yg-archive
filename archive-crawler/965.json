{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137477665,"authorName":"Igor Ranitovic","from":"Igor Ranitovic &lt;igor@...&gt;","profile":"iranitovic","replyTo":"LIST","senderId":"mhZYwbvFOjWB09YhtIApyF-mTawwXgA3ZxlPQUioiCP1SrwV7uw8Hnf-y0T7J4NBfaPEVe504WQbjSS62ry6BCFdx0X-i6_E","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Re: I don&#39;t need download jpg/gif","postDate":"1094577736","msgId":965,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQxM0RFRTQ4LjQwNDA3MDlAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDE2NzAxLjM3ODIzLjIzMjcxLjY0Mjc0OEB0aXBoYXJlcy5iYXNpc3RlY2gubmV0Pg==","referencesHeader":"PDE2Njk2LjIxNzg1LjEyNjA2Mi42Mjg5MzRAdGlwaGFyZXMuYmFzaXN0ZWNoLm5ldD4JPGNoanVjZithMDBiQGVHcm91cHMuY29tPiA8MTY3MDEuMzc4MjMuMjMyNzEuNjQyNzQ4QHRpcGhhcmVzLmJhc2lzdGVjaC5uZXQ+"},"prevInTopic":964,"nextInTopic":966,"prevInTime":964,"nextInTime":966,"topicId":909,"numMessagesInTopic":8,"msgSnippet":"You are blocking (filtering out) robots.txt file. In order to fetch any URL, two prerequisite must be in place; dns lookup and robots.txt has to be fetched.","rawEmail":"Return-Path: &lt;igor@...&gt;\r\nX-Sender: igor@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 24963 invoked from network); 7 Sep 2004 17:25:36 -0000\r\nReceived: from unknown (66.218.66.218)\n  by m18.grp.scd.yahoo.com with QMQP; 7 Sep 2004 17:25:36 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (209.237.232.202)\n  by mta3.grp.scd.yahoo.com with SMTP; 7 Sep 2004 17:25:36 -0000\r\nReceived: (qmail 10072 invoked by uid 100); 7 Sep 2004 17:15:40 -0000\r\nReceived: from pauk.archive.org (HELO ?207.241.238.153?) (igor@...@207.241.238.153)\n  by mail-dev.archive.org with SMTP; 7 Sep 2004 17:15:40 -0000\r\nMessage-ID: &lt;413DEE48.4040709@...&gt;\r\nDate: Tue, 07 Sep 2004 10:22:16 -0700\r\nUser-Agent: Mozilla Thunderbird 0.7.3 (Windows/20040803)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;16696.21785.126062.628934@...&gt;\t&lt;chjucf+a00b@...&gt; &lt;16701.37823.23271.642748@...&gt;\r\nIn-Reply-To: &lt;16701.37823.23271.642748@...&gt;\r\nContent-Type: text/plain; charset=us-ascii; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=0.0 required=7.0 tests=AWL autolearn=ham version=2.63\r\nX-eGroups-Remote-IP: 209.237.232.202\r\nFrom: Igor Ranitovic &lt;igor@...&gt;\r\nSubject: Re: [archive-crawler] Re: I don&#39;t need download jpg/gif\r\nX-Yahoo-Group-Post: member; u=137477665\r\nX-Yahoo-Profile: iranitovic\r\n\r\nYou are blocking (filtering out) robots.txt file. In order to fetch any URL, two prerequisite must \nbe in place; dns lookup and robots.txt has to be fetched. Since you are filtering out robots.txt you \nare getting -2 (prerequisites failed) error code. More on error codes see: \nhttp://crawler.archive.org/cgi-bin/wiki.pl?FetchStatusCodes\nSo, remove |txt| and you should be OK.\n\nTake care,\ni.\n\nTom Emerson wrote:\n\n&gt; crawlerobo writes:\n&gt; \n&gt;&gt;It is a default setup except add of a URIRegExp filter.\n&gt;&gt;Seed.txt only add (http://mobile.yahoo.co.jp)\n&gt;&gt;\n&gt;&gt;20040907085003065     1   56 dns:mobile.yahoo.co.jp P \n&gt;&gt;http://mobile.yahoo.co.jp/ text/dns #001 501 - -\n&gt;&gt;\n&gt;&gt;20040907085005588    -6   - http://mobile.yahoo.co.jp/ - - no-type\n&gt;&gt;#001 - - 2t\n&gt;&gt;\n&gt;&gt;If a URIRegExp filter is not used, it operates normally.\n&gt; \n&gt; \n&gt; I&#39;ve had the exact same problem with that regexp when initiating a\n&gt; crawl with it. I haven&#39;t had a chance to isolate the problem.\n&gt; \n&gt; When I came up with the regexp I was adding it to an already running\n&gt; crawl.\n&gt; \n&gt;     -tree\n&gt; \n\n\n"}}