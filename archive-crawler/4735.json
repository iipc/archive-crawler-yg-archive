{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":329911563,"authorName":"ivan.vlcek","from":"&quot;ivan.vlcek&quot; &lt;ivan.vlcek@...&gt;","profile":"ivan.vlcek","replyTo":"LIST","senderId":"TUG-JPJONxyC9qlCOfcPSFZ0T08Bxdbh0hRzBwlVQe4I5GHF9CS5OcR3c60yDX_nK1bSrVMO98VkzD1L9SJuAYO_0nW9-aCDa2d60g","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: How to crawl 50 urls for a seed","postDate":"1195673602","msgId":4735,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZpMjE2Mis1bnA3QGVHcm91cHMuY29tPg==","inReplyToHeader":"PGFmNDQzYTk3MDcxMTIxMDgzNWgyZjIzODRhYXFmNmU0NGM0MGJkZmRhYzRlQG1haWwuZ21haWwuY29tPg=="},"prevInTopic":4734,"nextInTopic":0,"prevInTime":4734,"nextInTime":4736,"topicId":4733,"numMessagesInTopic":3,"msgSnippet":"... Yes I mean URL s as in complete webpages (text + images etc.) Or 50 ... Thank","rawEmail":"Return-Path: &lt;ivan.vlcek@...&gt;\r\nX-Sender: ivan.vlcek@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 21009 invoked from network); 21 Nov 2007 19:33:23 -0000\r\nX-Received: from unknown (66.218.67.97)\n  by m45.grp.scd.yahoo.com with QMQP; 21 Nov 2007 19:33:23 -0000\r\nX-Received: from unknown (HELO n19a.bullet.scd.yahoo.com) (66.94.237.48)\n  by mta18.grp.scd.yahoo.com with SMTP; 21 Nov 2007 19:33:23 -0000\r\nX-Received: from [66.218.69.4] by n19.bullet.scd.yahoo.com with NNFMP; 21 Nov 2007 19:33:23 -0000\r\nX-Received: from [66.218.66.89] by t4.bullet.scd.yahoo.com with NNFMP; 21 Nov 2007 19:33:23 -0000\r\nDate: Wed, 21 Nov 2007 19:33:22 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;fi2162+5np7@...&gt;\r\nIn-Reply-To: &lt;af443a970711210835h2f2384aaqf6e44c40bdfdac4e@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;ivan.vlcek&quot; &lt;ivan.vlcek@...&gt;\r\nSubject: Re: How to crawl 50 urls for a seed\r\nX-Yahoo-Group-Post: member; u=329911563; y=QDACgA0qp9f1XzNToWJq_5meQ5j-FBawzkZbROgpoRdJL1RKQQ\r\nX-Yahoo-Profile: ivan.vlcek\r\n\r\n--- In archive-crawler@yahoogroups.com, &quot;Bart Kiers&quot; &lt;bkiers@...&gt; \nwrote:\n&gt;=\r\n\n&gt; Do you mean URL&#39;s as in complete webpages (text + images etc.)? \n\nYes I =\r\nmean URL&#39;s as in complete webpages (text + images etc.)\n\n\nOr 50\n&gt; documents=\r\n in total?\n&gt; The latter can be done by setting *max-document-download.*\n&gt; S=\r\nee *6.3.1.1. Crawl limits *of:\n&gt; http://crawler.archive.org/articles/user_m=\r\nanual/config.html\n&gt; \n&gt; Regards,\n&gt; \n&gt; Bart Kiers.\n&gt; \n&gt; \n&gt; \n&gt; On Nov 21, 2007=\r\n 2:57 PM, ivan.vlcek &lt;ivan.vlcek@...&gt; wrote:\n&gt; \n&gt; &gt;   Hello is there any ch=\r\nance how to crawl 50 URLs for each seed. \nThank\n&gt; &gt; you\n&gt; &gt;\n&gt; &gt;  \n&gt; &gt;\n&gt;\n\n\n\n"}}