{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"bEvvit-TVRnGmOKtUMPx7PISK-VtpCvOONJ9xsq-hpgY7Kas2wJ2D2Dll6zxhlj7Nvq8XS8m179o06vaGGfJeEM3HsFwyRI","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Re: Debugging/Stepping through a Crawl process","postDate":"1230620495","msgId":5619,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ5NTlDNzRGLjgwOTA1MDZAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGdqN2R1citsYmIzQGVHcm91cHMuY29tPg==","referencesHeader":"PGdqN2R1citsYmIzQGVHcm91cHMuY29tPg=="},"prevInTopic":5617,"nextInTopic":0,"prevInTime":5618,"nextInTime":5620,"topicId":5615,"numMessagesInTopic":4,"msgSnippet":"... The plan is for continuous and adaptive crawling to be implemented by the 2.4 release, in early 2009. That means within operator-set limits and","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 51990 invoked from network); 30 Dec 2008 07:01:33 -0000\r\nX-Received: from unknown (66.218.67.96)\n  by m42.grp.scd.yahoo.com with QMQP; 30 Dec 2008 07:01:33 -0000\r\nX-Received: from unknown (HELO relay03.pair.com) (209.68.5.17)\n  by mta17.grp.scd.yahoo.com with SMTP; 30 Dec 2008 07:01:33 -0000\r\nX-Received: (qmail 48348 invoked from network); 30 Dec 2008 07:01:31 -0000\r\nX-Received: from 70.137.129.105 (HELO ?10.0.13.77?) (70.137.129.105)\n  by relay03.pair.com with SMTP; 30 Dec 2008 07:01:31 -0000\r\nX-pair-Authenticated: 70.137.129.105\r\nMessage-ID: &lt;4959C74F.8090506@...&gt;\r\nDate: Mon, 29 Dec 2008 23:01:35 -0800\r\nUser-Agent: Thunderbird 2.0.0.18 (Windows/20081105)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;gj7dur+lbb3@...&gt;\r\nIn-Reply-To: &lt;gj7dur+lbb3@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Re: Debugging/Stepping through a Crawl process\r\nX-Yahoo-Group-Post: member; u=137285340; y=L4UP3WnGKjrBEyteAjrS0vpkNilnpmUWZnL4KOIDcp_n\r\nX-Yahoo-Profile: gojomo\r\n\r\nckannanck wrote:\n&gt; Thanks a lot !!! That helps.... I am looking for continuous crawling\n&gt; functionality which I believe is being developed on 2.x ( correct me\n&gt; if I am wrong ) ...I am trying to set up my dev environment in\n&gt; netbeans..I will post the instructions if I am able to figure it out :-)\n\nThe plan is for continuous and adaptive crawling to be implemented by \nthe 2.4 release, in early 2009. That means within operator-set limits \nand preferences, the crawler will set its own schedule for revisiting \nURIs based on their observed history of changes.\n\nHowever, only some steps towards that currently exist in the 2.x \nreleases so far, the 2.x trunk, and a working branch with configuration \nchanges. So there&#39;s not yet any continuous functionality that demands \nthe use of 2.x.\n\n&gt; Few more questions:\n&gt; 1) Is there a way to add new urls/seeds to a crawl job without\n&gt; stopping the crawl ? If yes, when will the seeds get crawled...Any\n&gt; pointers in the documentation or code would be helpful...\n\nI can think of two ways:\n\n(1) If you edit the seed list while the crawl is paused, then trigger a \nrescan of the settings (which may happen when editing the seeds via the \nweb UI, or definitely happens if you tweak any other single-field \nsetting), the seeds will be rescanned. Any that are not-yet-discovered \nwill be queued for crawling. (I&#39;m sure this works in 1.X, and I think it \nworks in 2.x).\n\n(2) Use the JMX operations &#39;importUri&#39; or &#39;importUris&#39; on the &#39;CrawlJob&#39; \nobject. Some info that could help:\n\nManual section on remote monitoring/control (1.x):\nhttp://crawler.archive.org/articles/user_manual/outside.html#mon_com\n\nOld post mentioning importUri operation:\nhttp://tech.groups.yahoo.com/group/archive-crawler/message/4589\n\nPage for the bundled &#39;cmdline-jmxclient&#39; utility:\nhttp://crawler.archive.org/cmdline-jmxclient/\n\n(In 2.0.x importUris moved to being an operation on the Frontier object.)\n\n--\nIn both cases, the URIs will be scheduled as if just discovered -- so \ngenerally it will go at the end of the relevant per-host queue. (Of \ncourse, if it&#39;s an all-new site with no other URIs, it may be first in \nthat queue.) When each queue then comes up for active crawling depends \non other frontier settings.\n\n&gt; 2) Are you talking about the UI changes as mentioned @\n&gt; http://webteam.archive.org/confluence/display/Heritrix/Continuous+Recrawling+Phase+A+Design+Notes\n&gt; or are there more changes\n\nYes. The primary change is to a Spring-based configuration and crawl \nlifecycle system, but this will have ripple effects through the web UI.\n\n- Gordon @ IA\n\n&gt; Thanks\n&gt; Kannan\n&gt; \n&gt; --- In archive-crawler@yahoogroups.com, Gordon Mohr &lt;gojomo@...&gt; wrote:\n&gt;&gt; ckannanck wrote:\n&gt;&gt;&gt; Hi All,\n&gt;&gt;&gt;\n&gt;&gt;&gt; I am a newbie to heritrix..I checked out the latest stable version of\n&gt;&gt;&gt;  Heritrix 2...and I tried to debug the crawl process step by step...\n&gt;&gt; For a beginner, the 1.14.x code could be a better place to start -- the \n&gt;&gt; documentation is better, and there are still significant \n&gt;&gt; UI/configuration changes planned in the 2.x line.\n&gt;&gt;\n&gt;&gt;&gt; My Attempts & and the end results:\n&gt;&gt;&gt; 1)I tried setting up the debugger ( using netbeans ide..can use\n&gt;&gt;&gt; eclipse if necessary) on the WebUI...but this limits me to step\n&gt;&gt;&gt; through only the UI code... I am unable to step through the actual\n&gt;&gt;&gt; crawl process.. \n&gt;&gt;&gt; 2)Tried to debug the main method of the\n&gt;&gt;&gt; org.archive.crawler.Heritrix.java ... the debugger ends its session at\n&gt;&gt;&gt; the end of the main method ( since the main thread starts\n&gt;&gt;&gt; sleeping).subsequent actions on the webui does&#39;nt get followed...\n&gt;&gt;&gt;\n&gt;&gt;&gt; Can somebody  help me with this problem and also wondering what is the\n&gt;&gt;&gt; best way to understand the program flow....(besidees the developer and\n&gt;&gt;&gt; user manuals) \n&gt;&gt; Heritrix developers use step debugging in Eclipse all the time, in \n&gt;&gt; 1.14.x and 2.x, so it&#39;s definitely possible.\n&gt;&gt;\n&gt;&gt; When I launch from Eclipse for debugging, for Heritrix 1.14.x, my \n&gt;&gt; command-line options include as a VM option &quot;-Dheritrix.development&quot;, \n&gt;&gt; setting a system property that prevents Heritrix from redirecting \n&gt;&gt; STDOUT/STDERR to a log file and changes slightly how configuration info \n&gt;&gt; is found.\n&gt;&gt;\n&gt;&gt; When I launch from Eclipse for debugging, for Heritrix 2.x, my \n&gt;&gt; command-line options to the Heritrix class include &quot;-w \n&gt;&gt; webui/src/main/webapp&quot; to point to my IDE_compiled classes for the\n&gt; webui \n&gt;&gt; (rather than the default WAR).\n&gt;&gt;\n&gt;&gt; In either case, because Heritrix uses a pool of worker threads to\n&gt; handle \n&gt;&gt; each URI in turn, and crawls are typically launched/controlled via\n&gt; short \n&gt;&gt; transaction in webui webserver threads or other short-lived \n&gt;&gt; special-purpose threads, attempting to step through activity from the \n&gt;&gt; main() thread will not be helpful. Instead, I would add breakpoints at \n&gt;&gt; other key methods to catch and observe operations of interest.\n&gt;&gt;\n&gt;&gt; To summarize, for your purposes, I would recommend:\n&gt;&gt;\n&gt;&gt; - As a newbie, start with Heritrix 1.14.x -- for now it&#39;s better for \n&gt;&gt; getting started. (Though, you can still use 2.x if you want.)\n&gt;&gt; - Use Eclipse -- I expect NetBeans would work but I&#39;m sure Eclipse\n&gt; will, \n&gt;&gt; and the source from project SVN is already arranged as an Eclipse\n&gt; project\n&gt;&gt; - Set breakpoints rather than trying to step from the main() launch\n&gt;&gt;\n&gt;&gt; Hope this helps,\n&gt;&gt;\n&gt;&gt; - Gordon @ IA\n&gt;&gt;\n&gt; \n&gt; \n&gt; \n&gt; ------------------------------------\n&gt; \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n"}}