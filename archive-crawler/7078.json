{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":478723495,"authorName":"heritrixquestions","from":"&quot;heritrixquestions&quot; &lt;heritrixquestions@...&gt;","profile":"heritrixquestions","replyTo":"LIST","senderId":"ikacmzsXDUyDt0VIdBVVkNIOKGZs2Nxce1DdvK6JvaIis6JdzluftepYPRyyGgGyXg9wbe4hWUm3oEij0QJwVCAQH6ON-WUSrXkRGXtOFnxPSIpBMVQaxg","spamInfo":{"isSpam":false,"reason":"0"},"subject":"keep data of hundreds of seeds separate","postDate":"1301660429","msgId":7078,"canDelete":false,"contentTrasformed":false,"systemMessage":true,"headers":{"messageIdInHeader":"PGluNGZ1ZCtjNGd2QGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":7079,"prevInTime":7077,"nextInTime":7079,"topicId":7078,"numMessagesInTopic":2,"msgSnippet":"Hi, what is the best way to do this: * I want to crawl several hundreds of websites (for text mining purposes, but also the images etc. for display) * I want","rawEmail":"Return-Path: &lt;heritrixquestions@...&gt;\r\nReceived: (qmail 66934 invoked from network); 1 Apr 2011 18:24:37 -0000\r\nReceived: from unknown (98.137.34.45)\n  by m3.grp.sp2.yahoo.com with QMQP; 1 Apr 2011 18:24:37 -0000\r\nReceived: from unknown (HELO n41b.bullet.mail.sp1.yahoo.com) (66.163.168.155)\n  by mta2.grp.sp2.yahoo.com with SMTP; 1 Apr 2011 18:24:37 -0000\r\nDKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoogroups.com; s=lima; t=1301682277; bh=5b1qN1x8CpqHpg+gX5aMlOppC8/3226g3DNuMVvj2gU=; h=Received:Received:X-Sender:X-Apparently-To:X-Received:X-Received:X-Received:X-Received:X-Received:Date:To:Message-ID:User-Agent:MIME-Version:Content-Type:Content-Transfer-Encoding:X-Mailer:X-Yahoo-Newman-Property:X-Originating-IP:X-Yahoo-Post-IP:From:Subject:X-Yahoo-Group-Post:X-Yahoo-Profile:X-YGroups-SubInfo:Sender:X-eGroups-Approved-By:X-eGroups-Auth; b=d2Jq/Wqq6j7lnj7QoXpNOzepes2Gf8yMFlKbu8Y2ldVuK+FtMp6BHnsPBZjT0HENy7GEzyj2KdU1+xY+xdKyM2ZDlaylwVMwEFUhY+CBLqsM/bPWw20lN51WlVCU+FaL\r\nReceived: from [69.147.65.151] by n41.bullet.mail.sp1.yahoo.com with NNFMP; 01 Apr 2011 18:24:37 -0000\r\nReceived: from [98.137.34.32] by t5.bullet.mail.sp1.yahoo.com with NNFMP; 01 Apr 2011 18:24:37 -0000\r\nX-Sender: heritrixquestions@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 54711 invoked from network); 1 Apr 2011 12:20:30 -0000\r\nX-Received: from unknown (66.196.94.105)\n  by m14.grp.re1.yahoo.com with QMQP; 1 Apr 2011 12:20:30 -0000\r\nX-Received: from unknown (HELO n46b.bullet.mail.sp1.yahoo.com) (66.163.168.160)\n  by mta1.grp.re1.yahoo.com with SMTP; 1 Apr 2011 12:20:30 -0000\r\nX-Received: from [69.147.65.174] by n46.bullet.mail.sp1.yahoo.com with NNFMP; 01 Apr 2011 12:20:29 -0000\r\nX-Received: from [98.137.34.34] by t12.bullet.mail.sp1.yahoo.com with NNFMP; 01 Apr 2011 12:20:29 -0000\r\nDate: Fri, 01 Apr 2011 12:20:29 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;in4fud+c4gv@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-system\r\nFrom: &quot;heritrixquestions&quot; &lt;heritrixquestions@...&gt;\r\nSubject: keep data of hundreds of seeds separate\r\nX-Yahoo-Group-Post: member; u=478723495; y=o897n6qscC7GzIZjSu4nNwolELWTalZhnOQlvttqKr3OwGv70jp0mwy_uG4\r\nX-Yahoo-Profile: heritrixquestions\r\nX-eGroups-Approved-By: gojomo &lt;gojomo@...&gt; via web; 01 Apr 2011 18:24:35 -0000\r\n\r\nHi,\n\nwhat is the best way to do this:\n\n* I want to crawl several hundreds o=\r\nf websites (for text mining purposes, but also the images etc. for display)=\r\n\n* I want to keep the crawled data separate per site\n* I want it to be fast=\r\n (obviously)\n\nI&#39;m new to heritrix. I started using 1.14.4. and used most of=\r\n the defaults, except for restricting it to stay on the sites that are the =\r\nseeds.\n\nThis works fine already, but with the default ARC output, all pages=\r\n, images, etc. from all the seeds of one job are mixed together in the ARC =\r\nfiles.\n\nIf I use only one seed per job, I get the files the way I want them=\r\n, but it is much, much slower, because obviously the crawling politeness ca=\r\nuses many pauses when there is only one host.\n\nHow can I improve this?\n\nTha=\r\nnk you,\nM.\n\n\n"}}