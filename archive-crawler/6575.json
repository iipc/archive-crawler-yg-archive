{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":337234122,"authorName":"Fuat","from":"&quot;Fuat&quot; &lt;afsungur@...&gt;","profile":"afsungur","replyTo":"LIST","senderId":"ul8eJ8zu26OxGIkXQnYCG9u8tFQTBmZ0o2Z4COaZNUz7aYX9_TbyuQLhhTyf2eMzNVgAPVWccHsA5XWT1glgwAKe","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Starting Development of Multimachine Crawler","postDate":"1276509793","msgId":6575,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGh2NHVwMStoN2EyQGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":0,"prevInTime":6574,"nextInTime":6576,"topicId":6575,"numMessagesInTopic":1,"msgSnippet":"Hi, I am currently working on Heritrix 1.14.4 on a notebook. I ve downloaded lots of web pages and write their content to database successfully by creating a","rawEmail":"Return-Path: &lt;afsungur@...&gt;\r\nX-Sender: afsungur@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 29850 invoked from network); 14 Jun 2010 10:03:50 -0000\r\nX-Received: from unknown (98.137.34.46)\n  by m10.grp.re1.yahoo.com with QMQP; 14 Jun 2010 10:03:50 -0000\r\nX-Received: from unknown (HELO n5-vm6.bullet.mail.sp2.yahoo.com) (67.195.135.101)\n  by mta3.grp.sp2.yahoo.com with SMTP; 14 Jun 2010 10:03:50 -0000\r\nX-Received: from [67.195.134.239] by n5.bullet.mail.sp2.yahoo.com with NNFMP; 14 Jun 2010 10:03:13 -0000\r\nX-Received: from [69.147.65.172] by t4.bullet.mail.sp2.yahoo.com with NNFMP; 14 Jun 2010 10:03:13 -0000\r\nX-Received: from [98.137.34.72] by t14.bullet.mail.sp1.yahoo.com with NNFMP; 14 Jun 2010 10:03:13 -0000\r\nDate: Mon, 14 Jun 2010 10:03:13 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;hv4up1+h7a2@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;Fuat&quot; &lt;afsungur@...&gt;\r\nSubject: Starting Development of Multimachine Crawler\r\nX-Yahoo-Group-Post: member; u=337234122; y=4SRJVlVSNvVz1UpFC_cR_haUbghF_lzlCV7IQTrWoIM4OpI\r\nX-Yahoo-Profile: afsungur\r\n\r\nHi,\n\nI am currently working on Heritrix 1.14.4 on a notebook. I&#39;ve download=\r\ned lots of web pages and write their content to database successfully by cr=\r\neating a new writer processor. Everything is ok for now, i am using one mac=\r\nhine.\n\nI want to crawl web sites with several machines. I looked for thread=\r\ns how can i design a system such this. I saw there are lots of methods such=\r\n as hcc, bloomfilter etc. But i could not find any documentation about para=\r\nllelism in crawler. Where can i start to develop a application based on clu=\r\nstered? I guess to develop that application a bit harder. \n\nI think that th=\r\nere will be 4 Linux ( RedHat 5 ) machines, those will be ordinary server ma=\r\nchine for now.  \n\nAny suggestion, documentation or step-by-step tutorial wi=\r\nll be appreciated.\n\nThanks. \n\n\n\n\n"}}