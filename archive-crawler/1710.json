{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"stackarchiveorg","from":"&quot;stackarchiveorg&quot; &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"qiz7Lx6WYVZNkd2dT-7xPf9BsJKBatmF36FxBAvZvaZwJme6Fkxapeflt-rryWDKTnwNCWujMCLy5wyqvOJJAFbPObnDE0i3biZ5Lw","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: plz help me out","postDate":"1112294128","msgId":1710,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGQyaGZ0ZytraGM4QGVHcm91cHMuY29tPg==","inReplyToHeader":"PDIwMDUwMzMxMTA0NTUxLjI3NDk4LnFtYWlsQHdlYjg0MDYubWFpbC5pbi55YWhvby5jb20+"},"prevInTopic":1708,"nextInTopic":1711,"prevInTime":1709,"nextInTime":1711,"topicId":1708,"numMessagesInTopic":3,"msgSnippet":"... computers.And in our last sem project,we are using Heritrix Web crawler.But, during its usage we felt the need of some support from your side. ... The","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 74117 invoked from network); 31 Mar 2005 18:35:48 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m25.grp.scd.yahoo.com with QMQP; 31 Mar 2005 18:35:48 -0000\r\nReceived: from unknown (HELO n15a.bulk.scd.yahoo.com) (66.94.237.32)\n  by mta1.grp.scd.yahoo.com with SMTP; 31 Mar 2005 18:35:48 -0000\r\nDomainKey-Signature: \r\nReceived: from [66.218.69.1] by n15.bulk.scd.yahoo.com with NNFMP; 31 Mar 2005 18:35:32 -0000\r\nReceived: from [66.218.66.80] by mailer1.bulk.scd.yahoo.com with NNFMP; 31 Mar 2005 18:35:32 -0000\r\nDate: Thu, 31 Mar 2005 18:35:28 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;d2hftg+khc8@...&gt;\r\nIn-Reply-To: &lt;20050331104551.27498.qmail@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Length: 1228\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:12:0\r\nFrom: &quot;stackarchiveorg&quot; &lt;stack@...&gt;\r\nSubject: Re: plz help me out\r\nX-Yahoo-Group-Post: member; u=168599281\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\n\n--- In archive-crawler@yahoogroups.com, chirag chauhan\n&lt;chirag_299@y...&gt; wrote:\n&gt; Respected sir,\n&gt;                      We are the students of last year B.E\ncomputers.And in our last sem project,we are using Heritrix Web\ncrawler.But, during its usage we felt the need of some support from\nyour side.\n&gt;  \n&gt; So let me tell you in which part we are facing some of the problems.\n&gt;  \n&gt; We need the exact place in  heritrix source code:-\n&gt;  \n&gt; When the directory &quot;logs&quot; is created?\n&gt;  \nThe getSettingsDirectory on this line --\nhttp://crawler.archive.org/xref/org/archive/crawler/framework/CrawlController.html#605\n-- creates the log directory.\n\n&gt; When exactly the final links which r crawled are written in log\nfiles and which log(crawl.log) file?\n&gt;  \nYes. Crawl.log.  Here is the class that does the writing:\nhttp://crawler.archive.org/xref/org/archive/crawler/io/UriProcessingFormatter.html.\n Its initial setup is done close to where logs directory is created\ncited above.\n\nSt.Ack\n\n&gt; We specifically need to fetch the crawled links for further usage in\nour project?\n\n\n&gt;  \n&gt;                         Hope you will do needful .Watiting for ur\nresponse.Expecting kind help.\n&gt; \n&gt; \n&gt; Yahoo! India Matrimony: Find your life partneronline.\n\n\n\n\n"}}