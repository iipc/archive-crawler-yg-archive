{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":6903103,"authorName":"Tom Emerson","from":"Tom Emerson &lt;Tree@...&gt;","profile":"tree02139","replyTo":"LIST","senderId":"czzFF-Egqmt2SRTGniXPhw-npr1s0BsEL08Ts80DqeoTFM2639z2uJ-hREjEjQykA5h49_1AIBWyq7ZjBxfDsbx3Dn3GlTo","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] persistent crawls","postDate":"1094086410","msgId":938,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDE2Njk0LjI4NDI2LjcxOTMwNy41MzM2ODVAdGlwaGFyZXMuYmFzaXN0ZWNoLm5ldD4=","inReplyToHeader":"PDIwMDQwOTAxMjIxNzA0LkdBMjYwMjRAYm9vZ2V5bWFuLmFybW9yeS5jb20+","referencesHeader":"PDIwMDQwOTAxMjExNTQxLkdBMjU4MzdAYm9vZ2V5bWFuLmFybW9yeS5jb20+CTwxNjY5NC4xNjI5OC43MzY4NjYuOTIyMjE2QHRpcGhhcmVzLmJhc2lzdGVjaC5uZXQ+CTwyMDA0MDkwMTIyMTcwNC5HQTI2MDI0QGJvb2dleW1hbi5hcm1vcnkuY29tPg=="},"prevInTopic":937,"nextInTopic":939,"prevInTime":937,"nextInTime":939,"topicId":934,"numMessagesInTopic":14,"msgSnippet":"Phil White writes: [...] ... [...] There has been a lot of research done on how to select URLs for subsequent crawling: the major search engines certainly","rawEmail":"Return-Path: &lt;Tree@...&gt;\r\nX-Sender: Tree@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 74223 invoked from network); 2 Sep 2004 00:53:31 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m23.grp.scd.yahoo.com with QMQP; 2 Sep 2004 00:53:31 -0000\r\nReceived: from unknown (HELO mailserver.basistech.com) (199.88.205.4)\n  by mta4.grp.scd.yahoo.com with SMTP; 2 Sep 2004 00:53:31 -0000\r\nReceived: from postfix.basistech.com ([10.1.3.65] RDNS failed) by mailserver.basistech.com with Microsoft SMTPSVC(6.0.3790.0);\n\t Wed, 1 Sep 2004 20:53:30 -0400\r\nReceived: by postfix.basistech.com (Postfix, from userid 5007)\n\tid C990B2F02D0; Wed,  1 Sep 2004 20:53:30 -0400 (EDT)\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=us-ascii\r\nContent-Transfer-Encoding: 7bit\r\nMessage-ID: &lt;16694.28426.719307.533685@...&gt;\r\nDate: Wed, 1 Sep 2004 20:53:30 -0400\r\nTo: archive-crawler@yahoogroups.com\r\nIn-Reply-To: &lt;20040901221704.GA26024@...&gt;\r\nReferences: &lt;20040901211541.GA25837@...&gt;\n\t&lt;16694.16298.736866.922216@...&gt;\n\t&lt;20040901221704.GA26024@...&gt;\r\nX-Mailer: VM 7.18 under Emacs 21.2.1\r\nReturn-Path: tree@...\r\nX-OriginalArrivalTime: 02 Sep 2004 00:53:31.0176 (UTC) FILETIME=[44295280:01C49087]\r\nX-eGroups-Remote-IP: 199.88.205.4\r\nFrom: Tom Emerson &lt;Tree@...&gt;\r\nReply-To: tree@...\r\nSubject: Re: [archive-crawler] persistent crawls\r\nX-Yahoo-Group-Post: member; u=6903103\r\nX-Yahoo-Profile: tree02139\r\n\r\nPhil White writes:\n[...]\n&gt; As a result, it&#39;s necessarily a longer term project and I&#39;d prefer to \n&gt; not have my DSL pegged out for the next 3 years or so.  8)\n[...]\n\nThere has been a lot of research done on how to select URLs for\nsubsequent crawling: the major search engines certainly don&#39;t recrawl\ntheir entire catalog on a regular basis. Searching on Google (you&#39;ll\nfind papers by Sergei Brin and Larry Page, who both worked on this\nproblem) or on CiteSeer will show a bunch. However, for your task this\nis probably overkill.\n\nOne hack comes to mind, which may or may not work:\n\nIn the Expert Settings for the crawl you can add &quot;Accept&quot; headers to\nthe request. It turns out that the way I implemented this allows you\nto add *any* header to the request. The upshot is that you could try\nadding an &#39;If-Modified-Since:&#39; header to the subsequent crawls, giving\nthe date of your initial crawl. It isn&#39;t perfect, but it may help.\n\nYou could also write a script that extracts all the URLs and then\nsends a HEAD request to determine which ones have changed... I was\nthinking of writing something like this, but have not gotten around to\nit.\n\n    -tree\n\n-- \nTom Emerson                                          Basis Technology Corp.\nSoftware Architect                                 http://www.basistech.com\n  &quot;Beware the lollipop of mediocrity: lick it once and you suck forever&quot;\n\n"}}