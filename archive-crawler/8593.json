{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":496150545,"authorName":"Markus.Mirsberger","from":"&quot;Markus.Mirsberger&quot; &lt;markus.mirsberger@...&gt;","profile":"mirschi74","replyTo":"LIST","senderId":"3jxPTFm9dCpww2w9AQ-HkBkP0ve40G4LyoWujaB5JOnC5t-t7AbkovsAmVZeP91DcdLcJKpgZtpybsOhRwkHmCkWNbrw5FAZDzJlLz0w0CyLFDo0fg","spamInfo":{"isSpam":false,"reason":"3"},"subject":"Re: [archive-crawler] how to speed up crawls?","postDate":"1409028931","msgId":8593,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDUzRkMxMzQzLjUwODA5MDJAZ214LmRlPg==","inReplyToHeader":"PDUzRkJBMjg3LjMwMDAzMDdAYXJjaGl2ZS5vcmc+","referencesHeader":"PDUzRjlENzMxLjUwMzA0MDlAZ214LmRlPiA8NTNGQUQ4NjAuNjAxMDIwN0BhcmNoaXZlLm9yZz4gPDUzRkFFOEZFLjkwOTA0MDRAZ214LmRlPiA8NTNGQkEyODcuMzAwMDMwN0BhcmNoaXZlLm9yZz4="},"prevInTopic":8592,"nextInTopic":8603,"prevInTime":8592,"nextInTime":8594,"topicId":8589,"numMessagesInTopic":10,"msgSnippet":"... Yes parallelQueues was set to 20 at the very beginning of the crawl. This is my basic setting in the profile Iam using for every Crawl. The same for","rawEmail":"Return-Path: &lt;markus.mirsberger@...&gt;\r\nX-Sender: markus.mirsberger@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 89678 invoked by uid 102); 26 Aug 2014 04:55:37 -0000\r\nX-Received: from unknown (HELO mtaq1.grp.bf1.yahoo.com) (10.193.84.32)\n  by m16.grp.bf1.yahoo.com with SMTP; 26 Aug 2014 04:55:37 -0000\r\nX-Received: (qmail 23449 invoked from network); 26 Aug 2014 04:55:36 -0000\r\nX-Received: from unknown (HELO mout.gmx.net) (98.139.245.163)\n  by mtaq1.grp.bf1.yahoo.com with SMTP; 26 Aug 2014 04:55:36 -0000\r\nX-Received: from [192.168.88.115] ([183.89.50.93]) by mail.gmx.com (mrgmx002)\n with ESMTPSA (Nemesis) id 0LqzEB-1WjUBx30B1-00ehDy for\n &lt;archive-crawler@yahoogroups.com&gt;; Tue, 26 Aug 2014 06:55:35 +0200\r\nMessage-ID: &lt;53FC1343.5080902@...&gt;\r\nDate: Tue, 26 Aug 2014 11:55:31 +0700\r\nUser-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20100101 Thunderbird/24.5.0\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;53F9D731.5030409@...&gt; &lt;53FAD860.6010207@...&gt; &lt;53FAE8FE.9090404@...&gt; &lt;53FBA287.3000307@...&gt;\r\nIn-Reply-To: &lt;53FBA287.3000307@...&gt;\r\nContent-Type: text/plain; charset=windows-1252; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Provags-ID:  V03:K0:qqXuhywqLLgqEFrhbEX8lqQXSaHmc1x1MHqu2OBUAvWYjIqLTXz\n /42xBE3JKzUS3o8PHPhwZ68oZ+y9ucLu9WZAAYp3wVsDlHDCqnBQ2wGj3R10qf4uZiVqwqN\n fqKuHLqfxo5P9Bb2hq8YqB+D3KlR7GcY2L2Ka5M5OaZDyT8dAyIWBUjzLt8YkUS2D4NDiDl\n MEmIKiPveSm0mnIogtrmg==\r\nX-UI-Out-Filterresults: notjunk:1;\r\nX-eGroups-Msg-Info: 2:3:4:0:0\r\nSubject: Re: [archive-crawler] how to speed up crawls?\r\nX-Yahoo-Group-Post: member; u=496150545; y=6C2rpynCu7SuPUZFGAfZXuGuLeXUL8m6JvDL3k8zn6T42HwkUHFtsqxMtBvJtv6Z2mwWhpI03yOsH74\r\nX-Yahoo-Profile: mirschi74\r\nFrom: &quot;Markus.Mirsberger&quot; &lt;markus.mirsberger@...&gt;\r\n\r\n\nOn 26.08.2014 03:54, Gordon Mohr gojomo@... [archive-crawler] wrote:\n&gt; On 8/25/14, 12:42 AM, &#39;Markus.Mirsberger&#39; markus.mirsberger@...\n&gt; [archive-crawler] wrote:\n&gt;&gt; I already set parallelQueues to 20 before but this didn&#39;t increase the\n&gt;&gt; number of active queues/threads as you could see.\n&gt; Hmm. That should be the only change necessary: from that point on, if\n&gt; you&#39;re using one of the standard QueueAssignmentPolicies, any URIs\n&gt; discovered on a single site should be scattered over 20 queues instead\n&gt; of 1. Unlike your prior stats snapshot showing only 1 queue with\n&gt; millions of URIs, you&#39;d then see 20 queues.\n&gt;\n&gt; Was &#39;parallelQueues&#39; set to a higher value from the very beginning of\n&gt; the crawl? Once a URI is sent to a queue, changing this setting\n&gt; mid-crawl doesn&#39;t cause any immediate change. The URI still needs to\n&gt; come off its original queue, one at a time. Then, depending on the\n&gt; &#39;deferToPrevious&#39; setting, it might get processed without reconsidering\n&gt; its queue (deferToPrevious=true), or be immediately re-evaluated\n&gt; (deferToPrevious=false) and thus potentially re-enqueued rather than\n&gt; fetched.\nYes &#39;parallelQueues&#39; was set to 20 at the very beginning of the crawl. \nThis is my basic setting in the profile Iam using for every Crawl.\nThe same for &#39;deferToPrevious&#39; ... this was set to &#39;false&#39; at the beginning.\nJust to be sure this might not be the reason for my problem. I am still \nusing Heritrix 3.1.1\n\n&gt;&gt; What I did now was setting deferToPrevious to &quot;true&quot;. At least this\n&gt;&gt; increased the number of parallel threads to 2-3.\n&gt;&gt; But I still dont get more than 4kb/sec :(\n&gt; That sounds exactly backwards. If deferToPrevious=true, you&#39;ll get\n&gt; *less* reassignment-among-queues and thus less long-run speedup. Only\n&gt; new URIs being discovered will get spread over 20 queues.\n&gt;\n&gt; Note, though, that with deferToPrevious=false, and changing\n&gt; parallelQueues mid-crawl, there is often then a tight busy-loop as\n&gt; 19-out-of-each-20 URIs on the original single queue pop off and *don&#39;t*\n&gt; get crawled, but instead get reenqueued over other queues. This might\n&gt; stick out as a period of higher CPU and local IO usage, without much (or\n&gt; any) fetch speedup. However, as the giant queue shrinks rapidly, and\n&gt; other queues grow, you should then start to see a higher request rate\n&gt; over time, approaching the 20x speedup (if there aren&#39;t other CPU/IO\n&gt; bottlenecks).\n&gt;\n&gt; So you&#39;d want to give the deferToPrevious=false setting some time to\n&gt; have its effect on queue-distribution.\nAs I mentioned in the comment before ... deferToPrevious was set to \nfalse at the beginning of the crawl and I ended up with only one queue.\n&gt;&gt; I think it is not necessary to use sheets in my case. I crawl every\n&gt;&gt; domain in an own crawljob and dont allow the job to crawl other domains.\n&gt; There were 14 other empty queues in your stats cut-and-paste... just be\n&gt; aware when rerunning this crawl, if a global parallelQueues=20 setting\n&gt; is in effect, they&#39;ll all be equally hammered.\nYes I am aware this. Every Job is crawling only one single domain by \nrequest of the domain&#39;s owner. So the speed of the crawl will be \nadjusted in agreement with the owner.\nAnd both the crawling server and the server with the domain on it are \nalmost sleeping and definitly not the bottlenecks here ... maybe if I \never make all the queues really running parallel :)\n\nThanks,\nMarkus\n\n&gt; - Gordon\n&gt;\n&gt;&gt; Regards,\n&gt;&gt; Markus\n&gt;&gt;\n&gt;&gt; On 25.08.2014 13:32, Gordon Mohr gojomo@... [archive-crawler] wrote:\n&gt;&gt;&gt; The core politeness assumptions of Heritrix have been that URIs for a\n&gt;&gt;&gt; single &#39;site&#39; should go into a single logical queue, and that only one\n&gt;&gt;&gt; URI should be in process from any one queue at a time.\n&gt;&gt;&gt;\n&gt;&gt;&gt; That&#39;s what you&#39;re running into, even after minimizing the other\n&gt;&gt;&gt; politeness delays between fetches.\n&gt;&gt;&gt;\n&gt;&gt;&gt; If you&#39;re sure that more-aggressive crawling is alright (as seems to be\n&gt;&gt;&gt; the case with your target site with owner permission), you can cause the\n&gt;&gt;&gt; usual queue-assignment to instead distribute a single site&#39;s URIs over\n&gt;&gt;&gt; many related queues. Then, if (for example) using 5 queues, 5 requests\n&gt;&gt;&gt; can be in process in parallel, resulting in up to 5X faster crawling.\n&gt;&gt;&gt;\n&gt;&gt;&gt; The relevant setting is &#39;parallelQueues&#39; on the QueueAssignmentPolicy.\n&gt;&gt;&gt; See some notes here:\n&gt;&gt;&gt;\n&gt;&gt;&gt; https://webarchive.jira.com/wiki/display/Heritrix/H3+Dev+Notes+for+Crawl+Operators#H3DevNotesforCrawlOperators-QueueAssignmentPolicies:%27parallelQueues%27and%27deferToPrevious%27settings\n&gt;&gt;&gt;\n&gt;&gt;&gt; As it&#39;s usually the case that you want most sites to be crawled in the\n&gt;&gt;&gt; normal polite manner, even when there are one or more sites that can be\n&gt;&gt;&gt; crawled more aggressively, it often makes sense to only set a higher\n&gt;&gt;&gt; &#39;parallelQueues&#39; value in a &quot;sheet override&quot; to affect some subset of\n&gt;&gt;&gt; sites. Thus, that&#39;s one of the example overridden settings in the sheets\n&gt;&gt;&gt; example at:\n&gt;&gt;&gt;\n&gt;&gt;&gt; https://webarchive.jira.com/wiki/display/Heritrix/Sheets\n&gt;&gt;&gt;\n&gt;&gt;&gt; - Gordon\n&gt;&gt;&gt;\n&gt;&gt;&gt; On 8/24/14, 5:14 AM, &#39;Markus.Mirsberger&#39; markus.mirsberger@...\n&gt;&gt;&gt; [archive-crawler] wrote:\n&gt;&gt;&gt;&gt; Hi,\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; are there any ways to speed up an active crawl?\n&gt;&gt;&gt;&gt; I am always crawling only one single domain and I was told by the owner\n&gt;&gt;&gt;&gt; that it is ok when I crawl it with up to 10Url/sec. As You can see in\n&gt;&gt;&gt;&gt; the pasted jobdata ... a little bit more than 1 Url/sec is all I can get.\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; I tried already several things like rising the amount of queues and\n&gt;&gt;&gt;&gt; threads, shorten the breaks between the requests but nothing really works.\n&gt;&gt;&gt;&gt; I also wonder that there is only one active thread and also only one\n&gt;&gt;&gt;&gt; queue in use.\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Do you have any suggestions where in the config I can turn on the turbo?:)\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Thanks in advance,\n&gt;&gt;&gt;&gt; Markus\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;        Job is Active: RUNNING\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Totals\n&gt;&gt;&gt;&gt;        738743 downloaded + 5950664 queued = 6689408 total\n&gt;&gt;&gt;&gt;        44 GiB crawled (44 GiB novel, 0 B dupByHash, 0 B notModified)\n&gt;&gt;&gt;&gt; Alerts\n&gt;&gt;&gt;&gt;        /none/\n&gt;&gt;&gt;&gt; Rates\n&gt;&gt;&gt;&gt;        1.16 URIs/sec (2.11 avg); 84 KB/sec (131 avg)\n&gt;&gt;&gt;&gt; Load\n&gt;&gt;&gt;&gt;        1 active of 100 threads; 1 congestion ratio; 5950664 deepest queue;\n&gt;&gt;&gt;&gt;        5950664 average depth\n&gt;&gt;&gt;&gt; Elapsed\n&gt;&gt;&gt;&gt;        4d1h7m37s131ms\n&gt;&gt;&gt;&gt; Threads\n&gt;&gt;&gt;&gt;        100 threads: 99 ABOUT_TO_GET_URI, 1 ABOUT_TO_BEGIN_PROCESSOR; 99\n&gt;&gt;&gt;&gt;        noActiveProcessor, 1 extractorHtml\n&gt;&gt;&gt;&gt; *Frontier*\n&gt;&gt;&gt;&gt;        RUN - 15 URI queues: 1 active (1 in-process; 0 ready; 0 snoozed); 0\n&gt;&gt;&gt;&gt;        inactive; 0 ineligible; 0 retired; 14 exhausted\n&gt;&gt;&gt;&gt; Memory\n&gt;&gt;&gt;&gt;        10369079 KiB used; 15480904 KiB current heap; 16270464 KiB max heap\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt; ------------------------------------\n&gt;&gt;&gt;\n&gt;&gt;&gt; ------------------------------------\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; ------------------------------------\n&gt;&gt;&gt;\n&gt;&gt;&gt; Yahoo Groups Links\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; ------------------------------------\n&gt;&gt;\n&gt;&gt; ------------------------------------\n&gt;&gt;\n&gt;&gt;\n&gt;&gt; ------------------------------------\n&gt;&gt;\n&gt;&gt; Yahoo Groups Links\n&gt;&gt;\n&gt;&gt;\n&gt;&gt;\n&gt;\n&gt; ------------------------------------\n&gt;\n&gt; ------------------------------------\n&gt;\n&gt;\n&gt; ------------------------------------\n&gt;\n&gt; Yahoo Groups Links\n&gt;\n&gt;\n&gt;\n\n\n"}}