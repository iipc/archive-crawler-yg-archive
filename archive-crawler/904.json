{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":193638946,"authorName":"Yousef Ourabi","from":"Yousef Ourabi &lt;yousef_ourabi@...&gt;","profile":"yousef_ourabi","replyTo":"LIST","senderId":"0NHy_gFTnUlIUEyI2OGdyEW9pMmM5mwKHSuh1UGPQcliwS3vGBE8Q6gJdM9pJRmtgCeIB0PnXlQ8jXnIjVbXZJtpsghv9-jotaHlOYkG","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Out of Memory","postDate":"1093587647","msgId":904,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDIwMDQwODI3MDYyMDQ3Ljc3MTcxLnFtYWlsQHdlYjkwMDAzLm1haWwuc2NkLnlhaG9vLmNvbT4=","inReplyToHeader":"PDQxMkVEMDFCLjYwMzAwMDJAYXJjaGl2ZS5vcmc+"},"prevInTopic":903,"nextInTopic":905,"prevInTime":903,"nextInTime":905,"topicId":881,"numMessagesInTopic":28,"msgSnippet":"Guys, Where are you??? Its 11 PST and St.Ack and Tree are still mointoring the list :) I am not ofcourse, this is an automated email really... So about that","rawEmail":"Return-Path: &lt;yousef_ourabi@...&gt;\r\nX-Sender: yousef_ourabi@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 38044 invoked from network); 27 Aug 2004 06:20:47 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m6.grp.scd.yahoo.com with QMQP; 27 Aug 2004 06:20:47 -0000\r\nReceived: from unknown (HELO web90003.mail.scd.yahoo.com) (66.218.94.61)\n  by mta4.grp.scd.yahoo.com with SMTP; 27 Aug 2004 06:20:47 -0000\r\nMessage-ID: &lt;20040827062047.77171.qmail@...&gt;\r\nReceived: from [67.180.39.195] by web90003.mail.scd.yahoo.com via HTTP; Thu, 26 Aug 2004 23:20:47 PDT\r\nDate: Thu, 26 Aug 2004 23:20:47 -0700 (PDT)\r\nTo: archive-crawler@yahoogroups.com\r\nIn-Reply-To: &lt;412ED01B.6030002@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=us-ascii\r\nX-eGroups-Remote-IP: 66.218.94.61\r\nFrom: Yousef Ourabi &lt;yousef_ourabi@...&gt;\r\nSubject: Re: [archive-crawler] Out of Memory\r\nX-Yahoo-Group-Post: member; u=193638946\r\nX-Yahoo-Profile: yousef_ourabi\r\n\r\nGuys,\nWhere are you??? Its 11 PST and St.Ack and Tree are\nstill mointoring the list :) I am not ofcourse, this\nis an automated email really...\n\nSo about that box, I think it is a little unrealistic.\nAre the memory requirements of Heritrix exponential?\nbecause Tree says H need 800megs for 2x10^6, so would\n1.6G heap size be enough for 4x10^6?\n\nHave you guys looked at Memcached for caching\nfrequently requested objects, I have not looked\nextenively at outgoing requests, but memcached might\nwork for frequently requested things perhaps DNS\nqueries? Any Ideas?\n\nBest, and Good night.\n-Yousef\n\n\n\n\n\n\n--- stack &lt;stack@...&gt; wrote:\n\n&gt; Tom Emerson wrote:\n&gt; \n&gt; &gt;For crawls pushing 2 million discovered URLs I have\n&gt; needed a heap of\n&gt; &gt;800MB, and that has pushed things.\n&gt; &gt;  \n&gt; &gt;\n&gt; &gt;This actually raises a question: what would the\n&gt; recommendation be for\n&gt; &gt;a dedicated crawling box? My thinking was along the\n&gt; lines of:\n&gt; &gt;\n&gt; &gt;- Dual CPU 32-bit 686\n&gt; &gt;- At least 3 GB physical memory\n&gt; &gt;- Minimally three 160 GB drives\n&gt; &gt;- Linux Kernel 2.4.x, tuned distro (e.g., Gentoo)\n&gt; &gt;- DVD-RW\n&gt; &gt;  \n&gt; &gt;\n&gt; We haven&#39;t spent much time thinking about it (We\n&gt; kinda have to make do \n&gt; with what we can get).   A minimal sketch\n&gt; (&quot;Optimized Hardware Profile&quot; \n&gt; at\n&gt;\n&#39;http://crawler.archive.org/cgi-bin/wiki.pl?CrawlingPerformance)\n&gt; \n&gt; would have a fast CPU -- we&#39;re CPU bound at the\n&gt; moment -- with small \n&gt; SCSI disks offloading ARCs as we progressed.  But I\n&gt; suppose it&#39;ll depend \n&gt; on character of the crawl.\n&gt; \n&gt; St.Ack\n&gt; \n&gt; &gt;This would be designed to run two Heritrix\n&gt; instances as well as\n&gt; &gt;off-line processing tools.\n&gt; &gt;\n&gt; &gt;    -tree\n&gt; &gt;\n&gt; &gt;  \n&gt; &gt;\n&gt; \n&gt; \n\n\n"}}