{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":225011788,"authorName":"Karl Wright","from":"Karl Wright &lt;kwright@...&gt;","profile":"daddywri","replyTo":"LIST","senderId":"9M2QWKhrqDxeh8xu4mDF2ks7TXE8laCkj6FHcyOLrgHME_fCshdc6wvvUQnHYzdgG_3B7HiJrhM3PiDtqsQaMIin_ip_oYTpbxM","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Robots.txt parsing problem?","postDate":"1141840807","msgId":2736,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ0MEYxQkE3LjIwNTAyMDNAbWV0YWNhcnRhLmNvbT4="},"prevInTopic":0,"nextInTopic":2737,"prevInTime":2735,"nextInTime":2737,"topicId":2736,"numMessagesInTopic":7,"msgSnippet":"Hi, We got dinged again by using Heritrix in that a crawlee complained that we were ignoring their robots.txt file.  On the face of it, they look like they are","rawEmail":"Return-Path: &lt;kwright@...&gt;\r\nX-Sender: kwright@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 93266 invoked from network); 8 Mar 2006 17:58:46 -0000\r\nReceived: from unknown (66.218.67.34)\n  by m35.grp.scd.yahoo.com with QMQP; 8 Mar 2006 17:58:46 -0000\r\nReceived: from unknown (HELO metacarta.com) (65.77.47.18)\n  by mta8.grp.scd.yahoo.com with SMTP; 8 Mar 2006 17:58:46 -0000\r\nReceived: from localhost (silene.metacarta.com [65.77.47.24])\n\tby metacarta.com (Postfix) with ESMTP id 96DB95182FE\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Wed,  8 Mar 2006 12:58:43 -0500 (EST)\r\nReceived: from metacarta.com ([65.77.47.18])\n\tby localhost (silene.metacarta.com [65.77.47.24]) (amavisd-new, port 10024)\n\twith ESMTP id 06453-05; Wed, 8 Mar 2006 12:58:42 -0500 (EST)\r\nReceived: from [65.77.47.197] (dhcp-65-77-47-197.metacarta.com [65.77.47.197])\n\tby metacarta.com (Postfix) with ESMTP\n\tid 646305182F9; Wed,  8 Mar 2006 12:58:42 -0500 (EST)\r\nMessage-ID: &lt;440F1BA7.2050203@...&gt;\r\nDate: Wed, 08 Mar 2006 13:00:07 -0500\r\nUser-Agent: Mozilla Thunderbird 1.0.2 (Windows/20050317)\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nCc: Keith Baker &lt;krbaker@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Virus-Scanned: by amavisd-new-20030616-p10 (Debian) at metacarta.com\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: Karl Wright &lt;kwright@...&gt;\r\nSubject: Robots.txt parsing problem?\r\nX-Yahoo-Group-Post: member; u=225011788; y=BGMQzP5dy-6pInZZoei3xbqEbsu2BmAxAzcs_mO03yfZEzk\r\nX-Yahoo-Profile: daddywri\r\n\r\nHi,\n\nWe got dinged again by using Heritrix in that a crawlee complained that \nwe were ignoring their robots.txt file.  On the face of it, they look \nlike they are correct in complaining:\n\nhttp://uaelp.pennnet.com/robots.txt\n===================================\n\n# pennwell robots.txt\n# updated 3/6/06 by bwn\n\nUser-agent: Googlebot\nDisallow: /Search/\nDisallow: /search/\nDisallow: /Userreg/\nDisallow: /userreg/\nDisallow: /Nav/\nDisallow: /nav/\nDisallow: /js\nDisallow: /JS\nDisallow: /whitepapers/wp_redirect.cfm\nDisallow: /*.js$\n\nUser-agent: *\nDisallow: /Search/\nDisallow: /search/\nDisallow: /Userreg/\nDisallow: /userreg/\nDisallow: /Nav/\nDisallow: /nav/\nDisallow: /js\nDisallow: /JS\nDisallow: /whitepapers/wp_redirect.cfm\n\n\nheritrix crawl log portion\n==========================\n\n2006-03-08T16:11:41.295Z   200      17266 \nhttp://uaelp.pennnet.com/whitepapers/wp_redirect.cfm?id=305 LLL \nhttp://uaelp.pennnet.com/whitepapers/wp.cfm?id=305 text/html #075 \n20060308161137362+1062 R5C73R3EPNNO4UYMWRPBTUJD3TWW32X7 2t\n\nAccording to our reading of the robots.txt spec, this URL should not \nhave been crawled.  The only reason I can find for the failure may be \nthat the last line is not terminated with a newline, but rather just an EOF.\n\nAny thoughts?\n\nKarl\n\n"}}