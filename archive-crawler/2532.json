{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"stack","from":"stack &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"V68MJrV1XvybjehNE0FNPUScGZ2zZzFgfGJEcOephgQlqXswSZ9Hb2MaBjNl_43B3DRiGMUPUtPwHrsP5yKT8w","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] BdbUniqFilter vs BloomUniqFilter","postDate":"1137002343","msgId":2532,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQzQzU0NzY3LjYwMDA3MDlAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDQ5NGFmZTFjMDYwMTExMDA0OXNkNTkwMGM3cmViMmVjMTI0ZjU3NTU5NWFAbWFpbC5nbWFpbC5jb20+","referencesHeader":"PGRwZjVkNyt2c2gxQGVHcm91cHMuY29tPiA8NDNCQzMwNjAuNTA2MDEwNEBhcmNoaXZlLm9yZz4gPDQ5NGFmZTFjMDYwMTExMDA0OXNkNTkwMGM3cmViMmVjMTI0ZjU3NTU5NWFAbWFpbC5nbWFpbC5jb20+"},"prevInTopic":2531,"nextInTopic":0,"prevInTime":2531,"nextInTime":2533,"topicId":2490,"numMessagesInTopic":4,"msgSnippet":"... Hello Vishwesh. ... Gordon has made a start exploring another implementation. See ","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 1954 invoked from network); 11 Jan 2006 17:08:17 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m21.grp.scd.yahoo.com with QMQP; 11 Jan 2006 17:08:17 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (207.241.224.171)\n  by mta6.grp.scd.yahoo.com with SMTP; 11 Jan 2006 17:08:17 -0000\r\nReceived: (qmail 8938 invoked by uid 100); 11 Jan 2006 17:01:53 -0000\r\nReceived: from adsl-71-130-102-78.dsl.pltn13.pacbell.net (HELO ?192.168.1.8?) (stack@...@71.130.102.78)\n  by mail-dev.archive.org with SMTP; 11 Jan 2006 17:01:53 -0000\r\nMessage-ID: &lt;43C54767.6000709@...&gt;\r\nDate: Wed, 11 Jan 2006 09:59:03 -0800\r\nUser-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.8) Gecko/20051219 SeaMonkey/1.0b\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;dpf5d7+vsh1@...&gt; &lt;43BC3060.5060104@...&gt; &lt;494afe1c0601110049sd5900c7reb2ec124f575595a@...&gt;\r\nIn-Reply-To: &lt;494afe1c0601110049sd5900c7reb2ec124f575595a@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=-96.6 required=7.0 tests=AWL,USER_IN_WHITELIST \n\tautolearn=no version=2.63\r\nX-eGroups-Msg-Info: 2:12:4:0\r\nFrom: stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] BdbUniqFilter vs BloomUniqFilter\r\nX-Yahoo-Group-Post: member; u=168599281; y=5tA5YBHOk2ndVzNPEa2-RrOUYtXi5itcD66OskFJpNtwwyEivPI6x6HV\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\nVishwesh Thakur wrote:\n&gt; Hello Stack,\n\nHello Vishwesh.\n\n&gt;  Is something being done on alreadySeen list thing. \n\nGordon has made a start exploring another implementation. See \nhttp://crawler.archive.org/xref/org/archive/crawler/util/DiskFPMergeUriUniqFilter.html. \n   He&#39;s using the Mercator technique sketched in section 3.8 URL-Seen \nTest of http://www.cindoc.csic.es/cybermetrics/pdf/68.pdf.  Should allow \nus to scale already-seen above current ~125million or so (per host).\n\n\n&gt; From the email \n&gt; threads it looks like Bloom has a straight memory dependence and \n&gt; berkeley database starts to slow down on look ups as the size increases.\n\nThats a fair summary.\n\n&gt;  Lets consider the proposal of trying to increase BdbUriUniqFilter?\n&gt;  Let the Filter have a set of berkely databases (n) numbered 1 to n \n&gt; rather than one single berkeley database. For putting a uri into this \n&gt; Filter we can do &quot;k = hash(uriFilgerprint) modulo n&quot;, and the uri goes \n&gt; to the berkeley database numbered k.\n&gt;  Would this thing help at all? or in other words would the idea of \n&gt; increasing berkeley databases for the alreadySeen filter help relieve \n&gt; the crawler performance with scale.\n\nI&#39;d guess that when the crawl gets large, multiple dbs would make little \ndifference.  When the crawl is big the bdbje cache misses grow too -- \nespecially if hashing function does good distribution -- so an \nincreasing percentage of URL-seen tests would require a disk access \nslowing the crawl.\n\nBut if the number of dbs was very large -- say approaching a db per host \nto crawl -- and the crawler kept an affinity for sites crawling them to \ncompletion before moving to a new host, then there might be an advantage \nin this approach but bdbje doesn&#39;t work too well w/ tens of thousands of \ndbs in one environment (We&#39;ve talked to them about such a config. and \nthey&#39;ve said they&#39;re looking into it).\n\n&gt; \n&gt;  If the alreadySeen Filter has problems of scale then I believe \n&gt; BdbFrontier would have the same issue as well. Although taking the \n&gt; approach mentioned above is certainly not so straight :-)\n\nYes.  True.\n\nSt.Ack\n\n\n\n&gt; \n&gt; Regards\n&gt; Thakur\n&gt; \n&gt; On 1/5/06, *stack* &lt;stack@... &lt;mailto:stack@...&gt;&gt; wrote:\n&gt; \n&gt;     joehung302 wrote:\n&gt;     &gt;  What is the difference?\n&gt;     &gt;\n&gt;     &gt;  I have a proof crawler setup at 1500MB heap. It can never run Bloom\n&gt;     &gt;  filter for more than 1 day (maybe half a day).\n&gt;     Why? OOME?  Can you give crawler bigger heap?  Bloom filter by default\n&gt;     uses ~500Megs [See note here:\n&gt;     http://crawler.archive.org/xref/org/archive/crawler/util/BloomUriUniqFilter.html#56.\n&gt;     &lt;http://crawler.archive.org/xref/org/archive/crawler/util/BloomUriUniqFilter.html#56.&gt; \n&gt; \n&gt;     Its also possible to adjust BloomFilter size: See line 68 in the\n&gt;     Constructor].  I believe we use heaps closer to 2Gigs running with\n&gt;     BloomFilter already-seen.\n&gt; \n&gt;     &gt;  I&#39;ve tried several\n&gt;     &gt;  configurations and none of them runs for more a day.\n&gt;     &gt;\n&gt;     &gt;  I then changed it to use BdbUniqFilter and now it&#39;s been running for\n&gt;     &gt;  5+ days with 13M+ links downloaded and still going strong. The\n&gt;     &gt;  crawler is configured with CrawlMapping (in preparation for multi-\n&gt;     &gt;  machine crawl) setup with HostQueuePolicy.\n&gt;     &gt;\n&gt;     &gt;  I know I&#39;m supposed to use Bloom filter for bigger crawls but can\n&gt;     &gt;  anyone explain to me that I should give bloom filter another try\n&gt;     &gt;  rather than stick with BdbUniqFilter? Assuming that my goal is to\n&gt;     &gt;  prove the 1500MB heap configuration can download more 30M links?\n&gt;     Lookups into a BdbUniqFilter, not surprisingly, start to slow\n&gt;     dramatically as size of already-seen list grows above 20 or 30\n&gt;     million. \n&gt;     Downloading 30Million URLs, you might have an already-seen list of\n&gt;     upwards of 3 or 4 times that, dependent on character of your crawl.\n&gt; \n&gt;     But perhaps the BdbUniqFilter is adequate to your purposes (Once you\n&gt;     had\n&gt;     30million urls queued, you might put in place a filter that prevented\n&gt;     any new URLs being added to the Frontier/already-seen).\n&gt;     &gt;\n&gt;     &gt;  I&#39;m running 1.5.0_05 32bit JVM on 1.6.0 heritrix.\n&gt;     You might also add details on the OS and hardware you&#39;re using Joe:\n&gt;     What\n&gt;     linux, kernel, etc.  (Perhaps you did already?).  Could help giving you\n&gt;     support.\n&gt; \n&gt;     Yours,\n&gt;     St.Ack\n&gt;     &gt;\n&gt;     &gt;  cheers,\n&gt;     &gt;\n&gt;     &gt;  -joe\n&gt;     &gt;\n&gt;     &gt;\n&gt;     &gt;\n&gt;     &gt;\n&gt;     &gt;\n&gt;     ------------------------------------------------------------------------\n&gt;     &gt;  YAHOO! GROUPS LINKS\n&gt;     &gt;\n&gt;     &gt;     *  Visit your group &quot;archive-crawler\n&gt;      &gt;       &lt;http://groups.yahoo.com/group/archive-crawler&gt;&quot; on the web.\n&gt;     &gt;       \n&gt;     &gt;     *  To unsubscribe from this group, send an email to:\n&gt;     &gt;        archive-crawler-unsubscribe@yahoogroups.com\n&gt;     &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com&gt;\n&gt;      &gt;       &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com\n&gt;     &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com&gt;?subject=Unsubscribe&gt;\n&gt; \n&gt;      &gt;       \n&gt;      &gt;     *  Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;      &gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;.\n&gt;      &gt;\n&gt;      &gt;\n&gt;      &gt;\n&gt;     ------------------------------------------------------------------------\n&gt;      &gt;\n&gt; \n&gt; \n&gt;     ------------------------------------------------------------------------\n&gt;     YAHOO! GROUPS LINKS\n&gt; \n&gt;         *  Visit your group &quot;archive-crawler\n&gt;           &lt;http://groups.yahoo.com/group/archive-crawler&gt;&quot; on the web.\n&gt;            \n&gt;         *  To unsubscribe from this group, send an email to:\n&gt;             archive-crawler-unsubscribe@yahoogroups.com\n&gt;           &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;            \n&gt;         *  Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;           Service &lt;http://docs.yahoo.com/info/terms/&gt;.\n&gt; \n&gt; \n&gt;     ------------------------------------------------------------------------\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; -- \n&gt; Thakur Vishwesh Singh\n&gt; ------------------------------------------------------------------------\n&gt; YAHOO! GROUPS LINKS\n&gt; \n&gt;     *  Visit your group &quot;archive-crawler\n&gt;       &lt;http://groups.yahoo.com/group/archive-crawler&gt;&quot; on the web.\n&gt;        \n&gt;     *  To unsubscribe from this group, send an email to:\n&gt;        archive-crawler-unsubscribe@yahoogroups.com\n&gt;       &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;        \n&gt;     *  Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;. \n&gt; \n&gt; \n&gt; ------------------------------------------------------------------------\n&gt; \n\n\n"}}