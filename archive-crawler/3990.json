{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"d_RwgXN83JrVi83Qk1FNjZwUmhma25eT31eNAOZMefD4MsyejSa_5DAw7kYA8DQP8BhaGBj_KQy8gQ8IQlejacecesjPLmc","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] DecidingScope and SURTs","postDate":"1175203467","msgId":3990,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ2MEMyRThCLjIwMTA3MDZAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDQ2MEMyODA3LjIwNjA4MDBAYXJjaGl2ZS5vcmc+","referencesHeader":"PDk3Mzg1OEMyQURGRjVDNEY5OTQxNTc4NEY5MzkxQzA2MDE4NTEzQTVAZ2xnZXhjaGFuZ2UwNC5nbGdyb3VwLmNvbT4gPDQ2MEMyODA3LjIwNjA4MDBAYXJjaGl2ZS5vcmc+"},"prevInTopic":3989,"nextInTopic":3993,"prevInTime":3989,"nextInTime":3991,"topicId":3988,"numMessagesInTopic":5,"msgSnippet":"Mike explains things well. The one other thing I m sure you re aware of but I ll note for the group is that since so much HTML content is served from URIs that","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 62509 invoked from network); 29 Mar 2007 21:22:27 -0000\r\nReceived: from unknown (66.218.66.71)\n  by m26.grp.scd.yahoo.com with QMQP; 29 Mar 2007 21:22:27 -0000\r\nReceived: from unknown (HELO mail.archive.org) (207.241.233.246)\n  by mta13.grp.scd.yahoo.com with SMTP; 29 Mar 2007 21:22:27 -0000\r\nReceived: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id 355A6141BC453\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Thu, 29 Mar 2007 14:22:24 -0700 (PDT)\r\nReceived: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id 16649-07-52 for &lt;archive-crawler@yahoogroups.com&gt;;\n\tThu, 29 Mar 2007 14:22:23 -0700 (PDT)\r\nReceived: from [192.168.1.203] (c-76-102-230-209.hsd1.ca.comcast.net [76.102.230.209])\n\tby mail.archive.org (Postfix) with ESMTP id C7E03141BC308\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Thu, 29 Mar 2007 14:22:23 -0700 (PDT)\r\nMessage-ID: &lt;460C2E8B.2010706@...&gt;\r\nDate: Thu, 29 Mar 2007 14:24:27 -0700\r\nUser-Agent: Thunderbird 1.5.0.9 (X11/20070104)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;973858C2ADFF5C4F99415784F9391C06018513A5@...&gt; &lt;460C2807.2060800@...&gt;\r\nIn-Reply-To: &lt;460C2807.2060800@...&gt;\r\nContent-Type: text/plain; charset=UTF-8; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Virus-Scanned: Debian amavisd-new at archive.org\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] DecidingScope and SURTs\r\nX-Yahoo-Group-Post: member; u=137285340; y=EUX2UAGE5zOsaggrgtDgWQRHxi6rraEKRIWi7MhvnXf5\r\nX-Yahoo-Profile: gojomo\r\n\r\nMike explains things well.\n\nThe one other thing I&#39;m sure you&#39;re aware of but I&#39;ll note for the group \nis that since so much HTML content is served from URIs that don&#39;t end \n&quot;&#92;.html?&quot;, REJECTing every URI that does not end that way would usually \nprevent a lot of HTML content from being crawled.\n\nFor example, even if a directory page like &lt;http://www.example.com/dir/&gt; \nredirected to URI &lt;http://www.example.com/dir/index.html&gt;, the second \nURI would not be found -- because the first would have been REJECTed \nbefore even being attempted.\n\nOTOH, your original formulation, with a late ACCEPT for anything that \nended &quot;&#92;.html?&quot;, would mainly have the effect of getting likely-HTML \nURIs, even if the previous rules had rejected them. (So in a way, it \nwould &#39;rescue&#39; any likely-HTML URIs that had previously been decided as \noff-SURT, too-deep-in-hops, suspiciously-path-segmented, etc.)\n\n- Gordon @ IA\n\n\n  Michael Magin wrote:\n&gt; Tom Emerson wrote:\n&gt; \n&gt;&gt; How should I go about figuring out what I&#39;m doing wrong. The order of \n&gt;&gt; decide rules is:\n&gt;&gt;\n&gt;&gt; rejectByDefault\n&gt;&gt; acceptIfSurtPrefixed\n&gt;&gt; rejectIfTooManyHops\n&gt;&gt; acceptIfTranscluded\n&gt;&gt; rejectIfPathological\n&gt;&gt; rejectIfTooManyPathSegs\n&gt;&gt; acceptHtmlOnly &lt;--- MatchesRegExpDecideRule with regexp .*(?i)&#92;.html?\n&gt;&gt; acceptIfPrerequisite\n&gt;&gt;\n&gt;&gt; Not only do I seem to be getting non-HTML files (which I thought would \n&gt;&gt; be filtered with the regexp decide rule) but I&#39;m getting stuff outside \n&gt;&gt; my SURTs.\n&gt;&gt;\n&gt;&gt; Should the acceptIfSurtPrefixed be moved below the others? Perhaps \n&gt;&gt; acceptIfTranscluded is overriding the setting?\n&gt; \n&gt; These rules are tested in order -- if you really want to be certain you \n&gt; don&#39;t go beyond the SURT scope at all, don&#39;t have any other ACCEPT rules \n&gt; after the acceptIfSurtPrefixed (except the acceptIfPrerequisite -- which \n&gt; makes sure that the crawler will be able to get DNS and robots.txt \n&gt; prereqs.)  Specifically, acceptIfTranscluded is probably allowing a \n&gt; number of off-site images/redirects/etc to be fetched, even though they \n&gt; are outside of the exact SURT scope.\n&gt; \n&gt; Also, if you want HTML _ONLY_, you probably want to change that rule to \n&gt; a rule that REJECTs if NotMatchesRegExpDecideRule with regexp \n&gt; .*(?i)&#92;.html?   The rule you have will merely accept anything matching \n&gt; that, it won&#39;t change the ACCEPT/REJECT result for things that do not match.\n&gt; \n&gt; So, I think you might be looking for something like:\n&gt; rejectByDefault\n&gt; acceptIfSurtPrefixed\n&gt; rejectIfTooManyHops\n&gt; rejectIfPathological\n&gt; rejectIfTooManyPathSegs\n&gt; rejectNonHTML &lt;--- NotMatchesRegExpDecideRule with regexp .*(?i)&#92;.html?\n&gt; acceptIfPrerequisite\n&gt; \n&gt; \n&gt; Mike\n&gt; \n&gt; \n&gt;  \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n\n"}}