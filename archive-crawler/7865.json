{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"YKNk6jLeJA_IhNm7Fu_oXfNbJnT7WeRnfFr5ZqEjB22TX6iDAYqH7n0I66z3V-c1wnyk0H2Slz6DpiHdy-sZbvglqKMc9uA","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] Url ordering/prerequisite : fetch the root url first","postDate":"1354668885","msgId":7865,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDUwQkU5QjU1LjYwMTA2MDhAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGs5aTVxZCtlcnQ5QGVHcm91cHMuY29tPg==","referencesHeader":"PGs5aTVxZCtlcnQ5QGVHcm91cHMuY29tPg=="},"prevInTopic":7864,"nextInTopic":8298,"prevInTime":7864,"nextInTime":7866,"topicId":7864,"numMessagesInTopic":3,"msgSnippet":"... You won t need to use the precedence policy facility, unless you need to do fine-grained prioritization, with many tiers. There is an existing option to","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 73542 invoked from network); 5 Dec 2012 00:54:48 -0000\r\nX-Received: from unknown (98.137.34.45)\n  by m14.grp.sp2.yahoo.com with QMQP; 5 Dec 2012 00:54:48 -0000\r\nX-Received: from unknown (HELO relay01.pair.com) (209.68.5.15)\n  by mta2.grp.sp2.yahoo.com with SMTP; 5 Dec 2012 00:54:48 -0000\r\nX-Received: (qmail 14522 invoked by uid 0); 5 Dec 2012 00:54:47 -0000\r\nX-Received: from 63.194.72.222 (HELO silverbook.local) (63.194.72.222)\n  by relay01.pair.com with SMTP; 5 Dec 2012 00:54:47 -0000\r\nX-pair-Authenticated: 63.194.72.222\r\nMessage-ID: &lt;50BE9B55.6010608@...&gt;\r\nDate: Tue, 04 Dec 2012 16:54:45 -0800\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.7; rv:16.0) Gecko/20121026 Thunderbird/16.0.2\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;k9i5qd+ert9@...&gt;\r\nIn-Reply-To: &lt;k9i5qd+ert9@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Url ordering/prerequisite : fetch the root\n url first\r\nX-Yahoo-Group-Post: member; u=137285340; y=ccm2vuJfcR6GrlQKisMMYhbU3sg9rbGHZPULGZ8ci7An\r\nX-Yahoo-Profile: gojomo\r\n\r\nOn 12/3/12 4:26 AM, bobbyledingo wrote:\n&gt; Hi,\n&gt;\n&gt; Each time heritrix extract the outlinks of a document, if it discover\n&gt; a link like http://www.domain.com/a/b/c.html I would like to create\n&gt; some dependency/prerequisite like forcing heritrix to always fetch\n&gt; the root url (eg http://www.domain.com/) before the found url (if it\n&gt; has not been crawled previously).\n&gt;\n&gt; So my goal is to always crawl the root url (http://www.domain.com)\n&gt; for all new website I discover, before fetching any deeper urls.\n&gt;\n&gt; I think the way to increase/decrease priority is by using\n&gt; UriPrecedencePolicy, but I don&#39;t know how and when to insert/schedule\n&gt; the &quot;fetch that root url&quot; prerequisite...\n\nYou won&#39;t need to use the &#39;precedence policy&#39; facility, unless you need \nto do fine-grained prioritization, with many tiers.\n\nThere is an existing option to automatically infer that the root page of \nevery discovered URI should also sent to the frontier for crawling. It&#39;s \nthe &#39;inferRootPage&#39; parameter (default false) on the &#39;ExtractorHTTP&#39; \ncomponent. If &#39;true&#39;, every URI crawled will be presumed to have an \nimplied outlink to the root URI of the same domain. So, the root URI \nwill be presented to the frontier along with an other outlinks on the \npage, and enqueued if novel.\n\nUnfortunately this only acts when the triggering HTTP URI is fetched \n(and thus the ExtractorHTTP component is run, along with the other \nextractors, on some response). And, this &#39;inferred&#39; root URI is given a \ndiscovery hop-type of &#39;I&#39; -- this mixes it with other inline-like items, \nso it will be crawled *before* other navigational outlinks (&quot;A HREF&quot; - \nhop-type &#39;L&#39;) on the same page, but mixed in with (and perhaps after) \nother transitive outlinks (&quot;IMG SRC&quot;, &quot;FRAME SRC&quot;, etc).\n\nPerhaps this is good enough - the root page will be fetched very early \namong a site&#39;s pages, but not necessarily &#39;first&#39;.\n\nIf that isn&#39;t enough, you&#39;ll have to write some custom code. I think the \nbest approach would be to write something like the ExtractorHTTP, or \nImpliedURIExtractor, but triggering off an earlier step. You wouldn&#39;t \nhave to write this new behavior in a compiled Java class; using the \nScriptedProcessor, you could supply a javascript/groovy/beanshell script \nas text, inside your crawl configuration\n\nI would suggest this script look for the domain&#39;s /robots.txt URI fetch. \n(That&#39;s always triggered, via an explicit prerequisite mechanism, before \nany other URIs from a domain are fetched.) When it sees such a fetch, it \ncould add the root page as an inferred outlink, just like ExtractorHTTP \ndoes. But, it would also give it an additional marking to promote it \nahead of other URIs already on the same domain queue. Using \nCrawlURI.setSchedulingDirective(SchedulingConstants.HIGH) on that \noutlink CrawlURI would probably do the trick.\n\n- Gordon\n\n"}}