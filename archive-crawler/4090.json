{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"uFdyWlcwZe_TNzjQcOarLyqNU7KurCWtJNmIbppTy-lYjB5yWjRRegxv3AjLXvrc5MENvKTjx_VNf_ue3VUgyd_g_33yub8","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Not excluding images and not creating arc file","postDate":"1176315024","msgId":4090,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ2MUQyNDkwLjcwNzA3QGFyY2hpdmUub3JnPg==","inReplyToHeader":"PGV2aWdraCthN2gyQGVHcm91cHMuY29tPg==","referencesHeader":"PGV2aWdraCthN2gyQGVHcm91cHMuY29tPg=="},"prevInTopic":4086,"nextInTopic":4100,"prevInTime":4089,"nextInTime":4091,"topicId":4086,"numMessagesInTopic":3,"msgSnippet":"Sounds like the symptom of your current configuration is: nothing is being crawled. That s suggestive that all URIs are being rejected. I see that you have a","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 91683 invoked from network); 11 Apr 2007 18:10:12 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m45.grp.scd.yahoo.com with QMQP; 11 Apr 2007 18:10:12 -0000\r\nReceived: from unknown (HELO mail.archive.org) (207.241.233.246)\n  by mta5.grp.scd.yahoo.com with SMTP; 11 Apr 2007 18:10:12 -0000\r\nReceived: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id 662481415FF4E\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Wed, 11 Apr 2007 11:07:53 -0700 (PDT)\r\nReceived: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id 19596-04-48 for &lt;archive-crawler@yahoogroups.com&gt;;\n\tWed, 11 Apr 2007 11:07:52 -0700 (PDT)\r\nReceived: from [192.168.1.203] (c-76-102-230-209.hsd1.ca.comcast.net [76.102.230.209])\n\tby mail.archive.org (Postfix) with ESMTP id 990341415FF38\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Wed, 11 Apr 2007 11:07:52 -0700 (PDT)\r\nMessage-ID: &lt;461D2490.70707@...&gt;\r\nDate: Wed, 11 Apr 2007 11:10:24 -0700\r\nUser-Agent: Thunderbird 1.5.0.10 (X11/20070306)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;evigkh+a7h2@...&gt;\r\nIn-Reply-To: &lt;evigkh+a7h2@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Virus-Scanned: Debian amavisd-new at archive.org\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Not excluding images and not creating arc file\r\nX-Yahoo-Group-Post: member; u=137285340; y=B4aegWvBoiqf85c8h1SHjxWn_07XlaSJH6-DpcR5UKzW\r\nX-Yahoo-Profile: gojomo\r\n\r\nSounds like the symptom of your current configuration is: nothing is \nbeing crawled.\n\nThat&#39;s suggestive that all URIs are being rejected.\n\nI see that you have a REJECTing SurtPrefixedDecideRule in the \nall-powerful last DecideRule position. I suspect its &#39;surt.txt&#39; is \nrejecting all your URIs of interest. (Note that the SurtPrefix rules \ndon&#39;t take general wildcard expressions.)\n\nTry adding a filename to the &#39;surts-dump-file&#39; setting of that same \nSurtPrefixedDecideRule, so you can see the SURT prefixes actually being \nused for rejection.\n\nContentTypeMatchesRegExpDecideRule only applies against the actual \n&#39;Content-Type&#39; of a fetched URI -- so by the time it can do anything, \nthe URI is already fetched. (The best it could do is mid-fetch abort or \nprevent a extracting/writing processor from running, if placed in the \nright place.)\n\nYou probably want to use the MatchesFilePatternDecideRule, which matches \nagainst the URI, so can be used in your general crawl scope. If you \nsimply use the preconfigured &#39;all&#39; pattern, all common non-HTML media \nfile-extensions will be matched.\n\nHope this helps,\n\n- Gordon @ IA\n\nfandufunkyman wrote:\n&gt; hi friend ,\n&gt; \n&gt; I&#39;m gving my order.xml and want to exclude images using filter but is is\n&gt; not excluding images and also not creating arc file.if i remove that\n&gt; filter then it work. I also tried it with ContentTypeRegExpFilter but it\n&gt; was not excluding images but creating arc file.\n&gt; i&#39;m not getting where i&#39;m wrong.\n&gt; this is my order.xml\n&gt; \n&gt; &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;crawl-order\n&gt; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\n&gt; xsi:noNamespaceSchemaLocation=&quot;heritrix_settings.xsd&quot;&gt;\n&gt;    &lt;meta&gt;\n&gt;      &lt;name&gt;default&lt;/name&gt;\n&gt;      &lt;description&gt;Default Profile&lt;/description&gt;\n&gt;      &lt;operator&gt;Admin&lt;/operator&gt;\n&gt;      &lt;organization&gt;&lt;/organization&gt;\n&gt;      &lt;audience&gt;&lt;/audience&gt;\n&gt;      &lt;date&gt;20050412015243&lt;/date&gt;\n&gt;    &lt;/meta&gt;\n&gt;    &lt;controller&gt;\n&gt;      &lt;string name=&quot;settings-directory&quot;&gt;settings&lt;/string&gt;\n&gt;      &lt;string name=&quot;disk-path&quot;&gt;&lt;/string&gt;\n&gt;      &lt;string name=&quot;logs-path&quot;&gt;logs&lt;/string&gt;\n&gt;      &lt;string name=&quot;checkpoints-path&quot;&gt;checkpoints&lt;/string&gt;\n&gt;      &lt;string name=&quot;state-path&quot;&gt;state&lt;/string&gt;\n&gt;      &lt;string name=&quot;scratch-path&quot;&gt;scratch&lt;/string&gt;\n&gt;      &lt;long name=&quot;max-bytes-download&quot;&gt;0&lt;/long&gt;\n&gt;      &lt;long name=&quot;max-document-download&quot;&gt;0&lt;/long&gt;\n&gt;      &lt;long name=&quot;max-time-sec&quot;&gt;0&lt;/long&gt;\n&gt;      &lt;integer name=&quot;max-toe-threads&quot;&gt;50&lt;/integer&gt;\n&gt;      &lt;integer name=&quot;recorder-out-buffer-bytes&quot;&gt;4096&lt;/integer&gt;\n&gt;      &lt;integer name=&quot;recorder-in-buffer-bytes&quot;&gt;65536&lt;/integer&gt;\n&gt;      &lt;integer name=&quot;bdb-cache-percent&quot;&gt;0&lt;/integer&gt;\n&gt;      &lt;newObject name=&quot;scope&quot;\n&gt; class=&quot;org.archive.crawler.deciderules.DecidingScope&quot;&gt;\n&gt;        &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;string name=&quot;seedsfile&quot;&gt;seeds.txt&lt;/string&gt;\n&gt;         &lt;newObject name=&quot;decide-rules&quot;\n&gt; class=&quot;org.archive.crawler.deciderules.DecideRuleSequence&quot;&gt;\n&gt;          &lt;map name=&quot;rules&quot;&gt;\n&gt;            &lt;newObject name=&quot;rejectByDefault&quot;\n&gt; class=&quot;org.archive.crawler.deciderules.RejectDecideRule&quot;&gt;\n&gt;            &lt;/newObject&gt;\n&gt; \n&gt;               &lt;newObject name=&quot;acceptIfSurtPrefixed&quot;\n&gt; class=&quot;org.archive.crawler.deciderules.SurtPrefixedDecideRule&quot;&gt;\n&gt;                  &lt;string name=&quot;decision&quot;&gt;ACCEPT&lt;/string&gt;\n&gt;                  &lt;string name=&quot;surts-source-file&quot;&gt;&lt;/string&gt;\n&gt;                  &lt;boolean name=&quot;seeds-as-surt-prefixes&quot;&gt;true&lt;/boolean&gt;\n&gt;                  &lt;string name=&quot;surts-dump-file&quot;&gt;&lt;/string&gt;\n&gt;            &lt;/newObject&gt;\n&gt;            &lt;newObject name=&quot;rejectIfTooManyHops&quot;\n&gt; class=&quot;org.archive.crawler.deciderules.TooManyHopsDecideRule&quot;&gt;\n&gt;              &lt;integer name=&quot;max-hops&quot;&gt;20&lt;/integer&gt;\n&gt;            &lt;/newObject&gt;\n&gt;            &lt;newObject name=&quot;acceptIfTranscluded&quot;\n&gt; class=&quot;org.archive.crawler.deciderules.TransclusionDecideRule&quot;&gt;\n&gt;              &lt;integer name=&quot;max-trans-hops&quot;&gt;0&lt;/integer&gt;\n&gt;            &lt;/newObject&gt;\n&gt;            &lt;newObject name=&quot;rejectIfPathological&quot;\n&gt; class=&quot;org.archive.crawler.deciderules.PathologicalPathDecideRule&quot;&gt;\n&gt;              &lt;integer name=&quot;max-repetitions&quot;&gt;2&lt;/integer&gt;\n&gt;            &lt;/newObject&gt;\n&gt;            &lt;newObject name=&quot;rejectIfTooManyPathSegs&quot;\n&gt; class=&quot;org.archive.crawler.deciderules.TooManyPathSegmentsDecideRule&quot;&gt;\n&gt;              &lt;integer name=&quot;max-path-depth&quot;&gt;20&lt;/integer&gt;\n&gt;            &lt;/newObject&gt;\n&gt;            &lt;newObject name=&quot;acceptIfPrerequisite&quot;\n&gt; class=&quot;org.archive.crawler.deciderules.PrerequisiteAcceptDecideRule&quot;&gt;\n&gt;            &lt;/newObject&gt;\n&gt;            &lt;newObject name=&quot;rejectIfSurtPrefixed&quot;\n&gt; class=&quot;org.archive.crawler.deciderules.SurtPrefixedDecideRule&quot;&gt;\n&gt;                        &lt;string name=&quot;decision&quot;&gt;REJECT&lt;/string&gt;\n&gt;                        &lt;string name=&quot;surts-source-file&quot;&gt;surt.txt&lt;/string&gt;\n&gt;                        &lt;boolean\n&gt; name=&quot;seeds-as-surt-prefixes&quot;&gt;false&lt;/boolean&gt;\n&gt;                        &lt;string name=&quot;surts-dump-file&quot;&gt;&lt;/string&gt;\n&gt;            &lt;/newObject&gt;\n&gt;          &lt;/map&gt;\n&gt;        &lt;/newObject&gt;\n&gt;      &lt;/newObject&gt;\n&gt;      &lt;map name=&quot;http-headers&quot;&gt;\n&gt;        &lt;string name=&quot;user-agent&quot;&gt;Mozilla/5.0 (compatible; heritrix/1.10.1\n&gt; +http://www.abc.com/)&lt;/string&gt;\n&gt;        &lt;string name=&quot;from&quot;&gt;abc@...&lt;/string&gt;\n&gt;      &lt;/map&gt;\n&gt;      &lt;newObject name=&quot;robots-honoring-policy&quot;\n&gt; class=&quot;org.archive.crawler.datamodel.RobotsHonoringPolicy&quot;&gt;\n&gt;        &lt;string name=&quot;type&quot;&gt;classic&lt;/string&gt;\n&gt;        &lt;boolean name=&quot;masquerade&quot;&gt;false&lt;/boolean&gt;\n&gt;        &lt;text name=&quot;custom-robots&quot;&gt;&lt;/text&gt;\n&gt;        &lt;stringList name=&quot;user-agents&quot;&gt;\n&gt;        &lt;/stringList&gt;\n&gt;      &lt;/newObject&gt;\n&gt;      &lt;newObject name=&quot;frontier&quot;\n&gt; class=&quot;org.archive.crawler.frontier.BdbFrontier&quot;&gt;\n&gt;        &lt;float name=&quot;delay-factor&quot;&gt;4.0&lt;/float&gt;\n&gt;        &lt;integer name=&quot;max-delay-ms&quot;&gt;20000&lt;/integer&gt;\n&gt;        &lt;integer name=&quot;min-delay-ms&quot;&gt;2000&lt;/integer&gt;\n&gt;        &lt;integer name=&quot;max-retries&quot;&gt;30&lt;/integer&gt;\n&gt;        &lt;long name=&quot;retry-delay-seconds&quot;&gt;900&lt;/long&gt;\n&gt;        &lt;integer name=&quot;preference-embed-hops&quot;&gt;1&lt;/integer&gt;\n&gt;        &lt;integer name=&quot;total-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt;        &lt;integer name=&quot;max-per-host-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt;        &lt;string name=&quot;force-queue-assignment&quot;&gt;&lt;/string&gt;\n&gt;        &lt;boolean name=&quot;pause-at-finish&quot;&gt;false&lt;/boolean&gt;\n&gt;        &lt;boolean name=&quot;hold-queues&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;integer name=&quot;balance-replenish-amount&quot;&gt;3000&lt;/integer&gt;\n&gt;        &lt;long name=&quot;queue-total-budget&quot;&gt;-1&lt;/long&gt;\n&gt;        &lt;string\n&gt; name=&quot;cost-policy&quot;&gt;org.archive.crawler.frontier.ZeroCostAssignmentPolicy&#92;\n&gt; &lt;/string&gt;\n&gt;      &lt;/newObject&gt;\n&gt;      &lt;map name=&quot;uri-canonicalization-rules&quot;&gt;\n&gt;        &lt;newObject name=&quot;Lowercase&quot;\n&gt; class=&quot;org.archive.crawler.url.canonicalize.LowercaseRule&quot;&gt;\n&gt;          &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;/newObject&gt;\n&gt;        &lt;newObject name=&quot;Userinfo&quot;\n&gt; class=&quot;org.archive.crawler.url.canonicalize.StripUserinfoRule&quot;&gt;\n&gt;          &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;/newObject&gt;\n&gt;        &lt;newObject name=&quot;WWW[0-9]*&quot;\n&gt;          class=&quot;org.archive.crawler.url.canonicalize.StripWWWNRule&quot;&gt;\n&gt;          &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;/newObject&gt;\n&gt;        &lt;newObject name=&quot;SessionIDs&quot;\n&gt; class=&quot;org.archive.crawler.url.canonicalize.StripSessionIDs&quot;&gt;\n&gt;          &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;/newObject&gt;\n&gt;        &lt;newObject name=&quot;SessionCFIDs&quot;\n&gt;          class=&quot;org.archive.crawler.url.canonicalize.StripSessionCFIDs&quot;&gt;\n&gt;          &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;/newObject&gt;\n&gt;        &lt;newObject name=&quot;QueryStrPrefix&quot;\n&gt; class=&quot;org.archive.crawler.url.canonicalize.FixupQueryStr&quot;&gt;\n&gt;          &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;/newObject&gt;\n&gt;      &lt;/map&gt;\n&gt;      &lt;map name=&quot;pre-fetch-processors&quot;&gt;\n&gt;        &lt;newObject name=&quot;Preselector&quot;\n&gt; class=&quot;org.archive.crawler.prefetch.Preselector&quot;&gt;\n&gt;          &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;          &lt;map name=&quot;filters&quot;&gt;\n&gt;          &lt;/map&gt;\n&gt;          &lt;boolean name=&quot;recheck-scope&quot;&gt;true&lt;/boolean&gt;\n&gt;          &lt;boolean name=&quot;block-all&quot;&gt;false&lt;/boolean&gt;\n&gt;          &lt;string name=&quot;block-by-regexp&quot;&gt;&lt;/string&gt;\n&gt;        &lt;/newObject&gt;\n&gt;        &lt;newObject name=&quot;Preprocessor&quot;\n&gt; class=&quot;org.archive.crawler.prefetch.PreconditionEnforcer&quot;&gt;\n&gt;          &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;          &lt;map name=&quot;filters&quot;&gt;\n&gt;          &lt;/map&gt;\n&gt;          &lt;integer name=&quot;ip-validity-duration-seconds&quot;&gt;21600&lt;/integer&gt;\n&gt;          &lt;integer name=&quot;robot-validity-duration-seconds&quot;&gt;86400&lt;/integer&gt;\n&gt;        &lt;/newObject&gt;\n&gt;      &lt;/map&gt;\n&gt;      &lt;map name=&quot;fetch-processors&quot;&gt;\n&gt;        &lt;newObject name=&quot;DNS&quot;\n&gt; class=&quot;org.archive.crawler.fetcher.FetchDNS&quot;&gt;\n&gt;          &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;          &lt;map name=&quot;filters&quot;&gt;\n&gt;          &lt;/map&gt;\n&gt;          &lt;boolean name=&quot;accept-non-dns-resolves&quot;&gt;false&lt;/boolean&gt;\n&gt;        &lt;/newObject&gt;\n&gt;        &lt;newObject name=&quot;HTTP&quot;\n&gt; class=&quot;org.archive.crawler.fetcher.FetchHTTP&quot;&gt;\n&gt;          &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;          &lt;map name=&quot;filters&quot;&gt;\n&gt;          &lt;/map&gt;\n&gt;          &lt;map name=&quot;midfetch-filters&quot;&gt;\n&gt;          &lt;/map&gt;\n&gt;          &lt;integer name=&quot;timeout-seconds&quot;&gt;1200&lt;/integer&gt;\n&gt;          &lt;integer name=&quot;sotimeout-ms&quot;&gt;20000&lt;/integer&gt;\n&gt;          &lt;long name=&quot;max-length-bytes&quot;&gt;0&lt;/long&gt;\n&gt;          &lt;string name=&quot;load-cookies-from-file&quot;&gt;&lt;/string&gt;\n&gt;          &lt;string name=&quot;save-cookies-to-file&quot;&gt;&lt;/string&gt;\n&gt;          &lt;string name=&quot;trust-level&quot;&gt;open&lt;/string&gt;\n&gt;          &lt;stringList name=&quot;accept-headers&quot;&gt;\n&gt;          &lt;/stringList&gt;\n&gt;          &lt;string name=&quot;http-proxy-host&quot;&gt;&lt;/string&gt;\n&gt;          &lt;string name=&quot;http-proxy-port&quot;&gt;&lt;/string&gt;\n&gt;          &lt;string name=&quot;default-encoding&quot;&gt;ISO-8859-1&lt;/string&gt;\n&gt;          &lt;boolean name=&quot;sha1-content&quot;&gt;true&lt;/boolean&gt;\n&gt;          &lt;boolean name=&quot;send-connection-close&quot;&gt;true&lt;/boolean&gt;\n&gt;          &lt;boolean name=&quot;send-referer&quot;&gt;true&lt;/boolean&gt;\n&gt;          &lt;boolean name=&quot;send-range&quot;&gt;false&lt;/boolean&gt;\n&gt;        &lt;/newObject&gt;\n&gt;      &lt;/map&gt;\n&gt;      &lt;map name=&quot;extract-processors&quot;&gt;\n&gt;        &lt;newObject name=&quot;ExtractorHTTP&quot;\n&gt; class=&quot;org.archive.crawler.extractor.ExtractorHTTP&quot;&gt;\n&gt;          &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;          &lt;map name=&quot;filters&quot;&gt;\n&gt;          &lt;/map&gt;\n&gt;        &lt;/newObject&gt;\n&gt;        &lt;newObject name=&quot;ExtractorHTML&quot;\n&gt; class=&quot;org.archive.crawler.extractor.ExtractorHTML&quot;&gt;\n&gt;          &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;          &lt;map name=&quot;filters&quot;&gt;\n&gt;          &lt;/map&gt;\n&gt;        &lt;/newObject&gt;\n&gt;        &lt;newObject name=&quot;ExtractorCSS&quot;\n&gt; class=&quot;org.archive.crawler.extractor.ExtractorCSS&quot;&gt;\n&gt;          &lt;boolean name=&quot;enabled&quot;&gt;false&lt;/boolean&gt;\n&gt;          &lt;map name=&quot;filters&quot;&gt;\n&gt;          &lt;/map&gt;\n&gt;        &lt;/newObject&gt;\n&gt;        &lt;newObject name=&quot;ExtractorJS&quot;\n&gt; class=&quot;org.archive.crawler.extractor.ExtractorJS&quot;&gt;\n&gt;          &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;          &lt;map name=&quot;filters&quot;&gt;\n&gt;          &lt;/map&gt;\n&gt;        &lt;/newObject&gt;\n&gt;        &lt;newObject name=&quot;ExtractorSWF&quot;\n&gt; class=&quot;org.archive.crawler.extractor.ExtractorSWF&quot;&gt;\n&gt;          &lt;boolean name=&quot;enabled&quot;&gt;false&lt;/boolean&gt;\n&gt;          &lt;map name=&quot;filters&quot;&gt;\n&gt;          &lt;/map&gt;\n&gt;        &lt;/newObject&gt;\n&gt;      &lt;/map&gt;\n&gt;      &lt;map name=&quot;write-processors&quot;&gt;\n&gt;        &lt;newObject name=&quot;Archiver&quot;\n&gt; class=&quot;org.archive.crawler.writer.ARCWriterProcessor&quot;&gt;\n&gt;          &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;map name=&quot;filters&quot;&gt;\n&gt;         &lt;newObject name=&quot;NoImages&quot;\n&gt;          class=&quot;org.archive.crawler.filter.URIRegExpFilter&quot;&gt;\n&gt;         &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;boolean name=&quot;if-match-return&quot;&gt;true&lt;/boolean&gt;\n&gt;         &lt;string\n&gt; name=&quot;regexp&quot;&gt;^.*(?i)&#92;.(bin|dmg|iso|tar&#92;.gz|tar&#92;.bz2|sit|hqx|xls|qt|dvi|&#92;\n&gt; zip|rpm|rtf|bmp|gif|jp&#92;\n&gt; e?g|png|pdf|tiff?|mid|mp[2-4]|wav|avi|mov|mpe?g|ram|rm|smil|wmv|doc|ppt|&#92;\n&gt; swf)$&lt;/string&gt;\n&gt;         &lt;/newObject&gt;\n&gt;         &lt;/map&gt;\n&gt;          &lt;boolean name=&quot;compress&quot;&gt;true&lt;/boolean&gt;\n&gt;          &lt;string name=&quot;prefix&quot;&gt;IAH&lt;/string&gt;\n&gt;          &lt;string name=&quot;suffix&quot;&gt;${HOSTNAME}&lt;/string&gt;\n&gt;          &lt;integer name=&quot;max-size-bytes&quot;&gt;100000000&lt;/integer&gt;\n&gt;          &lt;stringList name=&quot;path&quot;&gt;\n&gt;            &lt;string&gt;arcs&lt;/string&gt;\n&gt;          &lt;/stringList&gt;\n&gt;          &lt;integer name=&quot;pool-max-active&quot;&gt;5&lt;/integer&gt;\n&gt;          &lt;integer name=&quot;pool-max-wait&quot;&gt;300000&lt;/integer&gt;\n&gt;          &lt;long name=&quot;total-bytes-to-write&quot;&gt;0&lt;/long&gt;\n&gt;        &lt;/newObject&gt;\n&gt;      &lt;/map&gt;\n&gt;      &lt;map name=&quot;post-processors&quot;&gt;\n&gt;        &lt;newObject name=&quot;Updater&quot;\n&gt; class=&quot;org.archive.crawler.postprocessor.CrawlStateUpdater&quot;&gt;\n&gt;          &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;          &lt;map name=&quot;filters&quot;&gt;\n&gt;          &lt;/map&gt;\n&gt;        &lt;/newObject&gt;\n&gt;        &lt;newObject name=&quot;LinksScoper&quot;\n&gt;              class=&quot;org.archive.crawler.postprocessor.LinksScoper&quot;&gt;\n&gt;          &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;          &lt;map name=&quot;filters&quot;&gt;\n&gt;          &lt;/map&gt;\n&gt;          &lt;boolean name=&quot;seed-redirects-new-seed&quot;&gt;true&lt;/boolean&gt;\n&gt;          &lt;boolean name=&quot;override-logger&quot;&gt;false&lt;/boolean&gt;\n&gt;          &lt;map name=&quot;scope-rejected-url-filters&quot;&gt;\n&gt;          &lt;/map&gt;\n&gt;        &lt;/newObject&gt;\n&gt;        &lt;newObject name=&quot;Scheduler&quot;\n&gt;              class=&quot;org.archive.crawler.postprocessor.FrontierScheduler&quot;&gt;\n&gt;          &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;        &lt;/newObject&gt;\n&gt;      &lt;/map&gt;\n&gt;      &lt;map name=&quot;loggers&quot;&gt;\n&gt;        &lt;newObject name=&quot;crawl-statistics&quot;\n&gt; class=&quot;org.archive.crawler.admin.StatisticsTracker&quot;&gt;\n&gt;          &lt;integer name=&quot;interval-seconds&quot;&gt;20&lt;/integer&gt;\n&gt;        &lt;/newObject&gt;\n&gt;      &lt;/map&gt;\n&gt;      &lt;string name=&quot;recover-path&quot;&gt;&lt;/string&gt;\n&gt;      &lt;boolean name=&quot;recover-retain-failures&quot;&gt;false&lt;/boolean&gt;\n&gt;      &lt;newObject name=&quot;credential-store&quot;\n&gt; class=&quot;org.archive.crawler.datamodel.CredentialStore&quot;&gt;\n&gt;        &lt;map name=&quot;credentials&quot;&gt;\n&gt;        &lt;/map&gt;\n&gt;      &lt;/newObject&gt;\n&gt;    &lt;/controller&gt;\n&gt; &lt;/crawl-order&gt;\n&gt; \n&gt; \n&gt; \n\n\n"}}