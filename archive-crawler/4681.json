{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":132996324,"authorName":"joehung302","from":"&quot;joehung302&quot; &lt;joe.hung@...&gt;","profile":"joehung302","replyTo":"LIST","senderId":"errCh8sivNKuLqi2m78TulMONx1F7GiaTMhYrji59aW5vJpKRQcIBOozxrHY_i_tidtV5aVhyBQL6Qnh7Fp_c9vwYitMBRV3tyXNVbcl","spamInfo":{"isSpam":false,"reason":"6"},"subject":"How to configure &quot;domain + 1&quot; crawl?","postDate":"1195064785","msgId":4681,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGZoZmVraCtoYmx1QGVHcm91cHMuY29tPg=="},"prevInTopic":0,"nextInTopic":4682,"prevInTime":4680,"nextInTime":4682,"topicId":4681,"numMessagesInTopic":3,"msgSnippet":"The idea is like this. For example, if the seed list is cnn.com, we want to get every page under cnn.com, and every link that goes out of cnn.com...but only","rawEmail":"Return-Path: &lt;joe.hung@...&gt;\r\nX-Sender: joe.hung@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 79387 invoked from network); 14 Nov 2007 18:26:27 -0000\r\nX-Received: from unknown (66.218.67.96)\n  by m48.grp.scd.yahoo.com with QMQP; 14 Nov 2007 18:26:27 -0000\r\nX-Received: from unknown (HELO n50c.bullet.mail.sp1.yahoo.com) (66.163.168.184)\n  by mta17.grp.scd.yahoo.com with SMTP; 14 Nov 2007 18:26:27 -0000\r\nX-Received: from [216.252.122.218] by n50.bullet.mail.sp1.yahoo.com with NNFMP; 14 Nov 2007 18:26:27 -0000\r\nX-Received: from [66.218.69.5] by t3.bullet.sp1.yahoo.com with NNFMP; 14 Nov 2007 18:26:27 -0000\r\nX-Received: from [66.218.67.199] by t5.bullet.scd.yahoo.com with NNFMP; 14 Nov 2007 18:26:26 -0000\r\nDate: Wed, 14 Nov 2007 18:26:25 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;fhfekh+hblu@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: &quot;joehung302&quot; &lt;joe.hung@...&gt;\r\nSubject: How to configure &quot;domain + 1&quot; crawl?\r\nX-Yahoo-Group-Post: member; u=132996324; y=0XkmH9F5wKI_M0FKaOO9EQTD6GLLQKP6yvjUV3aUiTNwrqGpYQ\r\nX-Yahoo-Profile: joehung302\r\n\r\nThe idea is like this. For example, if the seed list is cnn.com, we \nwant t=\r\no get every page under cnn.com, and every link that goes out of \ncnn.com...=\r\nbut only one level deep for all the outgoing links.\n\nIs it possible to conf=\r\nigure Heritrix to crawl this way?\n\nCheers,\n-Joe\n\n\n\n"}}