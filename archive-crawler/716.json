{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":191507321,"authorName":"robeger","from":"&quot;robeger&quot; &lt;reger@...&gt;","profile":"robeger","replyTo":"LIST","senderId":"9n-7PrXCnt-GOsECYeCM_WPChE9g5DYgisksDJrfJ0BavpNgVpTYexLae7QKERhQ6XzSWEGBTsmkxENNu6dlvGlu","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: Limit crawling to Markup?","postDate":"1090951672","msgId":716,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGNlNjVsbytxdTJlQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDQxMDY5NUNELjYwNTA1MDJAYXJjaGl2ZS5vcmc+"},"prevInTopic":715,"nextInTopic":717,"prevInTime":715,"nextInTime":717,"topicId":705,"numMessagesInTopic":11,"msgSnippet":"Hi Igor, I just started looking at the URIRegExp filter too.  Thanks for the regex for it.  We re mostly interested (at this point) at textual content, not","rawEmail":"Return-Path: &lt;reger@...&gt;\r\nX-Sender: reger@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 67184 invoked from network); 27 Jul 2004 18:07:59 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m24.grp.scd.yahoo.com with QMQP; 27 Jul 2004 18:07:59 -0000\r\nReceived: from unknown (HELO n25.grp.scd.yahoo.com) (66.218.66.81)\n  by mta2.grp.scd.yahoo.com with SMTP; 27 Jul 2004 18:07:59 -0000\r\nReceived: from [66.218.67.176] by n25.grp.scd.yahoo.com with NNFMP; 27 Jul 2004 18:07:53 -0000\r\nDate: Tue, 27 Jul 2004 18:07:52 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;ce65lo+qu2e@...&gt;\r\nIn-Reply-To: &lt;410695CD.6050502@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=ISO-8859-1\r\nContent-Length: 2654\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-eGroups-Remote-IP: 66.218.66.81\r\nFrom: &quot;robeger&quot; &lt;reger@...&gt;\r\nSubject: Re: Limit crawling to Markup?\r\nX-Yahoo-Group-Post: member; u=191507321\r\nX-Yahoo-Profile: robeger\r\n\r\nHi Igor,\n\nI just started looking at the URIRegExp filter too.  Thanks for the\nregex for it.  We&#39;re mostly interested (at this point) at textual\ncontent, not images, so I wanted to figure out how to exclude images,\naudio, etc. to save disk space and bandwidth.  Also, just for the\npurpose of gaining a better understanding of Heritrix and how to use it.\n\nThanks,\nRob.\n\n--- In archive-crawler@yahoogroups.com, Igor Ranitovic &lt;igor@a...&gt; wrote:\n&gt; Hi Rob,\n&gt; \n&gt; If you think that filtering out URLs that don&#39;t look like html pages\nis good enough for your needs \n&gt; than you can just simple add URIRegExp exclude filter:\n&gt;\n^.*(?i)(&#92;&#92;.(bmp|gif|jpe?g|png|tiff|mid|mp2|mp3|mp4|wav|avi|mov|mpeg|ram|rm|smil|wmv|doc|pdf|ppt|swf)$\n&gt; \n&gt; Keep in mind that are many URLs out there that are not html pages\nand don&#39;t end with any generic \n&gt; suffix. For example:\n&gt;\nhttp://multi1.rmuk.co.uk/RealMedia/ads/adstream_nx.ads/www.pm.gov.uk/homepage@Top!Top\n&gt; is an image. Without examining HTTP Content-Type header it would be\nextremely hard to write any \n&gt; generic URL based filters to exclude these non-html pages.\n&gt; \n&gt; Take care,\n&gt; i.\n&gt; \n&gt; &gt; I guess I&#39;m somewhat confused because I was thinking that the\n&gt; &gt; additionalScopeFocus filter could be used for something like this,\n&gt; &gt; basically by having it return false instead of true, which I was\n&gt; &gt; thinking would cause the URI to be left out of the scope.  Admittedly\n&gt; &gt; my initial efforts at leaving out images, audio, etc. this way haven&#39;t\n&gt; &gt; worked, but I hadn&#39;t gotten around to asking about it here.  So, now\n&gt; &gt; I&#39;m asking.  \n&gt; &gt; \n&gt; &gt; Thanks,\n&gt; &gt; Rob Eger\n&gt; &gt; Aptas, Inc.\n&gt; &gt; \n&gt; &gt; --- In archive-crawler@yahoogroups.com, stack &lt;stack@a...&gt; wrote:\n&gt; &gt; \n&gt; &gt;&gt;Ahnu Nahki wrote:\n&gt; &gt;&gt;\n&gt; &gt;&gt;\n&gt; &gt;&gt;&gt;Is there a way to only have heritrix downloaded all text/html markup\n&gt; &gt;&gt;&gt;and disregard altogether images and other binaries. I notice that\nthis\n&gt; &gt;&gt;&gt;eats up alot of time on our crawls.\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;Thanks,\n&gt; &gt;&gt;&gt;Ahnu\n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;\n&gt; &gt;&gt;This topic has been discussed variously here on the list.  You might \n&gt; &gt;&gt;check the archive.\n&gt; &gt;&gt;\n&gt; &gt;&gt;In short, not without doing some work.  Lesser work would be a filter \n&gt; &gt;&gt;that skipped non-text/html content after download.  More work would\n&gt; &gt; \n&gt; &gt; be a \n&gt; &gt; \n&gt; &gt;&gt;check that interrupted crawls mid-download if the type was other than \n&gt; &gt;&gt;what you wanted. \n&gt; &gt;&gt;\n&gt; &gt;&gt;Though sub-optimal, you could try and write a regex that only\nexcludes \n&gt; &gt;&gt;resources with URIs that match a particular pattern.\n&gt; &gt;&gt;\n&gt; &gt;&gt;St.Ack\n&gt; &gt;&gt;\n&gt; &gt;&gt;\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;Yahoo! Groups Links\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt;\n&gt; &gt;&gt;&gt; \n&gt; &gt;&gt;&gt;\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt;  \n&gt; &gt; Yahoo! Groups Links\n&gt; &gt; \n&gt; &gt; \n&gt; &gt; \n&gt; &gt;  \n&gt; &gt;\n\n\n"}}