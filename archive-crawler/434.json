{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":163406187,"authorName":"Kristinn Sigurdsson","from":"&quot;Kristinn Sigurdsson&quot; &lt;kris@...&gt;","profile":"kristsi25","replyTo":"LIST","senderId":"0QVhprvjY0_uDUP3WZvevcCJUXwimlmUXcqrTLGRaiYVpmXrZe6t5waebrGJ8Ek9QKoxbJ9iE-A7ADjri0swtfXXEI2PlcuxCi6rwvedJw","spamInfo":{"isSpam":false,"reason":"0"},"subject":"RE: [archive-crawler] Large scale crawling with Heritrix","postDate":"1085154418","msgId":434,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PEQ5NTgxMTBCMjczQ0Q1MTFBQ0MxMDBCMEQwNzlBQTRFMDE5NjBDNzNAbG9raS5ib2suaGkuaXM+","inReplyToHeader":"PEQ5NTgxMTBCMjczQ0Q1MTFBQ0MxMDBCMEQwNzlBQTRFMDI2NUVFNTJAbG9raS5ib2suaGkuaXM+"},"prevInTopic":433,"nextInTopic":439,"prevInTime":433,"nextInTime":435,"topicId":432,"numMessagesInTopic":9,"msgSnippet":"... interspersed... ... No stuck threads. I was actually a little surprised by that but no thread has been running for more then a few minutes. ... take ... ","rawEmail":"Return-Path: &lt;kris@...&gt;\r\nX-Sender: kris@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 23086 invoked from network); 21 May 2004 15:47:08 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m23.grp.scd.yahoo.com with QMQP; 21 May 2004 15:47:08 -0000\r\nReceived: from unknown (HELO ia00524.archive.org) (209.237.232.202)\n  by mta6.grp.scd.yahoo.com with SMTP; 21 May 2004 15:47:08 -0000\r\nReceived: (qmail 25362 invoked by uid 100); 21 May 2004 15:40:14 -0000\r\nReceived: from forritun-4.bok.hi.is (HELO forritun4) (130.208.152.83)\n  by mail-dev.archive.org with SMTP; 21 May 2004 15:40:14 -0000\r\nTo: &lt;archive-crawler@yahoogroups.com&gt;\r\nDate: Fri, 21 May 2004 15:46:58 -0000\r\nMessage-ID: &lt;D958110B273CD511ACC100B0D079AA4E01960C73@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: text/plain;\n\tcharset=&quot;iso-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Priority: 3 (Normal)\r\nX-MSMail-Priority: Normal\r\nX-Mailer: Microsoft Outlook, Build 10.0.4510\r\nImportance: Normal\r\nIn-Reply-To: &lt;D958110B273CD511ACC100B0D079AA4E0265EE52@...&gt;\r\nX-MimeOLE: Produced By Microsoft MimeOLE V6.00.2800.1409\r\nX-Spam-DCC: : \r\nX-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on ia00524.archive.org\r\nX-Spam-Level: \r\nX-Spam-Status: No, hits=0.6 required=6.0 tests=AWL autolearn=ham version=2.63\r\nX-eGroups-Remote-IP: 209.237.232.202\r\nFrom: &quot;Kristinn Sigurdsson&quot; &lt;kris@...&gt;\r\nSubject: RE: [archive-crawler] Large scale crawling with Heritrix\r\nX-Yahoo-Group-Post: member; u=163406187\r\nX-Yahoo-Profile: kristsi25\r\n\r\n&gt;\n&gt;\n&gt;-----Original Message-----\n&gt;From: Gordon Mohr (@Internet Archive) [mai=\r\nlto:gojomo@...] \n&gt;Sent: 21. ma=ED 2004 15:35\n&gt;To: archive-crawler@y=\r\nahoogroups.com\n&gt;Subject: Re: [archive-crawler] Large scale crawling with He=\r\nritrix\n&gt;\n&gt;It&#39;s good to see the limits tested in a new way! Some comments\nin=\r\nterspersed...\n&gt;\n&gt;Kristinn Sigurdsson wrote:\n&gt;&gt; Initial progress was quite i=\r\nmpressive, running at over 50 documents per\n&gt;&gt; second initially. Eventually=\r\n it started to gradually drop and now several\n&gt;&gt; days later it stands at ar=\r\nound 17 documents per second. I&#39;m unsure of the\n&gt;&gt; reason for this gradual =\r\ndecline. It may be related to increasing sizes of\n&gt;&gt; various data structure=\r\ns. \n&gt;\n&gt;I would also check to see if any of the worker ToeThreads seem indef=\r\ninitely\n&gt;stuck on single URIs, effectively shrinking the working pool. Are =\r\nyou using\n&gt;fetch timeouts?\n\nNo stuck threads. I was actually a little surpr=\r\nised by that but no thread\nhas \nbeen running for more then a few minutes.\n\n=\r\n\n&gt;\n&gt;&gt; Disk use by the disk bound queues however has been much greater then =\r\nI\n&gt;&gt; anticipated. With said 11 million URLs waiting in the queues they now\n=\r\ntake\n&gt;&gt; up about 16 GB. This comes out at about 1.6 KB per URI. This will t=\r\nurn\nout\n&gt;&gt; to be the limiting factor for my current crawl since the disk in=\r\n question\n&gt;&gt; only has another 3 GB free so it will be exhausted soon.\n&gt;\n&gt;Th=\r\ne default Java object serialization we use is very bloated. On the bright\n&gt;=\r\nside, it compresses well: in excess of 95% using gzip in my tests. So at a\n=\r\n&gt;slight cost of CPU a gzip option could be offered (in the DiskByteQueue)\n&gt;=\r\nfor big disk savings where necessary.\n\nThat might be a good idea. I&#39;ll add =\r\nan RFE for it.\n\n&gt;\n&gt;&gt; Of course a crawl of that scope is not possible until =\r\nthe list of already\n&gt;&gt; seen URIs can be disk backed.  With the current meth=\r\nod of using 4 byte\n&gt;&gt; fingerprints for each encountered URI 1 GB of memory =\r\ncan hold around 28\n&gt;&gt; million URIs. Even with a machine with 4 GB RAM would=\r\n not be able to\nscale\n&gt;&gt; up to even a full .is TLD crawl.\n&gt;\n&gt;A disk-based a=\r\nlready-seen option is available, but hasn&#39;t been well-tested\n&gt;or profiled, =\r\nand you have to edit Frontier source code to enable it.\n&gt;(See Frontier.init=\r\nialize(), specifically the commented-out\nCachingDiskLongFPSet\n&gt;segment.) On=\r\ne of my bugs to tackle is enabling this option from the UI,\n&gt;so it gets rea=\r\nl testing.\n\nThat sounds good as well. If the code is mostly there already I=\r\n can look\ninto \nEnabling this on Monday. I&#39;ll see if I cant do some testing=\r\n on it and get an\nidea of how it affects the crawlers performance.\n\n- Kris\n=\r\n&gt;\n&gt;- Gordon\n&gt;\n&gt;\n\n\n"}}