{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":163406187,"authorName":"Kristinn Sigur√∞sson","from":"=?iso-8859-1?q?Kristinn_Sigur=F0sson?= &lt;kris@...&gt;","profile":"kristsi25","replyTo":"LIST","senderId":"l0mUjnr2ekswUEPh3Bq2JSt4u-kCChBjishwgLd86qLoM05iV65VEdyhtTNro7MfJew7wSMVEDMuRFhsynU04424Z_6j3kAScRKY3rLiQpUeG_o3mCX1-xZ0QvPxap0s","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [DeDuplicator] Skipping URLs marked as duplicates from being indexed","postDate":"1166194174","msgId":3597,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGVsdWNsdStuYXRxQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDIwMjc2LjE5My4xODAuMTg5LjE1OC4xMTY2MTI4MzcwLnNxdWlycmVsQHdlYm1haWwuaWZpLmxtdS5kZT4="},"prevInTopic":3596,"nextInTopic":3598,"prevInTime":3596,"nextInTime":3598,"topicId":3594,"numMessagesInTopic":5,"msgSnippet":"Hey Max, The reason for adding also those marked duplicates is that the typical usage scenario has been to rebuild the index each time. If you are adding to","rawEmail":"Return-Path: &lt;kris@...&gt;\r\nX-Sender: kris@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 97279 invoked from network); 15 Dec 2006 14:49:46 -0000\r\nReceived: from unknown (66.218.67.35)\n  by m37.grp.scd.yahoo.com with QMQP; 15 Dec 2006 14:49:46 -0000\r\nReceived: from unknown (HELO n27.bullet.scd.yahoo.com) (66.94.237.56)\n  by mta9.grp.scd.yahoo.com with SMTP; 15 Dec 2006 14:49:46 -0000\r\nReceived: from [66.218.69.4] by n27.bullet.scd.yahoo.com with NNFMP; 15 Dec 2006 14:49:35 -0000\r\nReceived: from [66.218.66.78] by t4.bullet.scd.yahoo.com with NNFMP; 15 Dec 2006 14:49:35 -0000\r\nDate: Fri, 15 Dec 2006 14:49:34 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;eluclu+natq@...&gt;\r\nIn-Reply-To: &lt;20276.193.180.189.158.1166128370.squirrel@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: =?iso-8859-1?q?Kristinn_Sigur=F0sson?= &lt;kris@...&gt;\r\nSubject: Re: [DeDuplicator] Skipping URLs marked as duplicates from being indexed\r\nX-Yahoo-Group-Post: member; u=163406187; y=Tec_ry_8YUnoOiFyWIyqdzMB4cefJ58aFyfNF_ce2ByV1NEF\r\nX-Yahoo-Profile: kristsi25\r\n\r\nHey Max,\n\nThe reason for adding also those marked duplicates is that the ty=\r\npical\nusage scenario has been to rebuild the index each time. If you are\nad=\r\nding to the index after each crawl then, yes, it would make sense to\noffer =\r\nthat option.\n\nThe main reason for rebuilding the index is that it avoids ha=\r\nving\nmultiple entries for URLs whose documents have changed (you only have\n=\r\nthe last version). The assumption here is that documents do not revert\nback=\r\n to earlier versions, which seems (on the whole) reasonable. So\nthe overall=\r\n index size (after 30 iterations or more) is kept down.\n\nAdding this as an =\r\noption might however be interesting. Feel free to\nsend me a patch and I&#39;ll =\r\nlook into integrating it into the module.\n\nBest,\nKris\n\n--- In archive-crawl=\r\ner@yahoogroups.com, &quot;Maximilian Schoefmann&quot;\n&lt;schoefma@...&gt; wrote:\n&gt;\n&gt; Hi *,=\r\n\n&gt; \n&gt; URLs marked as duplicates are being added to the DeDuplicator-index w=\r\nhen\n&gt; running the DigestIndexer in its current implementation.\n&gt; Would&#39;t it=\r\n make sense to add an option to skip such URLs ?\n&gt; This would keep the inde=\r\nx small and speed up the indexing process.\n&gt; \n&gt; Or is there any reason not =\r\nto do this, that I haven&#39;t thought of?\n&gt; \n&gt; Max\n&gt;\n\n\n\n"}}