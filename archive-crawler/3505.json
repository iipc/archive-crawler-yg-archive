{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":285106948,"authorName":"fandufunkyman","from":"&quot;fandufunkyman&quot; &lt;fandufunkyman@...&gt;","profile":"fandufunkyman","replyTo":"LIST","senderId":"KAig8z9xWRaM3oiVFfSDsEiNCTfFM_WMTbXxWxn9M8Yguy29YLvrZniI0Bd1JFj2nI6mr-KEcQkLr0ClvocEUE3Ij11q7-pWWcAWrDZYdOU","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: HostScope","postDate":"1162900981","msgId":3505,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGVpcHNsbCt0OG0xQGVHcm91cHMuY29tPg==","inReplyToHeader":"PDQzQzJDQjU3LjEwODAwQGFyY2hpdmUub3JnPg=="},"prevInTopic":2518,"nextInTopic":0,"prevInTime":3504,"nextInTime":3506,"topicId":2516,"numMessagesInTopic":3,"msgSnippet":"hi, i m using heritrix 1.10.1 and not getting able to use surt in order.xml and seeds.txt. i don t want to crawl few pages of my site using heritrix. how can i","rawEmail":"Return-Path: &lt;fandufunkyman@...&gt;\r\nX-Sender: fandufunkyman@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 21654 invoked from network); 7 Nov 2006 12:03:15 -0000\r\nReceived: from unknown (66.218.66.167)\n  by m27.grp.scd.yahoo.com with QMQP; 7 Nov 2006 12:03:15 -0000\r\nReceived: from unknown (HELO n21a.bullet.scd.yahoo.com) (66.94.237.50)\n  by mta6.grp.scd.yahoo.com with SMTP; 7 Nov 2006 12:03:11 -0000\r\nReceived: from [66.218.69.3] by n21.bullet.scd.yahoo.com with NNFMP; 07 Nov 2006 12:03:01 -0000\r\nReceived: from [66.218.66.75] by t3.bullet.scd.yahoo.com with NNFMP; 07 Nov 2006 12:03:01 -0000\r\nDate: Tue, 07 Nov 2006 12:03:01 -0000\r\nTo: archive-crawler@yahoogroups.com\r\nMessage-ID: &lt;eipsll+t8m1@...&gt;\r\nIn-Reply-To: &lt;43C2CB57.10800@...&gt;\r\nUser-Agent: eGroups-EW/0.82\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=&quot;ISO-8859-1&quot;\r\nContent-Transfer-Encoding: quoted-printable\r\nX-Mailer: Yahoo Groups Message Poster\r\nX-Yahoo-Newman-Property: groups-compose\r\nX-eGroups-Msg-Info: 1:6:0:0\r\nFrom: &quot;fandufunkyman&quot; &lt;fandufunkyman@...&gt;\r\nSubject: Re: HostScope\r\nX-Yahoo-Group-Post: member; u=285106948; y=-VaTJ4OhcuPMmSSJ4LxO6vJM-pgcEUhQ8h_3DZlIviQHGLirE_tnZA\r\nX-Yahoo-Profile: fandufunkyman\r\n\r\nhi,\ni&#39;m using heritrix 1.10.1 and not getting able to use surt in\norder.xml=\r\n and seeds.txt.\ni don&#39;t want to crawl few pages of my site using heritrix. =\r\nhow can i\ndefine it in order.xml and seeds.txt.\n\ni need help to resolve it.=\r\n\n\nregards\nmohit\n\n\n--- In archive-crawler@yahoogroups.com, &quot;Gordon Mohr (arc=\r\nhive.org)&quot;\n&lt;gojomo@...&gt; wrote:\n&gt;\n&gt; Andrea Goethals wrote:\n&gt; &gt; Hello,\n&gt; &gt; \n&gt;=\r\n &gt; I&#39;m trying to understand the HostScope scope better so that I can\nmake v=\r\nery \n&gt; &gt; focused crawls. I have a crawl going that was started from 40\nseed=\r\ns using \n&gt; &gt; the HostScope. I left the defaults of max-link-hops set to 25,=\r\n \n&gt; &gt; max-trans-hops set to 5 and max-path-depth set to 20. I configured\nit=\r\n to \n&gt; &gt; log any URIs that it considers out of scope. I can see in the \n&gt; &gt;=\r\n heritrix_out.log file that there are thousands of URIs that it is not \n&gt; &gt;=\r\n crawling because they are outOfScope. But in the crawl job report\nI can se=\r\ne \n&gt; &gt; that is still crawling many hosts and retrieving files\nsuccessfully =\r\nfrom \n&gt; &gt; hosts that are not the same as the hosts in the seed list. Is thi=\r\ns\nnormal \n&gt; &gt; for the HostScope? Ideally I would like to be able to only\nre=\r\ntrieve files \n&gt; &gt; from the hosts in the seed list or maybe go one link &#39;out=\r\n&#39; past\nthe host.\n&gt; &gt; \n&gt; &gt; BTW I&#39;m using heritrix 1.6.\n&gt; \n&gt; By default, Heri=\r\ntrix will include URIs that appear necessary to\nfully render\n&gt; other URIs i=\r\nn the main scope -- such as embedded images, scripts,\nframes,\n&gt; and resourc=\r\nes referred to inside Javascript code.\n&gt; \n&gt; This is probably what you are s=\r\neeing. A way to tell for sure is to look\n&gt; closely at the lines in crawl.lo=\r\ng about the off-host URIs that were\n&gt; included. After the URI itself will b=\r\ne a string of capital letters, such\n&gt; as &quot;LLE&quot; or &quot;LXXP&quot;. Each letter in th=\r\nis &#39;hops-path&#39; indicates the\ntype of\n&gt; one &#39;hop&#39; that led to this URL from =\r\na seed:\n&gt; \n&gt;   L regular link (eg &lt;A HREF=3D&quot;&quot;&gt;)\n&gt;   E &#39;embed&#39; (eg &lt;IMG SRC=\r\n=3D&quot;&quot;&gt; or &lt;FRAME SRC=3D&quot;&quot;&gt;)\n&gt;   R redirect/refresh\n&gt;   P prerequisite (robo=\r\nts or DNS)\n&gt;   X speculative -- best guess reference (URI-like strings foun=\r\nd in\nJavascript)\n&gt; \n&gt; A string of E/R/P/X hops, shorter than max-trans-hops=\r\n, at the end of the\n&gt; hops-path will cause otherwise out-of-scope URIs (suc=\r\nh as off-host\nURIs) to\n&gt; be included.\n&gt; \n&gt; You can tighten the HostScope to=\r\n never go off-host by setting\n&#39;max-trans-hops&#39;\n&gt; to 0.\n&gt; \n&gt; Other notes:\n&gt; =\r\n\n&gt; - HostScope and its sibling scopes DomainScope and PathScope are rather\n=\r\n&gt;    inefficient in their testing of URIs (performing a linear probe of\n&gt;  =\r\n  all allowed URI patterns). This doesn&#39;t matter much in small crawls\n&gt;    =\r\n(up to a few hundred seeds/allowed hosts) but can be a noticeable\n&gt;    fact=\r\nor in larger (many thousand seeds/hosts) crawls.\n&gt; - HostScope and its sibl=\r\nings also limit your ability to mix domain\n&gt;    (http://*.example.com), hos=\r\nt (http://example.com/*) and path\n&gt;    (http://example.com/topic/*) scopes =\r\nin a single crawl.\n&gt; - SurtPrefixScope adds a little complexity but both im=\r\nproves the\n&gt;    efficiency and mixing-flexibility of scope definition -- it=\r\n can do\n&gt;    everything HostScope/DomainScope/PathScope can do, and then so=\r\nme,\n&gt;    more efficiently.\n&gt; - For even finer-grained control, and sometime=\r\ns greater efficiency,\n&gt;    a DecidingScope with a customizable sequence of =\r\nDecideRules can be\n&gt;    used, though understanding/designing such scopes is=\r\n harder.\n&gt; \n&gt; Hope this helps,\n&gt; \n&gt; - Gordon @ IA\n&gt;\n\n\n\n\n"}}