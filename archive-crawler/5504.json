{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":90724651,"authorName":"John Lekashman","from":"John Lekashman &lt;lekash@...&gt;","profile":"lekash","replyTo":"LIST","senderId":"S93uram3nKSLqinHXYNgWxrBdDuVtrxG-i7X-tLQZiyTHQ1OOmU42lPADBPnhRxkQbV4iqE2ZYYQL_YGJau5NapLTMsBksQIAhA","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Re: How to let Heritrix do not crawl robots.txt and DNS","postDate":"1223480863","msgId":5504,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ4RUNENjFGLjIwMjA3MDZAYmF5YXJlYS5uZXQ+","inReplyToHeader":"PGdjaHJnNitkZmU1QGVHcm91cHMuY29tPg==","referencesHeader":"PGdjaHJnNitkZmU1QGVHcm91cHMuY29tPg=="},"prevInTopic":5503,"nextInTopic":5505,"prevInTime":5503,"nextInTime":5505,"topicId":5501,"numMessagesInTopic":7,"msgSnippet":"Hi, Could we please not publish this? I don t know if the original writer is real, or not. But it is suspicious. Eliminating one text file from a crawl to save","rawEmail":"Return-Path: &lt;lekash@...&gt;\r\nX-Sender: lekash@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 66846 invoked from network); 8 Oct 2008 15:47:48 -0000\r\nX-Received: from unknown (66.218.67.95)\n  by m46.grp.scd.yahoo.com with QMQP; 8 Oct 2008 15:47:48 -0000\r\nX-Received: from unknown (HELO mail.bayarea.net) (209.128.87.230)\n  by mta16.grp.scd.yahoo.com with SMTP; 8 Oct 2008 15:47:47 -0000\r\nX-Received: from [192.168.1.104] (h-66-167-125-192.snvacaid.covad.net [66.167.125.192])\n\t(authenticated bits=0)\n\tby mail.bayarea.net (8.13.8/8.13.8) with ESMTP id m98Flh2t009521\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Wed, 8 Oct 2008 08:47:47 -0700 (PDT)\n\t(envelope-from lekash@...)\r\nMessage-ID: &lt;48ECD61F.2020706@...&gt;\r\nDate: Wed, 08 Oct 2008 08:47:43 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; PPC Mac OS X Mach-O; en-US; rv:1.7.12) Gecko/20050915\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;gchrg6+dfe5@...&gt;\r\nIn-Reply-To: &lt;gchrg6+dfe5@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: John Lekashman &lt;lekash@...&gt;\r\nSubject: Re: [archive-crawler] Re: How to let Heritrix do not crawl robots.txt\n and DNS\r\nX-Yahoo-Group-Post: member; u=90724651; y=ugA27j3nZiHxLsp_FNkIIRng1LQ-YCfxrQTepw8h6URA\r\nX-Yahoo-Profile: lekash\r\n\r\nHi,\nCould we please not publish this?\n\nI don&#39;t know if the original writer is real, or not.\n\nBut it is suspicious. \n\nEliminating one text file from a crawl to save time is questionable.\n\nAnd even if they really need it, posting a cookbook how to, can reach\nout to all sorts of places we don&#39;t want.\n\nIts not something we need, heritrix becoming a script kiddie tool to\nget around robots.txt, and having the name on lists of bad robots.\n\nYes, I know, robots.txt is just advisory, but so are locks on the front \ndoor of a house.\nAny idiot with 5 minutes of will power can break them, but\nit is amazing how effective advisory locks are.\n\nJohn\n\n\nhappyxinglele wrote:\n\n&gt; Oh, I know.\n&gt; But could anyone tell me how to strip the robots.txt\n&gt;\n&gt; -Thanks\n&gt;\n&gt; --- In archive-crawler@yahoogroups.com \n&gt; &lt;mailto:archive-crawler%40yahoogroups.com&gt;, &quot;Jean-NoÃ«l Rivasseau&quot;\n&gt; &lt;elvanor@...&gt; wrote:\n&gt; &gt;\n&gt; &gt; I dont know for the robots.txt part, but you will still be forced to\n&gt; &gt; &quot;crawl&quot; (eg, contact) the DNS to obtain the IP address of the\n&gt; server.\n&gt; &gt; This is mandatory.\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; On Wed, Oct 8, 2008 at 10:29 AM, happyxinglele\n&gt; &gt; &lt;happyxinglele@...&gt; wrote:\n&gt; &gt; &gt; I only crawl test URLs of myself. And Heritrix need to crawl\n&gt; robots and\n&gt; &gt; &gt; DNS firstly, which is cost lots of time. I donot need the\n&gt; Heritrix to\n&gt; &gt; &gt; crawl the robots file and the DNS.\n&gt; &gt; &gt;\n&gt; &gt; &gt; Could you tell me how can I let it work?\n&gt; &gt; &gt; p.s. I use Heritrix-2.0.0\n&gt; &gt; &gt;\n&gt; &gt; &gt; Thanks a lot!\n&gt; &gt; &gt;\n&gt; &gt; &gt;\n&gt; &gt;\n&gt;\n&gt;  \n\n\n"}}