{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"Michael Stack","from":"Michael Stack &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"ol16DMRqLb12MOJ4OX7EUdNQDPDrq9C8Tck5q3JmxmTPY2BHbM_VCtaMgnCrWvI3JiR5Gwd015Af2RocDYYyxLov6YmEL1SU","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] lots of index.html files","postDate":"1167865883","msgId":3651,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ1OUMzODFCLjkwOTAwMDFAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PDY4ZDM0ODA2MDcwMTAzMTMzOXc2N2Q3YjRlZW5hNmE5MTlhNjgwMTMxMWVjQG1haWwuZ21haWwuY29tPg==","referencesHeader":"PGVuZzI3bCs2ZTk1QGVHcm91cHMuY29tPiA8NDU5QkUyNTkuOTA0MDEwNkBhcmNoaXZlLm9yZz4gPDY4ZDM0ODA2MDcwMTAzMTMzOXc2N2Q3YjRlZW5hNmE5MTlhNjgwMTMxMWVjQG1haWwuZ21haWwuY29tPg=="},"prevInTopic":3646,"nextInTopic":3663,"prevInTime":3650,"nextInTime":3652,"topicId":3641,"numMessagesInTopic":6,"msgSnippet":"A better source would be the crawl.log.   Does it have multiple instances of the said index.html page, with or without parameters?  If not, then its likely","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 53626 invoked from network); 3 Jan 2007 23:04:45 -0000\r\nReceived: from unknown (66.218.66.172)\n  by m27.grp.scd.yahoo.com with QMQP; 3 Jan 2007 23:04:44 -0000\r\nReceived: from unknown (HELO mail.archive.org) (207.241.233.246)\n  by mta4.grp.scd.yahoo.com with SMTP; 3 Jan 2007 23:04:41 -0000\r\nReceived: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id 28FC314156E85;\n\tWed,  3 Jan 2007 15:02:41 -0800 (PST)\r\nReceived: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id 23546-01-60; Wed, 3 Jan 2007 15:02:39 -0800 (PST)\r\nReceived: from [192.168.1.204] (c-71-198-60-165.hsd1.ca.comcast.net [71.198.60.165])\n\tby mail.archive.org (Postfix) with ESMTP id 793CC14156DB4;\n\tWed,  3 Jan 2007 15:02:39 -0800 (PST)\r\nMessage-ID: &lt;459C381B.9090001@...&gt;\r\nDate: Wed, 03 Jan 2007 15:11:23 -0800\r\nUser-Agent: Thunderbird 1.5.0.8 (X11/20061117)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;eng27l+6e95@...&gt; &lt;459BE259.9040106@...&gt; &lt;68d348060701031339w67d7b4eena6a919a6801311ec@...&gt;\r\nIn-Reply-To: &lt;68d348060701031339w67d7b4eena6a919a6801311ec@...&gt;\r\nContent-Type: text/plain; charset=UTF-8; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Virus-Scanned: Debian amavisd-new at archive.org\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: Michael Stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] lots of index.html files\r\nX-Yahoo-Group-Post: member; u=168599281; y=1MykB1VWb-rI358b-3SKvKQmhjUazTOMisyUD5mYAGpaU59AlpTJK85i\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\nA better source would be the crawl.log.   Does it have multiple \ninstances of the said &#39;index.html&#39; page, with or without parameters?  If \nnot, then its likely an issue with the mirrorwriter processor.\nSt.Ack\n\n\nJeroen Verhagen wrote:\n&gt;\n&gt; Hi Michael,\n&gt;\n&gt; On 1/3/07, Michael Stack &lt;stack@... \n&gt; &lt;mailto:stack%40archive.org&gt;&gt; wrote:\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; During a single crawl, Heritrix should only ever download a single \n&gt; instance of any particular URL. In your crawl logs, there is a single \n&gt; URL logged 38231 times? Or do the URLs differ by query parameters? \n&gt; What do you have for the &#39;uri-included-structure&#39;? Which URL is it?\n&gt;\n&gt; Sorry, should have passed this information immediately: it seems they\n&gt; all differ by query parameter, what&#39;s causing this?\n&gt;\n&gt; -rw-r--r-- 1 user users 153K 2007-01-03 22:08\n&gt; telegraaf2-20070103205205928/mirror/www.telegraaf.nl/indexr=9227765995&.html\n&gt; -rw-r--r-- 1 user users 157K 2007-01-03 22:25\n&gt; telegraaf2-20070103205205928/mirror/www.telegraaf.nl/indexr=9233963420&.html\n&gt; -rw-r--r-- 1 user users 157K 2007-01-03 22:26\n&gt; telegraaf2-20070103205205928/mirror/www.telegraaf.nl/indexr=9240160846&.html\n&gt; -rw-r--r-- 1 user users 157K 2007-01-03 22:27\n&gt; telegraaf2-20070103205205928/mirror/www.telegraaf.nl/indexr=9244292463&.html\n&gt; -rw-r--r-- 1 user users 157K 2007-01-03 22:27\n&gt; telegraaf2-20070103205205928/mirror/www.telegraaf.nl/indexr=9248666214&.html\n&gt; -rw-r--r-- 1 user users 153K 2007-01-03 22:08\n&gt; telegraaf2-20070103205205928/mirror/www.telegraaf.nl/indexr=9399645527&.html\n&gt; -rw-r--r-- 1 user users 153K 2007-01-03 22:08\n&gt; telegraaf2-20070103205205928/mirror/www.telegraaf.nl/indexr=9500153247&.html\n&gt; -rw-r--r-- 1 user users 157K 2007-01-03 22:27\n&gt; telegraaf2-20070103205205928/mirror/www.telegraaf.nl/indexr=9533197207&.html\n&gt; -rw-r--r-- 1 user users 153K 2007-01-03 22:04\n&gt; telegraaf2-20070103205205928/mirror/www.telegraaf.nl/indexr=9551437560&.html\n&gt; -rw-r--r-- 1 user users 153K 2007-01-03 22:08\n&gt; telegraaf2-20070103205205928/mirror/www.telegraaf.nl/indexr=9571525059&.html\n&gt;\n&gt; Thanks and regards,\n&gt;\n&gt; Jeroen\n&gt;\n&gt; ps: here&#39;s the order.xml for more information:\n&gt;\n&gt; &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;crawl-order\n&gt; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance \n&gt; &lt;http://www.w3.org/2001/XMLSchema-instance&gt;&quot;\n&gt; xsi:noNamespaceSchemaLocation=&quot;heritrix_settings.xsd&quot;&gt;\n&gt; &lt;meta&gt;\n&gt; &lt;name&gt;telegraaf2&lt;/name&gt;\n&gt; &lt;description&gt;http://www.telegraaf.nl \n&gt; &lt;http://www.telegraaf.nl&gt;&lt;/description&gt;\n&gt; &lt;operator&gt;Admin&lt;/operator&gt;\n&gt; &lt;organization&gt;&lt;/organization&gt;\n&gt; &lt;audience&gt;&lt;/audience&gt;\n&gt; &lt;date&gt;20070103205215&lt;/date&gt;\n&gt;\n&gt; &lt;/meta&gt;\n&gt; &lt;controller&gt;\n&gt; &lt;string name=&quot;settings-directory&quot;&gt;settings&lt;/string&gt;\n&gt; &lt;string name=&quot;disk-path&quot;&gt;&lt;/string&gt;\n&gt; &lt;string name=&quot;logs-path&quot;&gt;logs&lt;/string&gt;\n&gt; &lt;string name=&quot;checkpoints-path&quot;&gt;checkpoints&lt;/string&gt;\n&gt; &lt;string name=&quot;state-path&quot;&gt;state&lt;/string&gt;\n&gt;\n&gt; &lt;string name=&quot;scratch-path&quot;&gt;scratch&lt;/string&gt;\n&gt; &lt;long name=&quot;max-bytes-download&quot;&gt;0&lt;/long&gt;\n&gt; &lt;long name=&quot;max-document-download&quot;&gt;0&lt;/long&gt;\n&gt; &lt;long name=&quot;max-time-sec&quot;&gt;0&lt;/long&gt;\n&gt; &lt;integer name=&quot;max-toe-threads&quot;&gt;50&lt;/integer&gt;\n&gt; &lt;integer name=&quot;recorder-out-buffer-bytes&quot;&gt;4096&lt;/integer&gt;\n&gt;\n&gt; &lt;integer name=&quot;recorder-in-buffer-bytes&quot;&gt;65536&lt;/integer&gt;\n&gt; &lt;integer name=&quot;bdb-cache-percent&quot;&gt;0&lt;/integer&gt;\n&gt; &lt;newObject name=&quot;scope&quot; class=&quot;org.archive.crawler.scope.DomainScope&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;string name=&quot;seedsfile&quot;&gt;seeds.txt&lt;/string&gt;\n&gt; &lt;boolean name=&quot;reread-seeds-on-config&quot;&gt;true&lt;/boolean&gt;\n&gt;\n&gt; &lt;integer name=&quot;max-link-hops&quot;&gt;25&lt;/integer&gt;\n&gt; &lt;integer name=&quot;max-trans-hops&quot;&gt;5&lt;/integer&gt;\n&gt; &lt;newObject name=&quot;exclude-filter&quot;\n&gt; class=&quot;org.archive.crawler.filter.OrFilter&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;if-matches-return&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;force-accept-filter&quot;\n&gt; class=&quot;org.archive.crawler.filter.OrFilter&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;if-matches-return&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;additionalScopeFocus&quot;\n&gt; class=&quot;org.archive.crawler.filter.FilePatternFilter&quot;&gt;\n&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;if-match-return&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;string name=&quot;use-default-patterns&quot;&gt;All&lt;/string&gt;\n&gt; &lt;string name=&quot;regexp&quot;&gt;&lt;/string&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;transitiveFilter&quot;\n&gt; class=&quot;org.archive.crawler.filter.TransclusionFilter&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;\n&gt; &lt;integer name=&quot;max-speculative-hops&quot;&gt;1&lt;/integer&gt;\n&gt; &lt;integer name=&quot;max-referral-hops&quot;&gt;-1&lt;/integer&gt;\n&gt; &lt;integer name=&quot;max-embed-hops&quot;&gt;-1&lt;/integer&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;map name=&quot;http-headers&quot;&gt;\n&gt; &lt;string name=&quot;user-agent&quot;&gt;Mozilla/5.0 (compatible;\n&gt; heritrix/1.10.0 +http://loc.gov)&lt;/string&gt;\n&gt;\n&gt; &lt;string name=&quot;from&quot;&gt;webmaster@... \n&gt; &lt;mailto:webmaster%40loc.gov&gt;&lt;/string&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;newObject name=&quot;robots-honoring-policy&quot;\n&gt; class=&quot;org.archive.crawler.datamodel.RobotsHonoringPolicy&quot;&gt;\n&gt; &lt;string name=&quot;type&quot;&gt;classic&lt;/string&gt;\n&gt; &lt;boolean name=&quot;masquerade&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;text name=&quot;custom-robots&quot;&gt;&lt;/text&gt;\n&gt; &lt;stringList name=&quot;user-agents&quot;&gt;\n&gt;\n&gt; &lt;/stringList&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;frontier&quot; \n&gt; class=&quot;org.archive.crawler.frontier.BdbFrontier&quot;&gt;\n&gt; &lt;float name=&quot;delay-factor&quot;&gt;0.0&lt;/float&gt;\n&gt; &lt;integer name=&quot;max-delay-ms&quot;&gt;0&lt;/integer&gt;\n&gt; &lt;integer name=&quot;min-delay-ms&quot;&gt;0&lt;/integer&gt;\n&gt; &lt;integer name=&quot;max-retries&quot;&gt;30&lt;/integer&gt;\n&gt;\n&gt; &lt;long name=&quot;retry-delay-seconds&quot;&gt;900&lt;/long&gt;\n&gt; &lt;integer name=&quot;preference-embed-hops&quot;&gt;1&lt;/integer&gt;\n&gt; &lt;integer name=&quot;total-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt; &lt;integer name=&quot;max-per-host-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt; &lt;string \n&gt; name=&quot;queue-assignment-policy&quot;&gt;org.archive.crawler.frontier.HostnameQueueAssignmentPolicy&lt;/string&gt;\n&gt; &lt;string name=&quot;force-queue-assignment&quot;&gt;&lt;/string&gt;\n&gt;\n&gt; &lt;boolean name=&quot;pause-at-start&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;pause-at-finish&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;source-tag-seeds&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;recovery-log-enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;hold-queues&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;integer name=&quot;balance-replenish-amount&quot;&gt;3000&lt;/integer&gt;\n&gt;\n&gt; &lt;integer name=&quot;error-penalty-amount&quot;&gt;100&lt;/integer&gt;\n&gt; &lt;long name=&quot;queue-total-budget&quot;&gt;-1&lt;/long&gt;\n&gt; &lt;string \n&gt; name=&quot;cost-policy&quot;&gt;org.archive.crawler.frontier.ZeroCostAssignmentPolicy&lt;/string&gt;\n&gt; &lt;long name=&quot;snooze-deactivate-ms&quot;&gt;300000&lt;/long&gt;\n&gt; &lt;integer name=&quot;target-ready-backlog&quot;&gt;50&lt;/integer&gt;\n&gt; &lt;string \n&gt; name=&quot;uri-included-structure&quot;&gt;org.archive.crawler.util.BdbUriUniqFilter&lt;/string&gt;\n&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;map name=&quot;uri-canonicalization-rules&quot;&gt;\n&gt; &lt;newObject name=&quot;Lowercase&quot;\n&gt; class=&quot;org.archive.crawler.url.canonicalize.LowercaseRule&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;Userinfo&quot;\n&gt; class=&quot;org.archive.crawler.url.canonicalize.StripUserinfoRule&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;/newObject&gt;\n&gt;\n&gt; &lt;newObject name=&quot;WWW[0-9]*&quot;\n&gt; class=&quot;org.archive.crawler.url.canonicalize.StripWWWNRule&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;SessionIDs&quot;\n&gt; class=&quot;org.archive.crawler.url.canonicalize.StripSessionIDs&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;SessionCFIDs&quot;\n&gt; class=&quot;org.archive.crawler.url.canonicalize.StripSessionCFIDs&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;QueryStrPrefix&quot;\n&gt; class=&quot;org.archive.crawler.url.canonicalize.FixupQueryStr&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;map name=&quot;pre-fetch-processors&quot;&gt;\n&gt; &lt;newObject name=&quot;Preselector&quot;\n&gt; class=&quot;org.archive.crawler.prefetch.Preselector&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;boolean name=&quot;override-logger&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;recheck-scope&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;block-all&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;string name=&quot;block-by-regexp&quot;&gt;&lt;/string&gt;\n&gt; &lt;string name=&quot;allow-by-regexp&quot;&gt;&lt;/string&gt;\n&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;Preprocessor&quot;\n&gt; class=&quot;org.archive.crawler.prefetch.PreconditionEnforcer&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;integer name=&quot;ip-validity-duration-seconds&quot;&gt;21600&lt;/integer&gt;\n&gt; &lt;integer name=&quot;robot-validity-duration-seconds&quot;&gt;86400&lt;/integer&gt;\n&gt;\n&gt; &lt;boolean name=&quot;calculate-robots-only&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;map name=&quot;fetch-processors&quot;&gt;\n&gt; &lt;newObject name=&quot;DNS&quot; class=&quot;org.archive.crawler.fetcher.FetchDNS&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt;\n&gt; &lt;boolean name=&quot;accept-non-dns-resolves&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;sha1-content&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;HTTP&quot; class=&quot;org.archive.crawler.fetcher.FetchHTTP&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt;\n&gt; &lt;map name=&quot;midfetch-filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;integer name=&quot;timeout-seconds&quot;&gt;1200&lt;/integer&gt;\n&gt; &lt;integer name=&quot;sotimeout-ms&quot;&gt;20000&lt;/integer&gt;\n&gt; &lt;integer name=&quot;fetch-bandwidth&quot;&gt;0&lt;/integer&gt;\n&gt; &lt;long name=&quot;max-length-bytes&quot;&gt;0&lt;/long&gt;\n&gt; &lt;boolean name=&quot;ignore-cookies&quot;&gt;false&lt;/boolean&gt;\n&gt;\n&gt; &lt;boolean name=&quot;use-bdb-for-cookies&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;string name=&quot;load-cookies-from-file&quot;&gt;&lt;/string&gt;\n&gt; &lt;string name=&quot;save-cookies-to-file&quot;&gt;&lt;/string&gt;\n&gt; &lt;string name=&quot;trust-level&quot;&gt;open&lt;/string&gt;\n&gt; &lt;stringList name=&quot;accept-headers&quot;&gt;\n&gt; &lt;/stringList&gt;\n&gt; &lt;string name=&quot;http-proxy-host&quot;&gt;&lt;/string&gt;\n&gt; &lt;string name=&quot;http-proxy-port&quot;&gt;&lt;/string&gt;\n&gt;\n&gt; &lt;string name=&quot;default-encoding&quot;&gt;ISO-8859-1&lt;/string&gt;\n&gt; &lt;boolean name=&quot;sha1-content&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;send-connection-close&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;send-referer&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;send-range&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;string name=&quot;bind-address&quot;&gt;&lt;/string&gt;\n&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;map name=&quot;extract-processors&quot;&gt;\n&gt; &lt;newObject name=&quot;ExtractorHTTP&quot;\n&gt; class=&quot;org.archive.crawler.extractor.ExtractorHTTP&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;/newObject&gt;\n&gt;\n&gt; &lt;newObject name=&quot;ExtractorHTML&quot;\n&gt; class=&quot;org.archive.crawler.extractor.ExtractorHTML&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;boolean name=&quot;treat-frames-as-embed-links&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;ignore-form-action-urls&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;overly-eager-link-detection&quot;&gt;true&lt;/boolean&gt;\n&gt;\n&gt; &lt;boolean name=&quot;ignore-unexpected-html&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;ExtractorCSS&quot;\n&gt; class=&quot;org.archive.crawler.extractor.ExtractorCSS&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;ExtractorJS&quot;\n&gt; class=&quot;org.archive.crawler.extractor.ExtractorJS&quot;&gt;\n&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;ExtractorSWF&quot;\n&gt; class=&quot;org.archive.crawler.extractor.ExtractorSWF&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;map name=&quot;write-processors&quot;&gt;\n&gt; &lt;newObject name=&quot;MirrorWriter&quot;\n&gt; class=&quot;org.archive.crawler.writer.MirrorWriterProcessor&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;boolean name=&quot;case-sensitive&quot;&gt;true&lt;/boolean&gt;\n&gt;\n&gt; &lt;stringList name=&quot;character-map&quot;&gt;\n&gt; &lt;/stringList&gt;\n&gt; &lt;stringList name=&quot;content-type-map&quot;&gt;\n&gt; &lt;/stringList&gt;\n&gt; &lt;string name=&quot;directory-file&quot;&gt;index.html&lt;/string&gt;\n&gt; &lt;string name=&quot;dot-begin&quot;&gt;%2E&lt;/string&gt;\n&gt; &lt;string name=&quot;dot-end&quot;&gt;.&lt;/string&gt;\n&gt;\n&gt; &lt;stringList name=&quot;host-map&quot;&gt;\n&gt; &lt;/stringList&gt;\n&gt; &lt;boolean name=&quot;host-directory&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;string name=&quot;path&quot;&gt;mirror&lt;/string&gt;\n&gt; &lt;integer name=&quot;max-path-length&quot;&gt;1023&lt;/integer&gt;\n&gt; &lt;integer name=&quot;max-segment-length&quot;&gt;255&lt;/integer&gt;\n&gt; &lt;boolean name=&quot;port-directory&quot;&gt;false&lt;/boolean&gt;\n&gt;\n&gt; &lt;boolean name=&quot;suffix-at-end&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;string name=&quot;too-long-directory&quot;&gt;LONG&lt;/string&gt;\n&gt; &lt;stringList name=&quot;underscore-set&quot;&gt;\n&gt; &lt;/stringList&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;map name=&quot;post-processors&quot;&gt;\n&gt; &lt;newObject name=&quot;Updater&quot;\n&gt; class=&quot;org.archive.crawler.postprocessor.CrawlStateUpdater&quot;&gt;\n&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;LinksScoper&quot;\n&gt; class=&quot;org.archive.crawler.postprocessor.LinksScoper&quot;&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt;\n&gt; &lt;boolean name=&quot;override-logger&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;seed-redirects-new-seed&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;integer name=&quot;preference-depth-hops&quot;&gt;-1&lt;/integer&gt;\n&gt; &lt;map name=&quot;scope-rejected-url-filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;newObject name=&quot;Scheduler&quot;\n&gt; class=&quot;org.archive.crawler.postprocessor.FrontierScheduler&quot;&gt;\n&gt;\n&gt; &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;map name=&quot;filters&quot;&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;map name=&quot;loggers&quot;&gt;\n&gt; &lt;newObject name=&quot;crawl-statistics&quot;\n&gt; class=&quot;org.archive.crawler.admin.StatisticsTracker&quot;&gt;\n&gt; &lt;integer name=&quot;interval-seconds&quot;&gt;20&lt;/integer&gt;\n&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;/map&gt;\n&gt; &lt;string name=&quot;recover-path&quot;&gt;&lt;/string&gt;\n&gt; &lt;boolean name=&quot;checkpoint-copy-bdbje-logs&quot;&gt;true&lt;/boolean&gt;\n&gt; &lt;boolean name=&quot;recover-retain-failures&quot;&gt;false&lt;/boolean&gt;\n&gt; &lt;newObject name=&quot;credential-store&quot;\n&gt; class=&quot;org.archive.crawler.datamodel.CredentialStore&quot;&gt;\n&gt; &lt;map name=&quot;credentials&quot;&gt;\n&gt; &lt;/map&gt;\n&gt;\n&gt; &lt;/newObject&gt;\n&gt; &lt;/controller&gt;\n&gt; &lt;/crawl-order&gt;\n&gt;\n&gt;  \n\n\n"}}