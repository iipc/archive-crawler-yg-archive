{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"kEPhbX39ls3jTDiv5F5cNPDgiqtil3RxeePRugcC1PzLve30QRjs9TRSPbsL4JPXZyF4wTDW42oBFyiTN6jM303-iRBJtIY","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: [archive-crawler] Re: How can I speed up Heretrix?","postDate":"1175639718","msgId":4019,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQ2MTJENkE2LjIwNTAzMDdAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGV1c3Rqcys3NzNpQGVHcm91cHMuY29tPg==","referencesHeader":"PGV1c3Rqcys3NzNpQGVHcm91cHMuY29tPg=="},"prevInTopic":4011,"nextInTopic":4024,"prevInTime":4018,"nextInTime":4020,"topicId":3839,"numMessagesInTopic":10,"msgSnippet":"... That s essentially the reason -- the assumption that more than one connection at a time is impolite is deeply built into the Heritrix queueing","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 50570 invoked from network); 3 Apr 2007 22:33:04 -0000\r\nReceived: from unknown (66.218.66.70)\n  by m49.grp.scd.yahoo.com with QMQP; 3 Apr 2007 22:33:04 -0000\r\nReceived: from unknown (HELO mail.archive.org) (207.241.233.246)\n  by mta12.grp.scd.yahoo.com with SMTP; 3 Apr 2007 22:33:04 -0000\r\nReceived: from localhost (localhost [127.0.0.1])\n\tby mail.archive.org (Postfix) with ESMTP id AF96C141C6D49\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Tue,  3 Apr 2007 15:33:03 -0700 (PDT)\r\nReceived: from mail.archive.org ([127.0.0.1])\n\tby localhost (mail.archive.org [127.0.0.1]) (amavisd-new, port 10024)\n\twith LMTP id 17192-04-93 for &lt;archive-crawler@yahoogroups.com&gt;;\n\tTue, 3 Apr 2007 15:33:03 -0700 (PDT)\r\nReceived: from [192.168.1.203] (c-76-102-230-209.hsd1.ca.comcast.net [76.102.230.209])\n\tby mail.archive.org (Postfix) with ESMTP id 28877141C6CF6\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Tue,  3 Apr 2007 15:33:03 -0700 (PDT)\r\nMessage-ID: &lt;4612D6A6.2050307@...&gt;\r\nDate: Tue, 03 Apr 2007 15:35:18 -0700\r\nUser-Agent: Thunderbird 1.5.0.10 (X11/20070306)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;eustjs+773i@...&gt;\r\nIn-Reply-To: &lt;eustjs+773i@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Virus-Scanned: Debian amavisd-new at archive.org\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] Re: How can I speed up Heretrix?\r\nX-Yahoo-Group-Post: member; u=137285340; y=mYDDgA8REHbiMdgM2msPPZH8LD8ahfntFmLzlebRXtk_\r\nX-Yahoo-Profile: gojomo\r\n\r\nHei wrote:\n&gt; Hi Gordon,\n&gt; \n&gt; Is there a reason why Heritrix only fetches 1 URL at a time besides\n&gt; establishing multiple connections to the same host might be considered\n&gt; as DoS attack?\n\nThat&#39;s essentially the reason -- the assumption that more than one \nconnection at a time is impolite is deeply built into the Heritrix \nqueueing architecture.\n\n(It also simplifies some of the prerequisite and retry handling to know \nthat only 1 URI is outstanding from a queue at a time, but the \npoliteness is main reason.)\n\n- Gordon @ IA\n\n&gt; Thanks in advance.\n&gt; \n&gt; \n&gt; Cheers,\n&gt; Hei\n&gt; \n&gt; --- In archive-crawler@yahoogroups.com, Gordon Mohr &lt;gojomo@...&gt; wrote:\n&gt;&gt; Two notes:\n&gt;&gt;\n&gt;&gt; (1) Unless you are crawling sites with permission, those &#39;delay&#39; \n&gt;&gt; settings are fairly aggressive, and may trigger webmaster anger or \n&gt;&gt; blocking.\n&gt;&gt;\n&gt;&gt; (2) The usual reason for the &quot;why isn&#39;t Heritrix crawling faster&quot; \n&gt;&gt; concern is that a crawl has made enough progress to be narrowed \n&gt;&gt; down to just a handful of hosts remaining: typically the largest, \n&gt;&gt; slowest, or completely unresponsive hosts.\n&gt;&gt;\n&gt;&gt; Even with no delay between fetches to a host, Heritrix will only \n&gt;&gt; retrieve one URL at a time. If the content is large or the server \n&gt;&gt; slow, it may take many seconds for a single request to finish. If \n&gt;&gt; the host does not respond at all, Heritrix goes into the longer \n&gt;&gt; &#39;retry-delay-seconds&#39; wait (which is usually many minutes) before \n&gt;&gt; reconnecting.\n&gt;&gt;\n&gt;&gt; In addition to the info Paul mentioned, the &#39;frontier report&#39; will \n&gt;&gt; help determine if this is the case -- showing how many queues are \n&gt;&gt; still active with URLs to crawl, and how many are in various \n&gt;&gt; stages of &#39;snooze&#39; (to delay the next fetch for politeness or \n&gt;&gt; waiting-out-a-problem reasons).\n&gt;&gt;\n&gt;&gt; - Gordon @ IA\n&gt;&gt;\n&gt;&gt; nt_bdr wrote:\n&gt;&gt;&gt; I have already tried that, and does not seem to help speed up the\n&gt;&gt;&gt; crawl. Below are some of frontier settings I have\n&gt;&gt;&gt;\n&gt;&gt;&gt;  \n&gt;&gt;&gt;     &lt;long name=&quot;max-bytes-download&quot;&gt;0&lt;/long&gt;\n&gt;&gt;&gt;     &lt;long name=&quot;max-document-download&quot;&gt;0&lt;/long&gt;\n&gt;&gt;&gt;     &lt;long name=&quot;max-time-sec&quot;&gt;0&lt;/long&gt;\n&gt;&gt;&gt;     &lt;integer name=&quot;max-toe-threads&quot;&gt;100&lt;/integer&gt;\n&gt;&gt;&gt;     &lt;integer name=&quot;recorder-out-buffer-bytes&quot;&gt;4096&lt;/integer&gt;\n&gt;&gt;&gt;     &lt;integer name=&quot;recorder-in-buffer-bytes&quot;&gt;65536&lt;/integer&gt;\n&gt;&gt;&gt;     &lt;integer name=&quot;bdb-cache-percent&quot;&gt;0&lt;/integer&gt;\n&gt;&gt;&gt;     &lt;newObject name=&quot;scope&quot;\n&gt;&gt;&gt; class=&quot;org.archive.crawler.scope.SurtPrefixScope&quot;&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;reread-seeds-on-config&quot;&gt;false&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;integer name=&quot;max-link-hops&quot;&gt;25&lt;/integer&gt;\n&gt;&gt;&gt;       &lt;integer name=&quot;max-trans-hops&quot;&gt;5&lt;/integer&gt;\n&gt;&gt;&gt;       &lt;newObject name=&quot;robots-honoring-policy&quot;\n&gt;&gt;&gt; class=&quot;org.archive.crawler.datamodel.RobotsHonoringPolicy&quot;&gt;\n&gt;&gt;&gt;       &lt;string name=&quot;type&quot;&gt;classic&lt;/string&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;masquerade&quot;&gt;false&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;text name=&quot;custom-robots&quot;&gt;&lt;/text&gt;\n&gt;&gt;&gt;       &lt;stringList name=&quot;user-agents&quot;&gt;\n&gt;&gt;&gt;         &lt;string&gt;test-bot&lt;/string&gt;\n&gt;&gt;&gt;       &lt;/stringList&gt;\n&gt;&gt;&gt;     &lt;/newObject&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;     &lt;newObject name=&quot;frontier&quot;\n&gt;&gt;&gt; class=&quot;org.archive.crawler.frontier.BdbFrontier&quot;&gt;\n&gt;&gt;&gt;       &lt;float name=&quot;delay-factor&quot;&gt;0.4&lt;/float&gt;\n&gt;&gt;&gt;       &lt;integer name=&quot;max-delay-ms&quot;&gt;50&lt;/integer&gt;\n&gt;&gt;&gt;       &lt;integer name=&quot;min-delay-ms&quot;&gt;10&lt;/integer&gt;\n&gt;&gt;&gt;       &lt;integer name=&quot;max-retries&quot;&gt;5&lt;/integer&gt;\n&gt;&gt;&gt;       &lt;long name=&quot;retry-delay-seconds&quot;&gt;15&lt;/long&gt;\n&gt;&gt;&gt;       &lt;integer name=&quot;preference-embed-hops&quot;&gt;1&lt;/integer&gt;\n&gt;&gt;&gt;       &lt;integer name=&quot;total-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt;&gt;&gt;       &lt;integer name=&quot;max-per-host-bandwidth-usage-KB-sec&quot;&gt;0&lt;/integer&gt;\n&gt;&gt;&gt;       &lt;string\n&gt;&gt;&gt;\n&gt; name=&quot;queue-assignment-policy&quot;&gt;org.archive.crawler.frontier.HostnameQueueAssignmentPolicy&lt;/string&gt;\n&gt;&gt;&gt;       &lt;string name=&quot;force-queue-assignment&quot;&gt;&lt;/string&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;pause-at-start&quot;&gt;false&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;pause-at-finish&quot;&gt;false&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;source-tag-seeds&quot;&gt;false&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;recovery-log-enabled&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;boolean name=&quot;hold-queues&quot;&gt;true&lt;/boolean&gt;\n&gt;&gt;&gt;       &lt;integer name=&quot;balance-replenish-amount&quot;&gt;3000&lt;/integer&gt;\n&gt;&gt;&gt;       &lt;integer name=&quot;error-penalty-amount&quot;&gt;100&lt;/integer&gt;\n&gt;&gt;&gt;       &lt;long name=&quot;queue-total-budget&quot;&gt;-1&lt;/long&gt;\n&gt;&gt;&gt;       &lt;string\n&gt;&gt;&gt;\n&gt; name=&quot;cost-policy&quot;&gt;org.archive.crawler.frontier.UnitCostAssignmentPolicy&lt;/string&gt;\n&gt;&gt;&gt;       &lt;long name=&quot;snooze-deactivate-ms&quot;&gt;1000&lt;/long&gt;\n&gt;&gt;&gt;       &lt;integer name=&quot;target-ready-backlog&quot;&gt;50&lt;/integer&gt;\n&gt;&gt;&gt;       &lt;string\n&gt;&gt;&gt;\n&gt; name=&quot;uri-included-structure&quot;&gt;org.archive.crawler.util.BdbUriUniqFilter&lt;/string&gt;\n&gt;&gt;&gt;     &lt;/newObject&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;       &lt;integer name=&quot;timeout-seconds&quot;&gt;10&lt;/integer&gt;\n&gt;&gt;&gt;         &lt;integer name=&quot;sotimeout-ms&quot;&gt;5000&lt;/integer&gt;\n&gt;&gt;&gt;         &lt;integer name=&quot;fetch-bandwidth&quot;&gt;0&lt;/integer&gt;\n&gt;&gt;&gt;         &lt;long name=&quot;max-length-bytes&quot;&gt;0&lt;/long&gt;\n&gt;&gt;&gt;         &lt;boolean name=&quot;ignore-cookies&quot;&gt;false&lt;/boolean&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt; --- In archive-crawler@yahoogroups.com, &quot;Bart Kiers&quot; &lt;bkiers@&gt; wrote:\n&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Hi,\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Try changing some of your frontier-settings under the &quot;settings&quot;-tab\n&gt;&gt;&gt; from\n&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; the WUI.\n&gt;&gt;&gt;&gt; Look at Heritrix&#39; manual paragraph 6.3.3: Frontier Settings:\n&gt;&gt;&gt;&gt; http://crawler.archive.org/articles/user_manual.html#settings\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; Regards,\n&gt;&gt;&gt;&gt; Bart.\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt; On 2/23/07, nt_bdr &lt;nt_bdr@&gt; wrote:\n&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;  I have heretrix set up on a dual core Linux box with 2.8Ghz\n&gt;&gt;&gt; cpu&#39;s and\n&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt; 8G memory. And the box does not have anything else running on it but\n&gt;&gt;&gt;&gt;&gt; heretrix. Heretrix is downloading pages at at very slow rate. On an\n&gt;&gt;&gt;&gt;&gt; avg 1.03 Urls/sec. I have max_toe_threads set to 100. And I normally\n&gt;&gt;&gt;&gt;&gt; see 1 or 2 threads active at any given point. I would like to\n&gt; know why\n&gt;&gt;&gt;&gt;&gt; heretrix is running so slow, and what can I do to speed it up.\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt;&gt;&gt;  \n&gt;&gt;&gt; Yahoo! Groups - Join or create groups, clubs, forums &amp;\n&gt; communities. Links\n&gt;&gt;&gt;\n&gt;&gt;&gt;\n&gt; \n&gt; \n&gt; \n&gt; \n&gt;  \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n\n"}}