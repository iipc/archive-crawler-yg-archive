{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":137285340,"authorName":"Gordon Mohr","from":"Gordon Mohr &lt;gojomo@...&gt;","profile":"gojomo","replyTo":"LIST","senderId":"e91lWE-ZQSt3VcfIexqU4WckC44Y54RzyYv3QEKsmiPtjr1r_v6b62ft00YPA37gIVK5heTtkFi-0FP0GBKPripoOVn3ZGc","spamInfo":{"isSpam":false,"reason":"6"},"subject":"Re: [archive-crawler] H3 and custom HDFSWriterProcessor : questions about checkpoint and terminate","postDate":"1265088903","msgId":6347,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDRCNjdCOTg3LjUwMjAyQGFyY2hpdmUub3JnPg==","inReplyToHeader":"PGhrNnQ5cSs4NXVkQGVHcm91cHMuY29tPg==","referencesHeader":"PGhrNnQ5cSs4NXVkQGVHcm91cHMuY29tPg=="},"prevInTopic":6345,"nextInTopic":6348,"prevInTime":6346,"nextInTime":6348,"topicId":6345,"numMessagesInTopic":9,"msgSnippet":"The HDFSWriterProcessor is an outside contribution, and in fact it appears the link from our news page to download it is broken. (Do you have a working link?) ","rawEmail":"Return-Path: &lt;gojomo@...&gt;\r\nX-Sender: gojomo@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nX-Received: (qmail 26721 invoked from network); 2 Feb 2010 05:35:26 -0000\r\nX-Received: from unknown (66.196.94.106)\n  by m13.grp.re1.yahoo.com with QMQP; 2 Feb 2010 05:35:26 -0000\r\nX-Received: from unknown (HELO relay00.pair.com) (209.68.5.9)\n  by mta2.grp.re1.yahoo.com with SMTP; 2 Feb 2010 05:35:26 -0000\r\nX-Received: (qmail 57059 invoked from network); 2 Feb 2010 05:35:04 -0000\r\nX-Received: from 70.137.148.203 (HELO ?192.168.23.128?) (70.137.148.203)\n  by relay00.pair.com with SMTP; 2 Feb 2010 05:35:04 -0000\r\nX-pair-Authenticated: 70.137.148.203\r\nMessage-ID: &lt;4B67B987.50202@...&gt;\r\nDate: Mon, 01 Feb 2010 21:35:03 -0800\r\nUser-Agent: Thunderbird 2.0.0.23 (Windows/20090812)\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;hk6t9q+85ud@...&gt;\r\nIn-Reply-To: &lt;hk6t9q+85ud@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:6:0:0:0\r\nFrom: Gordon Mohr &lt;gojomo@...&gt;\r\nSubject: Re: [archive-crawler] H3 and custom HDFSWriterProcessor : questions\n about checkpoint and terminate\r\nX-Yahoo-Group-Post: member; u=137285340; y=UHzyowfwqJV521ASFXLc1DEHzeAH-jXpk2jf_YWnKqpK\r\nX-Yahoo-Profile: gojomo\r\n\r\nThe HDFSWriterProcessor is an outside contribution, and in fact it \nappears the link from our news page to download it is broken. (Do you \nhave a working link?)\n\nWe don&#39;t currently use it but I&#39;d like to help make sure it can be \nported to H3 and work with checkpointing.\n\nSeeing the whole stack might help narrow down the source of the error.\n\nAm I correct in assuming that you have no errors when terminating a \ncrawl that hasn&#39;t been checkpointed?\n\n- Gordon @ IA\n\nbertrand.dechoux wrote:\n&gt; Hi,\n&gt; \n&gt; I am using the version 3 of heritrix and the latest version of hadoop (0.20). I have adapted the HDFSWriterProcessor with regard to the changes done in Heritrix 3. And I also have modified the information written in hadoop but that&#39;s a side story.\n&gt; \n&gt; When I create a checkpoint, everything &quot;works fine&quot; i.e. the buffer(s) -if any- are flushed and the file(s) closed. But when I terminate the crawl job, I get a java.io.InterruptedIOException inside the DFSClient class (an hadoop class).\n&gt; \n&gt; My &quot;educated guess&quot; would be that a few toes (threads) are waiting on the outputStream and that they are interupted when the frontier cleans the toes.\n&gt; \n&gt; Is that something you have already experienced? How would you fix it? Has anyone tried the original HDFSWriterProcessor and experienced the same error?\n&gt; \n&gt; Thanks in advance\n&gt; \n&gt; Bertrand\n&gt; \n&gt; \n&gt; \n&gt; ------------------------------------\n&gt; \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n\n"}}