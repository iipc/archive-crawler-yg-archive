{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":168599281,"authorName":"stack","from":"stack &lt;stack@...&gt;","profile":"stackarchiveorg","replyTo":"LIST","senderId":"4wVtD8lk2C7LaavlUiLxRJQRI3Up2mK2wH9HfGTJrPYmn-jmsXNPBk03j0Es7s-YlFgRqvBylqZB4Y1_7GZOyg","spamInfo":{"isSpam":false,"reason":"12"},"subject":"Re: [archive-crawler] Re: coordianted crawls","postDate":"1120260349","msgId":2021,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDQyQzVEMEZELjIwODAxMDVAYXJjaGl2ZS5vcmc+","inReplyToHeader":"PGRhNGZycCtibmgwQGVHcm91cHMuY29tPg==","referencesHeader":"PGRhNGZycCtibmgwQGVHcm91cHMuY29tPg=="},"prevInTopic":2018,"nextInTopic":0,"prevInTime":2020,"nextInTime":2022,"topicId":1826,"numMessagesInTopic":4,"msgSnippet":"... There is not yet an automated way of running a crawl on a cluster. We re working on it.  Meantime, in house, we ve been using the recently added","rawEmail":"Return-Path: &lt;stack@...&gt;\r\nX-Sender: stack@...\r\nX-Apparently-To: archive-crawler@yahoogroups.com\r\nReceived: (qmail 13308 invoked from network); 1 Jul 2005 23:19:54 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m29.grp.scd.yahoo.com with QMQP; 1 Jul 2005 23:19:54 -0000\r\nReceived: from unknown (HELO dns.duboce.net) (63.203.238.114)\n  by mta2.grp.scd.yahoo.com with SMTP; 1 Jul 2005 23:19:54 -0000\r\nReceived: from [192.168.1.100] ([192.168.1.100])\n\t(authenticated)\n\tby dns-eth1.duboce.net (8.10.2/8.10.2) with ESMTP id j61MN7A17827\n\tfor &lt;archive-crawler@yahoogroups.com&gt;; Fri, 1 Jul 2005 15:23:07 -0700\r\nMessage-ID: &lt;42C5D0FD.2080105@...&gt;\r\nDate: Fri, 01 Jul 2005 16:25:49 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; PPC Mac OS X Mach-O; en-US; rv:1.7.8) Gecko/20050511\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: archive-crawler@yahoogroups.com\r\nReferences: &lt;da4frp+bnh0@...&gt;\r\nIn-Reply-To: &lt;da4frp+bnh0@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 8bit\r\nX-eGroups-Msg-Info: 1:12:0\r\nFrom: stack &lt;stack@...&gt;\r\nSubject: Re: [archive-crawler] Re: coordianted crawls\r\nX-Yahoo-Group-Post: member; u=168599281; y=i1WTrZzKclHkR0GssaYhRJuqxM8j31DW7taziGfQM8XECd51iiNU1XYG\r\nX-Yahoo-Profile: stackarchiveorg\r\n\r\nvideo_guid wrote:\n\n&gt; Thanks for the response. \n&gt;\n&gt; I&#39;m trying to crawl as many english language sites as possible.  I\n&gt; have a cluster of a few machines I can dedicate to this task.  I&#39;m\n&gt; only interested in text/html pages.\n\n\nThere is not yet an automated way of running a crawl on a cluster.  \nWe&#39;re working on it.  Meantime, in house, we&#39;ve been using the recently \nadded CrawlSplitter module to divide a crawl scope between a few \nmachines.  Here&#39;s the recipe:\n\nPut the CrawlSplitter at the very head of the processing chain ahead of \nall other processors.  CrawlSplitter is then configured per machine to \nrun on a particular crawl key range (Where crawl key is effectively name \nof the queue a particular URI will occupy; crawl keys are calculated \naccording to queue assignment policy; using \nSurtAuthorityQueueAssignmentPolicy makes it easier assigning ranges \nsince the keys are effectively the domain-portion of the URI reversed).  \nAs URIs come out of the Frontier, they are tested against the \nCrawlSplitter range.  If within the range to be handled by this machine, \nthe URI is let down through the processing chain; otherwise, its \nrejected and marked with a -5002 code in the crawl log.  On a period, \nmanual processing of the crawl log extracts these -5002s and loads them \ninto the machine of the appropriate crawl range using the JMX \nimportUris.  All machines are configured to have the same scope.  Seeds \nare assigned to machines according to the key range they fit.\n\nThe above recipe quickly becomes unmanageable at anything more than 2 or \n3 machines.\n\nYou&#39;ve seen the FAQ on how to crawl text/html only?  See \nhttp://crawler.archive.org/faq.html#midfetch.\n\nSt.Ack\n\n&gt;\n&gt;   Thankx,\n&gt;   Lou\n&gt;\n&gt; --- In archive-crawler@yahoogroups.com, &quot;Kristinn Sigurdsson&quot;\n&gt; &lt;kris@a...&gt; wrote:\n&gt; &gt; About the only thing you can do is to ensure that the scopes of the\n&gt; &gt; different crawls do not overlap. This in itself can be tricky,\n&gt; depending on\n&gt; &gt; how you are defining your crawl. If you post the details of your\n&gt; crawl you\n&gt; &gt; might get some suggestion on how to split the scope.\n&gt; &gt; \n&gt; &gt; Currently, Heritrix doesn&#39;t allow for multiple machines working\n&gt; together and\n&gt; &gt; sharing information. There are plans to address this, but I believe\n&gt; that it\n&gt; &gt; is still quite some time off.\n&gt; &gt; \n&gt; &gt; - Kris\n&gt; &gt;\n&gt; &gt; -----Original Message-----\n&gt; &gt; From: archive-crawler@yahoogroups.com\n&gt; &gt; [mailto:archive-crawler@yahoogroups.com] On Behalf Of video_guid\n&gt; &gt; Sent: 11. maï¿½ 2005 16:41\n&gt; &gt; To: archive-crawler@yahoogroups.com\n&gt; &gt; Subject: [archive-crawler] coordianted crawls\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; I&#39;m interested in trying to coordinate several different crawlers\n&gt; &gt; running heritrix.  I&#39;m worried that the crawls will overlap even if\n&gt; I\n&gt; &gt; don&#39;t have the same seed files on each machine.\n&gt; &gt;\n&gt; &gt; Any suggestions on the right way to partition crawls among multiple\n&gt; &gt; heritrix crawlers?\n&gt; &gt;\n&gt; &gt;   Thankx,\n&gt; &gt;   Lou\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;\n&gt; &gt;   _____ \n&gt; &gt;\n&gt; &gt; Yahoo! Groups Links\n&gt; &gt;\n&gt; &gt;\n&gt; &gt; *      To visit your group on the web, go to:\n&gt; &gt; http://groups.yahoo.com/group/archive-crawler/\n&gt; &gt;  \n&gt; &gt;\n&gt; &gt; *      To unsubscribe from this group, send an email to:\n&gt; &gt; archive-crawler-unsubscribe@yahoogroups.com\n&gt; &gt;\n&gt; &lt;mailto:archive-crawler-unsubscribe@...\n&gt; m?subject=Unsubscribe&gt;\n&gt; &gt;  \n&gt; &gt;\n&gt; &gt; *      Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt; Service\n&gt; &gt; &lt;http://docs.yahoo.com/info/terms/&gt; .\n&gt;\n&gt;\n&gt;\n&gt; ------------------------------------------------------------------------\n&gt; YAHOO! GROUPS LINKS\n&gt;\n&gt;     *  Visit your group &quot;archive-crawler\n&gt;       &lt;http://groups.yahoo.com/group/archive-crawler&gt;&quot; on the web.\n&gt;        \n&gt;     *  To unsubscribe from this group, send an email to:\n&gt;        archive-crawler-unsubscribe@yahoogroups.com\n&gt;       &lt;mailto:archive-crawler-unsubscribe@yahoogroups.com?subject=Unsubscribe&gt;\n&gt;        \n&gt;     *  Your use of Yahoo! Groups is subject to the Yahoo! Terms of\n&gt;       Service &lt;http://docs.yahoo.com/info/terms/&gt;.\n&gt;\n&gt;\n&gt; ------------------------------------------------------------------------\n&gt;\n\n\n"}}